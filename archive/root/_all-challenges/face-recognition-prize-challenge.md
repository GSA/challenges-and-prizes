---
ideaSubmitFormInstruction: '<strong>[STEP 1] Participants read the FRPC rules:</strong> 
  Participants read the rules in full.  The FRPC rules document can be found <a href="https://s3.amazonaws.com/challenge-gov/wp-content/uploads/2017/04/IARPA_NIST_FRPC_Rules.pdf">here</a>.    <strong>[STEP
  2] Participants send documentation to NIST:</strong>  As specified in the <a href="https://s3.amazonaws.com/challenge-gov/wp-content/uploads/2017/04/IARPA_NIST_FRPC_Rules.pdf">FRPC
  Rules</a>, participants must send a completed and signed Participation Agreement
  to NIST.  The participation agreement form is available at the <a href="https://www.nist.gov/programs-projects/face-recognition-prize-challenge/">NIST
  FRPC Support Website</a>.    <strong>[STEP 3] Participants send software to NIST:</strong> 
  As specified in the <a href="https://s3.amazonaws.com/challenge-gov/wp-content/uploads/2017/04/IARPA_NIST_FRPC_Rules.pdf">FRPC
  Rules</a>, participants must send algorithms to the National Institute of Standards
  and Technology (NIST) as a compiled library.  Software is to be compatible with
  the <a href="https://www.nist.gov/sites/default/files/documents/2017/04/11/iarpa_nist_frpc_face_challenge_api_v2.pdf">NIST
  Concept of Operations and API Specification</a>.  Source code and other intellectual
  property must not be submitted to NIST.    <strong>[STEP 4] Software is run on sequestered
  images:</strong>  NIST runs the algorithm on images that are not made available
  to developers.  This creates a repeatable and fair test.  It impedes gaming strategies. 
  NIST will link submitted libraries to their test harness which is used in three
  steps:  <ul>    <li>Validation: NIST confirms it can reproduce participant-provided
  outputs on a small common set of images, provided by NIST.</li>    <li>Timing: NIST
  confirms that the implementation meets limits on computation duration.</li>    <li>Evaluation:
  NIST runs the algorithm on the test images sequestered at NIST.</li>  </ul>  <strong>[STEP
  5] NIST computes performance:</strong>  Performance refers to accuracy and speed,
  and their dependence on quantities such as enrolled population size, image properties,
  and subject demographics.    <strong>[STEP 6] NIST delivers performance report to
  IARPA and judging commences. </strong>'
startDate: '2016-07-14T00:00:00'
votingAllowed: false
newCampaign: false
status: closed
commentCount: 0
challenge-id: 891
moderatorAdminOnlyIdeasEnabled: false
funnelId: 4
ideaFromUnauthorizedMemberAllowed: true
tagline: Do you have the most accurate unconstrained face recognition algorithm?
groupName: Office of Director of National Intelligence - Intelligence Advanced Research
  Project Activity
hideIdeaAuthor: false
template: ideation
campaignAttributes:
attributes:
total-prize-awarded-cash: ''
external-url: ''
submission-end: 06/15/2017 02:00 PM
why-use-prizes: ''
submission-start: 04/21/2017 12:00 AM
fiscal-year: FY17
public-voting-end-date: ''
budget-and-resources: ''
total-prize-offered-cash: '$50,000'
campaign-owner: Dr. Chris Boehnen
public-voting-start-date: ''
legal-authority: Other
total-number-of-prizes-awarded: ''
evaluation-of-submissions: ''
agency-id: '4901'
solicitation-of-submissions: ''
total-submission-received: ''
total-number-of-participant: ''
show-winners-instead-of-prizes: 'No'
estimated-value-of-partner-contributions: ''
non-monetary-incentives-awarded: "One-to-many identification accuracy:\t\t$25,000\r\nOne-to-many
  identification speed:\t\t\t$5,000\r\nOne-to-one verification accuracy:\t\t \t$20,000"
partner-agencies-federal: ''
judging-end-date: '09/30/2017 12:00 AM'
solicitation-methods: ''
advancing-the-agency-mission: ''
rules: 'Read the full rules and challenge eligibility document for the Face Recognition
  Prize Challenge (FRPC) by downloading the PDF below:    <a href="https://s3.amazonaws.com/challenge-gov/wp-content/uploads/2017/04/IARPA_NIST_FRPC_Rules.pdf">FRPC
  Rules</a>    The full NIST Concept of Operations and API Specifications can
  be found <a href="https://www.nist.gov/sites/default/files/documents/2017/04/11/iarpa_nist_frpc_face_challenge_api_v2.pdf">here.</a>'
submission-start-date-1: ''
hide-challenge-timeline: 'No'
judging-start-date: '09/01/2017 12:00 AM'
winners-announced-date: 10/31/2017 12:00 AM
cash-prizes-and-non-cash-prize-awards: ''
campaign-owner-email: christopher.boehnen@iarpa.gov
solution-type: Software and apps
partner-agencies-non-federal: ''
original-post-id: '161485'
total-number-of-winners-awarded: ''
hosting: Hosted on this platform
hide-challenge-funnel: 'Yes'
type-of-challenge: Software and apps
participation-requirements: ''
number-of-phases: ''
how-to-enter: "<strong>[STEP 1] Participants read the FRPC rules:</strong>  Participants
  read the rules in full.  The FRPC rules document can be found <a href=\"https://s3.amazonaws.com/challenge-gov/wp-content/uploads/2017/04/IARPA_NIST_FRPC_Rules.pdf\">here</a>.\r\n\r\n<strong>[STEP
  2] Participants send documentation to NIST:</strong>  As specified in the <a
  href=\"https://s3.amazonaws.com/challenge-gov/wp-content/uploads/2017/04/IARPA_NIST_FRPC_Rules.pdf\">FRPC
  Rules</a>, participants must send a completed and signed Participation Agreement
  to NIST.  The participation agreement form is available at the <a href=\"https://www.nist.gov/programs-projects/face-recognition-prize-challenge/\">NIST
  FRPC Support Website</a>.\r\n\r\n<strong>[STEP 3] Participants send software
  to NIST:</strong>  As specified in the <a href=\"https://s3.amazonaws.com/challenge-gov/wp-content/uploads/2017/04/IARPA_NIST_FRPC_Rules.pdf\">FRPC
  Rules</a>, participants must send algorithms to the National Institute of Standards
  and Technology (NIST) as a compiled library.  Software is to be compatible with
  the <a href=\"https://www.nist.gov/sites/default/files/documents/2017/04/11/iarpa_nist_frpc_face_challenge_api_v2.pdf\">NIST
  Concept of Operations and API Specification</a>.  Source code and other intellectual
  property must not be submitted to NIST.\r\n\r\n<strong>[STEP 4] Software is
  run on sequestered images:</strong>  NIST runs the algorithm on images that
  are not made available to developers.  This creates a repeatable and fair test. 
  It impedes gaming strategies.  NIST will link submitted libraries to their test
  harness which is used in three steps:\r\n<ul>\r\n \t<li>Validation: NIST confirms
  it can reproduce participant-provided outputs on a small common set of images,
  provided by NIST.</li>\r\n \t<li>Timing: NIST confirms that the implementation
  meets limits on computation duration.</li>\r\n \t<li>Evaluation: NIST runs the
  algorithm on the test images sequestered at NIST.</li>\r\n</ul>\r\n<strong>[STEP
  5] NIST computes performance:</strong>  Performance refers to accuracy and speed,
  and their dependence on quantities such as enrolled population size, image properties,
  and subject demographics.\r\n\r\n<strong>[STEP 6] NIST delivers performance
  report to IARPA and judging commences. </strong>"
partnerships: ''
groupAttributes:
judging-criteria-description-0: 'See the FRPC Rules document for full details
  on the evaluation.  A summary of the prize judging is as follows:    The Primary
  Prize winner will be declared by considering measurements of identification
  accuracy. This will be stated as the False Negative Identification Rate (FNIR)
  measured at the lowest scalar threshold that gives a fixed False Positive Identification
  Rate (FPIR) no higher than 10^-3.    — FNIR will be measured over many mate
  searches.  FNIR is defined as the proportion of mate searches for which a correct
  mate is not returned above a threshold, T.  Mate searches are those for which
  the person in the search image has a face image in the enrolled dataset.  —
  FPIR will measured over many non-mate searches.  FPIR is defined as the proportion
  of non-mate searches that yield one or more non-mates  at or above threshold,
  T. Non-mate searches are those which the person in the search image does not
  have a face image in the enrolled dataset.     The conduct of both mate and
  non-mate searches defines an open-set, or open-universe, problem.  In the case
  of a tie in identification accuracy between two participants, the algorithm
  with the lowest median search duration will be declared the Primary Prize winner.'
judging-criteria-percentage-0: '100'
judging-criteria-0: Search Accuracy Prize (i.e., Challenge IDENT Primary Prize)
judging-criteria-description-1: 'See the FRPC Rules document for full details
  on the evaluation.  A summary of the prize judging is as follows:    The Secondary
  Prize will be awarded to the algorithm that a) has FNIR no larger than twice
  that of the Primary Prize award winner, and b) executes one-to-many template
  searches with the shortest duration.  If the Primary Prize winner’s algorithm
  is the fastest, the both prizes will be awarded to the same participant.'
judging-criteria-percentage-1: '100'
judging-criteria-1: Search Speed Prize (i.e., Challenge IDENT Secondary Prize)
judging-criteria-description-10: ''
judging-criteria-percentage-10: ''
judging-criteria-10: ''
judging-criteria-description-11: ''
judging-criteria-percentage-11: ''
judging-criteria-11: ''
judging-criteria-description-12: ''
judging-criteria-12: ''
judging-criteria-percentage-12: ''
judging-criteria-description-13: ''
judging-criteria-13: ''
judging-criteria-percentage-13: ''
judging-criteria-percentage-14: ''
judging-criteria-14: ''
judging-criteria-description-14: ''
judging-criteria-percentage-15: ''
judging-criteria-15: ''
judging-criteria-description-15: ''
judging-criteria-16: ''
judging-criteria-percentage-16: ''
judging-criteria-description-16: ''
judging-criteria-17: ''
judging-criteria-percentage-17: ''
judging-criteria-description-17: ''
judging-criteria-description-18: ''
judging-criteria-percentage-18: ''
judging-criteria-18: ''
judging-criteria-description-19: ''
judging-criteria-percentage-19: ''
judging-criteria-19: ''
judging-criteria-description-2: 'See the FRPC Rules document for full details
  on the evaluation.  A summary of the prize judging is as follows:    The winner
  will be declared by considering measurements of verification accuracy. This
  will be stated as the False Non-Match Rate (FNMR) measured at the lowest scalar
  threshold that gives a fixed False Match Rate (FMR) no higher than 10^-3.    —
  FNMR will be measured over many genuine comparison.  FNMR is defined as the
  proportion of genuine comparisons that yield a similarity score below a threshold,
  T.  — FMR will measured over many impostor comparisons.  FMR is defined as the
  proportion of impostor comparisons that yield a similarity score at or above
  threshold, T.    In the case of a tie in verification accuracy between two participants,
  the algorithm with the lowest median template generation duration will be declared
  the winner.'
judging-criteria-2: Verification Accuracy Prize (i.e., Challenge VERIF Prize)
judging-criteria-percentage-2: '100'
judging-criteria-description-3: ''
judging-criteria-3: ''
judging-criteria-percentage-3: ''
judging-criteria-percentage-4: ''
judging-criteria-4: ''
judging-criteria-description-4: ''
judging-criteria-percentage-5: ''
judging-criteria-5: ''
judging-criteria-description-5: ''
judging-criteria-6: ''
judging-criteria-percentage-6: ''
judging-criteria-description-6: ''
judging-criteria-7: ''
judging-criteria-percentage-7: ''
judging-criteria-description-7: ''
judging-criteria-description-8: ''
judging-criteria-percentage-8: ''
judging-criteria-8: ''
judging-criteria-description-9: ''
judging-criteria-percentage-9: ''
judging-criteria-9: ''
prize-description-0: The Search Accuracy Prize (i.e., Challenge IDENT Primary
  Prize) of $25,000 is awarded to the most accurate search algorithm.
prize-cash-amount-0: '25000'
prize-name-0: Search Accuracy Prize
prize-description-1: The Search Speed Prize (i.e., Challenge IDENT Secondary Prize)
  of $5,000 is awarded to the fastest search algorithm.
prize-cash-amount-1: '5000'
prize-name-1: Search Speed Prize
prize-cash-amount-10: ''
prize-name-10: ''
prize-description-10: ''
prize-cash-amount-11: ''
prize-name-11: ''
prize-description-11: ''
prize-name-12: ''
prize-cash-amount-12: ''
prize-description-12: ''
prize-name-13: ''
prize-cash-amount-13: ''
prize-description-13: ''
prize-description-14: ''
prize-cash-amount-14: ''
prize-name-14: ''
prize-description-15: ''
prize-cash-amount-15: ''
prize-name-15: ''
prize-description-16: ''
prize-name-16: ''
prize-cash-amount-16: ''
prize-description-17: ''
prize-name-17: ''
prize-cash-amount-17: ''
prize-cash-amount-18: ''
prize-name-18: ''
prize-description-18: ''
prize-description-2: The Verification Prize (i.e., Challenge VERIF Prize) of $20,000
  is awarded to the most accurate verification algorithm.
prize-name-2: Verification Prize
prize-cash-amount-2: '20000'
prize-description-3: ''
prize-name-3: ''
prize-cash-amount-3: ''
prize-cash-amount-4: ''
prize-name-4: ''
prize-description-4: ''
prize-cash-amount-5: ''
prize-name-5: ''
prize-description-5: ''
prize-name-6: ''
prize-cash-amount-6: ''
prize-description-6: ''
prize-name-7: ''
prize-cash-amount-7: ''
prize-description-7: ''
prize-description-8: ''
prize-cash-amount-8: ''
prize-name-8: ''
prize-description-9: ''
prize-cash-amount-9: ''
prize-name-9: ''
winner-solution-description-0: ''
winner-solution-link-0: ''
winner-name-0: YITU
winner-solution-title-0: ''
winner-solution-link-1: ''
winner-solution-description-1: ''
winner-name-1: NTechLab
winner-solution-title-1: ''
winner-solution-description-2: ''
winner-solution-link-2: ''
winner-solution-title-2: ''
winner-name-2: NTechLab
winner-solution-link-3: ''
winner-solution-description-3: ''
winner-solution-title-3: ''
winner-name-3: ''
winner-name-4: ''
winner-solution-title-4: ''
winner-solution-description-4: ''
winner-solution-link-4: ''
winner-name-5: ''
winner-solution-title-5: ''
winner-solution-link-5: ''
winner-solution-description-5: ''
winner-solution-title-6: ''
winner-name-6: ''
winner-solution-description-6: ''
winner-solution-link-6: ''
winner-solution-title-7: ''
winner-name-7: ''
winner-solution-link-7: ''
winner-solution-description-7: ''
winner-solution-description-8: ''
winner-solution-link-8: ''
winner-name-8: ''
winner-solution-title-8: ''
winner-solution-link-9: ''
winner-solution-description-9: ''
winner-name-9: ''
winner-solution-title-9: ''
memberIdeaSubmissionAllowed: false
showTitle: true
description: '<strong>RESULTS:</strong> A full report of participants, performance
  results, and evaluations can be found in the final <a href="http://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8197.pdf">NIST
  report</a>.    Have you developed software to identity faces in general web photographs? 
  Can your software verify that a face in one photograph is the same as in another? 
  The Intelligence Advanced Research Projects Activity (IARPA), within the Office
  of the Director of National Intelligence (ODNI), announces the launch of the Face
  Recognition Prize Challenge (FRPC). The challenge aims to improve biometric face
  recognition by improving core face recognition accuracy.    <hr />    <a name="_Toc478897250"></a><strong>Who
  We Are:</strong> IARPA focuses on high-risk, high-payoff research. The Face Recognition
  Prize Challenge will improve recognition of face images acquired without capture
  constraints (i.e., unconstrained images or images in the “wild”).    <strong>What
  We’re Doing:</strong> The goal of the Face Recognition Prize Challenge is to improve
  core face recognition accuracy and expand the breadth of capture conditions and
  environments suitable for successful face recognition.  The Challenge comes in two
  parts:  1) Face identification involves executing one-to-many search to return the
  correct entry from a gallery, if any; 2) Face verification requires the algorithm
  to match two faces of the same person while correctly rejecting faces of different
  persons.  Both tasks involve "non-cooperative" images where subjects were unaware
  of the camera or, at least, did not engage with, or pose for, the camera.    <strong>Why
  We’re Doing This:</strong>  Face recognition is hard.  Algorithms are known to commit
  both false negative and false positive errors, especially when factors such as head
  pose, illumination, and facial expression depart from formal portrait photograph
  standards.   IARPA is also aware that enormous research has been conducted in recent
  years with the advent of various deep neural network technologies.  IARPA is interested
  to know whether this rich vein of research has produced advancements in face recognition
  accuracy.    <strong>Where and When We’re Doing This:  </strong>Registration to
  join the challenge takes place through this Challenge.gov website.  From here participants
  are directed to register with the National Institute of Standards and Technology
  (NIST) <a href="https://www.nist.gov/programs-projects/face-recognition-prize-challenge/">FRPC
  Support Website</a>.  Registration closes on <strong><u>June 15, 2017. </u></strong>  <ul>    <li><strong>When
  does the FRPC launch?</strong>  April 21, 2017</li>    <li><strong>Where to learn
  about the challenge, including rules, criteria, and eligibility requirements?</strong> 
  <a href="https://s3.amazonaws.com/challenge-gov/wp-content/uploads/2017/04/IARPA_NIST_FRPC_Rules.pdf">FRPC
  rules document</a></li>    <li><strong>When does the registration and submission
  period close?</strong>  June 15, 2017</li>    <li><strong>Where do participants
  register?</strong>  <a href="https://www.nist.gov/programs-projects/face-recognition-prize-challenge/">NIST
  FRPC Support Website</a></li>    <li><strong>When do the judges meet to determine
  winners?</strong>  September, 2017</li>    <li><strong>When will the winners be
  announced?</strong>  October, 2017</li>  </ul>  The challenge proceeds with developers
  sending pre-compiled software libraries to NIST, who is the designated test laboratory
  for the FRPC.  At NIST the algorithms will be run on sequestered images.  This means
  the FRPC is not an "open-book’’ or "take-home’’ test so neither the test images,
  nor any training images will be made available to developers.    <strong>Who should
  participate:</strong>  The FRPC is intended for prize participants who are eligible
  to compete for the challenge prizes.  IARPA encourages developers of automated face
  recognition algorithms to participate, both domestic and international, from academia
  and industry.  Other U. S. Government Agencies, Federally Funded Research and Development
  Centers (FFRDCs), University Affiliated Research Centers (UARCs), or any other similar
  organizations that have a special relationship with the Government, that gives them
  access to privileged or proprietary information, or access to Government equipment
  or real property, will not be eligible to participate in the prize challenge.  Entities
  affiliated with the IARPA Janus program are ineligible to participate.    Read the
  full rules and challenge eligibility document for the FRPC by downloading <a href="https://s3.amazonaws.com/challenge-gov/wp-content/uploads/2017/04/IARPA_NIST_FRPC_Rules.pdf">this
  document</a>.    <strong>Why Participate: </strong>The developers of the most accurate
  algorithms will be eligible to win cash prizes from a total prize purse of $50,000.
  Prizes will be distributed for the following criteria:  <ul>    <li><strong>One-to-many
  identification accuracy:</strong>  $25,000</li>    <li><strong>One-to-many identification
  speed:</strong> $5,000</li>    <li><strong>One-to-one verification accuracy:</strong> 
  $20,000</li>  </ul>  <strong>Related Links:</strong>  <ul>    <li><a href="https://www.iarpa.gov/index.php/research-programs/janus">IARPA
  Janus Program</a></li>    <li><a href="https://www.nist.gov/programs-projects/face-recognition-vendor-test-frvt">NIST
  Face Recognition Vendor Test</a></li>  </ul>  For general questions: <a href="mailto:frpc@iarpa.gov"
  target="_blank" rel="noopener noreferrer">frpc@iarpa.gov</a>  For technical questions:
  <a href="mailto:frpc@nist.gov" target="_blank" rel="noopener noreferrer">frpc@nist.gov</a>'
campaignStatusName: Launched
templateId: 0
stageStatistics: []
summaryEnabled: false
voteCount: 0
ideaTabEnabledForChallenge: true
moderatorAdminOnlyIdeasNotificationEnabled: false
hideCommentAuthor: false
authorizedGroupIds: []
userSubscriptionAllowed: false
bannerImage: ''
groupId: 269
showTagline: true
challenge-title: Face Recognition Prize Challenge
privateCampaign: true
ideaCount: 0
memberIdeaAttachmentAllowed: false
authorEdit: false
permalink: "/challenge/face-recognition-prize-challenge/"
layout: json-page
---