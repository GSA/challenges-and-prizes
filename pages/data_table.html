---
permalink: /data-table/
layout: default
title: Data Table
---

<style>
    table {border-collapse:collapse; table-layout:fixed; width:310px;}
    table td {overflow:hidden; width:100px; word-wrap:break-word;}
    </style>



<script>
  $(document).ready(function() {
        $('#table_id').DataTable( {
            "scrollY": 3600,
            "scrollX": true
        } );
    } );

$('#table_id').DataTable( {
    dom: 'Bfrtip',
    buttons: [
        'copy', 'excel', 'pdf'
    ]
} );
</script>

<div class="grid-container">
<div class="grid-row grid-gap">

<div class="desktop:grid-col-12 usa-prose usa-section"> 
  

<table id="table_id" class="table table-bordered cell-border table-hover table-condensed">
<thead><tr><th title="Field #1">01_title</th>
<th title="Field #2">02_lead_sponsoring_agency</th>
<th title="Field #3">02a_authority</th>
<th title="Field #4">03_status</th>
<th title="Field #5">04_competition_goals</th>
<th title="Field #6">05_goal_types</th>
<th title="Field #7">06_justification_for_using_PC</th>
<th title="Field #8">07_cash_prize_purse</th>
<th title="Field #9">08_solicitation_of_submissions</th>
<th title="Field #10">09_solicitation_type</th>
<th title="Field #11">10_participation_requirements</th>
<th title="Field #12">11_evaluation_of_submissions</th>
<th title="Field #13">12_results</th>
<th title="Field #14">13_budget_and_resources</th>
<th title="Field #15">14_partnerships</th>
<th title="Field #16">15_advancement_of_agency_mission</th>
<th title="Field #17">16_solution_types</th>
<th title="Field #18">17_plan_for_upcoming_2_FYs</th>
</tr></thead>
<tbody><tr>
<td>National School Lunch and School Breakfast 2017 Verification Response Rate Challenge</td>
<td>Food and Nutrition Service (FNS)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>School districts approve around five million household applications for free or reduced-price school meal benefits each year. Each year, school districts are required to identify a small percentage of those applications for verification. The identified households must send proof of income so the school districts can verify the student�s eligibility status. Households that do not respond to verification are changed to paid status. We know that some households that fail to respond are eligible for benefits. Even so, many districts struggle to get even half of their households to respond, and for some it is even fewer. Other districts have identified low-cost and creative strategies that allow them to exceed 70 (and even 80 or 90) percent response rates. The Verification Response Rate Challenge was a public forum to exchange ideas on how to increase household response in the annual verification process. Through this challenge, school district and state agency staff were able to share their verification success stories and/or were encouraged to build on others� submissions with constructive feedback and suggestions.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Solve a specific problem; Engage new people and communities</td>
<td>This Challenge was intended to generate creative ideas for increasing household response to verification. The prizes were intended to be fun and to encourage friendly competition among school districts across the country. Rather than monetary prizes, challenge winners were announced at the 2017 School Nutrition Association Annual National Conference in front of their peers and other interested parties at a session devoted to the verification process.  FNS believes that the challenge model provided access to the talents of individuals that it would have been unlikely to reach through traditional methods. FNS was looking to develop a series of unique verification response solutions, which left a great deal of room for creativity.  A traditional data collection contract would have been a more expensive (the challenge incurred no cost to the government) and less efficient way to tap school districts representing different geographic locations, different student populations, and facing different challenges.</td>
<td>There were no monetary prizes for this challenge. The contest offered non-monetary recognition on the contest website and at the 2017 School Nutrition Association (SNA) annual conference in the following categories: �Potential Game Changer� (up to 3), �Popular Choice,� �Best Documented,� �Honorable Mention� (up to 2).</td>
<td>FNS worked with its Office of Chief Communications Officer (OCCO) and with the SNA to promote the challenge. OCCO used social media and press announcements while SNA reached out to its membership through its newsletter and emails. Additionally, FNS used its network of contacts with school district staff to let them know about the challenge and asked those contacts to further spread the word about the challenge. The challenge was also featured on the FNS rotating banner on its website. FNS� impression is that SNA�s communication with its members and using the network to spread the word about the challenge were the most effective methods of communication. FNS discovered that school districts developed small competitions among themselves to see which district would have the best solution. The lessons learned suggest that for this type of challenge, tapping informal networks and using personal contacts to engage school district staff were the most effective ways to publicize the challenge.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The only requirement for participation was to have an idea about how to encourage households to respond to verification. Thus while the majority of those who entered the challenge were school districts, some private individuals also submitted solutions.</td>
<td>FNS staff reviewed all of the challenge submissions to narrow the pool down to the top ten submissions. The top ten solutions were presented to the judging panel which consisted of two FNS career staff and the president of the SNA. The criteria for both reviews were the same. Each solution was judged on demonstrated effectiveness (35%), research and creativity (35%), and presentation, clarity, and persuasiveness (30%). For each solution, judges awarded up to 35 points for the strength of evidence provided in support of the solution�s impact on household response (e.g., evidence of documented changes in response rates after the district implemented its solution), 35 points for solutions that made effective use of independent research and creativity (e.g., solutions that revealed insight into the barriers to household response and offered creative approaches to overcome those barriers), and 30 points for presentation, clarity, and persuasiveness (designed specifically for untested solutions or ones where the impact on household response was difficult to prove). The two-tiered judging process proved to be effective�narrowing the pool to the top ten solutions provided for more focused judging of only the best submissions.</td>
<td>Of the 36 entries submitted between May 4 and June 15, 2017, seven prizes were awarded to five winners.</td>
<td>FNS estimates that the work to create the challenge, including developing and overseeing the challenge and writing the materials necessary for the challenge required one month of staff time (1/12 FTE). This challenge did not require a budget as all of the prizes were non-monetary and there were no third party vendors. The judging panel volunteered to judge the contest submissions, and the time allocated for the two FNS judges to review the submissions is included in the FTE estimate.</td>
<td>FNS did not partner with any outside organization. However, because the intended participants were local education agency officials who manage the school meal programs, FNS reached out to the SNA to promote the challenge.</td>
<td>School districts are actively involved in finding effective ways of getting households to respond to verification requests. This challenge provided a forum for school district staff to share their experience and expertise with other school districts in a collaborative fashion, where staff could propose ideas and those ideas could be expanded through discussion boards. The goal of this effort was to provide a number of options schools districts might use to increase their verification response rates, reduce the time and expense associated with repeat follow-up reminders to households, and reduce the risk that eligible children lose access to program benefits. FNS used the challenge format to maximize school district staff engagement and uncover the most effective solutions. It was equally important that school districts were provided with an opportunity to highlight their work. At the end of the challenge, USDA featured the winning submissions at the 2017 SNA�s Annual National Conference in Atlanta. FNS also produced a verification tool-kit that is available to all school districts nationwide that highlights practices and ideas from contest participants. Because school districts vary, the opportunity to provide a range of solutions is very important and the challenge format allowed school district staff (and others) an opportunity to participate at essentially no cost. The Agency�s mission was advanced not only through the identification of different ways to attack the problem of non-response, but also in providing an opportunity for school districts to actively participate in the identification of those solutions.</td>
<td>Creative (design &amp; multimedia); Ideas</td>
<td>The FNS office that developed this challenge is not considering additional challenges at this point (this was the second challenge run from this office). However, FNS� experiences with both challenges have been positive, and FNS may look into opportunities for future challenges.</td>
</tr>
<tr>
<td>2017 Innovations in Food and Agricultural Science and Technology (I-FAST) Prize Competition</td>
<td>National Institute of Food and Agriculture (NIFA)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>NIFA announced the I-FAST prize competition to develop and implement the Innovations in Food and Agricultural Science and Technology (I-FAST) Program. NIFA partnered with the National Science Foundation (NSF) Innovation Corps (I-Corps) to provide entrepreneurship training to NIFA grantees under this I-FAST pilot program. The goals were to identify valuable product opportunities that can emerge from NIFA-supported academic research. Selected NIFA I-FAST project teams participated in the educational programs with NSF I-Corps Program. Over a period of twelve months the NIFA-supported teams in the I-FAST program learned what is needed to achieve an economic impact with their particular innovation. The final goal of the I-FAST Competition was to facilitate technology transfer of innovations that can make an impact in the marketplace and the global economy.</td>
<td>Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>Given the length of time for this prize (one year) and the travel requirements for team members to participate in the three-day kick off and lessons-learned training by the NSF I-Corps program, a prize competition was used to facilitate the teams to complete this requirement. The teams were also required to take several trips throughout the year of the prize competition to conduct customer interviews and discover their technology�s market.</td>
<td>The total prize purse offered was $400,000, or $50,000 for up to eight teams, and the total amount awarded was $150,000, as only three teams were selected to participate in the final program. Non-monetary incentives included mentoring and training.</td>
<td>The prize competition was published on the Federal Register and also e-mailed to the agency�s listservs as a solicitation of submissions. The agency is exploring additional sources as solicitation methods to increase the pool of applicants in future competitions.</td>
<td>Email (e.g., listservs); Press release</td>
<td>The Competition had a two-phase selection process. Teams initially submitted a pre-application to the competition via www.Challenge.gov and by email to contest@nifa.usda.gov. The pre-application had to contain a three-page executive summary that described the following: Composition of the team and roles of the members proposing to undertake the commercialization feasibility research, including the entrepreneurial lead, principal investigator, and mentor; Point of contact information for all of the members; Relevant current/previous NIFA award(s) including award number, project title, and the NIFA program the award was funded under;  Brief description of the potential commercial impact and commercialization plans. From the pre-applications, NIFA conducted phone interviews and selected teams that were invited to submit full applications. From the full applications, NIFA selected the winning teams.</td>
<td>NIFA screened all entries for eligibility and completeness. Entries from teams that did not meet the eligibility requirements and/or that failed to include required submission elements were not evaluated or considered for award. Eligible and complete entries were judged by a fair and impartial panel of individuals from NIFA and NSF. The Judging Panel evaluated the pre-application to determine the following:  (1) Did the proposed technology receive past NIFA funding within the specified timeframe? (2) Did the team have the required team members and are the roles of each team member clearly described and meet the noted responsibilities? (3) Did the commercialization plan provide a good understanding of the team�s knowledge of the current state of the art and how the technology could enter into a potential market? Following the evaluation, the Judging Panel conducted a phone interview with each selected team. This emphasized the required time commitment and availability of the entire team to complete the NSF I-CORPS program during one of the fall 2018 cohorts.</td>
<td>Of the four entries submitted by 16 participants in the full application phase between September 15 and October 6, 2017, three prizes were awarded to nine winners.</td>
<td>The Small Business Innovation Research (SBIR) 3% administrative fund as authorized by Congress was used for this prize. In FY17 and FY18, $14,058 of funding and 0.25 FTEs were used each fiscal year.</td>
<td>Expertise from several members of NSF was used during the judging process of conducting phone interviews with the teams. During the required kick-off and lessons learned training, the NSF staff provided expert instructors and training modules.</td>
<td>The NIFA USDA mission is to invest in and advance agricultural research, education, and extension to solve societal challenges. As part of this mission, NIFA is charged with providing grant funding for research, education, and extension that addresses key problems of national, regional, and multi-state importance in sustaining all components of agriculture. A majority of NIFA grant funding is provided to academic institutions to focus on developing research in the areas of farm efficiency and profitability, ranching, renewable energy, forestry (both urban and agroforestry), aquaculture, rural communities and entrepreneurship, human nutrition, food safety, biotechnology, and conventional breeding. The purpose of the I-FAST Competition is to identify NIFA-funded research teams who will receive additional support, in the form of mentoring, training, and funding to accelerate the translation of knowledge derived from fundamental research into emerging products and services that can attract subsequent third-party funding. Leveraging experience and guidance from established entrepreneurs and a targeted curriculum within the NSF I-Corp program, NIFA I-FAST teams learned to identify valuable product opportunities that can emerge from NIFA supported academic research. The I-FAST competition helped create a stronger national ecosystem for innovation that couples scientific discovery with technology development to address agricultural and societal needs.</td>
<td>Software and apps; Ideas; Technology demonstration and hardware</td>
<td>The NIFA I-FAST program will be soliciting applications again for FY19 and FY20 to exhaust funds from previous years and if the SBIR 3% administrative fund is renewed by Congress.</td>
</tr>
<tr>
<td>2017 RAMP: Reusable Abstractions of Manufacturing Processes</td>
<td>National Institute of Standards and Technology (NIST)</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY17.</td>
<td>The goal of this competition was to help familiarize the research community with a recent standard for modeling manufacturing processes developed by the American Society for Testing and Materials (ASTM) E60.13 Subcommittee on Sustainable Manufacturing, to provide an opportunity for participants to put this standard into practice in modeling processes of their own interest, and to share their experiences in applying the standard across a variety of manufacturing processes. Formal methods for acquiring and exchanging information about manufacturing processes will lead to consistent characterizations and help establish a mechanism for reuse of these models. Standard methods will ensure effective communication of computational analytics and sharing of sustainability performance data. In addition, the use of a reusable standard format is expected to further the models suitable for automated inclusion in a system analysis, such as a system simulation model or an optimization program.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Advance scientific research; Engage new people and communities; Stimulate a market</td>
<td>A prize-based approach enabled NIST to attract the attention and participation of a broad group of researchers by offering a modest cash prize and the opportunity to present their entry at a technical conference. Because the entry process is simple and easy to navigate, researchers could focus their efforts solely on the technical aspects of their competition entries.</td>
<td>The total prize purse offered and total amount awarded was $3,250. Non-monetary incentives included the opportunity for finalists to present their entries to a judging panel in a session at the 2017 American Society of Mechanical Engineers (ASME) International Manufacturing Science and Engineering Conference held in Los Angeles, California. Partners of the Challenge provided award plaques and travel stipends.</td>
<td>NIST used email, Challenge.gov, the NIST website and social media to announce the 2017 ASME International Manufacturing Science and Engineering Conference. The email announcements went to people who had previously expressed an interest in Reusable Abstractions of Manufacturing Processes (RAMP), as well as to a targeted list of university professors and departments involved in manufacturing-related work.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Interactive webinar</td>
<td>The target audience for RAMP 2017 was students in engineering programs with a familiarity of manufacturing processes and interest in sustainability. To be eligible for a cash prize, the official representative (individual or team lead, in the case of a group project) had to be age 18 or older at the time of entry and a U.S. citizen or permanent resident of the United States. In the case of a private entity, the business had to be incorporated in and maintain a primary place of business in the United States or its territories. Participants could not be a Federal entity or Federal employee acting within the scope of his or her employment. Eligibility excluded NIST employees and NIST Researcher Associates as well as direct recipients of NIST funding awards to collaborate on the development of the ASTM standard E3012-16. Employees of the National Science Foundation (NSF), the ASTM, and the ASME Manufacturing Science and Engineering Conference (MSEC) Conference Organizers were excluded from participating but members of these organizations were eligible to enter.  Any other individuals or legal entities involved with the design, production, execution, distribution or evaluation of the RAMP Challenge were not eligible to participate.</td>
<td>Subject matter experts consisting of NIST staff generated a rating  on a scale of 0 to 100 and wrote a brief narrative for each entry using five equally weighted criteria: (1) Completeness: Submission follows the guidelines and includes all necessary components. All submissions must describe the approach taken to validate the work and provide both a graphical and formal representation of the Unit Manufacturing Process (UMP) information model. (2) Complexity: Model reflects the complexities of the manufacturing process, especially those which influence sustainability indicators such as energy and material consumption. (3) Clarity: Model is clear in describing the process and the process-related information. (4) Accuracy: Submission accurately models the process as shown through validation. (5) Novelty: Approach taken develops new techniques to advance model reusability or reliability. Using scores provided by the subject matter experts, the Challenge manager identified the top eight submissions. A panel of judges (four from academia, and one from industry), appointed by the Acting NIST Director, reviewed the entries and subject matter expert input. The panel of judges participated in a session at the 2017 ASME International Manufacturing Science and Engineering Conference where finalists gave a brief presentation. The judges ranked the finalists to determine winners using five weighted criteria: (1) Complexity, 10%; (2) Clarity, 10%; (3) Accuracy 35%; (4) Novelty, 35%; and (5) Presentation, 10%.</td>
<td>Of the 14 entries submitted by 32 participants between December 19, 2016 and April 17, 2017, eight prizes were awarded to eight teams, with 21 individuals total.</td>
<td>In FY17, one FTE was used to support the design and management of the Challenge. The total funding for FY17 was $4,778, which included $3,250 designated for cash prizes and $1,528 for overhead costs on cash prizes. Funds for all costs provided in the budget were appropriated funds from the FY17 NIST Scientific Research and Technical Services account.</td>
<td>The ASME hosted the final portion of the competition at its Manufacturing Science and Engineering Conference. In addition, ASME provided subject matter experts and judges for the Challenge. The NSF provided travel funding for finalists, experts, and two of the competition judges. ASTM International provided access to the standard document, funding for award plaques, and subject matter expertise. The estimated value of partner contributions is $6,500. Travel stipends contributed by NSF totaled approximately $6,000 and award plaques provided by ASTM were valued at approximately $500.</td>
<td>NIST�s mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve our quality of life. The mission includes the development and dissemination of technical standards that support industrial competitiveness, such as those developed in ASTM E60.13. The 2017 RAMP Challenge not only serves to raise awareness and application of a manufacturing standard that NIST helped develop, but it lays a foundation of knowledge to aid development, collection, and reuse of manufacturing models. Formal methods for acquiring and exchanging information about manufacturing processes will lead to consistent characterizations and help establish a collection for reuse of these models. Standard methods will ensure effective communication of computational analytics and sharing of sustainability performance data. Results of the competition assist NIST by demonstrating the use of a reusable standard format leading to models suitable for automated inclusion in a system analysis, such as a system simulation model or an optimization program.</td>
<td>Software and apps; Analytics, visualizations, algorithms; Other - Manufacturing process models conforming to ASTM E3012-16</td>
<td>NIST disseminated these sustainable manufacturing standards and hosted an additional RAMP challenge in 2018.</td>
</tr>
<tr>
<td>2018 RAMP: Reusable Abstractions of Manufacturing Processes</td>
<td>NIST</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>The goal of the competition was to help familiarize the research community with a standard for modeling manufacturing processes that was developed by the ASTM E60.13 Subcommittee on Sustainable Manufacturing. NIST led the development of this standard working in partnership with ASTM International. The challenge provided an opportunity for participants to put those standards into practice in modeling processes of their own interest, and to share their experiences in applying the standards across a variety of processes. Formal methods for acquiring and exchanging information about manufacturing processes will lead to consistent characterizations and help establish a mechanism for reuse of these models. Standard methods will ensure effective communication of computational analytics and sharing of sustainability performance data. In addition, the use of a reusable standard format is expected to further the models suitable for automated inclusion in a system analysis, such as a system simulation model or an optimization program.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Advance scientific research; Engage new people and communities; Stimulate a market</td>
<td>A prize-based approach enabled NIST to attract the attention and participation of a broad group of researchers by offering a modest cash prize and the opportunity to present their entry at a technical conference.  Because the entry process was simple and easy to navigate, researchers could focus their efforts solely on the technical aspects of their competition entries.</td>
<td>The total prize purse offered was $3,250 and the total amount awarded was $2,850. The first place winner was awarded $1,000, the second place winner was awarded $750, the third place winner was awarded $500, and three runners up received $200 each. Non-monetary incentives included the opportunity for finalists to present their entries at the co-located ASME International Manufacturing Science and Engineering Conference 2018 and the 46th North American Manufacturing Research Institution of the Society of Manufacturing Engineers (NAMRI/SME) North American Research Conference in College Station, Texas. Award plaques were provided by ASTM International, and travel stipends were offered through NSF.</td>
<td>Email, Challenge.gov, the NIST website, and social media announcements were all used to promote this competition. NIST sent email announcements to people who had previously expressed an interest in the RAMP 2017 competition and a targeted list of university professors and departments involved in manufacturing-related work. The challenge partners notified their memberships and communities using email and other tools.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Interactive webinar</td>
<td>The target audience for RAMP 2018 was students in engineering programs with a familiarity of manufacturing processes and interest in sustainability. A participant (whether an individual, team, or entity) must have registered to participate and complied with all of the requirements under section 3719 of title 15, United States Code.  The official representative (individual or team lead, in the case of a group project) had to be age 18 or older at the time of entry and a U.S. citizen or permanent resident of the U.S. or its territories. In the case of a private entity, the business had to be incorporated in and maintain a primary place of business in the U.S. or its territories. Participants could not be a Federal entity or Federal employee acting within the scope of his or her employment. Eligibility excluded NIST employees and NIST Research Associates as well as direct recipients of NIST funding awards to collaborate on the development of the ASTM standard E3012-16. Employees of the NSF, the ASTM, the ASME MSEC Organizers, and the NAMRI/SME Organizers were excluded from participating but members of ASTM, ASME and SME were eligible to enter. Any other individuals or legal entities involved with the design, production, execution, distribution or evaluation of the RAMP 2018 Challenge were not eligible to participate. Participation was subject to all U.S. Federal, State and local laws and regulations.</td>
<td>Finalists were selected by NIST subject matter experts applying five weighted criteria: (1) Completeness, 10%: Submission follows the guidelines and includes all necessary components. All submissions must describe the approach taken to validate the work and provide both a graphical and formal representation of the UMP information model. (2) Complexity, 15%: Model reflects the complexities of the manufacturing process, especially those which influence sustainability indicators such as energy and material consumption. (3) Clarity and adherence to the theme as described in the Challenge Rules, 30%: Model is clear in describing the process and the process related information and its contribution to advancing the theme. (4) Accuracy, 30%: Submission accurately models the process as shown through validation. (5) Novelty, 15%: Approach taken develops new techniques to address the theme and to advance model reusability or reliability. A panel of five judges appointed by NIST�s Director (three from academia and two from NSF) determined the winners based on review of subject matter results, accounting for 75% of the score, along with presentation clarity, content, and quality conveyed during in-person presentations at a session of the co-hosted ASME International Manufacturing Science and Engineering Conference 2018 and the 46th NAMRI/SME North American Research Conference, which accounted for 25% of the score.</td>
<td>Of the nine entries submitted by 32 participants between January 29 and April 21, 2018, six prizes were awarded to six teams, with 21 individuals total.</td>
<td>In FY18, one FTE was used to support the design and management of the Challenge, as well as to develop competition resources such as the Unit Manufacturing Process Builder, an online tool available for participants to use when creating their entries. The total funding for FY18 was $4,190, including $2,850 designated for cash prizes and $1,340 for overhead costs on cash prizes. Funds for the Challenge came from appropriated funds in the FY18 NIST Scientific Research and Technical Services account.</td>
<td>NSF, ASTM International, ASME, and SME were supporting organizations on the Challenge, contributing in a variety of ways including providing the conference room for the finalist presentations; helping to promote the Challenge through their networks; and serving as judges or providing suggestions of academic experts to serve as judges. ASTM provided plaques for the winners (approximately $500 in value) and NSF offered travel stipends to finalists (approximately $5,000 in value). The partnership was effective in reaching a broader community of solvers and bringing greater attention to the importance of technical standards.</td>
<td>NIST�s mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve our quality of life. The mission includes the development and dissemination of technical standards that support industrial competitiveness, such as those developed in ASTM E60.13. The 2018 RAMP Challenge not only serves to raise awareness and application of a manufacturing standard that NIST helped develop, but it lays a foundation of knowledge to aid development, collection, and reuse of manufacturing models.  Formal methods for acquiring and exchanging information about manufacturing processes will lead to consistent characterizations and help establish a collection for reuse of these models. Standard methods will ensure effective communication of computational analytics and sharing of sustainability performance data. Results of the competition assist NIST by demonstrating the use of a reusable standard format leading to models suitable for automated inclusion in a system analysis, such as a system simulation model or an optimization program.</td>
<td>Software and apps; Analytics, visualizations, algorithms; Other - Manufacturing process models conforming to ASTM E3012-16</td>
<td>NIST will continue to disseminate these sustainable manufacturing standards and may host additional RAMP challenges (to be determined).</td>
</tr>
<tr>
<td>Agile Robotics for Industrial Automation Competition (ARIAC)</td>
<td>NIST</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>ARIAC is a simulation-based competition designed to address a critical limitation of robots used in industrial environments: they are not as agile as they need to be. Many robots are not able to quickly detect failures or recover from those failures. They are not able to sense changes in their environment and modify their actions accordingly. The goal of ARIAC is to enable industrial robots on workshop floors to be more productive, autonomous, and responsive to the needs of shop floor workers by utilizing the latest advances in artificial intelligence and robot planning.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology</td>
<td>The prize competition allowed NIST to gain a wider range of solutions to industrial challenges for a lower cost compared to traditional mechanisms such as grants or contracts, and helped grow awareness of the NIST research program in robotic systems for manufacturing. This competition resulted in six unique approaches to solving manufacturing robotic challenges that directly addressed the pain points experienced by industry. A contract to accomplish the same task would have been much more expensive than the cash prize purse, and would not have had the same diversity of solutions.</td>
<td>The total prize purse offered and the total amount awarded was $17,500. Non-monetary incentives included paid travel expenses for the winners to attend a workshop focusing on the theme of the competition.</td>
<td>NIST solicited participation on Facebook and Twitter feeds, Challenge.gov, and relevant mailing lists. Over 50 teams registered for the competition and six teams made it to the finals.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>The target audience for ARIAC was scientists and engineers from industry and academia who are knowledgeable about robot control software. To be eligible for a cash prize, a participant�whether an individual, team, or legal entity�had to have registered to participate and complied with all of the requirements under section 3719 of title 15 United States Code. At the time of entry, the official representative (individual or team lead, in the case of a group project) had to be age 18 or older and a U.S. citizen or permanent resident of the United States or its territories. In the case of a private entity, the business had to be incorporated in and maintain a primary place of business in the United States or its territories. Participants could not be a Federal entity or Federal employee acting within the scope of his or her employment. NIST employees were not eligible to participate. In addition, interested participants who do not meet the eligibility requirements to win a prize (i.e., individuals who are neither a U.S. citizen nor a permanent resident of the United States or non-US-based entities) were encouraged to participate in the Competition. They were invited to register on the ARIAC website and download the training material. The performance obtained by these participants was displayed on the ARIAC website in the same manner as the performance obtained by participants who were eligible to win cash prizes.</td>
<td>The winners were determined by a panel of three judges (one NIST employee and two individuals from industry) appointed by the NIST Director. The following judging criteria were used: (1) Overall performance based on scoring metrics described in the official rules of the Challenge (80 points). Using automated scoring metrics, the first place entry was awarded 80 points, the second place entry was awarded 70 points, the third place entry was awarded 60 points, and so on. (2) Novelty of approach and alignment with spirit of competition (20 points). At the judges� sole discretion, up to 20 points were awarded for entries that showed novel approaches to solving the agility challenges and whose approaches were consistent with the spirit of the competition of coming up with industrially-implementable approaches that will help industry make better use of their robotic platforms. Each entry was eligible for up to 20 points, and more than one entry could receive all 20 points (or any other value). This approach of combining an automated score with one assigned by judges provided an additional mechanism to award novel approaches and was an effective structure for a successful competition that rewarded high-performing entries aligned with the goals and spirit of the competition.</td>
<td>A total of 50 teams participated in the Challenge between January 26, 2018 and May 17, 2018. Three prizes were awarded to three teams.</td>
<td>In FY18, one FTE supported the design and implementation of the Challenge. The total budget in FY18 for the Challenge was $160,270, of which $100,000 was for a contract with Open Source Robotics Foundation, $17,500 was for the prize purse, $23,500 was for travel expenses for the winners to attend a workshop, and $19,270 was for overhead costs. Funds for all costs provided in the budget were from the FY18 NIST Scientific Research and Technical Services account (appropriated funds).</td>
<td>A contract was awarded to Open Source Robotics Foundation to develop the infrastructure for the competition (e.g., building and hosting the competition�s web platform) and assist with automated scoring.</td>
<td>NIST�s mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve quality of life. NIST staff involved in this competition worked closely with industry to understand their challenges in implementing robotic systems for manufacturing applications, and built the competition around these topics. By incentivizing research teams to address these industry challenges in the competition, NIST supports the development of technology solutions to help U.S. industry become more competitive in the global market.</td>
<td>Ideas; Analytics, visualizations, algorithms; Scientific</td>
<td>NIST intends to continue its research program on measurement science and standards for robotics in manufacturing, and will use challenges as appropriate to engage the community and drive innovative solutions to research problems in this space, whether ARIAC or another similar challenge.</td>
</tr>
<tr>
<td>Federal Impact Assessment Challenge</td>
<td>NIST</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY17.</td>
<td>Despite the proliferation of Federal research and the profound effect that many federally developed technologies have on our everyday life, more effort is needed to assess the impact of these technologies. The goal of this Challenge was to advance the methods for assessing impact and provide case studies of technologies transferred from Federal laboratories. The Challenge called on researchers to analyze a federally developed technology that has been transferred to the private sector, and present the results in a paper suitable for an archival publication.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Inform and educate the public; Engage new people and communities</td>
<td>A prize competition served as an incentive for graduate students and economic researchers to focus on assessing the impact of Federal technology transfer activities. NIST determined that the offer of a modest cash prize, opportunity for the article to be published, and the simple registration and participation process would incentivize participants and allow NIST to identify a new cadre of researchers interested in technology transfer.</td>
<td>The total prize purse offered was $20,000. Non-monetary incentives included the opportunity for the winning papers to be published in the Journal of Technology Transfer. No awards were made for the Challenge because there were no eligible winners.</td>
<td>The Challenge was issued on Challenge.gov. NIST gave a presentation of the Challenge to the Interagency Working Group on Technology Transfer, which informed all Federal agencies of the Challenge. In addition, NIST issued press releases, and distributed flyers to academic institutions, research organizations, and economic conferences. NIST also made a presentation on the Challenge at the 2016 Technology Transfer Society Annual Conference at Arizona State University.</td>
<td>Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Presentation at conference</td>
<td>The target audience was economic researchers, including graduate students working on dissertations. The Federal Impact Assessment (FIA) Challenge was open to all individuals over the age of 18 who are residents of the 50 United States, the District of Columbia, Puerto Rico, the U.S. Virgin Islands, Guam, the Commonwealth of the Northern Mariana Islands, and American Samoa. In the case of private entities, either non-profit or for-profit, corporations and institutions shall have been incorporated in, and maintained, a primary place of business in the United States or its territories. An individual, whether participating singly or with a group, must be a citizen or permanent resident of the United States. Federal employees were not eligible to participate. Any individuals or legal entities that had received Federal funds for the development of any part of a submission were ineligible.  Any other individuals or legal entities involved with the design, production, execution, distribution, or evaluation of the FIA Challenge were also not eligible to participate. A participant would not be deemed ineligible because the participant consulted with Federal employees or used Federal facilities in preparing its submission to the FIA Challenge if the employees and facilities were made available to all participants on an equitable basis.</td>
<td>Three subject matter experts reviewed each submitted paper, assigning a numerical score and providing a brief assessment of how well four evaluation criteria were met: (1) description of the technology (up to 20 points); (2) description of the demand environment (up to 30 points); (3) description of methodologies used to gather and assess impact data (up to 20 points); and (4) description of the economic and/or societal impacts that resulted from the technology transferred from the Federal agency (up to 30 points). The NIST Director appointed a panel of judges to review the papers and the corresponding reviews provided by subject matter experts. The panel consisted of three individuals (all Federal employees) with broad representation of relevant areas to the Challenge. The judges evaluated each paper using three equally weighted criteria: novelty of the approach, scope of the assessment, and quality of the paper. In this Challenge, only one paper was received. According to the processes outlined in the official rules of the Challenge, the paper was reviewed by subject matter experts and the judging panel determined the paper should receive an award. However, the submitting team was later determined to be ineligible and no prize was awarded. A lesson learned was that a more focused challenge may elicit greater participation. The theme of federal impact assessment was perhaps too broad for potential solvers. In the future, NIST may focus on a specific technology area or identify some transferred technologies so that the solvers can focus on their impact assessment.</td>
<td>One entry was submitted by four participants between September 27, 2016 and May 31, 2017. No prizes were awarded.</td>
<td>In FY17, 0.5 FTE supported the design and execution of the Challenge, including addressing inquiries and conducting technical reviews of the submission.</td>
<td>The journal of Technology Transfer agreed to review the winners of the Challenge and consider them for publication in their journal.</td>
<td>NIST�s mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve quality of life. On behalf of the Department of Commerce, NIST has a unique role in promoting and reporting on the overall strength of Federal efforts in technology transfer, including delivering annual reports to the White House and Congress on the use of technology transfer by the Department of Commerce and across all agencies. The Challenge also supported a Presidential memorandum that called on Federal agencies to establish performance goals, metrics, evaluation methods, and implementation plans to improve the effectiveness of Federal technology transfer activities. The Federal Impact Assessment Challenge was designed to encourage efforts to conduct research in the area of studies that assess the impact of technologies transferred from Federal laboratories.</td>
<td>Ideas; Analytics, visualizations, algorithms; Other - Economic impact assessment</td>
<td>There is a continuing need to assess the economic impact and/or return on investment for Federal research. Future challenges are possible mechanisms to stimulate research in this area.</td>
</tr>
<tr>
<td>NIST the Future of Public Safety Technology 100K Video Series Challenge</td>
<td>NIST</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY17.</td>
<td>The goal of the Challenge was to create a series of seven videos that explain open innovation and NIST�s Public Safety Communications Research Open Innovation Accelerator program to the public, while covering each of the key public safety technology programs covered by the NIST Public Safety Research Communications (PSCR) Division. In addition to educating the audience, the videos also invited people and companies across America to participate in future crowdsourcing competitions.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>For the creation of videos, a crowdsourced prize competition provided the opportunity for more diverse submissions, in a quick timeframe. The use of traditional contractual mechanisms (e.g., contracts, grants) would have limited entries and the ability for teams to be formed through the ideation phase. A phased prize competition allowed for more submissions in the concept phase with down-selection to follow-on phases, resulting in quality, production-ready end products in a short timeframe.</td>
<td>The total prize purse offered was $100,000 and the total amount awarded was $100,000. Non-monetary incentives included access to PSCR researchers and public safety professionals during the Challenge. Winners were invited to attend the PSCR 2018 Public Safety Broadband Stakeholder Meeting.</td>
<td>NIST PSCR employed the vendor, Tongal, through the NASA Center of Excellence for Collaborative Innovation (CoECI) blanket purchase agreement. Tongal reached out to its 120,000+ members with email blasts and postings on its website and social platforms. The vendor worked with NIST PSCR to announce and promote the project on the NIST website and social media pages (Facebook and Twitter), including a direct link to Tongal�s project page. Lessons learned from the solicitation process included recognizing that crowdsourcing allowed for unique and powerful ideas; that timelines built into the process supported a quality product with oversight; that crowdsourcing allowed experts to team with new people using a collaborative website; and that social media and online communities attracted the right solvers.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>The target audience for the Challenge was video producers and cinematography artists with interest in public safety. To be eligible, individuals must have been age 13 or older at the time of entry and U.S. citizens or permanent residents of the United States. In the case of private entity, the business shall have been incorporated in, and maintained, a primary place of business in the United States or its territories. A minor (for these purposes, a person under the age of 18 years of age, or under 19 years of age if the individual is a resident in Nebraska or Alaska or under 21 years of age in Mississippi) submitting an entry for a project must have received his/her parent/legal guardian�s permission and included his/her parent/legal guardian�s name and contact information on the official entry form where indicated. Participants may not be a Federal entity or Federal employee acting within the scope of their employment. NIST Guest Researchers, as well as direct recipients of NIST funding awards through any Center for Excellence established by NIST, were also not eligible for entrance. Multiple individuals and/or legal entities may have collaborated as a group to submit a single entry, but a single individual from the group must be designated as an official representative for each entry. That designated individual was responsible for meeting all entry and evaluation requirements.</td>
<td>The vendor, Tongal, reviewed all submissions to ensure they met the minimum requirements. Then, NIST PSCR utilized three types of evaluators - subject matter experts (SMEs), public safety focus groups, and a judge, appointed by the NIST Director. The SMEs reviewed the submissions and offered their expert opinions and recommendations to the judges. The SMEs and focus groups were a hybrid of NIST researchers and active first responders; the judge was a Federal employee. During each stage (concept, pitch, and video) of the challenge, Tongal evaluated the submissions for compliance with the objectives and the official rules of the contest. After it was determined the contestant complied with the objectives and official rules, SMEs and focus groups reviewed the submissions and offered recommendations to the judge. The appointed judge had sole discretion regarding the determination of awards in accordance with the rules for the Challenge. Key lessons learned during the evaluation process were that using active first responders for reviews brought operational accuracy to the end products; the use of video experts, along with NIST staff, provided critical feedback on the quality of the end products; designing the challenge with multiple stages, phased appropriately along a condensed timeline, ensured good engagement with the contestants and review teams; and regular meetings between the SMEs and the stage 2 winner provided quality and accuracy to the end solution.</td>
<td>Of the 107 entries submitted by 200 participants, six prizes were awarded to five teams consisting of a total of 20 individuals. The Challenge was broken into four phases. Phase 1 (concept) had four winners. Phase 2 (the pitch) had one winner in which the most compelling pitch won. The winner of Phase 2 moved onto Phase 3 (pre-production) in which a script, storyboard, and headshots were submitted for approval. The winner of Phase 2 then moved onto Phase 4 (Video), in which 13 videos were created. Submissions were received between August 24, 2017 and December 22, 2017.</td>
<td>In FY17, 0.25 FTE was used to support the design and execution of the Challenge, and to manage the contract with the vendor. Excluding FTE, the total funding in FY17 was $171,600: $100,000 for the prize purse, $12,100 for overhead costs, $9,300 for travel, and $59,200 the vendor contract through NASA CoECI. In FY18, 0.10 FTE was used to close out the Challenge. Funding for the Challenge came from the Public Safety Communications Trust Fund (006-55-0513); TAFS: 13-0513 2012/2022 (for more information, see https://www.nist.gov/ctl/pscr/about-pscr).  All funding used to support this Challenge was administered by NIST PSCR and came from a special appropriation.</td>
<td>Federal partners included the National Telecommunications and Information Administration (NTIA) Institute for Telecommunication Sciences (ITS) and NTIA FirstNet. NTIA-ITS provided subject matter experts and NTIA FirstNet provided a judge for the Challenge. Collectively, Federal partners provided approximately 20 hours of expertise. Non-Federal partners came from various academic, private-sector, and public safety organizations, providing expertise in the areas of communication, public relations, marketing, law, and public safety. Collectively, non-Federal partners provided approximately 40 hours of expertise. The estimated value of all partner contributions is $6,000. For future challenges designed to supply production-ready videos, NIST PSCR recommends using a mix of consultants from various disciplines, such as, public relations, marketing, communications law, along with the true subject matter experts, the first responders.</td>
<td>NIST&#39;s mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve our quality of life. NIST�s Public Safety Communications Research Program (PSCR) drives innovation and advances public safety communication technologies through cutting-edge research and development. PSCR works directly with first responders and the solver community to address public safety�s urgent need to access the same broadband communications and state-of-the-art technologies that consumers on commercial networks now expect. The 2017 NIST The Future of Public Safety Technology 100K Video Challenge advanced NIST and NIST�s PSCR missions through the creation of videos to engage the public in solving technical, scientific, and creative problems to advance technologies that public safety workers use in their jobs.</td>
<td>Creative (design &amp; multimedia); Ideas</td>
<td>Potential topical areas for NIST PSCR prize competitions during the upcoming two fiscal years are location-based services to locate, track, and inform first responders while indoors under difficult conditions; cybersecurity and device security issues with the understanding of critical applications and user interfaces required by first responders; improving the opportunity and ease of real-time public safety communications analytics; and increased and improved user interfaces targeting the public safety community.</td>
</tr>
<tr>
<td>NIST Virtual Public Safety Test Environment Challenge</td>
<td>NIST</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY17.</td>
<td>The purpose of the Challenge was to generate ideas and designs for measurement environments that use immersive virtual reality (VR) tools in conjunction with physical spaces to simulate first responder scenarios for accurate and repeatable testing of new first responder interfaces and technologies.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>Prize competitions were selected to crowdsource and gain many ideas in a short period of time, as well as to initiate visibility and awareness for the public safety research mission. There is a lack of repeatable test environments available using virtual reality tools for first responders, which made contracting vehicles not practical. Likewise, many members of the gaming community and virtual reality design shops do not currently focus their user interfaces on first responders. Partnerships or memorandums of understanding (MOUs) with other entities were not considered as ideal. For example, the Department of Defense virtual reality prototypes/training environments do not fully reflect the requirements and have not been available to the public safety community. The prize competition also served as a preferred method to achieve NIST PSCR�s mission to work with new innovators and individuals in the communication technology communities and encourage more rapid development of technology for the public safety community.</td>
<td>The total prize purse offered was $50,000 and the total amount awarded was $50,000. Non-monetary incentives included attendance at the PSCR 2017 Public Safety Broadband Stakeholder Meeting to present their results and interact with over 500 meeting participants who represented all segments of the public safety community; and access to PSCR researchers and other challenge subject matter experts. The value of non-cash prizes awarded was $7,000.</td>
<td>The vendor, HeroX/Topcoder, advertised the Challenge on their website, their social media accounts (Facebook, LinkedIn, Goggle+, Twitter), and on Challenge.gov. HeroX used their database of 5,000 contacts based on demographics of individuals and organizations who would likely participate in the Challenge. This targeted outreach resulted in approximately 250 click-throughs to the Challenge page. The vendor also included the competition in their March and April newsletters. The vendor had 14 forum posts throughout the course of the Challenge; the 14 posts spun off five threads that included questions and clarification on the challenge scope and guidelines. Lessons learned include extensive targeted outreach was important in building the participant community; forums helped to keep participants engaged during the competition; and repeated posts in social media helped spur interest in the Challenge.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Vendor-directed outreach efforts</td>
<td>The target audience was individuals familiar with the needs of first responders and a familiarity with the capabilities of using virtual/immersive environments with physical spaces to create accurate first responder scenarios. To be eligible for the cash prizes, individuals must have been age 18 or older at the time of entry and a U.S. citizen or permanent resident of the United States, or its territories. In the case of a private entity, the business must have been incorporated in and maintained a primary place of business in the United States or its territories. Participants may not be a Federal entity or Federal employee acting within the scope of their employment. Participants, including individuals and private entities, must not have been convicted of a felony criminal violation under any Federal law within the preceding 24 months and must not have any unpaid Federal tax liability that has been assessed, for which all judicial and administrative remedies have been exhausted or have lapsed, and that is not being paid in a timely manner pursuant to an agreement with the authority responsible for collecting the tax liability. Participants must not have been suspended, debarred, or otherwise excluded from doing business with the Federal Government. Multiple individuals and/or legal entities could collaborate as a group to submit a single entry and a single individual from the group must have been designated as an official representative for each entry.</td>
<td>The vendor, HeroX, evaluated all 21 entries to ensure they met the minimum requirements. They determined that seven entries did not meet the minimum viability requirements of the Challenge. NIST PSCR utilized three types of evaluators: HeroX, subject matter experts (SMEs), and a judge. HeroX provided initial scoring and forwarded the 18 submissions with comments and scores to the NIST evaluation panel for review. The SMEs reviewed the submissions and offered their expert opinions and recommendations to the judge. The SMEs were a hybrid of NIST researchers and public technology officials; the PSCR Division Chief was appointed by the NIST Director to serve in the role of judge. PSCR evaluated the submitted documents/solutions for compliance with the objectives and the official rules of the contest. Key lessons learned during the evaluation process include public voting for the non-cash, honorable mention award was a benefit to improve crowdsourcing efforts and awareness for NIST PSCR research; the Challenge allowed NIST PSCR to launch a second VR challenge using concepts learned from this challenge; frequent feedback to contestants is crucial to maintain the lifecycle of prize competitions, government research interest, and involvement with the research topic.</td>
<td>Of the 21 entries submitted by 60 participants between March 28, 2017 and May 03, 2017, five prizes were awarded to teams.</td>
<td>In FY17, 0.25 FTE was used to support the design and execution of the Challenge. Total funding for the Challenge, excluding FTE, was $66,000: $50,000 for the prize purse, $7,000 for non-cash awards in the form of travel support, and $9,000 for overhead costs. Funding for the vendor contract through NASA CoECI totaled $47,400 and came from FY16 obligations. Funding for the Challenge came from the Public Safety Communications Trust Fund (006-55-0513); TAFS: 13-0513 2012/2022 (for more information, see https://www.nist.gov/ctl/pscr/about-pscr).  All funding used to support this challenge was administered by NIST PSCR and came from a special appropriation.</td>
<td>The Department of Homeland Security provided approximately 25 hours of subject matter expertise for the Challenge. Non-Federal partners included public safety professionals and provided approximately 15 hours of subject matter expertise. Both Federal and non-Federal partners reviewed submitted concept papers, and provided the public safety, first-responder perspective during the review process. The estimated value of all partner contributions is $3,000.</td>
<td>NIST&#39;s mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve quality of life. NIST�s PSCR Program drives innovation and advances public safety communication technologies through cutting-edge research and development. PSCR works directly with first responders and the solver community to address public safety�s urgent need to access the same broadband communications and state-of-the- art technologies that consumers on commercial networks now expect. The 2017 Virtual Public Safety Test Environment Challenge advanced NIST and NIST�s PSCR missions by involving a diverse community of virtual reality (VR) and augmented reality (AR) experts to conceptualize and produce ideas for physical measurement environments using virtual reality tools. This challenge test environment introduced new solvers�i.e. gaming industry communities, startups, and small business�to the public safety industry. The selected solutions will provide researchers with a controlled and repeatable environment for use with virtual reality tools specific to the public safety community. In addition, NIST PSCR will have increased test environments for public safety users.</td>
<td>Ideas; Technology demonstration and hardware</td>
<td>Potential topical areas for NIST PSCR prize competitions during the upcoming two fiscal years are location-based services to locate, track, and inform first responders while indoors under difficult conditions; cybersecurity and device security issues with the understanding of critical applications and user interfaces required by first responders; improving the opportunity and ease of real-time public safety communications analytics; and increased and improved user interfaces targeting the public safety community.</td>
</tr>
<tr>
<td>PerfLoc: Performance Evaluation of Smartphone Indoor Localization Apps</td>
<td>NIST</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The goal of the Challenge was to incentivize the creation of the best possible indoor localization and tracking app for Android smartphones using NIST test data. Indoor localization is the capability to determine the location of an entity to be localized (or tracked), such as a person, a robot, or some other object equipped with an appropriate electronic device. While mapping apps on today�s cellphones can provide some navigation capability, they usually rely on GPS or Wi-Fi signals and are often not very accurate, particularly in buildings and subterranean structures such as tunnels, caves, and underground mines. The goal of the Challenge was to spur the development of localization apps that can use the sensors available in a phone and the strength of other signals available, such as those from Wi-Fi access points and cellular base stations, to pinpoint a highly accurate location estimate. Localization and tracking, whether indoors or outdoors, has a wide range of applications, including emergency response and law enforcement.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology</td>
<td>The PerfLoc competition presented a daunting technical challenge to the localization and tracking community. A prize competition was used to incentivize as many solvers as possible to apply their expertise to this important technical challenge that can address needs in the public safety research communications community.</td>
<td>The total prize purse offered was $35,000 and the total amount awarded was $20,000. Non-monetary incentives included inviting finalists to the NIST campus in Gaithersburg, Maryland, to conduct live tests during the App Demo Days where the winner was determined; invitational travel funds for the winning team and the highest scoring team (not eligible for a cash prize) to showcase their results at an international conference; and attendance to the annual PSCR Public Safety Broadband Stakeholder Meeting. The value of the non-cash prize awards was $8,000.</td>
<td>The Challenge was announced through several outlets. It was posted on Challenge.gov and NIST used social media (Linked In, Facebook) to promote the Challenge. The Challenge manager shared information about the Challenge with professional colleagues at scientific meetings and through scientific societies. The PSCR program also distributed information about the Challenge. Due to the highly technical nature of the competition, these methods for outreach were effective in identifying potential solvers. NIST held a webinar to provide details about PerfLoc that included a Q&amp;A session, and the webinar was archived online.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>The target audience for the Challenge was experts in academia and the private sector with understanding of location-based sensing and tracking algorithms, and the ability to create an app using their algorithm. To be eligible for a cash prize, a participant (whether an individual, team, or legal entity) must have registered to participate and complied with all of the requirements under section 3719 of title 15 United States Code. At the time of entry, the official representative (individual or team lead) must have been 18 years of age or older and a U.S. citizen or permanent resident of the U.S. or its territories. In the case of a private entity, the business must have been incorporated in and maintained a primary place of business in the United States or its territories. Participants may not be a Federal entity or Federal employee acting within the scope of their employment. NIST employees and NIST Research Associates as well as direct recipients of NIST funding awards for NIST projects in the development of an Android app in the area of the Challenge were not eligible to participate. Any other individuals or legal entities involved with the design, production, execution, distribution, or evaluation of the PerfLoc Prize Competition were also not eligible to participate. In addition, interested participants who did not meet the eligibility requirements to win a prize (i.e., individuals who were neither a U.S. citizen nor a permanent resident of the United States or non-US-based entities) were encouraged to participate in the competition.</td>
<td>The PerfLoc Performance Evaluation Portal generated a score for each uploaded entry. An entry consisted of a set of location estimates generated by the participant�s app. The algorithm for evaluating these entries is described in detail in the official rules for the Challenge. Each entry was automatically assigned a score up to 80 points by the evaluation software, based on the methodology provided in the rules. The top three teams eligible for a cash prize were selected as finalists. Finalists were invited to the NIST campus to test their apps in live testing scenarios during App Demo Days. The winner was determined by the judge, the PSCR Director, appointed by the NIST Director. The judging criteria were as follows: (1) overall performance on the PerfLoc Performance Evaluation Portal (80 points maximum), and (2) Performance during App Demo Days at NIST, including localization accuracy and latency of the app (20 points maximum).</td>
<td>Of the 16 entries submitted by 152 participants between March 22, 2017 and January 17, 2018, one prize was awarded to one team.</td>
<td>A total of 0.75 FTE was used in FY17 and FY18 to support the technical design and supervision of the Challenge. The total funding for FY17 was $101,500. It was used to support two NIST research associates (not Federal employees) to design and implement technical aspects of the Challenge (i.e., measurements for the NIST test data, website and scoring algorithm, monitoring entries, and live testing at App Demo Days). The total funding for FY18 was $161,100. Of the total, $101,500 was to support two NIST research associates to design and implement technical aspects of the Challenge (i.e., measurements for the NIST test data, website and scoring algorithm, monitoring entries, and live testing at App Demo Days); $11,000 was for travel support for finalists to attend App Demo Days and an international conference; $25,000 was for surveying Wi-Fi access points on NIST�s Gaithersburg campus; $20,000 was for the prize purse; and $3,600 was for overhead costs. Funding for the Challenge came from the Public Safety Communications Trust Fund (006-55-0513); TAFS: 13-0513 2012/2022 (for more information, see https://www.nist.gov/ctl/pscr/about-pscr). Funding used to support this challenge (i.e., travel, surveying, and cash prize) was administered by NIST PSCR, and came from a special appropriation.</td>
<td>N/A</td>
<td>NIST&#39;s mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve quality of life. NIST�s Public Safety Communications Research Program (PSCR) drives innovation and advances public safety communication technologies through cutting-edge research and development. PSCR works directly with first responders and the solver community to address public safety�s urgent need to access the same broadband communications and state-of-the-art technologies that consumers on commercial networks now expect. PSCR has identified a portfolio of key technology areas as part of its research and development program. The PerfLoc Prize Competition supports location-based services, one of the areas, which aims to advance technologies to seamlessly locate, track, and inform first responders while operating indoors.</td>
<td>Software and apps; Analytics, visualizations, algorithms; Scientific</td>
<td>Potential topical areas for NIST PSCR prize competitions during the upcoming two fiscal years are location-based services to locate, track, and inform first responders while indoors under difficult conditions; cybersecurity and device security issues with the understanding of critical applications and user interfaces required by first responders; improving the opportunity and ease of real-time public safety communications analytics; and increased and improved user interfaces targeting the public safety community.</td>
</tr>
<tr>
<td>The Unlinkable Data Challenge: Advancing Methods in Differential Privacy</td>
<td>NIST</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18, and is underway in FY18.</td>
<td>As the industry that serves public safety moves towards advanced analytics, the sharing of datasets is necessitating the ability to quickly and properly de-identify data sets with tested, validated, high-speed algorithms to ensure the protection of personally identifiable information (PII) for both public safety personnel and individuals in the community. The purpose of the Challenge is to incentivize solvers to develop algorithms that can protect PII while maintaining a dataset�s utility, by increasing the efficiency and speed of robust data de-identification for public safety and differential privacy. The Challenge is designed to stimulate and grow the algorithm developer community and produce a viable mid-stage solution for data de-identification. Specifically, the Challenge is intended to develop enhanced versions of the multiplicative weights and exponential mechanism algorithm that will outperform the original algorithm by several orders of magnitude, to the point where the resulting algorithms will be of practical use for privacy-preserving data release.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Engage new people and communities; Stimulate a market</td>
<td>NIST opted to use prize competitions to crowdsource and gain many ideas in a short period of time, as well as to initiate visibility and awareness for the public safety research mission. For data de-identification, a prize competition was selected to quickly advance the development of algorithms to support data de-identification using differential privacy. Holding a prize competition in data science is a well-understood and effective way to crowdsource ideas and teams for solving problems. Because differential privacy is not a well-known concept or commonly tackled method to solve data de-identification, using a third party vendor to encourage involvement by new solvers outside of the academic community was important. Using a data science vendor was also valuable for outreach to the data science community and to host the coding platform on which to run the competition. Stage 2 of the Challenge requires an evaluation of the source code, which will be compiled and run on the host platform. The prize competition also served as a preferred method to achieve NIST PSCR�s mission to work with new innovators and to encourage more rapid development of data de-identification for data analysts working on public safety issues.</td>
<td>The total prize purse offered is $190,000 and the total amount awarded, to date, is $40,000. Non-monetary incentives included attendance to the PSCR 2019 Public Safety Broadband Stakeholder Meeting to present their results and interact with over 500 meeting participants who represent all segments of the public safety community; and access to NIST PSCR researchers and other challenge subject matter experts.</td>
<td>The vendor, HeroX/Topcoder, advertised this challenge on their website, their social media accounts (Facebook, LinkedIn, Goggle+, Twitter) and NIST posted information on Challenge.gov. HeroX used their database of 5,000 contacts based on demographics of individuals and organizations who would likely participate in the challenge. For stage 1 of this competition, the vendor had six forum posts and more are anticipated as the Challenge progresses.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - HeroX and TopCoder outreach efforts</td>
<td>The target audience is innovators from various industries such as data security, data analysis, privacy protection, pseudonymization, health information technology, etc. To be eligible for a cash prize, a participant (whether an individual, team, or legal entity) must have registered to participate and complied with all of the requirements under section 3719 of title 15, United States Code. At the time of entry, the official representative (individual or team lead, in the case of a group project) must have been age 18 or older and a U.S. citizen or permanent resident of the United States or its territories. In the case of a private entity, the business shall have been incorporated in and maintained a primary place of business in the United States or its territories. Participants may not be a Federal entity or Federal employee acting within the scope of their employment. NIST employees were not eligible to participate. A participant shall not be deemed ineligible because the participant consulted with Federal employees or used Federal facilities in preparing its submission to the NIST Unlinkable Data Challenge: Advancing Methods in Differential Privacy Prize Competition if the Federal employees and facilities were made available to all Participants on an equitable basis.</td>
<td>Stage 1 evaluation was completed in September 2018. The vendor, HeroX, evaluated all 11 entries to ensure they met the minimum requirements. NIST PSCR utilized three types of evaluators: vendor staff, subject matter experts (SMEs), and a judge, appointed by the NIST Director. The judge determined the winners of Stage 1. The SMEs were a hybrid of agency staff and non-Federal volunteers; the judge was a NIST employee.</td>
<td>Of the 11 (Stage 1�concept paper) entries submitted between May 1, 2018 and August 2, 2018, five prizes were awarded to three teams. Stage 2, an algorithm coding contest based on concepts from Stage 1, is planned for October 2018 through May 6, 2019.</td>
<td>In FY17, 0.1 FTE was used to support the Challenge and $637,500 was spent on the third party vendor contracted through NASA CoECI. In FY18, 0.25 FTE was used to support the Challenge. Total funding for the Challenge in FY18 was $47,380, $40,000 of which was for the prize purse, $2,500 of which was for travel support, and $4,880 of which was for overhead costs. Funding for the Challenge came from the Public Safety Communications Trust Fund (006-55-0513); TAFS: 13-0513 2012/2022 (for more information, see https://www.nist.gov/ctl/pscr/about-pscr). Funding used to support this challenge (i.e., travel, surveying, and cash prize) was administered by NIST PSCR, and came from a special appropriation.</td>
<td>The Department of Homeland Security and the U.S. Census Bureau provided subject matter experts for the Challenge. Non-Federal partners included volunteers from various academic and private-sector research organizations. They contributed approximately 80 hours for Stage 1 as subject matter experts, reviewing submitted concept papers and data sets. Non-Federal partners will provide the external expertise for differential privacy during the review process. The estimated value of all partner contributions was $8,000.</td>
<td>NIST&#39;s mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve quality of life. NIST�s Public Safety Communications Research Program (PSCR) drives innovation and advances public safety communication technologies through cutting-edge research and development. PSCR works directly with first responders and the solver community to address public safety�s urgent need to access the same broadband communications and state-of-the-art technologies that consumers on commercial networks now expect. The Unlinkable Data Challenge, Advancing Methods in Differential Privacy, aims to advance NIST and NIST�s PSCR missions by developing more advanced differential privacy methods that can substantially improve the privacy protection of a dataset while maintaining the dataset�s analytical usefulness. Advancement of differential privacy algorithms that redact personally identifiable information (PII) while retaining data utility will increase the number of available datasets for researchers who focus on public safety issues. Examples of public safety research issues are: identifying risks in aviation, identifying patterns of violence in local communities, contingency planning in disaster scenarios, and assisting in tracking contagious diseases. Developments coming out of this competition would help drive major advances in the practical applications of differential policy for public safety researchers.</td>
<td>Software and apps; Ideas; Analytics, visualizations, algorithms; Other - Concept papers</td>
<td>Potential topical areas for NIST PSCR prize competitions during the upcoming two fiscal years are location-based services to locate, track, and inform first responders while indoors under difficult conditions; cybersecurity and device security issues with the understanding of critical applications and user interfaces required by first responders; improving the opportunity and ease of real-time public safety communications analytics; and increased and improved user interfaces targeting the public safety community.</td>
</tr>
<tr>
<td>The Unmanned Aerial Systems Flight and Payload Challenge</td>
<td>NIST</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>The Challenge supports the public safety community and its stakeholders by driving innovations in unmanned aerial systems (UAS), sometimes referred to as drones. One of the barriers for UAS use in a public safety realm is payload versus flight time. Vertical takeoff and landing (VTOL) UAS provide many different mission capabilities, but their flight time is limited. The payload capacity, energy source and flight time are linked through design trade-offs that can be optimized for efficiency and flexibility. The Challenge was designed to seek maximum UAS flight time, while carrying a set payload, for a reasonably-priced UAS. The ability to stay airborne in this manner can support first responders� communication technology on the ground while they conduct their search. The advancement of UAS research will help search and rescue operations support payloads for wireless communications or other life-saving goods to save lives.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Stimulate a market</td>
<td>Existing research, development, testing and evaluation (RDT&amp;E) of UAS does not focus on the needs of first responders. New RDT&amp;E efforts on UAS were needed to adequately support first responders� needs such as long-term operation and performance in hazardous or remote environments. NIST used prize competitions to crowdsource and gain many ideas in a short period of time, as well as to increase visibility and awareness for the public safety research mission. Typical contracting vehicles, including partnerships with academic institutions, would not have provided the development and evaluation of multiple concepts, from a diverse submission audience, in a short time period. The prize competition also served as a preferred method to achieve NIST PSCR�s mission to work with new innovators and to encourage more rapid development of UAS technology for first responders.</td>
<td>The total prize purse offered was $432,000 and the total amount awarded was $250,000. Non-monetary incentives included attendance at the PSCR 2018 Public Safety Broadband Stakeholder Meeting to present results and interact with over 500 meeting participants who represent all segments of the public safety community and access to NIST PSCR researchers and other challenge subject matter experts. The value of non-cash prizes awarded was $22,000.</td>
<td>NIST PSCR advertised this challenge on their website, in their newsletter, and on LinkedIn and Facebook, and used the support of the NIST Public Affairs Office to run and monitor paid advertisements in social media (Facebook and LinkedIn). A lesson learned for this type of challenge was that paid advertisement in Facebook, targeted at persons aged 35-64, was more productive (cost per click) than the LinkedIn paid advertisement. Another suggestion was to use Meetup groups, academic groups, and other regional groups to improve participant solicitation.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Other - Paid advertisements on Facebook and LinkedIn</td>
<td>The target audience was individuals with prior experience in building drones and/or unmanned aerial systems (UAS). To be eligible for the cash prizes, each contestant or team of contestants must have included an individual 18 years of age or older at the time of entry and a U.S. citizen or permanent resident of the United States or its territories. In the case of a private entity, the business must have been incorporated in and maintained a primary place of business in the United States or its territories. Contestants may not have been a Federal entity or Federal employee acting within the scope of their employment. NIST guest researchers, as well as direct recipients of NIST funding awards through any Center of Excellence established by NIST, were eligible to enter, but were not eligible to receive cash awards.  Contestants, including individuals and private entities, must not have been convicted of a felony criminal violation under any Federal law within the preceding 24 months and must not have any unpaid Federal tax liability that has been assessed, for which all judicial and administrative remedies have been exhausted or have lapsed, and that is not being paid in a timely manner pursuant to an agreement with the authority responsible for collecting the tax liability. Contestants must not have been suspended, debarred, or otherwise excluded from doing business with the Federal Government.</td>
<td>NIST PSCR used two types of evaluators: subject matter experts (SMEs) and judges. The SMEs reviewed the submissions and offered their expert opinions and recommendations to the judges. The SMEs were a hybrid of NIST researchers, active first responders, and public technology officials. A panel of judges appointed by the NIST Director consisted of two NIST employees and an expert from academia. During each stage of the challenge, NIST PSCR evaluated the submitted documents/solutions for compliance with the objectives and the official rules of the contest. After it was determined the contestant complied with the objectives and official rules, SMEs reviewed the solutions/submissions and offered recommendations to the judges. Points were assigned to each finalist submission based on the UAS flight and payload review criteria in the rules. The judges had sole discretion regarding the determination of awards in accordance with the rules for the challenge. A key lesson learned during the evaluation process was that in the final stage of the competition, teams began sharing information and benefiting from outside help. This was particularly problematic because official contestants were the only ones allowed to enter and win, and it was unclear what results were being achieved by which officially entered teams and thereby eligible for awards based on the rules. In the future, NIST may design into the end of the challenge a collaboration day for more free-form collaboration, to determine if better performance can be achieved by collaboration versus competition between teams.</td>
<td>Of the 30 entries submitted by 55 participants between January 08, 2018 and January 29, 2018, 11 prizes were awarded. Ten teams won Stage 1 (concept paper contest), and one team won the final stage (live test and evaluation) of the Challenge.</td>
<td>One FTE was used to support the design and implementation of the Challenge; 0.25 FTE was used in FY17 and 0.75 FTE was used in FY18. The total funding, excluding FTE, for the Challenge was $402,200: $250,000 for the cash prize purse, $45,900 for materials for the live testing event, $40,700 to support travel, $39,600 for overhead costs, $22,000 for non-cash awards, and $4,000 on advertisements. Funding for the Challenge came from the Public Safety Communications Trust Fund (006-55-0513); TAFS: 13-0513 2012/2022 (for more information, see https://www.nist.gov/ctl/pscr/about-pscr). Funding used to support this challenge (i.e., travel, surveying, and cash prize) was administered by NIST PSCR, and came from a special appropriation.</td>
<td>Non-Federal partners included public safety professionals. They provided approximately 60 hours of effort as subject matter experts who reviewed concept papers and final submissions. They also provided a critical public safety professional perspective on the relevance of the solutions. Non-Federal partners also provided approximately 240 hours for set-up, monitoring, and break-down of the live test and evaluation event. The estimated value of partner contributions is $25,000. For future events like this UAV challenge, we recommend including non-public safety UAV-experienced partners in addition to the public safety UAV experts.</td>
<td>NIST&#39;s mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve quality of life. NIST�s Public Safety Communications Research Program (PSCR) drives innovation and advances public safety communication technologies through cutting-edge research and development. PSCR works directly with first responders and the solver community to address public safety�s urgent need to access the same broadband communications and state-of-the- art technologies that consumers on commercial networks now expect. The Unmanned Aerial Systems Flight and Payload Challenge advanced NIST and NIST�s PSCR missions in assessing new technologies and their ability to support field operations for first responders. One of the barriers for UAS used in a public safety realm is payload versus flight time. Vertical takeoff and landing of a UAS provides many different mission capabilities, but their flight time is limited. The payload capacity, energy source and flight time are linked through design trade-offs that can be optimized for efficiency and flexibility. With these parameters in mind, this challenge was designed to help public safety operations by keeping a UAS and its payload airborne for the longest time possible with vertical and hovering accuracy. At a cost of less than $20,000 per UAS, first responders may someday have an affordable drone in their toolkit to carry wireless networks for search and rescue operations.</td>
<td>Ideas; Technology demonstration and hardware</td>
<td>Potential topical areas for NIST PSCR prize competitions during the upcoming two fiscal years are location-based services to locate, track, and inform first responders while indoors under difficult conditions; cybersecurity and device security issues with the understanding of critical applications and user interfaces required by first responders; improving the opportunity and ease of real-time public safety communications analytics; and increased and improved user interfaces targeting the public safety community.</td>
</tr>
<tr>
<td>Virtual Reality Heads-Up Display Navigation Challenge</td>
<td>NIST</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>The Challenge was motivated by the fact that augmented and virtual reality (AR/VR) technologies allow for testing in safe, controlled, measurable, and repeatable environments for first responders. However, there is a lack of AR/VR user interfaces focused on, and that align with the specific requirements of, the public safety community. NIST PSCR needed to expand the number of prototypes in their library to effectively test and measure AR/VR user interfaces for the public safety community. The goals of the challenge were to incentivize the creation of intuitive heads-up displays (HUD) for public safety officials within a VR environment; enable NIST PSCR to use these HUDs as a tool for testing and developing virtual reality user interfaces for first responders; engage new communities and identify stakeholders for NIST PSCR�s user-interface, user-experience (UI/UX) research portfolio; and further develop HUDs with location-based capabilities in a virtual reality environment.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Engage new people and communities; Stimulate a market</td>
<td>NIST selected a prize competition mechanism because the other main mechanisms available�contracts, grants, cooperative agreements, etc.�were not applicable and/or ideal. There is a lack of commercially available AR/VR user interfaces focused on the needs of first responders, which made contracting vehicles impractical. Likewise, many members of the gaming community and virtual reality design shops do not currently have readily available user interfaces or work for which a grant or cooperative agreement would align with the objective of securing multiple user interfaces for first responders. Partnerships or MOUs with other entities were also not considered appropriate; for example, the Department of Defense virtual reality prototypes/training environments have not been available to the public safety community or fully transitioned to reflect their requirements. In addition to not having other avenues to secure the virtual reality heads-up-display prototypes, the prize competition also served as a preferred method to achieve NIST PSCR�s mission to work with new innovators and individuals in the communication technology communities to encourage more rapid development of technology for the public safety community.</td>
<td>The total prize purse offered was $125,000 and the total amount awarded was $87,500. Non-monetary incentives included attendance to the PSCR 2018 Broadband Stakeholder Meeting by the finalists to present their results and interact with over 500 meeting participants who represent all segments of the public safety community and access to NIST PSCR researchers and other challenge subject matter experts. Value of the non-cash prizes awarded was $26,500.</td>
<td>NIST PSCR advertised the Challenge on their website, LinkedIn, other social media, and their e-newsletter, and also purchased an advertisement in the monthly publication of the Virtual Reality/AR Association. Of the six prize recipients, five learned about the Challenge through the advertisement in the association newsletter, and only one of the six prize recipients saw notification of the Challenge on Challenge.gov. This served as the key lesson learned with solicitation of submissions�many of the solvers are not yet familiar with NIST or PSCR or Federal Government challenges; NIST needs to expand solicitation and communication channel beyond NIST, PSCR and Challenge.gov platforms. During the one-on-one debriefs, most of the prize winners suggested contacting applicable Meetup groups or other regional groups to advertise the challenge opportunity.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Other - Paid advertisement in Virtual Reality/AR Association�s monthly publication</td>
<td>The target solver audience was the virtual reality and software coding communities. To be eligible for the cash prizes, each contestant or team of contestants had to include an individual who was 18 years of age or older at the time of entry and a U.S. citizen or permanent resident of the United States or its territories. In the case of a private entity, the business must have been incorporated in and have maintained a primary place of business in the United States or its territories. Contestants may not have been a Federal entity or Federal employee acting within the scope of their employment.  NIST guest researchers, as well as direct recipients of NIST funding awards through any Center of Excellence established by NIST, were eligible to enter, but were not eligible to receive cash awards. Multiple individuals and/or legal entities may have collaborated as a group to submit a single entry and a single individual from the group must be designated as an official representative for each entry. That designated individual was responsible for meeting all entry and evaluation requirements.</td>
<td>NIST PSCR utilized two types of evaluators: subject matter experts (SMEs), who reviewed the submissions and offered their expert opinions and recommendations to the judges, and a panel of two judges appointed by the NIST Director. The SMEs were a hybrid of NIST researchers, active first responders, and public technology officials. Both judges were government officials. During each stage of the challenge, NIST PSCR evaluated the submitted documents/solutions for compliance with the objectives and the official rules of the contest. After it was determined the contestant complied with the objectives and official rules, the SMEs reviewed the solutions/submissions and offered recommendations to the judges. The two appointed judges had sole discretion regarding the determination of awards in accordance with the rules for the challenge. For the first time for NIST, there was a tie for first place. Though it was allowed within the rules based on the advice of legal counsel, a key lesson learned during the evaluation process was that it would have been helpful for explicit guidelines to be included in the rules with regard to ties. Another key lesson learned regarded SMEs. NIST PSCR should continue to have active members of the public safety community involved (police, fire and/or EMT). NIST PSCR should ensure that SMEs with industry or technology expertise also participate and that they understand the context and appropriate conditions unique to first responders.</td>
<td>Of the 18 entries submitted by 50 participants between January 02, 2018 and January 29, 2018, six prizes were awarded to six teams. The Challenge was broken into four stages: Stage 1 consisted of a concept paper; Stage 2 consisted of a working concept and HUD prototype; Stage 3 was a HUD prototype test; and Stage 4 was a live competition of HUD prototypes.</td>
<td>A total of 0.6 FTE was used to design and execute the Challenge (0.1 FTE was used in FY17, and 0.5 FTE was used in FY18). Total funding for the Challenge, excluding FTE, was $182,300: $87,500 for the cash prize purse, $46,500 for travel, $26,500 for non-cash awards, and $21,800 for overhead costs. Funding for the Challenge came from the Public Safety Communications Trust Fund (006-55-0513); TAFS: 13-0513 2012/2022 for more information, see https://www.nist.gov/ctl/pscr/about-pscr). Funding used to support this challenge (i.e., travel, surveying, and cash prize) was administered by NIST PSCR, and came from a special appropriation.</td>
<td>For this competition, the National Telecommunications and Information Administration�s FirstNet Authority provided approximately 20 hours for evaluating submissions. Non-Federal partners included public safety professionals and first responder organizations. They provided approximately 45 hours as subject matter experts who reviewed concept papers and final submissions and provided the critical public safety professional perspective on the relevancy of the solutions. The estimated value of partner contributions is $4,300. For any future challenges focused on user interfaces and user experiences of first responders, NIST hopes to involve collaborations/partnerships to obtain the subject matter expertise of commercial/private sector technology entities, such as hardware or software-based virtual reality/augmented reality companies. This inclusion would help further advance NIST�s mission to propel forward communication technology for first responders.</td>
<td>NIST&#39;s mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve quality of life. NIST�s Public Safety Communications Research Program (PSCR) drives innovation and advances public safety communication technologies through cutting-edge research and development (R&amp;D). PSCR works directly with first responders and the solver community to address public safety�s urgent need to access the same broadband communications and state-of-the- art technologies that consumers on commercial networks now expect. The Virtual Reality Heads-Up Display Navigation Challenge advanced NIST and NIST�s PSCR missions by involving the virtual reality design and gaming industry communities to collaborate with first responders and NIST researchers to create AR/VR user interfaces for the public safety community. The selected user interfaces can be utilized as safe, repeatable, and measurable training environments for the public safety community, meanwhile PSCR has increased its collection of public safety user interfaces to measure and test navigational and other included elements.</td>
<td>Creative (design &amp; multimedia); Technology demonstration and hardware</td>
<td>Potential topical areas for NIST PSCR prize competitions during the upcoming two fiscal years are location-based services to locate, track, and inform first responders while indoors under difficult conditions; cybersecurity and device security issues with the understanding of critical applications and user interfaces required by first responders; improving the opportunity and ease of real-time public safety communications analytics; and increased and improved user interfaces targeting the public safety community.</td>
</tr>
<tr>
<td>Cleantech University Prize (Cleantech UP)</td>
<td>DOE</td>
<td>COMPETES Authority</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>Cleantech UP was designed to inspire clean energy innovation across the country by creating businesses from best in-class technology research, while inspiring and cultivating America�s next generation of entrepreneurs to drive those businesses forward. Cleantech UP goals included: (1) catalyzing clean energy startup formation on college campuses; (2) supporting novel training and educational opportunities that equip the next generation of energy entrepreneurs and innovators across the country; (3) establishing a national-level training program and competition for America&#39;s top clean energy student entrepreneurs; and (4) creating a sustained and diverse community to support student entrepreneurs.</td>
<td>Find and highlight innovative ideas; Develop technology; Engage new people and communities</td>
<td>Business plan competitions like Cleantech UP are influential instruments of change because they mobilize participants and spur innovation to accelerate research. Aspiring student entrepreneurs often lack the business development skills, market exposure, and investor feedback they need to launch viable new businesses. Student entrepreneurship prizes are critical catalysts for early-stage company formation and serve an important role in supporting innovation. The prize incentive draws talented entrepreneurs and technology developers, and the prizes help capitalize early stage development by providing funding. However, companies that enter competitions are usually at their earliest stage of development, and many students who participate in competitions require additional business and technology commercialization training. Serving as a springboard for new ventures, Cleantech UP enabled DOE to reach a wider audience of problem solvers to identify and devise creative approaches to energy challenges and increase collaboration and partnerships with public, private, and philanthropic communities. With the ingenuity and passion of student entrepreneurs, prize competitions are catalysts for the innovation needed in the cleantech ecosystem. In such a challenging environment, prize competitions can play a key role in helping startups become successful businesses by providing mentorship from other successful entrepreneurs and industry experts, expanding their networks and opening opportunities for partnerships, and lending credibility and national exposure that can be crucial to securing additional funding or finding the right strategic relationships.</td>
<td>The total prize purse offered and awarded was $570,000. DOE directly sponsored the $50,000 prize for each of the eight regional competitions, totaling $400,000 for regional prizes. The funding was allocated through a cooperative agreement awarded in 2015. The top three teams from each of the eight regional Cleantech UP collegiate competitions were invited to compete at the National Competition. The total prize purse of the National Competition amounted to $170,000. DOE sponsored $135,000, and DoD sponsored $35,000. Non-monetary incentives included access to energy entrepreneurship and commercialization training, including instruction and guidance in preparation for the competitions and supplemental curriculum that focused on the creation and development of student businesses in cleantech, as well as one-on-one mentorship, pitch coaching, and networking opportunities.</td>
<td>To attract entrants, each region executed their own outreach strategy. Regional organizers used multiple media methods to disseminate information about the competitions. Some conducted informational webinars or held in-person networking events. The regional competitions utilized online application platforms for entrants to submit applications, such as YouNoodle or F6S.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>As a program whose goals included the development of the next generation of entrepreneurs, Cleantech UP required that students be highly involved in each competition�s management and execution. In order to participate in the Cleantech UP competitions, at least 50% of any participating team�s formal team members had to be actively enrolled in an accredited U.S. university or college. Participants were also required to present business plans at the Cleantech UP competitions. All business plan proposals were required to fall within DOE�s Office of Energy Efficiency and Renewable Energy (EERE) mission and technology portfolio.</td>
<td>A general framework for the Cleantech UP National Competition eligibility requirements and judging criteria is outlined in a policy memo that has remained constant since the program�s inception. At the regional level, each competition determines selections independently, with the guidelines instructed through the eligibility requirements developed by DOE. Independent experts hailing from multiple sectors serve as judges at the application and competition stages. At the competition stages, submissions are judged on the following components: (1) solutions/products (value proposition, market differentiation, barriers to competition, and technical feasibility), 30%; (2) go-to-market strategy (feasibility of go-to-market plan, customer access and traction, and scalability), 30%; (3) team plan (quality of business plan, commitment to enterprise, team chemistry, gaps and action plans), 20%; and (4) impact on EERE mission, 20%.</td>
<td>Cleantech UP submission dates varied across each regional competition. Submission open dates ranged between September 2017 and February 2018, and submission close dates ranged between November 2017 and March 2018. Regional competitions were held between February and May 2018, and the National Competition was held in June 2018. Of the approximately 250 team applications submitted, 107 teams participated in the eight regional competitions, and 23 teams participated in the National Competition. In total, eight regional prizes and five national prizes were awarded.</td>
<td>Funding for FY17 and FY18 was obligated in FY15. In addition, 1 full-time equivalent (FTE) employee supported the program in FY17 and FY18. To execute the regional and national competitions, DOE released a competitive solicitation to determine the administrators of the competitions in 2015. In doing so, a National Hub and eight regional competitions were established. The Cleantech UP Hub organized the annual National Competition, developed an energy entrepreneurship training program, and facilitated a learning platform for best practices in energy entrepreneurship education. Each regional organizer supported the development of teams and their training by establishing and running an annual regional competition, which included recruiting applicants, mentors, judges, and other competition partners, developing an outreach and marketing plan, and promoting the event.</td>
<td>For the regional competitions and the National Competition, the National Hub and the regional organizers partnered with a variety of private sector and non-profit organizations for in-kind support, monetary contributions, judges, facility use, and marketing and outreach. The Department of Defense (DoD) participated as a Federal partner and provided judges for the competition. Non-Federal partners included the California Institute of Technology, Carnegie Mellon University, Clean Energy Trust, Massachusetts Institute of Technology, Rice University, Rutgers University, University of California, Berkeley, University of Central Florida, and VentureWell. The DoD contributed $35,000 for a prize at the 2018 National Competition.</td>
<td>Startups and innovative technologies are critical to the growth of the clean energy economy in the United States. However, persistent gaps exist between innovative technology developers and entrepreneurs. Significant barriers in creating clean energy technology startups has led to a dearth of participants entering the energy entrepreneurship pipeline. Cleantech UP aims to inspire clean energy innovation across the country and close the existing gap in early-stage training.</td>
<td>Business plans</td>
<td>A third-party, independent impact evaluation of the Cleantech UP program is ongoing for the next two fiscal years. The evaluation will analyze commercialization outcomes and impacts, education and career trajectory outcomes and impacts, and where the most value is imparted to participants.</td>
</tr>
<tr>
<td>Solar in your Community Challenge</td>
<td>DOE</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and is underway in FY18.</td>
<td>The goal of this Challenge is to make solar significantly more accessible to low and moderate income (LMI) households, non-profits, and governmental organizations through replicable business and financial models. Through the demonstration of solar projects and programs in their communities, teams aim to design, plan, and pilot new and scalable business and financial models to overcome current market barriers that block access for these market segments. These projects and programs must directly benefit: (1) LMI households, with a minimum of 20% of the energy and benefits assigned to LMI households; or (2) non-profit organizations, state, local, or tribal governments, or community service organizations, with a minimum of 60% of the energy and benefits assigned to one of these types of entities (referred herein as �non-profits�).</td>
<td>Find and highlight innovative ideas; Inform and educate the public; Engage new people and communities; Build capacity; Stimulate a market</td>
<td>Community solar is a new method for providing individuals, businesses, and other customers without direct access to solar energy the opportunity to benefit from the technology. Community solar allows customers to purchase portions of much larger solar power plants and be credited the benefits from the solar energy generation. Community solar is enabled by rules developed at the local level and are not the same across the country; thus, the execution of a prize program allows for flexibility in the development of impactful solutions. Furthermore, a prize program allows for new and large groups of innovators to think beyond the regional level, leading to novel solutions that have the potential to improve individual communities and the nation.</td>
<td>The total prize purse offered was $3 million including $2 million of seed prizes and $1 million for final grand prizes. The total amount awarded to date was $620,000. In addition, DOE allocated $3 million in non-monetary incentives for competing participants including $10,000 technical assistance vouchers to access the consultation services of over 100 Technical Assistance (TA) providers for on-demand and specialized support services. The program obligated $3 million in prior year funds to pay for these services, but the participants have access to these services in the form of vouchers, not cash. A $1 million set aside for final grand prizes is all prior year funds. A portion of the Seed prize funds have been provided using $620,000 in prior year funding.</td>
<td>The program used a multichannel strategy to build momentum and engage a national network of innovators thinking about solar access. The strategy focused on direct engagement, partner engagement, and digital/social engagement supported by an outreach/media campaign. Direct engagement used the National Community Solar Partnership regional workshops, where the program cultivated relationships and highlighted challenges and opportunities in this area. The program also hosted a series of informational webinars and in-person presentations in industry anchor event workshops such as Solar Power International 2016. Partner engagement involved attending a dozen two-hour, in-person informational workshops organized by supporting organizations in 12 different cities. The goal of these sessions was to help teams form and inspire them to participate in the Challenge. Lastly, digital engagement included DOE�s official press release, email blasts, social media posts on  Twitter and LinkedIn, newsletter clips, and other online postings by staff and a dozen supporting organizations.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The Challenge is open to citizens or permanent residents of the United States and private or non-Federal public entities, such as townships, tribes, corporations, or other organizations, that are incorporated in and maintain a primary place of business in the United States. DOE employees, employees of sponsoring organizations, members of their immediate families (spouses, children, siblings, parents), and persons living in the same household as such persons, whether or not related, are not eligible to participate in this competition. Federal entities and Federal employees, acting within the scope of their employment, are also not eligible to participate in any portion of this competition. A participant can join the Challenge as a member of a competing team (project-focused or program- focused), or exclusively as a TA provider to help the competition teams throughout the Challenge. An individual must choose to participate as either a member of a team or a TA provider. After an individual applies to one of the two options, they permanently lose their eligibility to participate in the Challenge in any other fashion. DOE, with written approval, may allow exceptions to this rule in rare cases or due to unanticipated extenuating circumstances. For full eligibility details, visit: https://www.solarinyourcommunity.org/en/page/applying-rules-en.</td>
<td>DOE-appointed judges evaluate and score submissions based on the evaluation criteria detailed in the published rules: (1) impact, 40%; (2) innovation, 30%; and (3) team, 30%. Judges will score applications according to the criteria on a 1�5 scale. Each judge will score assigned applications independently and will recommend whether applicants should be admitted into the competition or not, and if so, whether they should receive seed awards and TA vouchers. DOE will make final selection decisions based on the final scores and may apply any of the listed program policy factors detailed in the rules.</td>
<td>Of the 201 entries submitted between November 18, 2016 and March 17, 2017, 172 membered teams participated in the Challenge. The Challenge consisted of three phases: an initial seed round phase, an 18-month performance period phase of additional seed round prizes, and a final prizes post performance period. Thirty-five individuals or organizations received seed awards based on progress, and these winners were announced April 28, 2017.</td>
<td>Funding for FY17 included $318,916 in FY17 funds along with prior year funds from FY12. Funding for FY18 was provided through regular staff salaries. In addition, two full-time equivalent (FTE) employees supported the Challenge in both fiscal years. FY17 funds are available for TA, seed funds and prize administration by a third party vendor. Of the $318,916, a total of $30,441 has been spent on prize administration. No other FY17 funds have been spent on this challenge.</td>
<td>There have been two different non-Federal prize administrators for this Challenge. The State University of New York Polytechnic Institute was in the role from April 2017 until March 2018. The International City/County Management Association has taken over the role and will remain the administrator until the end of the period of performance. The administrator manages all participant agreements and related paperwork, vouchers, and communications. In collaboration with the Solar Energy Technologies Office (SETO), the administrator also engaged with other entities and organizations to provide expertise and resources  in the TA Marketplace, where over a hundred consultants created storefronts with services they can offer to teams with TA vouchers. Additional resources available to teams were generated with partnerships with General Technical Assistance consultants, who were separate from the Marketplace, and Solar Knowledge Bootcamps, which included in-person and webinar-style courses on different topics related to community solar. The total estimated value of partner contributions was between $250,000 and $300,000.</td>
<td>The SETO goals are to reduce the costs of solar energy technologies, safely and reliably integrate solar energy into the electric grid, and increase access to solar energy for all Americans. This aligns with DOE�s mission of delivering reliable, resilient and affordable energy options to America�s citizens, businesses and other energy consumers.</td>
<td>Ideas; Business plans</td>
<td>The Challenge is expected to end by March 2019 after announcing final prize winners.</td>
</tr>
<tr>
<td>The American-Made Solar Prize</td>
<td>DOE</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18.</td>
<td>The American-Made Solar Prize is designed to accelerate and sustain American solar innovation through a series of prize competitions while developing a diverse and powerful support network, the American-Made Network, that leverages national laboratories, energy incubators, and other resources from across the United States. Through a series of three progressive contests (Ready!, Set!, Go!) that are 90 days apart, the program will incentivize the Nation�s innovators and entrepreneurs to rapidly discover, research, iterate, and deliver new solutions to market with the goal of expanding solar manufacturing in the United States. The program will also lower barriers American innovators face in reaching manufacturing scale by accelerating the cycles of learning and supporting partnerships that connect entrepreneurs to the private sector and the network of DOE�s national laboratories.</td>
<td>Find and highlight innovative ideas; Develop technology; Engage new people and communities; Build capacity; Stimulate a market</td>
<td>The Solar Prize utilizes a new program structure that is designed to strengthen and scale critical connections that accelerate and sustain American innovation through two intertwined tracks: prize competitions and the establishment of the American-Made Network. The unique American-Made Network takes a structured approach to bring diverse sources of support, such as DOE�s national laboratories, business incubators, and prototype fabrication facilities, together under one umbrella. This approach is designed to be fast, agile, flexible, scalable, and extend beyond solar to other technology domains and sectors. Instead of investing in one-of-a-kind solutions or scaling �safe-bet� approaches with dated technologies, the Solar Prize will apply a resource-multiplying approach that not only invests in multiple new innovations but also creates a foundation for expanding support for future manufacturing growth. This will simultaneously enable the rapid development of technology and strengthen critical connections for commercialization. While global competitors are spending their resources scaling legacy technology, this program develops next-generation commercially viable solutions, planting the seeds for a U.S. manufacturing renaissance.</td>
<td>The total prize purse offered is $3 million for technology development competitors. The remaining $1.5 million will be used for vouchers for competitors for use at National Laboratories and other fabrication locations and awards to members of the American-Made Network based on their engagement with winning teams. Funds have yet to be allocated to any awardees. Non-monetary incentives include dedicated support and mentorship from five members of the American-Made Network, referred to as Power Connectors, and vouchers to use at any of the DOE�s 17 national labs and qualified private facilities for qualified winners. Remaining funds allocated to this round are for administration purposes.</td>
<td>The program used a multichannel strategy to build and engage a community of solvers in the Solar Prize. The strategy focused on direct engagement, partner engagement, and digital /social engagement. Direct engagement included hosting a series of informational webinars, in-person presentations in industry anchor events such as Intersolar and key meetings (e.g DuraMat Annual Workshop), and a focus workshop during Solar Power International. Partner engagement involved members of the American Made Network, such as Cleantech San Diego, who hosted in-person, live streamed presentations to inform and support innovators in their local communities interested in competing in the Solar Prize. In addition to DOE�s official press release featuring quotes from Secretary Perry, digital engagement utilized email blasts, social media posts on Twitter and LinkedIn, newsletter clips, and other online postings by staff and a dozen members of the American Made Network. Digital engagement was supported by an outreach/media campaign led by a National Renewable Energy Lab (NREL) team for more than 60 days prior the submission deadline in October 2018. NREL staff engaged in 30-day media/outreach campaign coordinating weekly with members of the American Made Network.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Competitors are entrepreneurial individuals or teams legally residing or based in the U.S., including members of one or multiple organizations, students, university faculty members, small business owners, researchers, or anyone with the desire and drive to transform ideas to impactful realities. Individuals can compete alone or as a group. For the Ready! Contest, an individual prize competitor (who is not competing as a member of a group) must be a United States citizen or a permanent resident. A group of individuals, competing as one competitor, may win, provided that the team captain responsible for the submission is a United States citizen or a permanent resident. Private entities must be incorporated in and maintain a primary place of business in the United States. Only winners of the Ready! Contest may compete in the subsequent Set! and Go! Contests. Set! and Go! contests are not open for submissions at the time of this report.</td>
<td>For the Ready! Contest, the prize administrator screens all completed submissions and assigns subject matter expert judges to independently score the content of each submission. Judges score the submissions based on the content of a 90-second video and narrative answers to four questions about the problem, innovation, team, and plan. Judges evaluate submissions by agreeing or disagreeing with assigned 18 statements on a 1�6 scale, with 1 corresponding to �strongly disagree� and 6 corresponding to �strongly agree�. These statements are the judging criteria as described in the Solar Prize rules document published online: https://americanmadechallenges.org/American-Made_Solar_Prize_Rules.pdf. The Ready! Contest is still open for submission.</td>
<td>Ready! Contest submissions opened June 7, 2018 and closed October 5, 2018. Winners were announced in February 2019. Twenty teams were selected to compete in the Set! and Go! Contests and were awarded $50,000 each.  The teams are actively competing now and will pitch their innovations to a panel of judges at the Set! Demo Day on June 6, 2019 at Greentown Labs.  Winners of the Set! Demo Day have a chance to win up to $200,000, plus vouchers to be used at national laboratories.  All 20 teams also have the opportunity to compete at the Go! Demo Day, which will take place on September 24, 2019 at Solar Power International (SPI), with a chance to win $500,000, plus additional vouchers to be used at national laboratories. Round 2 of the Solar Prize has been announced and all new Ready! submissions are due by July 16, 2019.</td>
<td>$5.3 million in total funding was authorized, excluding DOE Federal and contractor staff. The total funding for this round of the prize was funded from prior year funds. Note FY19 funds obligated by Congress for the prize will be used on round 2 to be released later in FY19. In addition, three FTE employees support the Prize for FY18. Expenditures in FY18 have totaled $385,121 and were used as follows: $341,209 for the prize administrator (NREL), $2,303 for the web platform (HeroX), and $41,609 for payments to connectors. As noted earlier, the funds expended in FY18 were from prior years.</td>
<td>NREL was the primary non-Federal partner and served as the prize administrator. The program also established the American-Made Network, currently consisting of 90 organizations, that includes DOE�s 16 national labs and five strategic partners: Elemental Excelerator (CA, HI), Greentown Labs (MA), Nation of Makers (MD), Powerhouse (CA), and Wilton E. Scott Institute for Energy Innovation (PA). Dozens of incubators, private fabrication facilities, and industry partners constitute the remaining Network members. Partners are funded for their role by DOE, and most partner activities are underway. The list of members of the Network is online at: https://americanmadechallenges.org/network.html.</td>
<td>New energy technologies have begun to reshape the national and global energy landscape. Advanced electrification, digitization, and deployment of grid-connected distributed energy assets are changing the energy industry. The United States has been at the forefront of this transformation, and as technologies, markets, service, and capital providers have evolved over the past decade, there is a need to reinvigorate our entrepreneurs across all facets of the Nation�s energy system to rapidly compete and shape these new frontiers. The Solar Prize empowers the country�s entrepreneurs and innovators to utilize technologies and innovations developed through DOE�s early-stage research and development, ultimately bringing new American-made products to market and achieving DOE�s mission of creating and sustaining leadership in the transition to a global clean energy economy.</td>
<td>Software and apps; Ideas; Technology demonstration and hardware; Business plans; Scientific</td>
<td>The program design allows for one round to be run in a fiscal year. SETO plans to run future rounds in each of the next two fiscal years. FY19 funding was provided in FY19 Committee Language, and appropriations for FY20 are pending.</td>
</tr>
<tr>
<td>American Inventions Made Onshore (AIM Onshore)</td>
<td>DOE</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18, and is underway in FY18.</td>
<td>The American Inventions Made Onshore (AIM Onshore) is a prize competition designed to incentivize incubators, accelerators, and other intermediary organizations to help energy technology innovators close the manufacturing-readiness gap. Two critical issues prevent transformative energy technologies from being manufactured in the United States: (1) American scientists and engineers are often not taught the fundamentals of manufacturing, which can lead to errors that are prohibitively costly to correct downstream; and (2) American technology inventors and manufacturers are largely disconnected, causing many inventors to outsource their design and manufacturing to product design firms. By incentivizing intermediary organizations to provide manufacturing fundamentals training to American innovators and forge partnerships between innovators and domestic manufacturers, AIM Onshore seeks to create an interface between American innovators and manufacturers to ultimately make it easier for U.S. technologies to be manufactured domestically.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity; Stimulate a market</td>
<td>DOE�s AIM Onshore prize competition seeks creative, specific, and innovative proposals to deliver DOE�s Build4Scale manufacturing training to innovators and create partnerships between U.S. innovators and U.S. manufacturers. Successful proposals had to include a sustainable revenue model to ensure the initiative will be viable past the point of government funding. Utilizing a prize structure allows DOE to make efficient use of government resources, offer a simplified application, and utilize a pay-for-performance structure to catalyze sustainable, resource-multiplying investments by the private sector. Through AIM Onshore, hardware innovators (scientists, engineers, inventors) will receive basic manufacturing training and form partnerships with domestic manufacturers for initial production. Small and medium-sized domestic manufacturers will be able to identify new business prospects�hardware innovators developing next-generation technologies with growth potential.</td>
<td>The total prize purse offered is $950,000. Four organizations were selected for AIM Onshore�s Initial Prize ($150,000 each). After one year, the two best-performing Initial Prize winners will receive the AIM Onshore Final Prize ($250,000 for first place; $100,000 for second place).</td>
<td>The program started building and engaging the targeted audience with the roll-out of DOE�s Build4Scale training. Build4Scale offers the only online manufacturing training designed specifically for scientists and engineers developing energy hardware technology prototypes. Potential applicants had time to acquaint themselves with Build4Scale and how this resource could position them to apply for the prize. Once the prize competition was announced, DOE promoted the prize through direct engagement, engagement of the entrepreneurship community, and interagency and social media engagement. DOE engaged the challenge.gov community, the Small Business Administration, and the Commerce Department�s Manufacturing Extension Partnership Centers, amongst others. The National Renewable Energy Lab (NREL), as prize administrator, also directed an outreach campaign, as did the entities involved in developing Build4Scale.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Incubators, accelerators, universities, community and technical colleges, manufacturing institutions, and other intermediary organizations that serve hardware technology innovators were encouraged to apply for the AIM Onshore prize competition. The prize competition sought creative, specific, and innovative proposals for designing a credible plan to: (1) deliver Build4Scale training to innovators and (2) forge partnerships between innovators and domestic manufacturers. The proposal must show how the participant will execute the plan, and how (1) and (2) can be continued beyond the period of government funding via a financially sustainable revenue model, i.e. through recurring revenue streams.</td>
<td>NREL initially screened submissions for compliance with the Official Rules. The screened submissions were then separately scored on multiple criteria by a panel of judges on a scale of 0-100 points (one hundred being the highest). The average score in each criterion was computed, and the average scores were combined to compute a total score. The entries with the highest final scores were recommended for selection for the Initial Prize. For the Initial Prize, three criteria were used for scoring:  Potential for Impact (30 points); Quality of Plan (40 points); and Team Experience and Abilities (30 points). For the Final Prize, three criteria will be used for scoring: success in training innovators (30 points); success in forging partnerships between innovators and domestic manufacturers (30 points); and success in proving a viable, sustainable revenue model (40 points). Metrics of evaluation will include the depth and extent of training delivered, the number of contracts signed between innovators and domestic manufacturers, and the revenue obtained from recurring sources (i.e., non-grants) via the participant�s revenue model.</td>
<td>The submissions for the Initial Prize of AIM Onshore opened February 6, 2018 and closed April 4, 2018. The winners of the Initial Prize were announced on June 13, 2018 at the 2018 MForesight National Summit in Washington DC. Of the 20 entries submitted for the Initial Prize, four prizes were awarded. Submissions for the Final Prize opened May 30, 2019 and will close June 20, 2019. The winners of the Final Prize are expected to be announced on July 25, 2019.</td>
<td>NREL received $257,000 in FY18 to administer the award. In addition, 1.25 FTE employees support the prize for FY18.</td>
<td>NREL is the primary non-Federal partner for this prize and serves as the prize administrator.</td>
<td>AIM Onshore is part of a DOE initiative to close the gap between American innovators who develop new energy technologies and domestic manufacturers who produce them. The training equips American scientists and engineers with knowledge of basic manufacturing processes, an understanding of product design for manufacturing, and the know-how to make and evaluate manufacturing-related decisions. By requiring winners to demonstrate a sustainable revenue stream to continue providing the training, DOE is leveraging a small initial federal investment in an initiative that will ultimately be sustained by the private sector.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas; Business plans; Scientific</td>
<td>There are no current plans to run additional prizes in this space.</td>
</tr>
<tr>
<td>Saving the ??hi?a � Hawai?i�s Sacred Tree</td>
<td>Department of the Interior (DOI)</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>The Rapid �?hi�a Death (ROD) disease is an extremely serious threat to Hawai�i�s native forests, as well as the ecology, hydrology, economy, and cultures of Hawai�i. The fungal disease currently requires a $10+ million response through 2019 and could prove to be even more costly if it is not contained, eliminated, and prevented in the near future. The goal of the �?hi�a Challenge is to create new technologies to identify and eradicate the ROD disease. In particular, this challenge seeks tools and solutions to advance field-based detection of ROD in asymptomatic trees; detection of the fungus at the landscape level; and environmental pathway identification, including predictive assessment.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity; Stimulate a market</td>
<td>Limited funds require unlimited thinking. A well of unlimited thinking can be created by motivating individuals and organizations both in and outside of the traditional fungicide field to compete for these funds. Where, with a traditional grant or contract for $100,000, the Department might possibly get one or two people working on a very complex issue, with the challenge prize DOI can bring in multiple organizations who will compete both for the purse and distinction of winning the prize. Also, challenges only pay for successful performance of a task, which ensures the taxpayer only pays for results.</td>
<td>The total prize purse offered was $70,000 and the anticipated total amount awarded is $70,000. Non-monetary incentives included recognition and networking.</td>
<td>Applications will be solicited via Challenge.gov. The Department will have a better idea about the effectiveness and lessons learned after the competition has finished in FY19.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>This Challenge is being conducted by DOI under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C. � 3719) as amended by the American Innovation and Competitiveness Act of 2017 (PL-114-329). Accordingly, cash prize purse awards for this Challenge may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States.</td>
<td>A panel of experts from conservation, industry, and technological innovation sectors will judge the Challenge entries against several criteria. Primary criteria for selecting the winner(s) include scalability, ease of use, and cost efficacy. Secondary criteria include cultural acceptability, sustainability, feasibility, and expected contribution to solving the ROD problem.</td>
<td>Of the entries submitted between August 28, 2018 and April 1, 2019, one prize will be awarded.</td>
<td>Total funding for the Challenge is $100,000, all from FY18 funds. Of this, $30,000 is obligated to be used to support the contract with Conservation X Labs (CXL) to help manage the Challenge, including proper formulation of the Challenge�s public material, rules, and guidelines. In addition, the total activity will require 0.15 FTE with one-third each from the National Park Service (NPS), the National Invasive Species Council (NISC) Secretariat, and DOI. The above figures exclude any additional resources that may be obtained by CXL to support the prize activity. CXL�s interest and potential to garner additional funding to support this activity was a factor in its selection as the contractor.</td>
<td>This Challenge brings together a range of Federal, State, and private stakeholders committed to battling Rapid �?hi�a Death. Panelists on the Challenge include members of the interagency ROD working group and the outreach and education group, specifically from the NPS, the U.S. Geological Survey (USGS), the U.S. Fish and Wildlife Service(USFWS), as well as the University of Hawaii and State of Hawaii Division of Forestry. DOI is reaching out to other partners, including Office of Hawaiian Affairs and University of Hawaii to leverage its efforts to promote the Challenge and find innovative solutions to this problem.</td>
<td>This Challenge meets the following Priorities of the DOI Secretary: (1) Creating a Conservation Stewardship Legacy Second Only to Teddy Roosevelt; (2) Restoring Trust with Local Communities; and (3) Generating Additional Revenues to Support DOI and National Interests. In relation to the first Priority, four National Parks and one Fish and Wildlife Refuge are already affected by ROD. Without immediate action, the fungi has the potential to spread to the rest of the Hawaiian Islands National Parks and Refuges as well as other natural areas. In relation to the second Priority, the ROD fungi know no borders. It is through partnerships with state and local government, private entities, and the Native Hawaiian Community, that these invasive fungi can be controlled and eventually eradicated from the Hawaiian Islands. In relation to the third Priority, according to the State of Hawai�i biosecurity plan, Ko�olau Mountain Watershed on O�ahu provides $14B in economic and ecosystem services. ROD, which is currently limited to Hawai�i Island, if it migrates to O�ahu would deeply affect the Ko�olau watershed.</td>
<td>Ideas; Technology demonstration and hardware; Scientific</td>
<td>ROD and other invasive species pose some of the greatest threats to the fulfillment of the NPS mission in Hawaiian parks. The potential losses due to ROD are irreversible and will threaten our economy and way of life. There is widespread support among Hawaii�s land managers in NPS and other organizations of the threat posed by ROD, and a genuine willingness to cooperate and share information. ROD research and management is a top priority for scientists and land managers in NPS, USGS, and USFWS, and will remain so for the next decade unless a solution is found to eliminate this disease.</td>
</tr>
<tr>
<td>Arsenic Sensor � Stage 1</td>
<td>Bureau of Reclamation (USBR)</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Measuring levels of arsenic in the environment and in drinking water is important for protecting human health. Drinking water and wastewater treatment facilities are subject to arsenic regulations in order to limit human exposure and environmental contamination. While current analytical methods are suitable for ensuring regulatory compliance, there is a need for rapid, low-cost monitoring of arsenic that would benefit water treatment plant operations, wastewater monitoring, contaminated site remediation, private well owners, scientific research and other interested parties.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The total prize purse offered was $50,000. Cash prizes of $50,000 were distributed to six winning solvers as determined by the judging panel with one winner paid $10,000 by non-Federal partner, Xylem, Inc. Non-cash prize awards were not offered for this competition.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with the National Aeronautics and Space Administration (NASA) Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream Research and Development (R&amp;D) magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website. Nevertheless, submissions included all solvers regardless of whether they are U.S. citizens/entities. Meritorious submissions from non-U.S. citizens and entities, were recognized in publications issued by Reclamation announcing the results of the competition, such as press releases, as applicable.</td>
<td>The prize competition was advertised as a �Theoretical Challenge.� Submissions consisted of a written description and rationale for why the Solver believes the proposed solution would meet or exceed the criteria stated in the prize competition posting document.  Submissions were evaluated by a Judging Panel composed of scientists, engineers, and other technical subject matter experts affiliated with Federal and State entities. The Panel had consultation access to technical experts outside of their expertise, as deemed necessary, to evaluate specific submissions. The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution. The judges assessed the merits of each solution by the degree upon which they meet the technical requirements. They also assessed the feasibility, flexibility, cost, and scalability of the proposed concept. At the end of the independent judging the individual scores were tallied and combined. The Panel convened through conference to discuss the strengths and weaknesses of each submission and arrive at a consensus judges opinion. Solutions that did not meet all criteria, but were deemed novel, interesting, and potentially worth pursuing, were eligible to win a partial prize.</td>
<td>Of the 39 entries submitted by 217 participants between December 13, 2016 and March 13, 2017, five prizes were awarded to seven winners (one award paid by non-Federal partner, Xylem, Inc.).</td>
<td>In FY17, there was 0.12 FTE used. FTE reported is based on labor budget consumption during the indicated fiscal year. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment; budget consumption by prize competition vendor service occurred prior to FY17.</td>
<td>Reclamation partnered with the U.S. Environmental Protection Agency (EPA) for design and judging; the Indian Health Service for design and judging; the National Institute of Standards and Technology (NIST) for design and judging; the Agricultural Research Service for design; the U.S. Agency for International Development for design; the USGS for design and judging; and Xylem, Inc. for judging and paying a $10,000 purse award to one winner.</td>
<td>Stage 1 of the Arsenic Sensor prize competition sought concepts for rapidly, accurately, and cost-effectively measuring arsenic in water through improved sensor technologies. Current analytical methods are suitable for ensuring regulatory compliance, but there remains a need for rapid, low-cost monitoring of arsenic. The selected ideas represent a positive step forward to better understand and manage water quality, potentially opening up more usable supplies for the West and the country.</td>
<td>Ideas</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a methods for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; and in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see. For prize competitions, such as this one, where a successful system needs to solve a suite of different problems to successfully meet system requirements, a separate prize for each piece of the problem should be considered. Alternatively, Reclamation could consider a competition that focuses only on the most difficult part of the system problem.</td>
</tr>
<tr>
<td>Colorado River Basin Data Visualization</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and is underway in FY18.</td>
<td>The Bureau of Reclamation plays a significant role in managing the Colorado River Basin (CRB), including operating dams and canals to deliver water and generate power, overseeing water allocations and water use, and protecting and restoring habitat for endangered and threatened species. Management of the CRB is governed by numerous compacts, laws, court decisions and decrees, and regulatory guidelines collectively known as the �Law of the River.� Reclamation relies on a broad range of CRB data to support short-term water management and long-term planning, including data on historical, current, and projected weather and climate conditions, reservoir storage and releases, and streamflows and diversions. State and local agencies, water users, recreationists, researchers and other stakeholders and partners also rely on CRB data for a wide variety of uses. Reclamation is currently working to make CRB data open and accessible to both Reclamation and non-Reclamation users; however, better approaches to visualizing CRB data are needed to improve data exploration, analysis, interpretation, and communication by internal and external users. In particular, better visualization approaches are needed to improve understanding and communication of current and projected conditions in the basin and the water management actions that affect those conditions.The objective of the visualization tool is to support exploration and understanding of climate, hydrology, river, and reservoir conditions across the CRB, as well as how these conditions vary in space and time. The tool should also help users understand how fluctuations in river and reservoir conditions relate to user interests, such as water supply and recreation opportunities.</td>
<td>Improve government service delivery; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse was $60,000 and was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). Nine cash prizes of $60,000 were distributed to 12 winning solvers as determined by the judging panel. Non-cash prize awards were not offered for this competition.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website. Nevertheless, submissions included all solvers regardless of whether they are U.S. citizens/entities. Meritorious submissions from non-U.S. citizens and entities, were recognized in publications issued by Reclamation announcing the results of the competition, such as press releases, as applicable.</td>
<td>The prize competition was advertised as a �Theoretical Challenge.� Competitors were required to submit a written proposal including a detailed description and rationale for why the proposed solution met or exceeded the performance criteria stated in the challenge posting. Submissions were evaluated by a Judging Panel composed of scientists, engineers, and other technical subject matter experts affiliated with Federal and State entities. The Panel had consultation access to technical experts outside of their expertise, as deemed necessary, to evaluate specific submissions. The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution. The judges assessed the merits of each solution by the degree upon which they meet the technical requirements. They also assessed the feasibility, flexibility, cost, and scalability of the proposed concept. At the end of the independent judging the individual scores were tallied and combined. The Panel convened several conference calls and then attended an all-day web conference to discuss the strengths and weaknesses of each submission and arrive at a consensus judges opinion. Solutions that did not meet all criteria, but were deemed novel, interesting, and potentially worth pursuing, were eligible to win a partial prize.</td>
<td>Of the 24 entries submitted by 254 participants between September 7 and November 17, 2017, nine prizes were awarded to 12 winners.</td>
<td>In FY17 the funding was $15,134 and there was 0.59 FTE used. In FY18, the funding was $60,000 and there was 0.37 FTE used. FTE reported is based on labor budget consumption during the indicated fiscal year. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment; budget consumption by prize competition vendor service.</td>
<td>USBR partnered with USGS for design and judging; National Oceanic and Atmospheric Administration (NOAA) for design and judging; U.S. Department of Agriculture for design and judging; and International Boundary and Water Commission for design and judging.</td>
<td>Successful development of innovative, interactive, and user-driven visualizations of CRB data will facilitate improved data analysis and decision making by Reclamation and non-Reclamation users. Integrated visualization of CRB data and ancillary information will improve interpretation and understanding of basin conditions, management actions that affect those conditions, and legal and regulatory factors that influence management actions. Reclamation anticipates implementing the winning solution(s) as part of a new web-based data analysis and visualization tool; a successful solution will help to make this tool a common platform for communication and collaboration between Reclamation and CRB stakeholders and partners.</td>
<td>Analytics, visualizations, algorithms</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a method for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see. For prize competitions, such as this one, where a successful system needs to solve a suite of different problems to successfully meet system requirements, a separate prize for each piece of the problem should be considered. Alternatively, Reclamation could consider a competition that focuses only on the most difficult part of the system problem.</td>
</tr>
<tr>
<td>DataApp: A Mobile App Framework for Field Data Capture</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Data collection is fundamental to water and environmental science and management. Streamflows, reservoir elevations, and flows in canals and conduits, for example, are continuously monitored to support water management decisions ranging from real-time operations to long-term planning. Data are routinely collected to monitor infrastructure conditions and identify maintenance priorities, and a wide range of environmental data are collected to characterize habitat conditions, monitor fish and wildlife populations, and support ecosystem restoration programs.Scientists, engineers, and technicians are increasingly using mobile devices such as tablets and smartphones to record measurements, document site locations via the Global Positioning System (GPS), and take photos and notes in the field. Although numerous apps are already available to support general data collection on mobile devices, these existing apps do not provide the functionality and flexibility needed to support the broad range of current water and environmental monitoring needs. More importantly, these existing apps do not support the development, integration, and sharing of new and unique features and functions to meet the specialized needs of individual data collection scenarios and communities of practice. DataApp Challenge Stage 1 was the first stage of a planned three-stage challenge seeking development of new and improved software application (app) frameworks to support electronic data collection and capture using mobile devices (i.e., smartphones and tablets) across a diverse range of water and environmental data collection situations.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse was $30,000 and was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). Cash prizes of $30,000 were distributed to seven winning solvers as determined by the judging panel. Non-cash prize awards were not offered for this competition.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website. Nevertheless, submissions included all solvers regardless of whether they are U.S. citizens/entities. Meritorious submissions from non-U.S. citizens and entities, were recognized in publications issued by Reclamation announcing the results of the competition, such as press releases, as applicable.</td>
<td>The prize competition was advertised as an �Ideation Challenge.� Competitors were required to submit a written proposal including a detailed description and rationale for why the proposed solution met or exceeded the performance criteria stated in the Challenge posting. Submissions were evaluated by a Judging Panel composed of scientists, engineers, and other technical subject matter experts affiliated with Federal and State entities. The Panel had consultation access to technical experts outside of their expertise, as deemed necessary, to evaluate specific submissions. The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution. The judges assessed the merits of each solution by the degree upon which they meet the technical requirements. They also assessed the feasibility, flexibility, cost, and scalability of the proposed concept. At the end of the independent judging the individual scores were tallied and combined. The Panel convened several conference calls and then attended an all-day web conference to discuss the strengths and weaknesses of each submission and arrive at a consensus judges opinion. Solutions that did not meet all criteria, but were deemed novel, interesting, and potentially worth pursuing, were eligible to win a partial prize.</td>
<td>Of the 24 entries submitted by 167 participants between May 23 and July 6, 2017, prizes were awarded to seven winners.</td>
<td>For FY17, the funding was $40,000 with 0.31 FTE used. For FY18, the funding was $30,000 with 0.02 FTE used. FTE reported is based on labor budget consumption during the indicated FY. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment; budget consumption by prize competition vendor service occurred prior to FY17.</td>
<td>Partnered with the USGS for design and judging, and the NPS for judging.</td>
<td>Development of a flexible, extensible, and open source data collection app framework for GPS-enabled mobile devices will facilitate the use of mobile devices for field data collection, which in turn will improve data collection efficiency, lower data collection costs, and improve data quality, transparency, and dissemination for applications to management, decision making, and scientific discovery. Flexibility and extensibility will allow the use of mobile devices for across broader range of data collection situations, whereas use of open source software will allow data collection communities of practice to develop common protocols and standards for data collection, management, and sharing.</td>
<td>Ideas</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a method for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see. For prize competitions, such as this one, where a successful system needs to solve a suite of different problems to successfully meet system requirements, a separate prize for each piece of the problem should be considered. Alternatively, Reclamation could consider a competition that focuses only on the most difficult part of the system problem.</td>
</tr>
<tr>
<td>Detecting Leaks and Flaws in Water Pipelines - Stage 1</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>Reclamation�s water conveyance system includes over 20,000 miles of buried pipelines made of various materials including metal, plastic, concrete, and composite. Municipal water utility collaborators also have extensive transmission and distribution pipeline networks. Pipeline components, such as joints, fittings, valves, linings, and individual pipe sections are subject to leakage due to damage, corrosion, and other types of degradation. Detecting water loss from pipelines will trigger appropriate maintenance, allowing conservation of scarce water resources and more reliable service to clients. Presently, the available water pipeline leak detection techniques might be suitable for determining general system delivery information or for close evaluation of small pipeline sections, none accommodate the needs to efficiently inspect thousands of miles of pipelines and to precisely determine leak location and severity. In addition, many of the techniques are unable to inspect the pipe while it is in service (pressurized, flowing water in pipe) or cannot overcome operational complications such as limited pipe entry points, diameter changes, elevation changes, or lateral bends.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse was $75,000 and was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). Five cash prizes from the $75,000 were distributed to 12 winning solvers as determined by the judging panel. Non-cash prize awards were not offered for this competition.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website. Nevertheless, submissions included all solvers regardless of whether they are U.S. citizens/entities. Meritorious submissions from non-U.S. citizens and entities, were recognized in publications issued by Reclamation announcing the results of the competition, such as press releases, as applicable.</td>
<td>The prize competition was advertised as a �Theoretical Challenge.� Competitors were required to submit a written proposal including a detailed description and rationale for why the proposed solution met or exceeded the performance criteria stated in the Challenge posting. Submissions were evaluated by a Judging Panel composed of scientists, engineers, and other technical subject matter experts affiliated with Federal and State entities. The Panel had consultation access to technical experts outside of their expertise, as deemed necessary, to evaluate specific submissions. The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution. The judges assessed the merits of each solution by the degree upon which they meet the technical requirements. They also assessed the feasibility, flexibility, cost, and scalability of the proposed concept. At the end of the independent judging the individual scores were tallied and combined. The Panel convened several conference calls and then attended an all-day web conference to discuss the strengths and weaknesses of each submission and arrive at a consensus judges opinion. Solutions that did not meet all criteria, but were deemed novel, interesting, and potentially worth pursuing, were eligible to win a partial prize.</td>
<td>Of the 54 entries submitted by 294 participants between March 8, 2018 and May 8, 2018, prizes were awarded to five winners.</td>
<td>For FY17, the funding was $15,134 with 0.3 FTE used. For FY18, there was no monetary funding, but there were seven FTE used. FTE reported is based on labor budget consumption during the indicated FY. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment; budget consumption by prize competition vendor service.</td>
<td>The Design Team in-kind Partners were the San Diego County Water Authority, Southern Nevada Water Authority, and Isle Utilities. The Judging Team in-kind partners provided subject matter experts for the panel, and included USBR, U.S. Army Corps of Engineers (USACE), Calleguas Municipal Water District, Central Arizona Project, Denver Water, Great Lakes Water Authority, Isle Utilities, Southern Nevada Water Authority, and the San Diego County Water Authority. The estimated value of partner contributions was $30,000 in FY17 and $90,000 in FY18.</td>
<td>Reclamation seeks methods and technologies that can reliably and easily detect leaks and flaws in operating, pressurized water pipeline infrastructure regardless of size, depth of burial, pipe material or interior lining. Our primary focus is finding condition assessment solutions for 48-inch or greater pipe diameters and for steel and prestressed concrete cylinder pipe types, although solutions for all pipe types and diameters greater than 24 inches will be considered. This competition advances the agency�s mission to reliably deliver water to our clients by allowing the agency to be proactive in pipeline leak detection and repair.</td>
<td>Ideas</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a method for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see. For prize competitions, such as this one, where a successful system needs to solve a suite of different problems to successfully meet system requirements, a separate prize for each piece of the problem should be considered. Alternatively, Reclamation could consider a competition that focuses only on the most difficult part of the system problem.</td>
</tr>
<tr>
<td>Detecting the Movement of Soils (Internal Erosion) Within Earthen Dams, Canals, Levees and their Foundations</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The quality of life for many people around the globe depends on water storage behind earthen dams, water movement within earthen canals, and flood-protection behind levees. However, earthen dams, canals and levees are prone to internal erosion of soils caused by seepage, either through or under the structures. The internal erosion process is largely invisible as it occurs below the ground surface. By the time visible signs are present, damage has likely occurred to the structure that will require mitigation or repair. Earlier detection is required to increase the time available to intervene, and to decrease the extent and cost of repairs.While there are a number of specific erosion mechanisms, they all share a common feature: the erosion results in the movement of soils from an initiation point to an exit point. The distance from the initiation point to the exit point can be as small as a few meters, or as large as hundreds of meters. If soil movement can be detected earlier, problems can be corrected and damage avoided. The Bureau of Reclamation, in collaboration with the U.S. Army Corps of Engineers, is seeking new methods for detecting the movement (erosion) of soils in earthen structures and foundations. These methods may detect internal erosion either directly or indirectly (detecting properties that typically indicate internal erosion is taking place). The goal is to detect soil movement earlier than occurs by current visual inspection and instrumentation methods.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse was $20,000 and was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). Cash prizes of $20,000 were distributed to five winning solvers as determined by the judging panel. Non-cash prize awards were not offered for this competition.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website. Nevertheless, submissions included all solvers regardless of whether they are U.S. citizens/entities. Meritorious submissions from non-U.S. citizens and entities, were recognized in publications issued by Reclamation announcing the results of the competition, such as press releases, as applicable.</td>
<td>The prize competition was advertised as an �Ideation Challenge.� Competitors were required to submit a written proposal including a detailed description and rationale for why the proposed solution met or exceeded the performance criteria stated in the Challenge posting. Submissions were evaluated by a Judging Panel composed of scientists, engineers, and other technical subject matter experts affiliated with Federal and State entities. The Panel had consultation access to technical experts outside of their expertise, as deemed necessary, to evaluate specific submissions. The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution. The judges assessed the merits of each solution by the degree upon which they meet the technical requirements. They also assessed the feasibility, flexibility, cost, and scalability of the proposed concept. At the end of the independent judging the individual scores were tallied and combined. The Panel convened several conference calls and then attended an all-day web conference to discuss the strengths and weaknesses of each submission and arrive at a consensus judges opinion. Solutions that did not meet all criteria, but were deemed novel, interesting, and potentially worth pursuing, were eligible to win a partial prize.</td>
<td>Of the 29 entries submitted by 133 participants between March 31 and May 10, 2016, prizes were awarded to five winners.</td>
<td>For FY17, the funding was $20,000 with 0.05 FTE used. FTE reported is based on labor budget consumption during the indicated fiscal year. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment; budget consumption by prize competition vendor service occurred prior to FY17.</td>
<td>USACE and the State of Colorado Dam Safety Program provided in-kind support for design and judging of the prize competition. The agencies also provided assistance with marketing and outreach. No monetary or non-cash awards were provided by partners. In 2017, the estimated value of partner contributions was $7,000.</td>
<td>This prize competition sought methods to detect the movement of material earlier than observable by currently used visual inspection and instrumentation methods. This could help prevent the loss of life, property and interruption of the service the infrastructure provides. Furthermore, the reliability of water infrastructure is improved.</td>
<td>Ideas</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a method for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see. For prize competitions, such as this one, where a successful system needs to solve a suite of different problems to successfully meet system requirements, a separate prize for each piece of the problem should be considered. Alternatively, Reclamation could consider a competition that focuses only on the most difficult part of the system problem.</td>
</tr>
<tr>
<td>Downstream Fish Passage at Tall Dams</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Reclamation sought new ideas for ensuring successful and cost-effective downstream passage of juvenile fish at tall (high-head) dams. The solutions addressed reducing: stress (e.g. crowding, removal from water, disorientation); physical damage on fish; interference with the operation of the dam (flood control, energy, water distribution); and total costs.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse was $20,000 and was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). Cash prizes of $20,000 were distributed to four winning solvers as determined by the judging panel. Non-cash prize awards were not offered for this competition.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website. Nevertheless, submissions included all solvers regardless of whether they are U.S. citizens/entities. Meritorious submissions from non-U.S. citizens and entities, were recognized in publications issued by Reclamation announcing the results of the competition, such as press releases, as applicable.</td>
<td>The prize competition was advertised as an �Ideation Challenge.� Competitors were required to submit a written proposal including a detailed description and rationale for why the proposed solution met or exceeded the performance criteria stated in the Challenge posting. Submissions were evaluated by a Judging Panel composed of scientists, engineers, and other technical subject matter experts affiliated with Federal and State entities. The Panel had consultation access to technical experts outside of their expertise, as deemed necessary, to evaluate specific submissions. The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution. The judges assessed the merits of each solution by the degree upon which they meet the technical requirements. They also assessed the feasibility, flexibility, cost, and scalability of the proposed concept. At the end of the independent judging the individual scores were tallied and combined. The Panel convened several conference calls and then attended an all-day web conference to discuss the strengths and weaknesses of each submission and arrive at a consensus judges opinion. Solutions that did not meet all criteria, but were deemed novel, interesting, and potentially worth pursuing, were eligible to win a partial prize.</td>
<td>Of the 44 entries submitted by 180 participants between March 31 and May 10, 2016, prizes were awarded to four winners.</td>
<td> For FY17, the budget was $20,000 and there was 0.05 FTE used. FTE reported is based on labor budget consumption during the indicated fiscal year. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment. Budget consumption by prize competition vendor service occurred prior to FY17.</td>
<td>USGS, NOAA-National Marine Fisheries Service, and USACE provided in-kind support for design and judging of the prize competition. The Federal agencies also provided assistance with marketing and outreach. One subject matter expect from State of California Department of Water Resources also provided in-kind design and judging assistance. No monetary or non-cash awards were provided by partners. The estimated value of partner contributions was $24,000.</td>
<td>Reclamation and other Federal, State, and local organizations have a stake in recovering threatened and endangered fish. This prize competition was developed to help migrating juvenile fish get over or around tall dams. Moving migrating juvenile fish past tall dams will ensure habitat connectivity that many threatened and endangered fish populations need to survive and reproduce.</td>
<td>Ideas</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a method for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see. For prize competitions, such as this one, where a successful system needs to solve a suite of different problems to successfully meet system requirements, a separate prize for each piece of the problem should be considered. Alternatively, Reclamation could consider a competition that focuses only on the most difficult part of the system problem. For fish passage, this is likely the ability to guide fish through a reservoir and successfully attract them to the fish collection and conveyance feature of the system. A tighter, sharper focus on the critical pieces of the problem may help solvers better focus and deliver.</td>
</tr>
<tr>
<td>Eradication of Invasive Mussels in Open Water - Stage 1</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Two species of dreissenid mussels, Dreissena polymorpha (zebra mussel) and Dreissena rostriformis �bugensis� (quagga mussel), have become established in freshwater lakes, reservoirs, and rivers in the United States. Invasive dreissenid mussels pose significant challenges for Reclamation and all agencies and industries that manage water. Invasive mussels are prolific breeders and settle on or within water facility infrastructure such as water intakes, gates, diversion screens, hydropower equipment, pumps, pipelines, and boats. Infested water and hydropower infrastructure can fail or choke off water transmissions. Invasive mussels negatively impact the natural ecology, which can be detrimental to native and endangered species, including native fisheries. Maintaining and operating water supply and delivery facilities, water recreation, and other water dependent industries and economies in mussel infested water bodies are dramatically more expensive and complex. Public recreation may also be severely impacted by mussel infestations, from shell fragments degrading swim beaches to increased requirements and cost for boaters. Management of invasive mussel infestations can also lead to restricted public access, in some cases through a complete ban on public use of infested waters. Currently, no practical methods exist for large-scale eradication of invasive dreissenid mussel populations once they become widely established in a reservoir, lake, or river (referred to as �open water�). Reclamation sought innovative solutions for 100% eradication of zebra and quagga mussels in open water through direct mortality or through non-lethal treatment that lead to their eventual eradication. Proposed treatments must be specific to invasive mussels without significant harm to non-target organisms such as native mussels or threatened and endangered species.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse of $100,000 was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.).</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website.</td>
<td>The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution against the criteria stated in the prize competition posting document.</td>
<td>Of the 67 entries submitted by 238 participants between December 14, 2017 and February 28, 2018, three prizes were awarded to four winners.</td>
<td>In FY17, the funding was $15,134 and there was 0.01 FTE used. In FY18, the funding was $100,000 and there was 0.25 FTE used. FTE reported is based on labor budget consumption during the indicated fiscal year, divided by $200,000 per FTE; work represents finalizing design, launch support, competition judging and final reporting. Budget reported excludes FTE staffing, and includes purse payment and budget consumption by prize competition vendor service for design support.</td>
<td>USACE, USGS, and Molloy &amp; Associates LLC provided in-kind support for design and judging of the prize competition. Partners also provided assistance with marketing and outreach. One subject matter expert from Portland State University also provided in-kind design and judging assistance, but the university was not a full partner. No monetary or non-cash awards were provided by partners.</td>
<td>Invasive dreissenid mussels pose significant challenges for Reclamation and all agencies and industries that manage water. Invasive mussels are prolific breeders and settle on or within water facility infrastructure such as water intakes, gates, diversion screens, hydropower equipment, pumps, pipelines, and boats. Infested water and hydropower infrastructure can fail or choke off water transmissions. Invasive mussels negatively impact the natural ecology, which can be detrimental to native and endangered species, including native fisheries. Maintaining and operating water supply and delivery facilities, water recreation, and other water dependent industries and economies in mussel infested water bodies are dramatically more expensive and complex. Public recreation may also be severely impacted by mussel infestations, from shell fragments degrading swim beaches to increased requirements and cost for boaters to have their watercraft inspected and decontaminated, and potential impacts on populations of game fish. Management of invasive mussel infestations can also lead to restricted public access, in some cases through a complete ban on public use of infested waters. Eradication of invasive dreissenid mussels ensures Reclamation�s ability to meet water and power deliveries now and into the future.</td>
<td>Ideas; Technology demonstration and hardware; Scientific</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a methods for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see.</td>
</tr>
<tr>
<td>Indirect Estimates of Reservoir Water Storage</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Water storage in reservoirs behind dams is a vital component for water management, and the amount available defines the delivery of benefits from reservoirs. Available water storage, over time, decreases as sediment deposition occurs, thus decreasing the capacity for storage. This sediment deposition, known as sedimentation, also adversely affects reservoir infrastructure operation and maintenance such as outlet works and water intakes. Assessing the loss of storage capacity currently is an expensive and time consuming process performed directly by in-field surveys. The Bureau of Reclamation, in collaboration with the U.S. Army Corps of Engineers, was seeking a cost effective method to indirectly estimate the storage capacity and/or sediment volume (storage loss) in reservoirs. This is a Reduction-to-Practice Challenge required written documentation, source code, and delivery of an executable application.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse was $75,000 and was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). A partial cash prize of $1,000 was distributed to 1 winning solver as determined by the judging panel. Non-cash prize awards were not offered for this competition.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine.</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website. Nevertheless, submissions included all solvers regardless of whether they are U.S. citizens/entities. Meritorious submissions from non-U.S. citizens and entities, were recognized in publications issued by Reclamation announcing the results of the competition, such as press releases, as applicable.</td>
<td>The prize competition was advertised as a �Theoretical Challenge.� Competitors were required to submit a written proposal including a detailed description and rationale for why the proposed solution met or exceeded the performance criteria stated in the Challenge posting. Submissions were evaluated by a Judging Panel composed of scientists, engineers, and other technical subject matter experts affiliated with Federal and State entities. The Panel had consultation access to technical experts outside of their expertise, as deemed necessary, to evaluate specific submissions. The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution. The judges assessed the merits of each solution by the degree upon which they meet the technical requirements. They also assessed the feasibility, flexibility, cost, and scalability of the proposed concept. At the end of the independent judging the individual scores were tallied and combined. The Panel convened several conference calls and then attended an all-day web conference to discuss the strengths and weaknesses of each submission and arrive at a consensus judges opinion. Solutions that did not meet all criteria, but were deemed novel, interesting, and potentially worth pursuing, were eligible to win a partial prize.</td>
<td>Of the 20 entries submitted by 280 participants between February 22 and May 22, 2017, a prize was awarded to one winner.</td>
<td>In FY17, there was $1,000 of funding and 0.09 FTE used. FTE reported is based on labor budget consumption during the indicated fiscal year. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment; budget consumption by prize competition vendor service occurred prior to FY17.</td>
<td>USACE provided in-kind services for two subject matter experts to design and judge the prize competition including an in-person judges meeting. USACE also assisted with marketing and outreach. No monetary or non-cash prize awards were provided by partners.</td>
<td>Measurement of reservoir storage loss due to sediment accumulation is paramount in supporting Reclamation�s mission. Reservoir sedimentation is a chronic problem that has become more visible and has continually increasing impacts with the aging of dams. Sediment deposition in reservoirs limits the active life of reservoirs by reducing reservoir storage capacity and impacting structures such as outlet works and water intakes. In order to determine the magnitude and rate of sedimentation to assess future impacts, direct measurements, such as a bathymetric (below water) survey in combination with a topographic (above water) survey are necessary. This process can be costly and time consuming. As of 2015, less than 40% of Reclamation reservoirs have had at least one resurvey since first filling to estimate storage loss as a result of sedimentation. The alternative to direct measurements of storage loss is indirect estimates of storage loss. Developing an efficient and accurate indirect estimate model of reservoir storage would result in a better, faster, and cheaper solution to support Reclamation in meeting water and power deliveries now and into the future.</td>
<td>Technology demonstration and hardware</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a method for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see. For prize competitions, such as this one, where a successful system needs to solve a suite of different problems to successfully meet system requirements, a separate prize for each piece of the problem should be considered. Alternatively, Reclamation could consider a competition that focuses only on the most difficult part of the system problem.</td>
</tr>
<tr>
<td>Long-Term Corrosion Protection of Existing Hydraulic Steel Structures � Stage 1</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Common hydraulic steel structures such as hydroelectric penstocks and gates corrode, or degrade, without a properly applied corrosion control method. This degradation produces a localized or general thinning of material, which reduces the structure�s ability to support load, carry water, etc. Failure of hydraulic steel structures can cause extensive downtime, loss of productivity, property damage, and even loss of life.The cost of maintenance and replacement of existing corrosion control systems has increased greatly in recent decades due to increasing health, safety, and environmental concerns associated with coatings that have performed well in the past as well as the decreased life cycles of commercially available alternative coatings. New long-term solutions to protect steel structures in water immersion service will help to reduce the high cost incurred to keep steel infrastructure reliable and functional.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse was $75,000 and was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). Five cash prizes of $47,500 were distributed to seven winning solvers as determined by the judging panel. Non-cash prize awards were not offered for this competition.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website. Nevertheless, submissions included all solvers regardless of whether they are U.S. citizens/entities. Meritorious submissions from non-U.S. citizens and entities, were recognized in publications issued by Reclamation announcing the results of the competition, such as press releases, as applicable.</td>
<td>The prize competition was advertised as an �Theoretical Challenge.� Competitors were required to submit a written proposal including a detailed description and rationale for why the proposed solution met or exceeded the performance criteria stated in the Challenge posting. Submissions were evaluated by a Judging Panel composed of scientists, engineers, and other technical subject matter experts affiliated with Federal and State entities. The Panel had consultation access to technical experts outside of their expertise, as deemed necessary, to evaluate specific submissions. The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution. The judges assessed the merits of each solution by the degree upon which they meet the technical requirements. They also assessed the feasibility, flexibility, cost, and scalability of the proposed concept. At the end of the independent judging the individual scores were tallied and combined. The Panel convened several conference calls and then attended an all-day web conference to discuss the strengths and weaknesses of each submission and arrive at a consensus judges opinion. Solutions that did not meet all criteria, but were deemed novel, interesting, and potentially worth pursuing, were eligible to win a partial prize.</td>
<td>Of the 30 entries submitted by 171 participants between June 13 and September 5, 2017, five prizes were awarded to seven winners.</td>
<td>In FY17, there was 0.21 FTE used. In FY18 there was $47,500 in funding. FTE reported is based on labor budget consumption during the indicated fiscal year. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment; budget consumption by prize competition vendor service occurred prior to FY17.</td>
<td>Reclamation partnered with the U.S. Army Engineer Research and Development Center for planning and judging; NIST for planning and judging; the Naval Facilities Engineering Command for planning and judging; and North Carolina State University for judging. The estimated value of partner contributions in FY17 was $70,000.</td>
<td>The annual estimated cost of corrosion in the U.S. is $451 billion or 2.7% of the Nation�s GDP (IMPACT Study, NACE International, 2016). This enduring cost is in spite of the development of numerous technologies dedicated to providing corrosion protection. The Bureau of Reclamation is seeking new corrosion control methods or technologies to curb the rising costs of protecting its steel structures and ensure safe and reliable operation of its water infrastructure.</td>
<td>Ideas</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a method for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see. For prize competitions, such as this one, where a successful system needs to solve a suite of different problems to successfully meet system requirements, a separate prize for each piece of the problem should be considered. Alternatively, Reclamation could consider a competition that focuses only on the most difficult part of the system problem.</td>
</tr>
<tr>
<td>More Water, Less Concentrate - Stage 1</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Innovative solutions were sought to expand usable water supplies by maximizing fresh water production from inland desalination systems in a cost effective and environmentally sound manner. Currently, significant and desirable water supplies are trapped in concentrate streams that are a byproduct of desalination technologies. The cost to manage or dispose of concentrate is rather large and very limiting to utilization of desalination in inland applications. Solutions could be novel technologies or approaches that build upon existing technologies. Solutions should address one of the following objectives, 1) ways to improve overall system recovery of existing desalination technologies, 2) ways to treat concentrate streams to extract additional useable water and thus to increase overall system recovery, or 3) new high recovery desalination technologies or processes that increase overall system recovery beyond current desalination technologies.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse was $150,000 and was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). Cash prizes of $150,000 were distributed to ten winning solvers as determined by the judging panel. Non-cash prize awards were not offered for this competition.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website. Nevertheless, submissions included all solvers regardless of whether they are U.S. citizens/entities. Meritorious submissions from non-U.S. citizens and entities, were recognized in publications issued by Reclamation announcing the results of the competition, such as press releases, as applicable.</td>
<td>The prize competition was advertised as an �Theoretical Challenge.� Competitors were required to submit a written proposal including a detailed description and rationale for why the proposed solution met or exceeded the performance criteria stated in the Challenge posting. Submissions were evaluated by a Judging Panel composed of scientists, engineers, and other technical subject matter experts affiliated with Federal and State entities. The Panel had consultation access to technical experts outside of their expertise, as deemed necessary, to evaluate specific submissions. The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution. The judges assessed the merits of each solution by the degree upon which they meet the technical requirements. They also assessed the feasibility, flexibility, cost, and scalability of the proposed concept. At the end of the independent judging the individual scores were tallied and combined. The Panel convened several conference calls and then attended an all-day web conference to discuss the strengths and weaknesses of each submission and arrive at a consensus judges opinion. Solutions that did not meet all criteria, but were deemed novel, interesting, and potentially worth pursuing, were eligible to win a partial prize.</td>
<td>Of the 66 entries submitted by 282 participants between December 13, 2016 and March 13, 2017, eight prizes were awarded to ten winners.</td>
<td>There was 0.14 FTE used in 2018. FTE reported is based on labor budget consumption during the indicated fiscal year. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment; budget consumption by prize competition vendor service occurred prior to FY17.</td>
<td>Reclamation partnered with the EPA for design; USACE for design and judging; U.S. Army for design and judging; the Water Environment and Reuse Foundation for design, judging, and outreach; and Water Research Foundation for outreach</td>
<td>Currently, significant and desirable water supplies are trapped in concentrate streams that are a byproduct of desalination technologies. The cost to manage or dispose of concentrate is rather large and limiting to utilization of desalination in inland applications. This Challenge sought innovative concepts to expand usable water supplies by maximizing fresh water production from inland desalination systems, and thereby reduce the volume of concentrate.The National Academy of Sciences identified developing cost-effective approaches for concentrate management that minimize environmental impacts as one of their highest priority research topics to enable the more widespread use of desalination to expand water supplies in the United States.The demand for fresh water will be increasing, and we need to be able to develop new water supplies from non- traditional water sources, like brackish groundwater and surface water using desalination and novel technologies. The competition sought innovative concepts to expand usable water supplies by maximizing fresh water production from inland desalination systems in a cost-effective and environmentally sound manner.</td>
<td>Ideas</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a method for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see. For prize competitions, such as this one, where a successful system needs to solve a suite of different problems to successfully meet system requirements, a separate prize for each piece of the problem should be considered. Alternatively, Reclamation could consider a competition that focuses only on the most difficult part of the system problem.</td>
</tr>
<tr>
<td>Pathogen Monitoring - Stage 1</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>As Western U.S. water demands grow and water supplies become more scarce, water reuse is becoming an increasingly important water management strategy. Wastewater is a drought-resistant and reliable water source that is readily available in urban centers for beneficial reuse. While advanced water treatment technologies exist to produce high quality, potable water from wastewater, there is a need to better ensure treatment process integrity through improved pathogen detection and monitoring. Waterborne pathogens (e.g., bacteria, viruses, protozoa, and helminths) are regulated due to the risk they pose to human health, and their presence must be limited in water intended for potable use.The Bureau of Reclamation, with financial support from Xylem, Inc, in collaboration with the Water Research Foundation and the EPA, are seeking the development of rapid, accurate, and preferably on-line/on-site monitoring techniques to provide added protection of public health and optimize the design and operations of advanced water treatment facilities. Success could result in reliable, effective pathogen detection technologies that can facilitate public and regulatory acceptance of direct potable reuse systems.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse of $40,000 was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). Xylem, Inc. offered $40,000 in partner contribution. Judging is in progress.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website.</td>
<td>Judging is in progress at the date of this report.The judging will be conducted by blind review as all submissions will be identified solely by a number assigned by InnoCentive. Judges will be provided with scoring sheets to be completed independently after reviewing each proposed solution against the criteria stated in the prize competition posting document.The prize competition was advertised as a �Theoretical Challenge.� Submissions consist of a written proposal including a detailed description and rationale for why the proposed solution met or exceeded the performance criteria stated in the prize competition posting.</td>
<td>Entries were submitted between May 10 and August 8, 2018, and prizes and winners have yet to be determined.</td>
<td>In FY17, there was $15,134 of funding and 0.21 FTE used. FTE reported is based on labor budget consumption during the indicated fiscal year, divided by $200,000 per FTE; work represents finalizing design, launch support, competition judging and final reporting. Budget reported excludes FTE staffing, and includes only budget consumption by prize competition vendor service for design support. Purse consumption will occur in FY19, where maximum purse will be $80,000 with 50% involving USBR budget consumption and 50% involving partner contribution by Xylem.</td>
<td>Reclamation partnered with the EPA for design and judging; Xylem, Inc. for design and judging; and the Water Research Foundation for design, judging, and outreach.</td>
<td>Relamation seeks to enable the development of rapid, more accurate, and preferably on-line/on-site monitoring techniques to provide added protection of public health and optimize the design and operations of advanced water treatment facilities. Success could result in reliable, effective pathogen detection technologies that can facilitate public and regulatory acceptance of direct potable reuse systems.Stage 1 of the competition is seeking technical proposals for how to rapidly, accurately, and cost-effectively detect viruses in water reuse treatment plants. Reclamation will award an $80,000 prize purse ($40,000 of which is provided by Xylem Inc.), among winning eligible U.S. solvers. Winning eligible international solvers may receive meritorious recognition.</td>
<td>Ideas</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a methods for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see.</td>
</tr>
<tr>
<td>Powering Electronic Instruments on a Rotating Shaft - Stage 1</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>Reclamation�s hydropower generating units are expected to safely and reliably produce the power that is delivered to the Western U.S. electric grid. Equipment monitoring techniques provide a critical advancement toward keeping these units operational and reducing costly outages. However, the monitoring equipment requires a continuous power source in order to keep it online and performing its key role. New solutions are needed to permanently install low power electronics on the generator�s rotating shaft in order to collect continuous data pertinent to operation and performance of the machine. Presently, the available power sources for electronics on rotating shafts include batteries and contact solutions. Powering the electronic equipment with a battery does not provide continuous operation and requires downtime of the equipment to replace them, resulting in lost power generation. Existing contact solutions, such as slip rings, have unacceptable installation and maintenance requirements. Non-contact solutions include emerging technologies that may prove beneficial but are not yet explored for this application.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse of $250,000 was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). The prize competition is open to solvers.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website.</td>
<td>The prize competition is open to solvers.The judging will be conducted by blind review as all submissions will be identified solely by a number assigned by InnoCentive. Judges will be provided with scoring sheets to be completed independently after reviewing each proposed solution against the criteria stated in the prize competition posting document.</td>
<td>Entries were submitted between September 6 and December 6, 2018, and winners have yet to be determined.</td>
<td>In FY18 there was 0.35 FTE used. FTE reported is based on labor budget consumption during the indicated fiscal year, divided by $200,000 per FTE; work represents finalizing design, launch support, competition judging and final reporting.Budget reported excludes FTE staffing, and includes only budget consumption by prize competition vendor service for design support. Phase 1 purse consumption ($50,000 of the total $250,000 purse) will occur in FY19; Phase 2 purse consumption will occur in FY19 or FY20.</td>
<td>Reclamation partnered with USACE for judging and the Bonneville Power Administration for judging.</td>
<td>Reclamation and our collaborators seek novel methods and technologies to reliably provide direct current power for loads of up to twenty watts to electronics on rotating shafts. Proposed solutions must be applicable to rotating shafts that are 18- to 144-inch diameter, whether at rated speed (80 to 550 revolutions per minute), standstill, or when ramping up or down. Small, lightweight solutions are preferred, and could be achieved via multiple methods, including air movement, light, vibration, magnetic induction, kinetic motion, or wireless energy transfer. A successful solution would make online, continuous monitoring of hydropower generating units possible, which increases the reliability of power delivery and reduces costly outages.</td>
<td>Ideas; Technology demonstration and hardware; Scientific</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a methods for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see.</td>
</tr>
<tr>
<td>Preventing Rodent Burrows in Earthen Embankments</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Rodent burrows can fill with water when water levels change, creating seepage paths, which can lead to internal erosion in embankments resulting in the potential for catastrophic failure. Embankment failures can cause property damage, loss of life, and interrupt crucial deliveries of water in the West and across the Nation. Trapping or baiting rodents on earthen embankments are short-term remedies, and experience has shown that within a short time, the rodents inevitably return. Annual programs of rodent removal over thousands of miles of earthen embankment are cost prohibitive and only marginally successful. Solvers are asked to �dig deeper� than the rodents and offer creative, cost effective, long-term solutions to this real and serious problem.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse was $20,000 and was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). Cash prizes of $20,000 were distributed to five winning solvers as determined by the judging panel. Non-cash prize awards were not offered for this competition.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website. Nevertheless, submissions included all solvers regardless of whether they are U.S. citizens/entities. Meritorious submissions from non-U.S. citizens and entities, were recognized in publications issued by Reclamation announcing the results of the competition, such as press releases, as applicable.</td>
<td>The prize competition was advertised as an �Ideation Challenge.� Competitors were required to submit a written proposal including a detailed description and rationale for why the proposed solution met or exceeded the performance criteria stated in the Challenge posting. Submissions were evaluated by a Judging Panel composed of scientists, engineers, and other technical subject matter experts affiliated with Federal and State entities. The Panel had consultation access to technical experts outside of their expertise, as deemed necessary, to evaluate specific submissions. The judging was conducted by blind review as all submissions were identified solely by a number assigned by InnoCentive. Judges were provided with scoring sheets to be completed independently after reviewing each proposed solution. The judges assessed the merits of each solution by the degree upon which they meet the technical requirements. They also assessed the feasibility, flexibility, cost, and scalability of the proposed concept. At the end of the independent judging the individual scores were tallied and combined. The Panel convened several conference calls and then attended an all-day web conference to discuss the strengths and weaknesses of each submission and arrive at a consensus judges opinion. Solutions that did not meet all criteria, but were deemed novel, interesting, and potentially worth pursuing, were eligible to win a partial prize.</td>
<td>Of the 75 entries submitted by 224 participants between August 29 and October 11, 2016, prizes were awarded to five winners.</td>
<td>In FY17, there was $20,000 in funding and 0.29 FTE used. FTE reported is based on labor budget consumption during the indicated fiscal year. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment; budget consumption by prize competition vendor service occurred prior to FY17.</td>
<td>USACE and State of Colorado Natural Resources Dam Safety Branch provided in-kind support for design and judging of the prize competition. The agencies also provided assistance with marketing and outreach. No monetary or non-cash awards were provided by partners.</td>
<td>Rodents can burrow through both sides of an embankment providing a pathway for water to move through and erode the embankment, potentially causing serious issues for the surrounding communities. Burrows may also intersect or expose other anomalies in the embankment that may result in a failure of the embankment and interruption of water supply to clients. This prize competition advanced the agency�s mission of reliable water delivery by proposing new solutions to solve failures of canal embankments due to rodent burrows.</td>
<td>Ideas</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a method for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see. For prize competitions, such as this one, where a successful system needs to solve a suite of different problems to successfully meet system requirements, a separate prize for each piece of the problem should be considered. Alternatively, Reclamation could consider a competition that focuses only on the most difficult part of the system problem.</td>
</tr>
<tr>
<td>Sub-Seasonal Climate Forecast Rodeo</td>
<td>USBR</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and is underway in FY18.</td>
<td>Water managers need more skillful information on weather and climate conditions with lead-times ranging from 15 days to 45 days and beyond. Lacking skillful sub-seasonal information limits water managers� ability prepare for shifts in hydrologic regimes, such as the onset of drought or occurrence of wet weather extremes. The challenge of sub-seasonal forecasting is that it encompasses the time frame where initial state information (e.g., coupled land-atmosphere processes) becomes less important and slowly varying long term states (e.g., sea surface temperatures, soil moisture, snow pack) become more important to prediction skill. This is a Reduction to Practice Challenge. Solvers will have three months to develop their system before the forecasting rodeo begins, at which point they are asked to provide forecasts every two weeks over a 13 month period, with the first month being a �pre-season� to become familiar with the submission and evaluation processes. Including judging, awarding of prizes, and identification of next steps, the expected completion is mid-2018. It is possible that another competition may be a recommended next step, perhaps focusing on extremes or a longer outlook. A variety of prizes may be awarded as part of this competition, the total of which is approximately $800,000. Prize categories are based on skill at two outlook timescales (weeks 3-4 and weeks 5-6) and for temperature as well as precipitation.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>A prize competition was selected as a preferred method to achieve the aforementioned goals because it helps engage a non-traditional, national solver community while also complementing traditional research designed to target the most persistent science and technology challenges. Competitions also can incentivize the submission of solutions. They are made open to a national, non-Federal solver community including citizens, businesses, and other organizations. Reclamation selected a prize competition to address this technical Challenge because it allowed the agency to pay only for results; established an important goal without having to limit approaches or teams that are most likely to succeed; increased the number and diversity of the individuals, organizations, and teams that would address the problem or challenge of national/international significance; can stimulate private sector investment that is many times greater than the cash value of the prize; and furthered Reclamation�s mission by attracting more interest and attention to a defined program, activity, issue or concern.</td>
<td>The cash prize purse of $800,000 was funded via Reclamation�s Science and Technology Program, Research and Development Office as per Federal Acquisition Regulation (FAR, as codified at Chapter 1 of Title 48 of the Code of Federal Regulations, 48 C.F.R.). Judging is in progress.</td>
<td>Reclamation created a unique webpage as well as cross-posted at Challenge.gov and InnoCentive sites. A video was created and shared via YouTube to support social media outreach, while a webinar was hosted to accompany the launch news release. InnoCentive was the prize competition administrator. The advantage of contracting with InnoCentive was the ability to bundle and brand the portfolio of Reclamation�s Water Prize Competition Center while leveraging InnoCentive�s global network of 380,000+ individuals. Overall, the quality and types of proposed solutions varied significantly. Many submissions, any of whom could be a potential winner, proposed technologies or methods already in practice with little or no potential to improve existing capabilities. Others, although some might be considered novel or different, were judged to not meet solution requirements or not feasible. No new, ready-to-implement, �silver bullet� was found to solve this difficult problem; however Reclamation understands this is not a realistic expectation for a single-stage ideation prize completion. Five solutions were considered worthy of a prize award consistent with the stated prize competition rules and criteria. Lessons learned include the need for casting a wider solver net, as well as more support for the payments process. With this in mind, Reclamation is pursuing an Interagency Agreement with NASA�s Center of Excellence for Collaborative Innovation to allow access to trending models, infrastructure, expertise and multiple external competition crowdsourcing services.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Advertisement in Reclamation�s Knowledge Stream R&amp;D magazine</td>
<td>This prize competition targeted the Challenge.gov and InnoCentive solver communities. This Challenge was conducted under the authority of the America COMPETES Reauthorization Act of 2010 (15 U.S.C.� 3719). The Act states that awards for this Prize Competition may only be given to an individual that is a citizen or permanent resident of the United States, or an entity that is incorporated in and whose primary place of business is in the United States. Other restrictions were published in the Challenge Specific Agreement on the InnoCentive website.</td>
<td>Judging is in progress.</td>
<td>Entries were submitted between December 20, 2016 and May 3, 2018, and winners are yet to be determined.</td>
<td>In FY17, the funding was $64,757 and there was 0.3 FTE used. In FY18, the funding was $104,926 and there was 0.15 FTE used. FTE reported is based on labor budget consumption during the indicated fiscal year. Work represents competition judging and final reporting. Budget reported excludes FTE staffing, and includes only purse payment; budget consumption by prize competition vendor service.</td>
<td>NOAA co-led the design of this Challenge along with Reclamation. NOAA will also host the leaderboard and assist with evaluating the submissions. NOAA�s mission includes science, service and stewardship. Specifically, NOAA aims to understand and predict changes in climate, weather, oceans, and coasts; to share that information and knowledge with others; and to conserve and manage coastal and marine ecosystems and resources (www.noaa.gov). USGS and USACE contributed subject matter experts to review and assist with the design of this Challenge. The mission of the USGS is to serve the Nation by providing reliable scientific information to describe and understand the Earth; minimize loss of life and property from natural disasters; manage water, biological, energy, and mineral resources; and enhance and protect our quality of life (www.usgs.gov). The mission of the USACE is to deliver vital public and military engineering services; partnering in peace and war to strengthen our Nation�s security, energize the economy and reduce risks from disasters (www.usace.army.mil).</td>
<td>Techniques that outperform current forecast practices are expected to offer valuable insight as to how operational forecasts can be improved at the sub-seasonal timescale. This in turn will offer a variety of sectors�not just water management�much needed information to better manage resources and prepare for extreme events. A few examples include advanced emergency preparedness, enhanced water order scheduling, and wildfire management.</td>
<td>Analytics, visualizations, algorithms</td>
<td>Future consideration to increase the effectiveness and efficiency of conducting prize competitions include: incorporating a methods for judges to quickly set aside solutions that have no merit, such as a quick initial reality check on the question, �Can this work?�; in addition to the stated judging criteria, incorporate a free format field for each judge to characterize the merits of the solution in their own words based on the strengths and weaknesses they see.</td>
</tr>
<tr>
<td>AHRQ Step Up App Challenge: Advancing Care Through Patient Assessments</td>
<td>Agency for Healthcare Research and Quality (AHRQ)</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>While patient-reported outcomes (PRO) data have proven useful to healthcare providers, they are not widely used in clinical settings. Existing PRO data collection methods can inconvenience busy patients and providers and make the data difficult to access and analyze due to a lack of standardization. Developing an easily adoptable tool that collects and shares standardized data should help solve this problem and advance the state of PRO usage. In this Challenge, AHRQ is looking for teams to design, develop, and pilot a user-friendly application that simplifies and standardizes the process of collecting, interpreting, aggregating, and sharing PRO data related to physical function outcomes in the ambulatory care setting.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>The prize competition furthers AHRQ�s mission by generating innovative ideas to address agency goals. The hope is that attracting diverse teams via a challenge competition can bring innovation. The prize competition stimulates private sector investment that is many times greater than the cash value of the award. AHRQ can receive innovative solutions within a short time frame.</td>
<td>The total prize purse offered is $250,000. In Phase one, AHRQ awarded ten winners with $12,000 each. In Phase two, three winners were awarded. The grand prize winner was awarded $35,000 and invited to pilot their app with MedStar Health. Second- and third-place winners received $30,000 and $25,000, respectively. The grand prize winner will receive another $40,000 after the pilot test.</td>
<td>AHRQ promoted the Challenge through the Blue Button 2.0 Developer Conference, AHRQ�s press release, blog, listserv, social media (e.g., Facebook, Twitter), and stakeholders outreach. The Office of the National Coordinator for Health Information Technology (ONC) also promoted the Challenge through their listserv.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Other -Blue Button 2.0 Developer Conference; Other - Webinar</td>
<td>Participants in the AHRQ Step Up Challenge are subject to the following requirements: (1) Shall have registered to participate in the Challenge under the rules promulgated by the Agency for Healthcare Research and Quality; (2) Shall have complied with all the stated requirements of the Step Up App Challenge; (3) In the case of a private entity, shall be incorporated in and maintain a primary place of business in the United States, and in the case of an individual, whether participating singly or in a group, shall be a citizen or permanent resident of the United States; (4) May not be a Federal entity or Federal employee acting within the scope of their employment; (5) Shall not be an HHS employee working on their applications or Submissions during assigned duty hours; (6) Shall not be an employee of the Agency for Healthcare Research and Quality; (7) Federal grantees may not use Federal funds to develop COMPETES Act Challenge applications unless consistent with the purpose of their grant award; and (8) Federal contractors may not use Federal funds from a contract to develop COMPETES Act Challenge applications or to fund efforts in support of a COMPETES Act Challenge Submission.</td>
<td>Phase one evaluation criteria included team/participant capabilities (20%), impact (30%), feasibility (30%), and originality (20%). Phase two evaluation criteria includes technical merit (40%), usability and functionality (30%), and deployability (30%).</td>
<td>In October 2018, ten winners were selected from Phase one to compete in Phase two (app development). In March 2019, three winners were selected from Phase two. The grand prize winner is partnering with MedStar Health to pilot test the winning app (Phase three). Phase three pilot testing is scheduled to complete in September 2019.</td>
<td>AHRQ received funding from the Secretary�s portion (managed by ASPE) of the Patient Centered-Outcomes Research Trust Fund to manage a project to advance the collection and use of patient-reported outcome data through health information technology. AHRQ devoted $250,000 to hire a contractor to manage the Challenge and allocated another $250,000 as the total prize pot. AHRQ program staff manages the Challenge including being a COR on the contract to manage the Challenge, coordinating with Federal partners, and working with AHRQ�s Office of Communications to promote the Challenge. AHRQ Office of Communications staff set up an AHRQ microsite for the Challenge and promoted the Challenge via different mechanisms such as social media and blog posts. Approximately 1 FTE was utilized.</td>
<td>The AHRQ Step Up App Challenge is one component within a PRO project funded by Secretary�s portion (managed by the Office of the Assistant Secretary for Planning and Evaluation) of the Patient-Centered Outcomes Research Trust Fund. ONC received $2 million as a partner in the PRO project. ONC provides technical expertise and hired a contractor to develop the technical specifications that will be used in the AHRQ Step Up App Challenge. ONC also shares experience with hosting challenges and promoted AHRQ�s Challenge through their listserv. NIH provides expertise and consultation regarding the Patient-Reported Outcomes Measurement Information System (PROMIS�) physical function measures that are used in the Challenge. They also connected AHRQ staff with the faculty member at Northwestern University who manages the PROMIS Assessment Center Application Program Interface (API). A faculty member at Northwestern University provides in-kind technical support regarding the use of the PROMIS Assessment Center API to Challenge participants.</td>
<td>AHRQ is the lead Federal agency charged with improving the safety and quality of America&#39;s health care system. AHRQ develops the knowledge, tools, and data needed to improve the health care system and help Americans, health care professionals, and policymakers make informed health decisions. The Step Up App Challenge is part of AHRQ�s ongoing effort to help shape the Nation�s digital health care ecosystem and realize its potential to improve outcomes through broader use of patient data. PRO data or patient self-assessments offer a complementary perspective to clinician assessments and are also used in research to explore patient perspectives about their treatments, health outcomes, and the quality of services they received. Having user- friendly apps that are capable of collecting standardized PRO data in various ambulatory settings can increase clinicians� ability to use the data or easily share these data across health systems for research or other purposes, including quality improvement.</td>
<td>Software and apps</td>
<td>AHRQ will be hosting at most two challenges in the form of a datathon or codeathon that focuses on increasing accessibility to data analytics and utilizing AHRQ�s rich data resources to develop innovative and timely insights into the healthcare system to make data more accessible to the public. This will address AHRQ�s mission to make health care safer, higher quality, more accessible, equitable, and affordable is understood and used.</td>
</tr>
<tr>
<td>2017 Million Hearts� Hypertension Control Challenge</td>
<td>Centers for Disease Control (CDC)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>Heart disease and stroke are the first and fifth leading causes of death in the United States. High blood pressure, or hypertension, is a leading risk factor for both conditions with approximately 1.5 million heart attacks and strokes occurring in the U.S. annually. Yet, of the 75 million adults with hypertension only half have their blood pressure under control. The Million Hearts� Hypertension Control Challenge seeks to identify clinical practices and health systems that excel in hypertension control and to identify the successful strategies used by those who excel in hypertension control in order to broadly share and promote those strategies. Through past challenges, including the 2017 Challenge, CDC has identified 83 clinical practices and health systems who care for 5 million patients with hypertension. The average control rate among these champions is 79%.</td>
<td>Find and highlight innovative ideas</td>
<td>The Million Hearts� initiative, co-led by CDC and the Centers for Medicare and Medicaid, aims to prevent a million heart attacks and strokes and related conditions by 2022. In support of that goal, CDC was interested in gathering documentation from clinical practices and health systems regarding successful strategies that support hypertension control. The 2017 Hypertension Control Challenge was a way to recognize and promote clinicians who are excelling at hypertension control in their patient population and then using their successful strategies to encourage others to improve hypertension control.</td>
<td>No prize purse or monetary incentives were offered for this Challenge. Champions received local and national recognition through the Million Hearts� and CDC websites, as well as national press releases congratulating the champions. Documentation of clinical systems and strategies champions adopted that support hypertension control are housed online and attributed to the champions.</td>
<td>The Challenge was promoted through Challenge.gov, the Million Hearts� website, through social media (Facebook, Twitter), and by other Federal and non-Federal partners. All HHS agencies are Million Hearts� partners. The Challenge was also promoted through email to partners.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Website</td>
<td>The 2017 Million Hearts� Hypertension Control Challenge was open to public and private individual clinicians, practices, and health systems providing health care services to patients in a U.S. State or territory. Participants were required to treat all adult patients with hypertension in the practice seeking care, not a select subgroup of patients; treat a minimum of 500 adult patients annually; have a hypertension control rate of at least 70% during the 12-month reporting period; have a data management system (electronic or paper) that allows for verification of data submitted; and be free from convictions or pending investigations of criminal and health care fraud offenses and must not have any serious sanctions for healthcare fraud or mis-prescribing of prescription medications.</td>
<td>Applications were initially evaluated by CDC staff for completeness and plausibility and any areas of concern are noted. A contractor experienced in validating hypertension control rates completed a background check on the applicants. Data validation was done by the contractor to determine if proper methods were used in calculation the hypertension control rates and various patient population characteristics such as the prevalence of hypertension in their population. Applicants were required to submit documentation that a random sample of the hypertensive population (up to 30 patients) had a documented diagnosis of hypertension prior to the most recent blood pressure measurement. CDC reviewed all information from the contractor and submitted the findings to a panel of judges who were CDC FTEs for determination of whether the applicants satisfied the requirements for being a champion. In 2017, applicants were required to have at least a hypertension control rate of 70%.</td>
<td>Of the 98 entries submitted by participants, prizes were awarded to 24 winners.</td>
<td>Agency resources included 5% FTE time; $40,000 cost to build the data collection website; and $179,000 contractor cost for data validation.</td>
<td>Non-Federal partners included the National Association for Chronic Disease Directors.</td>
<td>Hypertension is a leading risk factor for heart disease and stroke, the first and fifth leading causes of death in the U.S., respectively. Prevention of heart disease and stroke is a major focus for CDC�s National Center for Chronic Disease Prevention and Health Promotion. The CDC and the Centers for Medicare and Medicaid co-lead the Million Hearts� initiative, with a mission to prevent a million heart attacks, strokes, and related conditions by 2022.</td>
<td>Ideas</td>
<td>The 2018 Million Hearts Hypertension Control Challenge is in the final stages and champions will be announced in November 2018. The 2019 Challenge is planned to launch in February 2019.</td>
</tr>
<tr>
<td>2018 Million Hearts� Hypertension Control Challenge</td>
<td>CDC</td>
<td>COMPETES Authority</td>
<td>This competition was underway in FY18.</td>
<td>Heart disease and stroke are the first and fifth leading causes of death in the United States. High blood pressure, or hypertension, is a leading risk factor for both conditions with approximately 1.5 million heart attacks and strokes occurring in the U.S. annually. Yet, of the 75 million adults with hypertension only half have their blood pressure is under control. The Million Hearts� Hypertension Control Challenge seeks to identify clinical practices and health systems that excel in hypertension control and to identify the successful strategies used by those who excel in hypertension control in order to broadly share and promote those strategies. Through past challenges, including the 2017 challenge, CDC has identified 83 clinical practices and health systems who care for 5 million patients with hypertension. The average control rate among these champions is 79%.</td>
<td>Find and highlight innovative ideas</td>
<td>The Million Hearts� initiative, co-led by CDC and the Centers for Medicare and Medicaid, aims to prevent a million heart attacks and strokes and related conditions by 2022. In support of that goal, CDC is interested in gathering documentation from clinical practices and health systems regarding successful strategies that support hypertension control. The 2018 Hypertension Control Challenge is a way to recognize and promote clinicians who are excelling at hypertension control in their patient population and then using their successful strategies to encourage others to improve hypertension control.</td>
<td>No prize purse or monetary incentives are offered for this challenge. Champions will receive local and national recognition through the Million Hearts� and CDC websites, as well as national press releases congratulating the champions. Documentation of clinical systems and strategies champions adopted that support hypertension control will be housed online and attributed to the champions.</td>
<td>The Challenge is promoted through challenge.gov, the Million Hearts� website, through social media (Facebook, twitter), and by other Federal and non-Federal partners. All HHS agencies are Million Hearts� partners. The Challenge was also promoted through email to partners.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Website</td>
<td>The Million Hearts� Hypertension Control Challenge is open to public and private individual clinicians, practices, and health systems providing health care services to patients in a U.S. State or territory. Participants are required to treat all adult patients with hypertension in the practice seeking care, not select a subgroup of patients; must treat a minimum of 500 adult patients annually; have a hypertension control rate of at least 80% during the 12-month reporting period; have a data management system (electronic or paper) that allows for verification of data submitted; and be free from convictions or pending investigations of criminal and healthcare fraud offenses and must not have any serious sanctions for healthcare fraud or mis-prescribing of prescription medications.</td>
<td>Applications are initially evaluated by CDC staff for completeness and plausibility and any areas of concern are noted. A contractor experienced in validating hypertension control rates completes a background check on the applicants. Data validation is done by the contractor to determine if proper methods were used in calculation the hypertension control rate and various patient population characteristics such as the prevalence of hypertension in their population. Applicants must submit documentation that a random sample of the hypertensive population (up to 30 records) has a documented diagnosis of hypertension prior to the most recent blood pressure measurement.  CDC reviews all information from the contractor and submits the findings to a panel of judges who are CDC FTEs for determination of whether the applicants have satisfied the requirements for being a champion.  In 2018, applicants were required to have at least a hypertension control rate of 80%.</td>
<td> At the time of this report, the 2018 Million Hearts Hypertension Control Challenge had received 23 entries by participants. Champions will be announced in November 2018.</td>
<td>Agency resources included 5% FTE time; $40,000 cost to build the data collection website; $179,000 contractor cost for data validation.</td>
<td>Non-Federal Partners included the National Association for Chronic Disease Directors.</td>
<td>Hypertension is a leading risk factor for heart disease and stroke, the first and fifth leading causes of death in the U.S., respectively. Prevention of heart disease and stroke is a major focus for CDC�s National Center for Chronic Disease Prevention and Health Promotion. The CDC and the Centers for Medicare and Medicaid co-lead the the Million Hearts� initiative, with a mission to prevent a million heart attacks, strokes, and related conditions by 2022.</td>
<td>Ideas</td>
<td>Challenges are planned to launch in February of 2019-2022.</td>
</tr>
<tr>
<td>The Healthy Behavior Data Challenge</td>
<td>CDC</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The Healthy Behavior Data Challenge responds to the call for new ways to address the challenges and limitations of self-reported health surveillance information and tap into the potential of innovative data sources and alternative methodologies for public health surveillance. The Division of Population Health at the CDC wanted to explore new, innovative alternative approaches to gather key health-related information, data that are critical for effective and efficient public health program and policy planning and implementation. The Healthy Behavior Data Challenge supported the development and implementation of prototypes to use these novel methodologies and data sources (e.g., wearable devices, mobile applications, and/or social media) to enhance traditional chronic disease surveillance systems in the areas of nutrition, physical activity, sedentary behaviors, and sleep among the adult population aged 18 years and older.</td>
<td>Find and highlight innovative ideas; Solve a specific problem</td>
<td>The Behavioral Risk Factor Surveillance System (BRFSS) is the Nation&#39;s premier system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. Continued data collection methodological research is needed. In recent years, the reduced BRFSS funding did not allow for funding of innovative research in data collection methodology. Challenges and competitions enabled the Federal Government to tap into the expertise and creativity of the public in new ways. Challenges and competitions are high-risk, high-reward policy tools that can foster collaboration and participation in government activities through the process of co-creation. As an inducement of participation, challenges and competitions may offer a variety of prizes including cash, recognition, or the deployment of a winning solution. Federal agencies have explicit statutory authority to conduct Challenges and award prizes through the America COMPETES Act.</td>
<td>The total prize purse offered was $100,000 and the total amount awarded was $85,000. The Population Health Surveillance Branch (PHSB) awarded $5000 to each of the five Phase I winners. The Phase II winners were award $40,000 and $20,000 for first and second place, respectively. All prizes were awarded in FY18.</td>
<td>The Healthy Behavior Data Challenge was a main stage announcement at the 2017 Health Datapalooza on April 29, 2017. The Challenge was posted on Challenge.gov, Twitter, CDC Govdelivery for those interested in BRFSS, and on the CDC Website.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Other - Announcement of the Challenge at the 2017 Health Datapalooza</td>
<td>N/A</td>
<td>A committee of FTEs consisting of 13 staff members read and rated the submissions for Phase I. Each committee member provided an independent rating. The committee then met to achieve consensus on the winners of Phase I. A total of 6 FTEs reviewed the more limited submissions for Phase II. Each member provided independent reviews of each of the submissions and committee meetings were held to reach consensus.</td>
<td>Phase I (prototype development) received nine submissions between April 29 and July 31, 2017 and awarded $5,000 each to five challenge winners. Phase II (prototype implementation) received four submissions between October 26, 2017 and January 31, 2018, and awarded $40,000 and $20,000 to the first and second place winners, respectively.</td>
<td>The Innovation Fund (IFund) supported the prize money costs associated with the Challenge. PHSB was awarded $100,000 through the IFund to research an innovative data collection methodology using wearable devices. PHSB awarded $5,000 to each of the five Phase I winners. The Phase II winners were award $40,000 for 1st place and $20,000 for 2nd place. There were 3 FTEs that participated in the meetings to design the implementation of the Challenge. There were 13 FTEs that reviewed and scored the Phase I submissions. There were 6 FTEs that reviewed and scored the Phase II finalist. FTEs were able to complete these tasks without additional budget.</td>
<td>PHSB partnered with HHS, the Public Health Agency of Canada, Canadian Institutes for Health Research, and MaRS Discovery District.</td>
<td>Public health information is essential to plan, fund and evaluate health program outcomes, and to understand population health status, use of preventive measures and risk behaviors. Population health surveillance has tracked self-reported health behaviors using a variety of data collection modes in the past. These include personal interviews, telephone surveys, paper and pencil questionnaires and web-based data collection. These methods are both costly and time consuming and are subject to measurement error related to recall and selective bias. Wearable devices track a number of health behaviors in a passive manner which eliminates bias. The ability to track data using wearable devices apps, and other social media has the potential to decrease costs and eliminate some bias. This project will advance understanding of whether wearable device information can be used to supplement surveillance data. This information will forward the goal of efficient data collections methods which can be used to track healthy behaviors such as adequate sleep, physical activity and nutritious food consumption.</td>
<td>Software and apps; Ideas</td>
<td>Development of a challenge aimed at discovering and testing novel ways to validate the fruits and vegetable questions from the BRFSS using wearable devices.</td>
</tr>
<tr>
<td>2016 FDA Naloxone App Competition</td>
<td>Food and Drug Administration (FDA)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The primary objectives of the prize competition were to spur innovation around the development of an app that increases the likelihood of timely naloxone administration by connecting opioid users experiencing an overdose with nearby naloxone carriers; propose innovative solutions to the opioid overdose epidemic; and to foster the development of a multi-disciplinary community engaged in addressing this public health issue.</td>
<td>Find and highlight innovative ideas; Engage new people and communities</td>
<td>One of the goals was to spur innovation in this area and the opportunity to launch a crowd-sourced challenge best supported this goal.</td>
<td>The total prize purse offered and awarded was $40,000. Non-monetary incentives included the opportunity to participate in a Code-A-Thon with background presentations by experts from NIH, National Highway Traffic Safety Administration (NHTSA), the Substance Abuse and Mental Health Services Administration (SAMSHA), and FDA.</td>
<td>We used the Challenge.gov platform to receive submissions.  Participants were asked to submit a brief synopsis of their idea and a video detailing their prototype design.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies);</td>
<td>N/A</td>
<td>The judges were cross-agency. Prior to the in-person judging conference, all of the judges completed scoring sheets for the qualifying submissions. At the judging conference, each judge was provided the scores along with summary data on overall scoring for a submission. The judges reviewed any outliers and decided that the top six teams would move to the next phase of judging. Using a pairwise comparison for the top six submissions, the judges chose one winner.</td>
<td>N/A</td>
<td>To execute this Challenge, there were 2 FTEs devoted to all aspects of designing, executing, and closing out the Challenge. This included creating the websites, managing the promotion/marketing of the competition, responding to inquiries from interested participants, organizing the Code-A-Thon, convening the judging panel and handling the budget and administrative aspects of the competition. FY17 funding was $40,000, with $20,000 from the Office of Public Health Strategy and Analysis (OPHSA) and $20,000 from the Patient Affairs and Stakeholder Engagement (PASE) staff.</td>
<td>FDA received in-kind support from NIH, SAMSHA, and NHTSA in the form of presenters, judges, and participants at Code-A-Thon.</td>
<td>The 2016 FDA Naloxone App Competition aligned with agency�s mission to promote the safe use of opioids.</td>
<td>Software and apps</td>
<td>The Commissioner recently released FDA�s Strategic Policy Roadmap outlining four priority areas: (1) reduce the burden of addiction crises that are threatening American families; (2) leverage innovation and competition to improve health care, broaden access, and advance public health goals; (3) empower consumers to make better and more informed decisions about their diets and health; and expand the opportunities to use nutrition to reduce morbidity and mortality from disease; (4) strengthen FDA�s scientific workforce and its tools for efficient risk management. There may be opportunities in these areas for challenge competitions.</td>
</tr>
<tr>
<td>Bridging the Word Gap Challenge</td>
<td>Health Resources and Services Administration (HRSA)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The word gap is the difference between the number of words children from low-income families are exposed to as compared to children from high-income families. By age three, children from low-income families are hearing 30 million fewer words than those from higher-income families. This is staggering and it can have serious consequences. It can influence how young children develop language skills and affect their future performance in school and ultimately in their careers. The main goal of the Challenge was to spur the development of a low-cost, scalable, technology-based intervention that drives parents and caregivers to talk and engage in more back-and-forth interactions with their young children. But in addition to spurring innovation in technology-based solutions, the larger goals were also to raise awareness of the word gap issue, to spur innovation in the market, and to partner with non-traditional partners to address this issue through innovative means.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>While HRSA and others are actively investing in research to better understand the word gap issue, approaches to develop tools to encourage parents and caregivers to better interact with their children and expose them to more words are also needed. The Challenge was crafted to attract a wide range of innovators and to encourage development of low-cost, scalable technology-based interventions. These interventions would not only immediately benefit children from low-income families, but serve as tools to further research. It would also encourage more diverse approaches to increase the odds of breakthrough solutions. HRSA selected the challenge mechanism to solicit creative solutions and to attract new thinking and new combinations of talent to this issue. Additionally, as opposed to a grant or contract where an agency pays for the final product at the initial time of award, the HRSA wanted to establish the three-phase structure where applicants would learn what was working and what was not working, continuously incorporate user feedback, and refine each iteration until the best possible innovation was developed. This structure was highly effective and resulted in the development of tested, improved, human-centered final solutions. Semi-finalists, who would otherwise have been ineligible for grants or contracts, echoed this unique opportunity to participate in a Federal program. Winners represented, among others, Silicon Valley start-ups, local non-profits, and a group of former teachers turned farmers. One feedback quote we received from a semi-finalist highlights the role the challenge mechanism can play: �I wish more of the Federal Government were like this. I�ve submitted super long grant applications with bizarre formatting requirements. Due to their sheer length, I now disregard most such programs. In contrast, I have nothing but positive things to say about this experience. If the government really wants to attract innovation from places like Silicon Valley this is how you should do it.�</td>
<td>The total prize purse offered and awarded was $300,000. Non-monetary incentives included expert feedback, public recognition, access to one-on-one advisors, connections to stakeholders in the field, networking opportunities, and a live broadcast Demo Day.</td>
<td>HRSA Maternal and child Health Bureau (MCHB), as well as the contractor, Sensis, used social media, email outreach, partnerships with outside organizations, and live video streaming of the Demo Day to market the competition as well to promote the winners of each phase. The solicitation strategy reached diverse populations outside of the normal reach of government to garner Phase 1 submissions, including technology sector, start-ups, and communities of solvers. The Challenge was also promoted through existing grantee networks, which led to greater awareness of the challenge and submissions from academia. The nine challenge advisors widely promoted the Challenge through their professional networks, which include non-profit early childhood organizations, the technology field, and pediatric networks. The help of these advisors was critical to the success of outreach efforts.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The Challenge used the standard eligibility requirements as suggested in the HHS IDEA Lab guidance.</td>
<td>A Federal judging panel, with input from the challenge advisors, made the judging decisions in all phases. For Phase 1, both qualitative and quantitative goals were set that allowed for a cohort of the highest-scoring submissions to be discussed and then evaluated based on these scores in addition to qualitative considerations. For Phases 2 and 3, the judging was also based on a set of previously established criteria, and the judges and advisors used both quantitative and qualitative means to determine the winners. These evaluation methods have been highly effective. More details on the evaluation criteria for each phase are available on the website, but included elements such as accessibility, measurability, sustainability, impact, implementation, and evidence-base.</td>
<td>Of the 80 entries submitted for Phase 1 between November 9, 2015 and January 29, 2016, 10 winners were awarded $10,000 each. Of these 10 entries, five winners were awarded $25,000 each during Phase 2, which ran March 11 through August 11, 2016. One grand winner was awarded $75,000 in Phase 3 which ran September 26, 2016 through March 26, 2017.</td>
<td>HRSA MCHB worked with a contractor to implement the Challenge. Sensis was awarded an approximately $296,000 contract for 3 years in September 2014. In 2016, HRSA MCHB used $16,000 to fund the travel of the nine Phase 1 winners to attend and compete in the in-person Demo Day held at HHS, where the 5 winning teams were announced for Phase 2. These resources are separate and distinct from the prize purse. The Challenge utilized approximately 1.5 FTE. The source of funds is the Social Security Act, Title V, Special Projects of Regional and National Significance. Specifically, the amount allocated is as follows: Appropriation: 75-15�0354 Allotment: HRMCHB49000 Allowance: 1650100089 Amount: $300,000 (obligated).</td>
<td>As mentioned before, nine expert advisors provided insight and guidance on all aspects of the Challenge, including design and evaluation criteria, and who also served as individual mentors to the Phase 1 winners and judges. HRSA partnered with other agencies to staff the Federal judging panel; Federal judges included staff from the Department of Education, the Office of the Assistant Secretary for Planning and Evaluation, and the Administration for Children and Families. The primary lesson learned from these partnerships is the incredible value of the perspectives of a diverse set of expert advisors whose feedback to the teams greatly improved the quality of their interventions as they developed.</td>
<td>The mission of HRSA is to improve health and achieve health equity through access to quality services, a skilled health workforce and innovative programs. As part of HRSA, the mission of MCHB is to improve the health of America�s mothers, children, and families. The Challenge produced one grand winner and the seeding and support for five innovations that are available for widespread use through iTunes and Google Play, helping HRSA MCHB in addressing the word gap and in advancing the health and well-being of America�s children.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware</td>
<td>N/A</td>
</tr>
<tr>
<td>Addressing Opioid Use Disorder in Pregnant Women and New Moms</td>
<td>HRSA, Maternal and Child Health Bureau (MCHB)</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18.</td>
<td>Women who are pregnant or are new mothers struggling with opioid use disorder face a variety of barriers in obtaining safe and effective care and treatment including limited access to quality care, significant stigma, interactions with the criminal justice system, and limited social supports. Women and families in rural and under-resourced communities are particularly affected. The Challenge�s main goal is to improve access to quality health care, including substance use disorder and treatment, recovery, and support services for pregnant women with opioid use disorders, their infants, and families, especially those in rural and geographically isolated areas. The Challenge will solicit innovative technology solutions aimed at reducing the barriers to care experienced by pregnant women and new moms with opioid use disorder.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>This Challenge will support the development and testing of low-cost, scalable tech innovations to improve access to quality health care for pregnant women and new moms with opioid use disorder. The goal is to reach a diverse audience of solvers, and those who are not traditional HRSA stakeholders or grantees. Additionally, HRSA hopes to accelerate the proliferation of technology-based solutions in a more accelerated timeline than a contract or grant would allow.</td>
<td>The total prize purse offered is $375,000, which will be awarded in three phases. Phase 1 will include seven to ten winners each of whom will be awarded up to $10,000 for design. Phase 2 will include three to five winners each of whom will be awarded up to $25,000 for development and small-scale testing. The grand winner will be awarded up to $150,000 in Phase 3. The source of funds is the Social Security Act, Title V, Special Projects of Regional and National Significance. Specifically, the amount allocated is as follows: Appropriation: 75-17-0354 Allotment: HRMCHB49000 Allowance: 1650100089 Amount: $375,000 (obligated). Non-monetary incentives included expert feedback, public recognition, access to one-on-one advisors, connections to stakeholders in the field, and networking opportunities.</td>
<td>HRSA MCHB and the support contractor, Capital Consulting Corp, have used social media, email outreach, and partnerships with outside organizations to market the competition. MCHB also widely promoted the Challenge through existing grantee networks, with a goal of greater awareness of the challenge and submissions from academia. Ten challenge advisors widely promoted the Challenge through their professional networks, which include health systems, non-profit early childhood organizations, the technology field, and maternal and child health networks.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Eligibility requirements are the standard requirements for HHS challenges.</td>
<td>A Federal judging panel, with input from the challenge advisors will make the judging decisions in all phases. For each phase, the evaluation criteria will be adjusted, however the core subjects of accessibility, sustainability, impact, and innovation will be guides for the judging of submissions. Review criteria for all three Phases can be found at: https://mchbgrandchallenges.hrsa.gov/challenges/addressing-opioid-use-disorder-pregnant-women-and-new- moms/review-criteria.</td>
<td>Phase 1 submissions were collected September 19 through November 19, 2018, and the Challenge is ongoing.</td>
<td>HRSA MCHB worked with a contractor to implement the Challenge. Capital Consulting Corp was awarded a $1,9013,755.34 contract for 3 years in September 2017. The contract funding supports managing all four challenges, as well as the prize money for all three phases. Additionally, approximately 2.5 FTEs have been involved in managing the project.</td>
<td>MCHB partnered with the National Institutes of Health (NIH) and the Centers for Medicare and Medicaid Services (CMS) to develop the Federal judging panel. The expert panel incorporated experts in the field of maternal and child health, including policy makers, providers, consumer of services and Federal representatives. These individuals provided insight on all aspects of the design and evaluation criteria and will serve as advisors to the Phase 2 challenge winners. Their involvement is invaluable to the success of this initiative. The primary lesson learned from our partnerships is the incredible value of a diverse set of expert advisors. They provide unique insights into multiple aspects of the process and their feedback to the teams will greatly improve the quality of their interventions as they proceed through each stage of the Challenge. The partnerships have assisted in the promotion of the Challenge in all phases, particularly in the initial phase in attracting high-quality applicants.</td>
<td>Spurring the use of technology to address barriers to treatment and care will help advance HRSA and MCHB missions to improve the health of women and children, as well as achieve health equity through access to quality services. Along with the general population, there has been a rapid rise in opioid use among pregnant women in recent years resulting in a surge of infants born with Neonatal Abstinence Syndrome (NAS), increasing nearly fivefold nationally between 2000 to 2012. This increase has led to rising costs of care and gaps in services for this population. Medicaid payments to hospitals for NAS treatment services have increased from about $564 million to $1.2 billion nationwide, with more than 80 percent of NAS cases paid for by Medicaid. Despite this rising need, availability of services for pregnant and postpartum women is limited. Family-centered approaches to recovery address many of the barriers to care that women and families face, and research shows that women are more likely to seek and stay in treatment longer if they are able to maintain their caregiving role while in treatment, as well as either stay within the same treatment services or retain relationships with treatment providers throughout the provision of services. Technological innovations are poised to address these gaps and improve treatment and recovery services for pregnant women and new moms suffering from opioid use disorder.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware</td>
<td>Phase 1 winners will be selected in Winter 2018 and proceed to Phase 2. Phase 2 winners will be selected in Summer 2019 and proceed to Phase 3. The Phase 3 winner will be selected in Winter 2019.</td>
</tr>
<tr>
<td>Care Coordination for Children with Special Health Care Needs (CSHCN)</td>
<td>HRSA, MCHB</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18.</td>
<td>This Challenge will support the development and testing of low-cost, scalable, technology-based innovations to meet the needs of children with special health care needs (CSHCN) and their families. Innovations should improve the quality of care, enhance family engagement, and positively impact health care outcomes with the potential of saving costs to families, society, and to the health care system. An additional goal is to create partnerships between HRSA/MCHB and non-traditional partners to address issues through innovative technology solutions.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Engage new people and communities; Stimulate a market; Other - Improve health care delivery and experiences of health care</td>
<td>HRSA/MCHB sees the use of Federal prize challenges as a way to reach non-traditional partners�academics, entrepreneurs, private sector start-ups, research and development accelerators, non-profit organizations, the technology sector�to encourage new and different innovative approaches to address the need for cross-system information management for CSHCN in a way that our traditional grant programs would be unable to do. Given the complexity of the problem, solutions must come from multiple sources, involve multiple levels and sectors, and take into account the synergy of multiple strategies.</td>
<td>The total prize purse offered is $375,000, which will be awarded in three phases. Phase 1 will include seven to ten winners each of whom will be awarded up to $10,000 for the Design. Phase 2 will include three to five winners each of whom will be awarded up to $25,000 for the Development and Small-Scale Testing. The final winner will be awarded up to $150,000 in Phase 3. The Challenge utilized approximately 0.5 FTE. The source of funds is the Social Security Act, Title V, Special Projects of Regional and National Significance. Specifically, the amount allocated is as follows: Appropriation: 75-17-0354 Allotment: HRMCHB49000 Allowance: 1650100089 Amount: $375,000 (obligated). Non-monetary incentives included expert feedback, public recognition, access to one-on-one advisors, connection to stakeholders in the field, and networking opportunities.</td>
<td>HRSA/MCHB and Capital Consulting Corp have used social media, email outreach, and partnerships with outside organizations to market the competition. MCHB also widely promoted the Challenge through existing grantee networks and children with special health care needs stakeholder groups. The challenge advisors promoted the Challenge through their professional networks, which include health professional organizations, academia, family support and advocacy organizations, technology and health informatics fields, and maternal and child health networks.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Eligibility requirements are the standard requirements for HHS challenges.</td>
<td>A Federal judging panel, with input from the Challenge advisors will make the judging decisions across all phases. Review criteria for all three Phases are available at https://mchbgrandchallenges.hrsa.gov/care-coordination- cshcn/review-criteria.</td>
<td>Entries were submitted from August 30 through October 30, 2018, and the Challenge is ongoing.</td>
<td>HRSA MCHB has worked with a contractor to implement the Challenge. Capital Consulting Corp was awarded a $1,913,755.34 contract for 3 years in September 2017. The contract funding supports managing all four challenges, as well as the prize money for all three phases. Additionally, multiple Federal staff members have been involved in managing the project.</td>
<td>MCHB partnered with other agencies to develop the Federal judging panel; Federal judges include staff from the ONC and the AHRQ. Partnerships with the expert panel and Federal judges have been invaluable. The expert advisors and Federal judges actively participated in the challenge development process. These individuals provided guidance in all aspects of the Challenge design, including the development of submission and review criteria. Their feedback and identification of resources greatly improved the quality of the Challenge solicitation. The partnerships have ensured vital stakeholders� views and needs are incorporated into the challenges, and wide promotion of the Challenge in stakeholder communities. Challenge advisors have donated time throughout the duration of the Challenge in-kind.</td>
<td>This Challenge addresses HRSA�s mission which is to improve health and achieve health equity through access to quality services, a skilled health workforce and innovative programs. As part of HRSA, MCHB is committed to ensuring children with special health care needs, who account for approximately 19% of U.S. children, receive family-centered, community-based, coordinated care. This Challenge will address care coordination for CSHCN, particularly those with medical complexity, who often require complex and long-term health services, consume a disproportionate share of children�s health care dollars, and experience disparities in accessing care. Effective care coordination and communication with the efficient flow of information across providers and settings have been demonstrated to improve the quality and experiences of care. However, for CSHCN, communication across systems of care is often fragmented and uncoordinated. HIT tools and low cost digital interfaces that enable consolidation and sharing of health information for use by families will contribute to care coordination across settings and providers for optimizing quality of care and experiences of these children and their families</td>
<td>Software and apps; Technology demonstration and hardware; Analytics, visualizations, algorithms</td>
<td>Phase one winners will be selected in fall 2018. Phase 2 winners will be selected in spring 2019 and proceed to Phase 3. Phase 3 winner will be selected in fall 2019.</td>
</tr>
<tr>
<td>Remote Pregnancy Monitoring</td>
<td>HRSA, MCHB</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18.</td>
<td>Many women who are low-income in both rural and urban communities face barriers in accessing prenatal care, many of which continue into the postpartum period (i.e., up to 3 months post-birth). Personal barriers (e.g., work, childcare, transportation, education, culture, and language), health system barriers (e.g., hours of operation, and lack of services), and environmental barriers (e.g., location, and connectivity or cell phone coverage) make it difficult to attend prenatal and postpartum care appointments. The current paradigm for prenatal care includes 15 face-to-face visits with providers. The content of those visits includes critical medical services, risk assessments, patient education, and building of trusting patient-provider relationships. The main goal of this Challenge is to solicit innovative solutions that increase remote and virtual access to quality care for low-income pregnant women. Such innovations may include alleviating barriers to quality care and improving communications among patients, providers and/or broader support networks. Solutions will empower pregnant women with knowledge and tools to take charge of their health and their care.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>This Challenge will support the development and testing of low-cost, scalable tech innovations to improve the ability of prenatal care providers to monitor the health and wellbeing of pregnant women, while helping pregnant women to monitor their own health and make informed decisions about care. The goal is to reach a diverse audience of solvers, and those who are not traditional HRSA stakeholders or grantees. Additionally, HRSA hopes to accelerate the proliferation of technology-based solutions in a more accelerated timeline than a contract or grant would allow.</td>
<td>The total prize purse offered is $375,000 and has not yet been awarded. Phase 1 will include seven to ten winners, each of whom will be awarded up to $10,000 for design. Phase 2 will include three to five winners, each of whom will be awarded up to $25,000 for the development and small-scale testing. Phase 3 will award the final winner up to $150,000. The source of funds is the Social Security Act, Title V, Special Projects of Regional and National Significance. Specifically, the amount allocated is as follows: Appropriation: 75-17-0354 Allotment: HRMCHB49000 Allowance: 1650100089 Amount: $375,000 (obligated). Non-monetary incentives included expert feedback, public recognition, access to one-on-one advisors, connections to stakeholders in the field, and networking opportunities.</td>
<td>HRSA MCHB and Capital Consulting Corp, have used social media, email outreach, and partnerships with outside organizations to market the competition. We also widely promoted the Challenge through existing grantee networks, with a goal of greater awareness of the challenge and submissions from academia. The ten challenge advisors widely promoted the challenge through their professional networks, which include non-profit early childhood organizations, the technology field, and maternal and child health networks.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Eligibility requirements are the standard requirements for HHS challenges.</td>
<td>A Federal judging panel, with input from the challenge advisors will make the judging decisions across all phases. For each phase, the evaluation criteria will be adjusted, however the core subjects of accessibility, sustainability, impact, and innovation will be guides for the judging of submissions. Review criteria for all three phases are available at https://mchbgrandchallenges.hrsa.gov/challenges/remote-pregnancy-monitoring/review-criteria.</td>
<td>Entries were submitted between September and November 2018, and the Challenge is ongoing.</td>
<td>HRSA MCHB has worked with a contractor to implement the Challenge. Capital Consulting Corp was awarded a $1,913,755.34 contract for 3 years in September 2017. The contract funding supports managing all four challenges, as well as the prize money for all three phases. Additionally, multiple Federal staff members have been involved in managing the project. Approximately 2.5 FTEs were utilized in FY18.</td>
<td>HRSA partnered with other agencies to develop the Federal judging panel, which includes staff from NIH and CMS. The expert panel incorporated experts in the field of maternal and child health, including policy makers, providers, consumer of services and Federal representatives. These individuals provided insight on all aspects of the design and evaluation criteria and will serve as advisors to the Phase 2 challenge winners. Their involvement is invaluable to the success of this initiative. The primary lesson learned from these partnerships is the incredible value of a diverse set of expert advisors. They provide unique insights into multiple aspects of the process and their feedback to the teams will greatly improve the quality of their interventions as they proceed through each stage of the Challenge. The partnerships have assisted in the promotion of the Challenge in all phases, particularly in the initial phase in attracting high-quality applicants. Challenge advisors have donated time throughout the duration of the Challenge in-kind.</td>
<td>The mission of HRSA is to improve health and achieve health equity through access to quality services, a skilled health workforce and innovative programs. As part of HRSA, the mission of MCHB is to improve the health of America�s mothers, children and families. Recent trends in hospital closures in rural America increase the need for technological innovations that support remote monitoring of pregnant women.  Between 2004 and 2014, 179 rural counties (9% of all rural counties) lost access to in-county hospital obstetric services, and the percent of all rural counties in the U.S. that lacked hospital obstetric services increased from 45% to 54%, due to hospital and obstetric- unit closures. Many low-income women, in both rural and urban communities, do not access prenatal care. Technological advances have improved the ability of healthcare providers to monitor their patients from afar. Spurring the use of technology to address barriers to prenatal care will help advance HRSA and MCHB missions to improve the health of women and children, as well as achieve health equity through access to quality services.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware</td>
<td>Phase 1 winners will be selected in Winter 2018. Phase 2 winners will be selected in Summer 2019. Phase 3 winner will be selected in Winter 2019.</td>
</tr>
<tr>
<td>Using Technology to Prevent Childhood Obesity in Low-Income Families and Communities</td>
<td>HRSA, MCHB</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18.</td>
<td>The goal of this Challenge is to support the creation of multiple innovations to promote healthy weight for low-income children and families. The innovations will be community-driven, empowering to families, and technology-based. Potential areas of focus include (1) promoting access to healthy, affordable food, particularly for families and individuals who are food insecure or are living in food deserts; (2) supporting community-owned solutions that increase families&#39; knowledge and skills related to healthy eating and nutrition; (3) finding innovative ways that increase physical activity, while accounting for social, cultural, and environmental barriers in low-income communities; and (4) empowering families to achieve healthy eating practices, healthy lifestyles (including reduced screen time, reduced sedentary behaviors, and good sleep hygiene), and sustainable changes in the home environment, while accounting for limited access to healthy foods and other barriers in low-income communities.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity; Stimulate a market; Other - Improve health care delivery and experiences of health care</td>
<td>Innovative solutions and partnerships are necessary to tackle the many factors affecting childhood obesity in low-income families and communities. A challenge will maximize competition and spur innovation for and within communities in a cost-effective and accelerated timeframe. It will reach a broader stakeholder group and allow engagement of non-traditional partners who can bring new thinking to address this issue. Some examples include entrepreneurs, private sector start-ups, research and development accelerators, non-profit organizations, and the technology sector. A challenge will also provide support for the development of novel and innovative community-owned ideas through a pay-for-results mechanism, ultimately leading to the development of multiple scalable interventions. Childhood obesity is a complex and multi-faceted public health issue and solutions must come from multiple sources, involve multiple levels and sectors, and take into account the synergy of multiple strategies. By using a challenge mechanism, everyone can be a part of the solution and everyone has the potential to be a game changer.</td>
<td>The total prize purse offered is $375,000 and has not yet been awarded. Phase 1 will include seven to ten winners each of whom will be awarded up to $10,000 for design. Phase 2 will include three to five winners each of whom will be awarded up to $25,000 for development and small-scale testing. Phase 3 will award the final winner up to $150,000. The source of funds is the Social Security Act, Title V, Special Projects of Regional and National Significance. Specifically, the amount allocated is as follows: Appropriation: 75-17-0354, Allotment: HRMCHB49000, Allowance: 1650100089, Amount: $375,000 (obligated). Non-monetary incentives included expert feedback, public recognition, access to one-on-one mentoring with Expert Advisors, connection to stakeholders in the field, and networking opportunities.</td>
<td>HRSA MCHB and Capital Consulting Corp have used social media, email outreach, and partnerships with outside organizations to market the competition. We also widely promoted the Challenge through existing grantee networks and healthy weight stakeholder groups. The challenge advisors promoted the Challenge through their professional networks, which include health professional organizations, academia, non-profit organizations, technology and health informatics fields, and maternal and child health networks. The project lead also briefed policy makers and promoted the Challenge at the Back-to-School Congressional Workshop�Examining Solutions to Address Childhood Obesity: Policymaker and Community Perspectives. Coordinated by the Campaign to End Obesity, the workshop briefing convened thought leaders from Capitol Hill and the community to examine evidence-based solutions to address childhood obesity.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Congressional Workshop; Other - presentations to stakeholders</td>
<td>Eligibility requirements are the standard requirements for HHS challenges.</td>
<td>A Federal judging panel, with input from the challenge expert advisors will make all final decisions regarding winners across all Phases. Review criteria can be found at: https://mchbgrandchallenges.hrsa.gov/challenges/preventing-childhood-obesity/review-criteria.</td>
<td>Entries were submitted between July 24 and September 18, 2018, and the Challenge is ongoing.</td>
<td>HRSA MCHB has worked with a contractor to implement the Challenge. Capital Consulting Corp was awarded a $1,913,755.13 contract for 3 years in September 2017. The contract funding supports managing all four challenges, as well as the prize money for all three phases. Multiple Federal staff members have been involved in managing the project. The Challenge utilized 0.5 FTE in FY18.</td>
<td>HRSA partnered with the Centers for Disease Control and Prevention/Division of Nutrition, Physical Activity, and Obesity and the National Heart, Lung, and Blood Institute to staff the Federal judging panel. HRSA partnered with non-Federal partners including Robert Wood Johnson Foundation, The Nemours Foundation, Alfred I. Dupont Hospital for Children, Northeastern University, Louisiana Department of Health, University of Minnesota School of Public Health, and Northwestern University Feinberg School of Medicine to staff the Expert Advisory Panel. Partnerships with the expert advisors and Federal judges have been invaluable. The experts and Federal judges actively participated in the challenge development process. These individuals provided guidance in all aspects of the challenge design, including the development of submission and review criteria. Their feedback and identification of resources greatly improved the quality of the challenge solicitation. The partnerships have ensured vital stakeholders� views and needs are incorporated into the challenges and wide promotion of the Challenge in stakeholder communities. Expert advisors will also provide mentoring to semi-finalist winners, providing a non-financial incentive for potential solvers. Challenge expert advisors have donated time throughout the duration of the Challenge in kind.</td>
<td>HRSA�s mission is to improve health and achieve health equity through access to quality services, a skilled health workforce, and innovative programs. As part of HRSA, MCHB�s mission is to improve the health of America�s mothers, children, and families. Childhood obesity is a growing epidemic in the United States with low-income families and communities disproportionately affected. Individuals in low income communities are at increased risk for both food insecurity and obesity: they do not have sufficient opportunities to buy healthy, affordable food and this inequitable access to healthy food is a major contributor to health disparities. Potential solutions from this Challenge will target both access to healthy foods as well as innovations around healthy weight behaviors, with the goal to empower families in low-income communities to achieve healthy weight behaviors and make sustainable changes in the home environment. This Challenge will address childhood obesity prevention, particularly those in low-income communities, and supports several of HRSA�s goals: build healthy communities (goal 3), improve health equity (goal 4), and improve access to quality care and services (goal 1).</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware; Analytics, visualizations, algorithms; Other - A new or enhanced service; Other - a new channel; Other - a new platform or network; Other - a new system design</td>
<td>Phase 1 winners will be selected in Fall 2018. Phase 2 winners will be selected in Spring 2019. The Phase 3 winner will be selected in Fall 2019.</td>
</tr>
<tr>
<td>Rare Diseases are not Rare! Challenge</td>
<td>National Institutes of Health (NIH), National Center for Advancing Translational Sciences (NCATS)</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18.</td>
<td>NCATS is seeking innovative ways to communicate with and educate people about rare diseases through social media or art. The goal of this Challenge, which is being led by NCATS&#39; Office of Rare Diseases Research, is threefold: (1) raise awareness for all rare diseases in a collective manner, (2) bring attention to the many people with rare diseases, and (3) highlight the need for research and the development of new treatments.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Inform and educate the public; Engage new people and communities</td>
<td>Challenge and prize competitions are an important, cost-effective tool in Federal agencies� innovation toolboxes. They identify and reward creative solutions to an array of problems by utilizing the talents of citizen solvers and crowdsourcing. These competitions use cash prizes and non-cash incentives to advance the mission, reaching beyond the usual suspects to inspire inventive approaches to issues, effective public engagement, and new ideas and technologies. Prizes offer the option of involving the public in judging, a feature that is especially important for competitions such as this.</td>
<td>The total prize purse offered is $5,000 to be shared among three awardees. Additionally, the winners and ten honorable mentions will be posted on the NCATS website.</td>
<td>NCATS uses the following vehicle to publicize the opportunity to increase the number and quality of submissions: (1) publish a notice in the NIH Guide to Grants and Contracts to announce the competition, (2) post the notice on the government-wide Challenge.gov site, (3) post the Challenge on the NCATS challenges website, (4) link to the Challenge page from the NCATS funding opportunities page, (5) announce the Challenge at professional meetings, (6) advertise via social media (Twitter, e-newsletters, etc.), and (7) announce the Challenge at NCATS Day.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release</td>
<td>N/A</td>
<td>The evaluation will be conducted by a panel of Federal and non-Federal judges with expertise directly relevant to this Challenge. Entries will receive up to five points for each of the following criteria: (1) how creative and original is the entry?, (2) to what extent does the entry address rare diseases collectively?, and (3) how likely is it that the entry could be an effective communication vehicle? Will it appeal to a broad audience? Is it easy to disseminate?</td>
<td>Entries were submitted between September 30 and October 31, 2018.</td>
<td>The Challenge utilized approximately 2.5 days of one FTE in FY18.</td>
<td>N/A</td>
<td>The general purpose of NCATS is to transform the translational process so that new treatments and cures for diseases can be delivered to patients faster by understanding the translational process to create a basis for more science-driven, predictive and effective intervention development for the prevention and treatment of all diseases. This Challenge will lead to innovative ways to communicate with others and to educate people about rare diseases through social media and/or art.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas</td>
<td>N/A</td>
</tr>
<tr>
<td>NEI 3-D Retina Organoid Challenge (3-D ROC)</td>
<td>NIH, National Eye Institute (NEI)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The goal of this Challenge was to develop innovative ideas to create human three-dimensional (3D) retinal tissues that can faithfully model ocular disease or develop drugs. The current animal models and cell lines used to screen drugs and model disease are of limited utility. Using advanced tissue engineering techniques in 3D bioprinting and microfluidics, these improved human retina models will allow new insights into the biology and pathology of various vision impairments and diseases. NEI expected the Challenge to nucleate multidisciplinary teams of bioengineers, materials scientists, chemists, and vision scientists and help breakdown silos in various sub-specialties and help transform the way vision research is conducted.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Engage new people and communities</td>
<td>House Appropriations FY 2016 Report language directed NEI �to create a challenge program to advance the speed of basic research to cure retina disease.� Developing retinal organoids is an unmet research need that will speed basic and therapeutic research. The challenge vehicle would spur interest from researchers from outside the vision field especially from bioengineers, material scientists, stem cell biologists, and developmental biologists. It would also encourage partnerships with industry in order to allow the commercialization of new 3D culture platforms that could promote the discovery of treatments to a variety of retinal diseases.</td>
<td>The total prize purse offered was $100,000 and the total amount awarded was $90,000. The Challenge also offered the opportunity to be featured on the NEI website.</td>
<td>NEI solicited submissions by attending several conferences including the annual meetings of the Tissue Engineering and Regenerative Medicine International Society, the Society of Developmental Biology, the Association for Research in Vision and Ophthalmology (ARVO), and a Cold Spring Harbor Laboratory course �Vision: A Platform for Linking Circuits, Behavior &amp; Perception.� After the Challenge launched, NEI ran an online advertising campaign which targeted articles from journals across the Nature Publishing Group platform and placed an announcement of the Challenge in an e-alert for Nature Cell Biology subscribers. NEI also had an active social media awareness campaign through the NEI Twitter account.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Online advertising with the journal Nature</td>
<td>Although all researchers were eligible, NEI tried to attract bioengineers and other neuroscientists outside of the vision field. Participants were encouraged to form multidisciplinary teams via an online forum where they could have a profile and post their interests and expertise. Most teams that participated included at least one vision researcher.</td>
<td>NEI used a technical review panel to help review the submissions and provide the expertise about the methods and technology proposed in the submissions. They provided comments on the submissions to the Federal judges who were drawn from a variety of institutes and other agencies, which included the National Science Foundation and the Department of Defense.</td>
<td>Of the 13 entries submitted by 50 participants between June 1 and August 1, 2017, one prize was awarded to one winner.</td>
<td>A full time employee was recruited to manage the Challenge competition. A working group of about 6 NEI staff convened about twice a month to help with the activities of the Challenge such as developing advertising materials, coordinating outreach activities, and organizing review meetings. The initial amount obligated in FY17 was $100,000, which included $10,000 for a trainee category. The Challenge utilized 2 FTEs and funded $5162.52 for online and print advertising in FY17.</td>
<td>NEI partnered with ARVO for outreach purposes, as the majority of vision researchers are ARVO members. NEI sent information about the Challenge to ARVO members and gave a presentation at the ARVO annual meeting (estimated value: $1000).</td>
<td>NEI was established to protect and preserve the vision of the American people. As an institute under NIH, NEI conducts and supports research that helps prevent and treat eye diseases and other disorders of vision. This Challenge served to develop methodology and technology to advance the speed of basic research to treat retina disease.</td>
<td>Ideas; Scientific</td>
<td>From the submissions received through this initial ideation Challenge, the development of more robust retina organoids was deemed feasible to accomplish within two to three years. This prompted the development of a follow-up challenge in FY18 that will go until March 2020 to spur the creation of retinal organoids that could better model disease and test drugs.</td>
</tr>
<tr>
<td>NEI 3-D Retina Organoid Challenge (3-D ROC) 2020</td>
<td>NIH, NEI</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>The goal of the 3D Retinal Organoid Challenge 2020 is to stimulate research into making more robust and reproducible retinal organoids to better model retinal disease or to test drugs. NEI hopes to draw attention to this goal and to recruit researchers from outside the vision field. NEI encouraged support from companies to help the participants accomplish their research without Federal funding.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>House Appropriations FY 2016 Report language directed NEI �to create a challenge program to advance the speed of basic research to cure retina disease.� Developing retinal organoids is an unmet research need that will speed basic and therapeutic research. The challenge vehicle would spur interest from researchers from outside the vision field especially from bioengineers, material scientists, stem cell biologists, and developmental biologists. The Challenge would also encourage partnerships with industry in order to allow the commercialization of new 3D culture platforms that could promote the discovery of treatments to a variety of retinal diseases.</td>
<td>The total prize purse offered is $1,000,000. In the first round, up to six awards of up to $100,000 were to be granted in Fall 2018. The final round of prizes will be awarded in Spring 2020 and will include up to three awards totaling $400,000 and may include any additional money not awarded from the first round. Non-monetary incentives included opportunities to work with companies and receive discounts on reagents, services, and equipment. Inventors also retain intellectual property on final products, which may have significant commercial and research value.</td>
<td>NEI solicited submissions by attending or sending flyers or slides to numerous conferences and meetings. NEI also sent emails to various listservs, posted on social media and notified other relevant NIH grantees through program officers at other institutes.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Although all researchers were eligible, NEI tried to attract bioengineers and other neuroscientists outside of the vision field. Participants were encouraged to form multidisciplinary teams via an online forum where they could have a profile and post their interests and expertise.</td>
<td>NEI will use a technical review panel to help review the submissions and provide the expertise about the methods and technology proposed in the submissions. They will provide comments on the submissions to the Federal judges who will be drawn from a variety of institutes and other agencies involved in tissue engineering.</td>
<td>First round entries were submitted between September 4 and October 1, 2018. Final submissions will be submitted between February 14 and March 2, 2020.</td>
<td>A full time employee managed the Challenge competition. A working group of about 6 NEI staff convened about once a month to help with the activities of the Challenge such as developing advertising materials, coordinating outreach activities, and organizing review meetings. The amount obligated in FY18 was $1,000,000. The Challenge utilized 2 FTEs in FY18.</td>
<td>NEI has developed informal partnerships with corporate sponsors who have pledged to offer discounts or in-kind contributions to challenge participants in terms of products, services, or consulting. Two companies have signed Memoranda of Understanding to pledge support that would be in excess of $50,000 to participants. In-kind services or resources have not yet been utilized by participants. Non-Federal partners did not give directly to prize funding.</td>
<td>NEI was established to protect and preserve the vision of the American people. As an institute under NIH, NEI conducts and supports research that helps prevent and treat eye diseases and other disorders of vision. This challenge program serves to catalyze technological and methodological advances that will improve our understanding of retinal disease and enable the development of treatments.</td>
<td>Scientific</td>
<td>No additional challenges are planned for this institute until this Challenge has completed.</td>
</tr>
<tr>
<td>Improving Care for People with Alzheimer�s Disease and Related Dementias using Technology (iCare-AD/ADRD) Challenge</td>
<td>NIH</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18.</td>
<td>Navigating the complex U.S. healthcare system can be challenging for persons with dementia and their caregivers. They must pursue an uncertain course of care, of unknown duration, across different care settings and interact with many different types of care providers and interventions. This Challenge is intended to stimulate innovation in the use of technology to improve care coordination, navigation, and aid with the care experience, so that overall dementia care quality is improved. This Challenge invites solutions that involve the development of an IT system-level, computer, mobile, or other form of technology-based application. The solutions may involve creation of a new technology application, or modification or novel implementation of an existing technology. The solutions may be targeted at consumers (persons with dementia or caregivers), healthcare providers, healthcare service organizations, health systems, or community, local, and State governments. Specific methods for stimulating uptake and use of the solutions must be included with the proof-of-concept demonstrations.</td>
<td>Develop technology</td>
<td>Traditional mechanisms, such as grants and contracts, would not produce the desired innovation at such a speed. Additionally, this Challenge encourages multi-stakeholder connections and adoption of the most relevant technological innovations to close the identified gap in dementia care quality.</td>
<td>The total prize purse offered is $400,000. Up to three winners will be awarded. The first, second, and third-place winners will receive up to $250,000, $100,000, and $50,000, respectively. Additional solvers may be recognized with non-monetary awards. Awards are not expected to be distributed until FY19. The prize funds for this Challenge were obligated in FY18 from the National Institute on Aging�s (NIA) annual appropriations.</td>
<td>NIA promoted the iCare-AD/ADRD Challenge widely, to many public sectors and via a number of vehicles, including but not limited to outreach through the Advisory Council on Alzheimer�s Research, Care, and Services; NIH-wide SBIR networks, which reached over 20,000 recipients; and through Challenge.gov�s government-wide listserv. NIA also used its relationships with a number of stakeholder groups to publicize the challenge. NIA will consider the prize submissions generated (e.g., number, quality, relevance) to gauge the effectiveness of these outreach methods, and the institute will use this information to inform future prize activities.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Examples of possible solvers include small businesses, individuals�including but not limited to people living with dementia and caregivers�midsize to large technology companies, health insurance companies, electronic health record (EHR) vendors, students working collaboratively across multiple disciplines, health systems, states, and counties implementing care coordination programs.</td>
<td>A panel of Federal employees serving as judges will review the Challenge submissions using the following criteria: (1) creativity and innovation (20%), (2) rationale and potential impact (20%), (3) value to relevant stakeholders (20%), (4) usability (20%), and (5) functional product feasibility (20%)</td>
<td>Entries will be submitted between September 2018 and June 2019.</td>
<td>In FY18, the only resource used for the iCare-AD/ADRD Challenge was FTE time, estimated at 0.048 FTE. This Challenge was launched at the end of FY18, thus most of the activities in FY18 included agency planning and promotion of the Challenge. Examples of activities include drafting challenge ideas, soliciting public input, analyzing public comments, obtaining agency clearance, and posting challenge information via the internet.</td>
<td>N/A</td>
<td>Per 42 U.S.C. 285e, the mission of NIA is to conduct and support biomedical, social, and behavioral research, training, health information dissemination, and other programs with respect to the aging process and the diseases and other special problems and needs of the aged. As many as 5.5 million Americans age 65 and older are estimated to be living with Alzheimer�s disease, the most common form of dementia. Many more under age 65 are also affected. In addition, many thousands more have Alzheimer�s disease-related dementias. Effective dementia care management has been shown to improve outcomes such as reducing behavioral and psychological symptoms of dementia and lower health care costs by reducing emergency department visits, inpatient hospitalizations, and some readmissions. Research based models of dementia care have evolved in recent years and have the potential to improve outcomes. This Challenge is intended to stimulate innovation in use of technology to improve care coordination and/or navigation so that overall dementia care quality is improved, thus advancing the NIA mission described above.</td>
<td>Software and apps</td>
<td>In the next two fiscal years, the field of Alzheimer�s disease and related dementias will continue to present opportunities for prize competitions. NIA will gauge the benefits of utilizing this mechanism and more traditional funding sources when setting priorities and helping spur innovation in the field.</td>
</tr>
<tr>
<td>Open Science Prize</td>
<td>NIH</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The goal of the Open Science Prize (OSP) was to stimulate the development of novel and ground-breaking tools and platforms to enable the reuse and repurposing of open digital research objects (e.g., data, publications, and other research outputs) relevant to biomedical or health applications. The prize also aimed to forge new international collaborations to bring together open science innovators from the United States and abroad to co-develop services and tools of benefit to the global research community.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity; Stimulate a market</td>
<td>The use of prize competitions as a funding mechanism has several advantages over traditional funding mechanisms, such as grants and contracts. Awards are only given to successful solutions, solvers can include anyone with the skills and knowledge to address the specified solution, and the time and expense to run a prize competition is typically much less than a traditional funding mechanism. For example, traditional NIH grants such as the Small Business Innovation Research and Small Business Technology Transfer or Research Project Grant (RO1) funding mechanisms tend to favor academic researchers (investigator background and research environment are two criteria in the peer-review process) and typically take a significant amount of time to produce results. The OSP was open to all interested solvers, and the entire process was completed in two years from conceptualization to awarding of the grand prize. Finally, co-funding collaborative projects with international funders using traditional government funding mechanisms can be complicated compared with prize competitions. The OSP provided an administrative mechanism through which three partnering agencies could share funding responsibilities and in-kind resources.</td>
<td>The total prize purse offered was $710,000, including six first round prizes at $80,000 each and one grand prize of $230,000. The National Institutes of Health Big Data to Knowledge Initiative provided $355,000  and $355,000 came from its partner, the Wellcome Trust. A portion of the funds ($80,000) was contributed to the Wellcome Trust by the Howard Hughes Medical Institute (HHMI). The NIH funded the U.S. solvers only. The other partners funded the international solvers. The prize money from the NIH was awarded to the prize winners through a contract vehicle NIH established with the Capitol Consulting Corporation to oversee prize administration. Phase 1 prizes were awarded in May 2016. The NIH portion was $240,000 in FY16, awarded to U.S. the solvers by the contract vehicle. The Phase 2 grand prize was awarded in February 2017. The NIH portion was $115,000 in FY17, awarded to the U.S. solvers through the contract vehicle. All six finalists were invited to showcase their applications at a symposium held in Bethesda, MD in December 2016. They were also invited to showcase their winning submissions on the Open Science Prize Website.</td>
<td>The NIH utilized social media, email outreach, webinars, and press releases in its initial marketing of the prize. Solicitations occurred during FY16. During FY17, an important aspect of the outreach strategy has been showcasing results at public events that garner media attention. Also notably, in FY17, during Phase 2 of the prize competition, NIH showcased the finalists� solutions at the Big Data to Knowledge Open Data Science Symposium, a full-day event celebrating uses of open data and open science at NIH. For this event, NIH utilized live streaming and social media as way of engaging diverse audiences. NIH and Wellcome Trust also utilized this meeting to launch five weeks of public voting as a way to engage diverse audiences and expose the public to the prototypes developed by the six finalist teams. Throughout this prize competition, NIH has worked closely with partner organizations such as the Federal Community of Prizes and Challenges, and open data and open science organizations to help educate the public about the prize and the resulting solutions.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The Prize was open to international teams, whose membership had to include at least one individual or group based in the United States, and at least one individual or group based in another country. There was no limit on the size of teams, and teams could include individuals and groups based at academic research institutions, not-for-profit bodies, and private sector organizations.</td>
<td>Participants were given wide latitude to choose their project and build their prototype accordingly. Judging was based on the following criteria:  (1) Impact: What level of impact and benefit could the proposal�if successful�deliver to the research enterprise and health/healthcare research? Does the proposal/prototype address implementation in multiple settings in a cross-national manner?, (2) Innovation: What level of creativity and technological innovation does the entrant demonstrate?, (3) Originality: Is the technology or service genuinely novel and targeting an unmet need? Has the applicant evaluated other existing or alternative approaches, or delineated their approach in comparison to existing approaches (if applicable)?, (4) Technological viability: Is the approach proposed viable? Can the proposed technology deliver?, (5) Resource feasibility: Does the team have the required skills and resources?, (6) Advancement of Open Science: To what extent does the proposal/prototype advance the goals of open science in biomedical/health research, and fulfill the goals of openness in terms of the product and way of working? To what extent would it move the field forward?<br/>Judges from NIH and the partnering organizations scored all of the Phase 1 and Phase 2 solutions using a five-point scale, based on these factors. The most promising solutions were submitted to a panel of external advisors for additional review. After considering the panel�s viewpoints, NIH, Wellcome Trust, and HHMI judges selected the top six solutions for Phases 1 and 2.</td>
<td>Of the 96 Phase 1 submissions entries submitted by 435 solvers from 45 countries between October 20, 2015 and February 29, 2016, six prizes of $80,000 each were awarded to six teams consisting of 33 total individuals. In Phase 2 (May 9, 2016 through December 1, 2017), a single grand prize was awarded on February 29, 2017.</td>
<td>The NIH utilized one and a half staff persons to oversee conceptual development of the prize, develop judging materials and judging processes, and coordinate all promotional and outreach activities. The Wellcome Trust utilized roughly the same number of employees for these tasks, focusing particularly on development of the website and on- line tools such as the public voting site. NIH utilized a contractor to assist with the logistical aspects of the prize, including meeting coordination, webinars, travel of participants to events and payment of prizes to winning teams. NIH�s share of the grand prize was $115,000. In addition, NIH established a multi-year contract with Capitol Consulting Corporation, spending approximately $50,000 for prize administration in FY17.</td>
<td>This Prize was a collaboration between the Wellcome Trust and HHMI. The partners provided substantial in-kind support, expert advice, marketing, and outreach. The Wellcome Trust maintained the voting and submissions portal. The partners co-authored an article detailing their lessons learned from the OSP (see https://doi.org/10.1371/journal.pbio.2002617). The seven findings were: 1) partnerships are always more time-consuming than first imagined; 2) a two-step funding model is an effective way to encourage innovation whilst minimizing the cost; 3) public participation is a good way to increase the reach of the competition and generate interest and enthusiasm for open data; 4) proposals at differing stages of development were received; 5) setting a broad remit allowed a wide-range of ideas to be proposed, but the six finalists naturally did not fully represent the breadth of the ideas proposed; 6) the international funding partnership increased both the global reach of the competition as well as the resources available; and 7) it is recommended that funders consider ways to incentivize the sustainability of tools and technologies that leverage open biomedical data to improve biomedical research and public health.</td>
<td>The importance of open data and open science for NIH is reflected in its strategic plan, which states, �NIH will serve as a focal point for catalyzing this historic research opportunity, continuing to leverage its roles as an influential convener and major funding agency to encourage rapid, open sharing of data and greater harmonization of scientific efforts.� Wellcome Trust has long championed open scientific research, including open access to publications and, more recently, the sharing of research data sets and computer code. Similarly, HHMI has a long-standing policy that strongly encourages their investigators to make publications publicly available and make data and other research materials available to the other scientists. The Open Science Prize is strongly aligned with NLM�s recently released Strategic Plan, titled �A Platform for Biomedical Discovery and Data-Powered Health,� which includes a strategic goal to �reach more people in more ways through enhanced dissemination and engagement pathways� and a distinct objective to �foster open science policies and practices.�</td>
<td>Software and apps; Ideas; Technology demonstration and hardware; Analytics, visualizations, algorithms; Scientific</td>
<td>While NLM has no imminent plans for a follow-up prize, the agency has a strong commitment to furthering open science policies and practice. It is conceivable that NLM may wish to engage in another open innovation activity with these or other partners given the success of this effort in advancing open science.</td>
</tr>
<tr>
<td>Storytelling About Wellness in Tribal Communities</td>
<td>NIH</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The goal of this Challenge was to develop a brief digital story (i.e., a video) that communicates how traditions and heritage promote health in American Indians and Alaska Natives (AI/AN). The videos would augment the agency�s ongoing efforts to inform a strengthened research portfolio that advances AI/AN research needs. This challenge was also designed to attract more interest and attention to the research needs of these communities and communicate these needs in a culturally appropriate manner.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>To commemorate Native American Heritage Month, NIH celebrated the use of storytelling to convey stories of health and wellness. Use of this mechanism allowed the agency to reach out to non-traditional audiences that would not necessarily be immediately eligible for a grant or contract.</td>
<td>The total prize purse offered and awarded was $10,000. The first place winner was invited to a meeting of the NIH Tribal Advisory Committee.</td>
<td>The Challenge was announced in the Federal Register; on Challenge.gov; on the Division of Program Coordination, Planning, and Strategic Initiatives� website; a blog post from the NIH Director; and through flyers made available at meetings and downloaded from the internet. A number of groups further disseminated the Challenge to listservs and to interested parties.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>The NIH outlined eligibility requirements in the Federal Register and included, but not limited to U.S. citizens or businesses, an adult 18 years of age or older, not an employee of NIH, among other things. The announcement was clear that Tribal governments and employees, and community members, schools, organizations, and others were eligible to participate.</td>
<td>NIH evaluated the submissions in accordance with judging criteria stated in the Federal Register announcement. Judges reviewed the submissions online and scored through an electronic scoring system. The approach generally worked well for the number of submissions received. This approach to judging may not necessarily be scalable to a larger number of submissions.</td>
<td>Of the 32 entries submitted between November 28, 2016 and January 31, 2017, five prizes were awarded to five winners.</td>
<td>The NIH used approximately 0.1 FTE to design, announce, judge, and otherwise administer the challenge. In addition, NIH engaged a contractor to assist in developing the online scoring system. Their effort was approximately $1,000. Several NIH employees of varying grade levels were also involved in the judging panel.</td>
<td>N/A</td>
<td>This Challenge is consistent with the statutory authority of the Division of Program Coordination, Planning, and Strategic Initiatives, National Institutes of Health. The Division identifies research that represents important areas of emerging scientific opportunities, rising public health challenges, or knowledge gaps that deserve special emphasis and would benefit from conducting or supporting additional research that involves collaboration between two or more national research institutes or national centers, or would otherwise benefit from strategic coordination and planning. As part of this authority, the Division oversees the Tribal Health Research Office, whose function includes managing information dissemination related to tribal health research coordination. The winning videos submitted for this Challenge will help communicate about health and wellness of AI/AN communities. AI/AN communities have higher rates of diseases and disorders across several areas of health such as: diabetes, chronic liver disease, certain cancers, mental health, and substance use. Factors known to contribute to health status and disparities are complex, and include social and historical factors, ethnicity, culture, historical trauma, socioeconomic status, gender/sex, age, geographical access to care, and levels of insurance as well as underlying biology, physiology, and genetics. The NIH hopes that this Challenge will incentivize the public to showcase the strengths and resilience of these communities, their heritage and traditions, and how their culture promotes their health and well-being.</td>
<td>Creative (design &amp; multimedia)</td>
<td>NIH does not have any related plans in this area at the moment.</td>
</tr>
<tr>
<td>A Wearable Alcohol Biosensor: A Second Challenge</td>
<td>NIH, National Institute on Alcohol Abuse and Alcoholism (NIAAA)</td>
<td>COMPETES Authority</td>
<td>This competition was underway in FY17, and was completed in FY18.</td>
<td>The goal of the Challenge was to produce a prototype of a sleek, unobtrusive smart electronic device incorporated into clothing or an accessory and capable of monitoring blood alcohol non-invasively and in real time. Highest priority was given to devices that used non-invasive technologies to measure alcohol concentration in blood or interstitial fluids, as opposed to detection of alcohol exuded through the skin in sweat or vapor. Such a device would significantly advance current alcohol monitoring capabilities. The envisioned wearable alcohol monitors would serve useful purposes in alcohol research and treatment settings, could play a role in public safety, and would be of interest in the consumer market to individuals interested in tracking personal health parameters. Designs could have emphasized any of these potential market subsets or sought to be broadly marketable.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Stimulate a market</td>
<td>The prize competition provided a mechanism to enlist innovators and talented people who would not typically apply for a NIH grant and encourage them to present novel and innovative solutions to real-time alcohol measurement in humans. Enlisting individuals beyond the traditional NIAAA grantee community was especially beneficial for the biosensor challenge where engineering expertise was needed and is not typically found. The competitive nature of the Challenge broadened awareness about alcohol research needs within and beyond the alcohol research and treatment communities.</td>
<td>A total of $300,000 was obligated from the unconditional gift funds for the purpose of a first ($200,000) and second prize ($100,000). After judging, NIAAA determined that only one entry met the requirements for an award. Following consultation with NIH general counsel, NIAAA confirmed its ability to award a lessor amount of $100,000 to the entrant who held the most promise for achieving the goals of the competition. The remaining $200,000 was de-obligated and returned to the unconditional gift fund.</td>
<td>NIAAA issued a NIH press release, posted an announcement on the Challenge.gov website, published an announcement video on the NIAAA website, issued tweets from the NIAAA twitter account, and notified contacts in media outlets from the first competition, academic institutions and engineering circles. Two NIAAA staff members attended conferences to publicize the availability of the Challenge and assess other potential technologies that might be useful in meeting the alcohol measurement goals. One member spoke at the Consumer Electronic Show and the technology portion of the South By South West conference. These activities resulted in promising contacts for future collaborations and introduced NIAAA and its mission to technologists and engineers, some of whom are considering applying for NIAAA small business grants.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Other - Presentations at conferences</td>
<td>America COMPETES Act requirements limit the Challenge to U.S. citizens and U.S.-based companies. Within those parameters, this Challenge was open to individuals, small businesses, academic groups, and non-profit organizations.</td>
<td>Submitted solutions were judged on the following criteria: (1) achievement of real time-monitoring and quantification of blood alcohol level; (2) collection and interpretation of data; (3) elimination of as much of the biological and device-related delays as possible through innovative, validated, and verifiable techniques; (4) secure storage or wireless transmission of data to a smartphone or other device; (5) operation from a dependable and rechargeable power source; (6) plans for process of manufacture and likelihood of bringing the product to market; and (7) appeal and acceptability to wearers. The functionality of prototypes was evaluated by NIAAA in a laboratory setting. Judging was done by a panel of NIH employees selected by NIAAA with knowledge in alcohol pharmacokinetics, chemistry, engineering, information technology and system security, behavioral and social sciences, and wearables.</td>
<td>Of the five entries submitted by between December 10, 2016 and May 15, 2017, one prize were awarded to one winner.</td>
<td>The NIAAA staff involved in the prize competition contributed approximately 248 hours of effort as this round of the competition was built upon the previous year�s challenge. For this version of the competition, the largest amount of NIAAA staff time was dedicated to attending and presenting at technology conferences, estimated at $7107.33 in FY17. These activities raised awareness of the Challenge and the broader mission of NIAAA. The prize money was obligated from NIAAA�s unconditional gift funds.</td>
<td>N/A</td>
<td>The mission of the NIAAA is to generate and disseminate fundamental knowledge about the effects of alcohol on health and well-being, and apply that knowledge to improve diagnosis, prevention, and treatment of alcohol-related problems, including alcohol use disorder, across the lifespan. The development of alcohol biosensors that can be worn and used by individuals in the course of their daily lives will advance NIAAA�s mission by providing more accurate tools for alcohol researchers, clinicians, and therapists and individuals seeking healthy lifestyle choices. Current technologies for continuous alcohol monitoring, which are commonly used in the criminal justice system, are effective but cumbersome. Moreover, they only take readings every 30 minutes, and they reflect blood alcohol content as it was 60�90 minutes prior to assessment, not in real time. Recent developments in electronics, miniaturization, wireless technology, and biophysical techniques of alcohol detection in humans increase the likelihood of successful development of a useful real-time alcohol biosensor. The NIAAA believes that this Challenge will further stimulate investment from public and private sectors in the development of real-time alcohol biosensors that will be appealing to individuals, treatment providers, and researchers and will continue to further NIAAA�s mission to improve diagnosis, prevention, and treatment of alcohol related problems.</td>
<td>Software and apps; Technology demonstration and hardware; Analytics, visualizations, algorithms</td>
<td>NIAAA is looking for novel means to engage individuals and institutions in the miniaturization of a spectroscopic solution for blood alcohol monitoring; establishing biomarkers for alcohol research; and novel interventions through technology to assist persons with problem drinking.</td>
</tr>
<tr>
<td>Design by Biomedical Undergraduate Teams (DEBUT)</td>
<td>NIH, National Institute of Biomedical Imaging and Bioengineering (NIBIB)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>The DEBUT Challenge was open to teams of undergraduate students working on projects that develop innovative solutions to unmet health and clinical problems, the proposed goals are: (1) to provide undergraduate students valuable experiences such as working in teams, identifying unmet clinical needs, and designing, building and debugging solutions for such open-ended problems; (2) to generate novel, innovative tools to improve healthcare, consistent with NIBIB�s purpose to support research, training, the dissemination of health information, and other programs with respect to biomedical imaging and engineering and associated technologies and modalities with biomedical applications; (3) to highlight and acknowledge the contributions and accomplishments of undergraduate students; and (4) to encourage students to think about the patentability, market potential, and economic feasibility of the solutions they developed.</td>
<td>Find and highlight innovative ideas; Develop technology; Engage new people and communities; Build capacity; Other - Educate Biomedical Engineering Students</td>
<td>Prizes offer a way to directly incentivize undergraduate students in biomedical engineering and physical science to participate in conceiving and developing unique bioengineering innovations. DEBUT also excites and invigorates biomedical engineering faculty and departments. Students and faculty take on increasingly sophisticated projects in the hopes of winning a prize. This cannot be easily accomplished by a traditional grant mechanism. The monetary prizes combined with the recognition of winning undergraduates teams at the annual meeting of the Biomedical Engineering Society provide encouragement to the teams to further advance their projects and take it to market where they have the potential to address unmet needs in healthcare.</td>
<td>The total prize purse offered in FY17 was $65,000 ($45,000 from NIBIB and $20,000 from VentureWell) and the full amount was awarded. The total prize purse offered in FY18 was $65,000 ($45,000 from NIBIB and $20,000 from VentureWell) and is expected to be fully distributed in FY18. In both fiscal years, first, second, and third place prizes were $20,000, $15,000, and $10,000, respectively. VentureWell awarded two additional prizes, the Venture prize ($15,000) and the Design Excellence prize ($5,000). There were five honorable mentions in FY17 and six honorable mentions in FY18. The Challenge also offered commendation at a major annual scientific meeting (Biomedical Engineering Society) with a session dedicated to DEBUT.</td>
<td>In addition to NIBIB�s social media and email outreach efforts, VentureWell contributed to publicizing the competition through direct mailing and social media. VentureWell also was in charge of the receipt of the entries and initial evaluation.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>DEBUT is geared toward undergraduate students in biomedical engineering (BME). Teams made up of at least three undergraduate students can compete in the competition. At least one student must be in a BME department. Foreign students can compete and receive public recognition if their team wins. However, they are not eligible to receive prize money.</td>
<td>The NIBIB Director was responsible for the final designation of winners of the NIBIB prizes. This designation was based on the evaluation of a judging panel made up of NIH staff with related expertise. This panel took into consideration the evaluation of a panel of experts VentureWell convened in order to make its selections for Venture and Design Excellence prizes. All judging was based on the review criteria announced for the prizes.</td>
<td>In FY17, 41 eligible entries were received from 22 universities in 16 different states by the deadline on May 31, 2017, engaging 224 students. In FY18, 36 eligible entries were received from 25 universities in 15 different states by the deadline on May 31, 2018, engaging 180 students. Ten prizes were awarded.</td>
<td>Three members of NIBIB staff were mostly responsible for the management of the competition and the awarding of prizes. Eight other staff members were involved in the judging of the entries. $45,000 was distributed in total prizes yearly. FY17 and FY18 cash prizes were obligated to NIBIB&#39;s Direct Appropriation Account (TAFS 75-17-0898). VentureWell provided $20,000 in prizes yearly, bringing the challenge total for prizes to $65,000 annually.</td>
<td>Since 2016, NIBIB has been in a public-private partnership with VentureWell, a higher education non-profit that describes its mission as �to launch new ventures from an emerging generation of young inventors driven to improve life for people and the planet.� The competition jointly held by NIBIB and VentureWell was able to enhance the set of prizes available to students as well as offer a single portal for submitting entries. In addition to maintaining this informational and entry submission portal, VentureWell contributed to publicizing the competition as well as the receipt and initial evaluation of the entries. VentureWell also convened its own evaluation panel in order to make its selections for Venture and Design Excellence prizes. All judging was based on the review criteria announced for the prizes. The estimated value of this partnership was $63,000 annually.</td>
<td>The mission of the NIBIB is to improve health by leading the development and accelerating the application of biomedical technologies. NIBIB is committed to integrating the physical and engineering sciences with the life sciences to advance basic research and medical care. This prize is designed to spark early undergraduate interest in the areas NIBIB supports. The underlying goals of the prize highlight and advance the agency�s mission by: 1) providing undergraduate students valuable experiences such as working in teams, identifying unmet clinical needs, and designing, building and debugging solutions for such open-ended problems; 2) generating novel, innovative tools to improve healthcare, consistent with NIBIB�s purpose to support research, training, the dissemination of health information, and other programs with respect to biomedical imaging and engineering and associated technologies and modalities with biomedical applications; and 3) highlighting and acknowledging the contributions of biomedical engineering to advancing healthcare.</td>
<td>Creative (design &amp; multimedia); Technology demonstration and hardware</td>
<td>In FY19-20, the DEBUT Challenge will continue to be open to teams of undergraduate students working on projects that develop innovative solutions to unmet health and clinical problems. No major changes are currently planned for the Challenge.</td>
</tr>
<tr>
<td>The 2017 �$100,000 for Start a SUD Startup� Challenge</td>
<td>NIH, National Institute on Drug Abuse (NIDA)</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The Challenge goal was to support research ideas that could be the basis for the development of new and potentially successful commercial applications. NIDA intended to fund the would be startup founders much earlier than most investors, incubators, or traditional models of research funding (e.g. small business grants). The Challenge allows scientists to test the hypothesis that their research idea can be fostered into a biotech startup, and that eventually these newly created startups will contribute to the pool of innovative small business companies that can successfully compete for NIDA�s Small Business Innovation Research (SBIR) and Small Business Technology Transfer (STTR) funding.</td>
<td>Find and highlight innovative ideas; Inform and educate the public; Engage new people and communities; Build capacity</td>
<td>NIDA issued the �$100,000 for Start a SUD Startup� Challenge in 2016, and re-issued it in 2017. In 2016, the idea-submitting teams were from U.S. academic institutions, newly formed small business companies, and members of the general public. The selected teams were diverse in terms of age, level of education, gender, race and understanding of commercialization and entrepreneurship. Importantly, only 25% of submitted ideas came from NIDA-funded researchers. About 60% of submitted ideas came from the teams or individuals that previously did not apply for NIH grant funding. Thus, this Challenge was the preferable method to identify potential startup founders and work with them on research idea development and preparation of successful SBIR grant applications.</td>
<td>The total prize purse offered was $100,000. The Challenge offered up to ten awards of $10,000 each and provided mentorship support from NIDA entrepreneurship experts for development of a minimum viable proof (MVP) of the proposed product. No institutional indirect costs were allowed. The names of the winners and the titles of their submissions are posted on the NIDA web site.</td>
<td>NIDA posted the Challenge at Challenge.gov and was responsible for the challenge outreach. The Challenge info, including the Challenge flyer, was disseminated to scientific and business communities including: NSF I-Corp Sites (46 universities); provosts of entrepreneurial universities (37 universities/contact sites); tech transfer offices of entrepreneurial universities (41 top NIDA-funded universities); 2017 Annual CPDD meeting (June 2017); 19th Annual HHS SBIR/STTR Conference (November 2017, WI); 2017 Annual Neuroscience Conference (November 2017); personal emails to all PIs who applied to RFA-DA-17-007 �Growing Great Ideas: Research Education Course in Product Development and Entrepreneurship for Life Science Researchers (R25)�; listserv of the Yale Entrepreneurial Institute; DHHS Opioid Symposium and Code-a-Thon (December 2017, DC); NIDA landing page rotator and NIDA challenge webpage; Academic mentors (active NIDA P01&amp; P50 grantees); active NIDA CEBRA R21 grantees; small business companies and start-ups contacted NIDA and considered to apply to SBIR/STTR program.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Other - Targeted outreach of entrepreneurial organizations; Other - Presentations and flyers at scientific meetings and conferences</td>
<td>The Challenge was open to any individual 18 years of age or older. No prior startup experience was necessary.</td>
<td>Submissions that were responsive and complied with the entry requirements were reviewed by a panel of judges consisting of NIDA Federal employees. The judging panel made recommendations to the award approving official based upon the following five criteria: (1) Significance and unmet needs. Are there significant needs for your product or service? Does the project address an important problem or a critical barrier to progress in the field of drug abuse research?; (2) Innovation. Does the submission seek to shift current paradigms by utilizing novel theoretical concepts, approaches, methodologies, instrumentation, service or interventions for drug abuse research? Is your product novel in a broad sense?; (3) Approach. Are the overall strategy, methodology, and analyses well-reasoned and appropriate to test the proposed idea? Has feedback from end users been incorporated into the validity of the idea proposed?; (4) Team expertise. Does the individual or team demonstrate high level of ability, perseverance and grit?; (5) Commercialization. Is there a clear path for the product or service to reach the market? Are the product users and purchasers clearly identified? Each criterion was scored with the maximum of ten points. Final recommendations are determined by a vote of the judges based on score. Scores from each criterion are weighted equally, but failure to meet a minimum standard for any one criterion might disqualify a submission.</td>
<td>Of the 18 entries submitted by 39 participants between June 09, 2017 and December 22, 2017, ten prizes were awarded to ten teams.</td>
<td>NIDA Federal employees were solely responsible for solicitation and management of this Challenge. The panel of NIDA judges spent 50 FTE hours for review of submissions, scoring, and selection of the winners. The NIDA Office of Translations Initiative and Program Innovation (OTIPI) was responsible for challenge design, clearance, solicitation, management, outreach, communication with the participants and post-challenge activities. The winners of this Challenge were encouraged to use the prize funds to develop a MVP as quickly as possible and to obtain customer feedback to discover if the MVP meets the customer needs. If the product prototype was successfully validated, winners were encouraged to create or further advance their biotech startup no later than 6 months after the prize was awarded. OTIPI developed the curriculum for this post-challenge educational program and worked closely and intently with the teams to perform costumer discovery, identify product differentiation features, refine the overall value proposition, and put together competitive NIDA SBIR/STTR applications. As a result, within seven months of the post-challenge period, nine teams incorporated nine small businesses and worked to submit their SBIR /STTR applications in Fall 2018.</td>
<td>N/A</td>
<td>NIDA is the lead Federal agency supporting scientific research on drug use and its consequences. NIDA�s mission is to advance science on the causes and consequences of drug use and addiction and to apply that knowledge to improve individual and public health. This Challenge is consistent with and advances the mission of NIDA as described in 42 U.S.C. 285o in that it supports new and potential biotech start-ups in the development of research ideas that would further an understanding of neurobiology as it relates to substance use disorders (SUD). NIDA hopes that participation in the contest will enable scientists to test whether their research ideas can be fostered into a SUD biotech startup. The startup product could be the result of novel scientific discoveries, repurposing an existing technology for a new use, extending a research observation or discovery made in a different scientific area into SUD, devising a new business model or distribution or delivery channel that unlocks new value, or simply bringing a product or service to an underserved customer.</td>
<td>Ideas; Business plans; Scientific</td>
<td>Based upon the success of the �$100,000 for Start a SUD Startup� Challenge and the overwhelming positive feedback received from the teams, NIDA plans to re-issue the Challenge in 2019 and 2020.</td>
</tr>
<tr>
<td>Follow that Cell</td>
<td>NIH, National Institute of Mental Health (NIMH) and Office of Strategic Coordination</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The goal of the Challenge was to develop new tools and methods that allow time-dependent measurements at the single-cell level in a complex tissue environment to assess functional changes, provide information on the health status of a given cell, and help guide diagnosis and therapeutic treatments related to human disease states. Technological breakthroughs in this arena could allow researchers and physicians to identify rare cells in a mixed population, such as individual cells that can transform and become cancerous, cells that are latently infected with a pathogenic virus, or cells that develop resistance to drugs over time.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology</td>
<td>The NIH Common Fund supported grants under the Single Cell Analysis Program (SCAP), the majority of which are associated with academic institutions. This Challenge, structured in two phases, was designed to strengthen and complement the existing SCAP grant portfolio by reaching out to a more diverse population of innovators and solvers, including not only those who are from academic institutions but also those who are from research and development communities in the private sector and those who are outside biomedical disciplines. The NIH believed this Challenge would stimulate investment from both public and private sectors in single-cell analysis research and product development, which, in turn, could lead to the development of more sensitive, robust, and cost-effective assay approaches, reagents, tools, and devices for basic research and clinical diagnosis.</td>
<td>The total prize purse offered and awarded was $400,000. The first place individual winner was awarded $300,000 and $100,000 was split among three eligible members of the second place team.  All funds were from the FY14 appropriation. Non-monetary incentives included the opportunity to present at the fifth annual Single Cell Analysis Principal Investigator Meeting.</td>
<td>Phase 2 was a limited competition among the 16 winners and finalists from Phase 1. Phase 2 solvers were encouraged to partner with others as necessary to exercise their solutions. NIH conducted a webinar for all 16 potential solvers to answer questions about the Challenge and submission requirements. NIH kept in contact with potential solvers via direct email. Phase 1 was launched with a marketing strategy developed to define targeted methods that would be used to attract solvers at the launch and during the open period of the Challenge.The marketing plan was designed to attract a large number of varied solvers that could theorize innovative research tools, technologies or other breakthroughs that would allow identification, manipulation, or measurement of relevant biological changes at the single cell level. Outreach methods included the Federal Register Notice, NIH and contractor website postings, Nature website posting, emails, and social media.</td>
<td>Social media (e.g., Twitter, Facebook); Other - Webinar; Other - Direct email</td>
<td>The target solver audience was the community of investigators who could potentially provide solutions to the Challenge. Efforts were made to extend beyond the set of investigators already funded by NIH to pursue related areas of research. Specific eligibility requirements were posted in the Federal Register Notice.</td>
<td>Ten solutions were submitted. InnoCentive, the contractor who hosted the platform for submission, screened for eligibility and completeness of solution. All ten solutions were forwarded to NIH for scientific evaluation. A technical evaluation panel consisting of NIH intramural investigators convened in-person to evaluate the submissions based on the criteria published in the Federal Register Notice. In parallel, NIH extramural staff reviewed top two submitted solutions for scientific alignment to SCAP, relevance to the NIH mission, and potential overlap with existing projects. Evaluation summaries were generated for all ten Phase 2 Solutions, which included the executive summary describing the research, technical evaluation panel discussion summary, and extramural staff summary. The SCAP Challenge team met to discuss the evaluation outcomes and to develop a rationale for recommending the selection of prize winners for Phase 2 competition. The judges and awarding official accepted the recommendation and approved the payment of prizes. NIMH was unable to develop a process or policy for ascertaining and managing conflict of interest of external individuals who could serve on the technical evaluation panel without limiting participation of solvers so NIMH chose to use Federal employees.</td>
<td>Of the ten entries submitted by 27 participants between March 17, 2015 and March 30, 2017, two prizes were awarded.</td>
<td>Approximately 0.5 FTE was utilized to manage Phase 2 of the Challenge, including evaluation and approvals, recognition event and publicity, authorizing payment of prizes, and close-out reporting.</td>
<td>N/A</td>
<td>The NIH SCAP was searching for novel, robust methods for analysis of individual cells that could serve as the basis for predicting alterations in cell behavior and function over time. The ultimate goal was to develop new tools and methods that allow time-dependent measurements at the single cell level in a complex tissue environment to assess functional changes, provide information on the health status of a given cell, and help guide diagnosis and therapeutic treatments related to human disease states. Technological breakthroughs in this arena will allow researchers and physicians to identify rare cells in a mixed population, such as individual cells that may begin to transform and become cancerous; cells that are latently infected with a pathogenic virus; or cells that develop resistance to drugs over time.</td>
<td>Scientific</td>
<td>While other institutes at NIH are currently hosting challenges and have plans for the future, the NIH Common Fund Single Cell Analysis Program has sunset.</td>
</tr>
<tr>
<td>Antimicrobial Resistance, Rapid, Point-of-Need Diagnostic Test Challenge</td>
<td>NIH and Office of the Assistant Secretary for Preparedness and Response (ASPR), Biomedical Advanced Research and Development Authority (BARDA)</td>
<td>COMPETES Authority</td>
<td>This competition was underway in both FY17 and FY18, but has not concluded.</td>
<td>The goals of the AMR Diagnostic Challenge are (1) to improve antibiotic stewardship and counter the increasing spread of antibiotic resistant microorganisms; (2) develop new, innovative, accurate, and cost-effective diagnostic tests to rapidly inform clinical treatment decisions, and be of significant clinical and public health utility to combat antimicrobial resistant pathogens; (3) incentivize a broad range of scientists, engineers, and innovators to develop diagnostic tests; and (4) development of unique diagnostics could facilitate the discovery of new antibiotics.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>On September 18, 2014, the President issued Executive Order 13676 on Combating Antibiotic-Resistant Bacteria announcing the Administration would hold the Antimicrobial Resistance Diagnostic Challenge. The National Strategy for Combating Antibiotic Resistant Bacteria was released simultaneously with specific goals to address the increasing public health threat of antibiotic resistant microorganisms. An accompanying White House Fact Sheet called for NIH and ASPR/BARDA to hold a $20M challenge competition for the development of rapid, point-of-need diagnostic assays for combating antibiotic resistant pathogens. The National Action Plan for Combating Antibiotic-Resistant Bacteria issued in 2015 set three- and five-year goals for this NIH and ASPR/BARDA-sponsored competition.</td>
<td>The total prize purse offered was $20,000,000. $50,000 was awarded to each of ten semi-finalists in Step 1 ($500,000 total), and up to $100,000 may be awarded to each semi-finalist in Step 2 ($1,000,000 total). The remaining funds ($18,500,000) will be awarded to up to three winners in FY20. Finalists will also receive public recognition.</td>
<td>A Federal Register Notice (FRN) and a Notice in the NIH Guide for Grants and Contracts were used to initially announce the Challenge and request submissions. The Challenge is posted on the Challenge.gov website. The NIH support contractor maintains a website with frequently asked questions, which serves as the site for submissions. Amended FRNs and NIH Guide Notices were issued to provide updates for submissions for each Step of the competition. The NIH Director and ASPR issued a press release when the Challenge was announced. The NIH Director also issued a blog to encourage submissions. Emails are sent to key NIH academic, professional society, and industry partners at various stages of the Challenge soliciting submissions. A Twitter session was held with the NIH Director following announcement of the Step 1 semi-finalists. A YouTube session was held with the NIH coordinator for the Challenge. NIH and BARDA maintain websites encouraging submissions. The organizers of the U.K. Longitude Prize for an AMR diagnostic include announcements of the NIH/BARDA Challenge on their website.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Step 1 and 2 submissions were open to all solvers; Step 3 is only open to the Step 2 semi-finalists. Solutions were welcome from individuals, teams, and entities from all U.S. sources including the public sector, private sector, and nonprofit groups. Members of the technical evaluation panel for Step 1 are not eligible to participate in or contribute to any proposal for Steps 2 and 3. Submissions are not eligible from any HHS (or its components) Federal employee. Employees of other Federal Government entities need to check with their ethics office to see if they can limit or accept the prize. Federal grantees are eligible to compete, but cannot use Federal funds to develop a submission unless consistent with purpose of their grant. Federal contractors are eligible to compete, but cannot use funds from a Federal contract to develop a submission. Solvers must be at least 18 years old and a U.S. citizen or resident. A team, led by a U.S. citizen or resident, can include international citizens, but the latter are not eligible for the cash prize. If an entity applies, it must be incorporated in the United States and maintain a primary place of business in the United States. An individual, entity, or team that is currently on the excluded parties list will not be selected as a semi-finalist or winner. An individual shall not be deemed ineligible if he or she uses a Federal facility or consults with Federal employees, as applicable, provided that such facilities and/or employees are made available on an equitable basis to all individuals or teams.</td>
<td>All Step 1 submissions were subjected to an initial review by NIH scientific staff to ensure they are complete and within scope of the Challenge. Submissions that were incomplete were disqualified and not evaluated further. A three-tier review process was used including a technical evaluation panel, a programmatic assessment panel, and a judging panel. The technical evaluation panel, convened by the NIH Center for Scientific Review, included non-governmental scientific experts and a limited number of government scientific experts who evaluated and rated the submissions based on six criteria including: innovation; clinical significance; diagnostic performance; feasibility; time to test result; and setting and ease of use. The programmatic assessment panel, including NIH, BARDA, and FDA scientific staff, reviewed the highly rated submissions for scientific alignment with the National Action Plan for Combating Antibiotic Resistant Bacteria. The judging panel, consisting of three senior leadership members from NIH and BARDA, used the technical and programmatic evaluations to determine the semi-finalists based on innovation advancing existing clinical diagnostics and relevance to NIH�s and BARDA�s missions. Step 2 submissions will be subjected to similar evaluation by a technical evaluation panel based on four criteria: innovation; clinical significance; diagnostic performance and feasibility; and sample matrix/setting and ease of use/throughput. Step 3 prototype submissions will be evaluated by two independent CLIA-certified laboratories for usability, stated time to result, analytical sensitivity and specificity, as well as confirmation of analytical performance as stated in the Step 2 data submitted by the solver. The results of the CLIA laboratory testing will be submitted to a technical evaluation panel followed by review by the programmatic assessment panel, and finally submitted to the judging panel for their determination of a winner(s).</td>
<td>A total of 74 submissions were received and 10 prizes awarded in Step 1, which opened on September 8, 2016. Twenty submissions were received and up to 10 prizes awarded will be awarded in Step 2. Up to 10 participants will submit Step 3 entries by January 3, 2020 and up to three prizes may be awarded. Step 3 winners will be announced July 31, 2020.</td>
<td>A total of 1.5 FTEs conducted activities related to the review, management, and approval of awards. In FY16, the National Institutes of Health/National Institute of Allergy and Infectious Diseases (NIH/NIAID) and ASPR/BARDA each provided $10,000,000 for this Challenge. In FY17, the NIH Division of Program Coordination, Planning, and Strategic Initiatives within the Office of the Director (NIH/OD/DPCPSI) obligated and disbursed $22,000 for the Step 1 technical evaluation panel meeting. In FY18, NIH/OD/DPCPSI obligated $29,000 for the Step 2 technical evaluation panel meeting.</td>
<td>CDC and FDA provided technical and regulatory expertise to the development of the award evaluation process. They participated with NIH and BARDA scientific staff on the AMR Diagnostic Working Group. CDC scientific staff participated on the technical evaluation panel and FDA scientific staff participated on the programmatic assessment panel. Capital Consulting Corporation served as a support contractor to NIH for the Challenge and developed a website providing information to submitters as well as the mechanism to submit solutions for Steps 1 and 2 of the Challenge.</td>
<td>BARDA�s mission is to develop and procure medical countermeasures that address the public health and medical consequences of chemical, biological, radiological, and nuclear accidents, incidents and attacks, pandemic influenza, and emerging infectious diseases. Specifically, BARDA supports the advanced development and procurement of drugs, vaccines and other products that are considered priorities for national health security. BARDA�s support ensures continuity of funding at a critical point for medical countermeasures developed by industry or emerging from the basic research and preclinical development activities sponsored by NIH. In procuring medical countermeasures for the Strategic National Stockpile, BARDA enhances the capabilities of CDC to organize an effective response to a public health threat. NIH and BARDA are utilizing the AMR Diagnostic Challenge to identify novel and innovative in vitro diagnostic tests that would rapidly inform clinical treatment decisions and be of potential significant clinical and public health utility to combat the development and spread of antibiotic resistant bacteria.</td>
<td>Technology demonstration and hardware; Scientific</td>
<td>In FY19 and FY20, NIH and ASPR/BARDA will proceed with Steps 2 and 3, respectively, of the AMR Diagnostic Challenge.</td>
</tr>
<tr>
<td>The Simple Extensible Sampling Tool Challenge</td>
<td>Office of Inspector General (OIG)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The objective of this Challenge was to develop the foundation for an upgraded version of RAT-STATS software that is 508 compliant with a user friendly design. The current version of RAT-STATS is well-validated; however, its user interface can be difficult to navigate and does not meet Federal accessibility standards. OIG needed a new, modern version of the software that was easier to use and was 508 compliant. In addition, by using a competition, OIG hoped to increase public awareness about the RAT-STATS software.</td>
<td>Solve a specific problem; Inform and educate the public</td>
<td>The relatively small scale of the programming project made it amendable to work by a single individual knowledgeable about programming. We believed that a prize competition would lower the barrier to access and allow individuals less familiar with the government contracting process to take in the upgrade effort. In addition, the prize competition was designed to allow users to select from several different replacement packages. Finally, the problem was well amendable to a competition given that it involved clear metrics for success, but also allowed for a significant amount of creativity by the solvers. In particular, OIG had definitive performance requirements, but were interested in seeing what the public could come up with in terms of the software layout, structure, and new features.</td>
<td>The total prize purse offered was $40,000 and the total amount awarded was $34,000. The grand prize winner was listed within the software that was created as a result of the competition. The grand prize winner was also be listed on the agency website and within the instruction manuals for the software. No private sector or philanthropic funds were contributed for the prizes. All funds were obligated and expended from HHS OIG appropriations.</td>
<td>OIG announced the competition in the Federal Register, on the HHS/OIG agency website, the Challenge.gov website, and the Challenge.gov Twitter account. OIG also advertised the competition on several industry websites with free job posting areas. Finally, the HHS IDEA Lab included a blog posting describing the competition on its website. OIG was satisfied with the level of response received given the solicitation approach, though larger scale advertising would likely have been needed for a larger competition.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>The contest was open to the public and anyone who could provide a solution. OIG targeted individuals who were knowledgeable about programming and software design. Rules for participation in the challenge are available at: https://www.Challenge.gov/challenge/statistical-software-for-healthcare-oversight/.</td>
<td>A technical expert reviewed each submission to identify whether it was complete, followed the competition rules, and was able to fully replicate RAT-STATS on 60 test datasets. The expert identified three entries that met this requirement. The grand prize was selected by a committee of 12 HHS/OIG employees who represent the types of individuals who would be end users for the new software. Each of the 12 individuals voted on which of the software packages they would prefer to use. The finalist with the most votes was declared the grand prize winner.</td>
<td>Of the eight entries submitted by between September 29, 2016 and May 15, 2017, one participant was awarded the grand prize.</td>
<td>The Challenge was run using only internal agency resources. In 2017, these include IT resources and approximately 200 FTE hours, including 180 hours at GS-15 level and 20 hours at GS-13 level. Funds associated with the Challenge were used to pay for cash prizes and the Federal Register Notice posting.</td>
<td>N/A</td>
<td>Each year HHS handles hundreds of millions of Medicare and Medicaid claims valued at more than a trillion dollars. Due to the high volume of claims, statistical sampling provides a critical tool to ensure effective oversight of these expenditures. In addition, sampling is used by the providers in their own efforts to monitor their performance. The RAT-STATS software package, which was originally developed by HHS/OIG, has a unique niche in that it provides a straightforward tool for individuals who need a simple but robust method for selecting and analyzing statistical samples. The competition was designed to advance the agency mission by helping HHS/OIG create a 508 compliant version of the RAT-STATS software that can be expanded as needed to ensure HHS/OIG can meet its audit sampling requirements moving forward.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>Blockchain in Healthcare Code-a-Thon</td>
<td>Office of the National Coordinator for Health Information Technology (ONC)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>In September 2016, ONC announced the Use of Blockchain in Health IT and Health-Related Research Challenge. The challenge solicited white papers that investigated the potential relationship between blockchain technology and its use in health IT and health-related research; these were later used to inform the Use of Blockchain in Healthcare and Health-Related Research Workshop. The workshop convened Federal, public, and private stakeholders to receive briefings from Federal and industry leaders utilizing blockchain and/or alternative distributed ledger technologies. Ultimately, participants in the Blockchain in Healthcare Code-A-Thon heard presentations from eight of the Blockchain Challenge winners, shared successes, and generated new ideas around blockchain technology solutions in the healthcare ecosystem. One of the next steps identified during the workshop was to support demonstrations and trial implementations to determine whether blockchain had a place in health IT and, if so, ascertain its role.</td>
<td>Develop technology; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>Prizes were chosen with the scope to engage a broader stakeholder community including researchers, innovators and start-up or small entities to spur innovation, educate the larger community, spur adoption of metrics, and lay the groundwork for potential future collaboration.</td>
<td>The total prize purse offered was $15,000 and the total amount awarded was $13,000. Non-monetary incentives included the opportunity to participate in the Digital Chamber of Commerce�s annual Blockchain conference at Georgetown University.</td>
<td>Solicitation of submissions included social media outreach (Twitter, LinkedIn), email blasts, and a live webinar.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>The Challenge was open to the public and targeted technology developers and the health IT community. The Challenge was run under the authority of section 105 of the America COMPETES Reauthorization Act and, therefore, had the eligibility criteria pursuant to it and to HHS policy guidance.</td>
<td>A panel of judges assessed each solution based on the following criteria: (1) technical competence and capabilities (35%); (2) use of data to provide effective outcomes (20%), (3) creativity/innovation (20%); and (4) valuable information and insights regarding data (25%).</td>
<td>A total of 83 participants submitted entries between January 23 and March 7, 2017 and prizes were awarded to ten winners.</td>
<td>Code-A-Thon development and preparation duties were the responsibility of ONC employees. Contract funds were used to provide event support and logistics and to fund the cash awards. The Challenge utilized 0.4 FTE and $145,000 in funding in FY17.</td>
<td>Digital Chamber of Commerce, a 801c non-profit, provided the venue, food, advertising and an opportunity for the winner to have public exposure through a Blockchain conference. Services provided in this partnership provided a better platform in which to conduct the Challenge without adding additional cost to the taxpayer. The estimated value of this partnership is $50,000.</td>
<td>As the final step in a progression of blockchain-centered events, the Code-A-Thon was an opportunity to ascertain if blockchain could be used to address common problem areas that affect exchange of health data on a national scale.</td>
<td>Software and apps; Creative (design &amp; multimedia); Technology demonstration and hardware</td>
<td>N/A</td>
</tr>
<tr>
<td>CHPL Data Challenge</td>
<td>ONC</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18.</td>
<td>The ONC Certified Health IT Product List (CHPL) Data Challenge is a call for developers, researchers, and innovators to develop a software application that makes use of the data in the CHPL API in novel ways. The application should provide solutions to challenges for healthcare providers, healthcare consumers, and the health IT community.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public</td>
<td>The opening up of the CHPL with an API and XML files allows the public to use its data in creative ways, including those for which ONC does not have the internal capacity to fulfill or has not even imagined. Compared to a contract or other mechanism, a prize challenge provides the opportunity to reach out to the public for new ideas. Individuals and entities that work daily in the health IT and healthcare field, interacting with patients, can bring new viewpoints to issues that ONC policy specialists may not. The Challenge also provides an opportunity to engage app and software developers who might not be familiar with the health IT world but can bring experience and knowledge from other industries to bear.</td>
<td>The total prize purse offered is $40,000 and has not yet been awarded. First and each of two second place runner-ups will receive $20,000 and $10,000, respectively. Non-monetary incentives included public recognition and opportunities to showcase work at ONC-sponsored events.</td>
<td>Solicitation of submissions has included social media outreach (Twitter, LinkedIn), email blasts, and a live webinar.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming</td>
<td>The Challenge is open to the public and targets technology developers and the health IT community. The Challenge is being run under the authority of section 105 of the America COMPETES Reauthorization Act and, therefore, has the eligibility criteria pursuant to it and to HHS policy guidance.</td>
<td>Submissions were evaluated in November 2018.</td>
<td>Entries were submitted between July 10, 2018 and October 31, 2018, and the Challenge is ongoing.</td>
<td>Challenge development and preparation duties were the responsibility of ONC employees. Once ready for launch, the Challenge began utilizing the services of a contractor which has been involved in such duties for ONC since 2010. The current contract is funded at $125,000 and structured to provide support for up to three challenges over a one-year period. These services include hosting of the challenge website, preparation of communications materials, ongoing day-to-day activities of challenge management, and support for reviewing and awarding functions. ONC estimates the Challenge utilized approximately 0.4 FTEs in FY18.</td>
<td>N/A</td>
<td>The Challenge is an opportunity to solve problems using CHPL data for health care providers, health care consumers, and the health IT community. ONC anticipates that participants will create novel solutions using this data, amplified by creative user interfaces that optimize the user�s understanding of the proposed issue. These solutions can help provide insight to the public of ONC�s certification processes and priorities and demonstrate the program�s impact.</td>
<td>Software and apps; Creative (design &amp; multimedia)</td>
<td>N/A</td>
</tr>
<tr>
<td>Consumer Health Data Aggregator Challenge</td>
<td>ONC</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The Consumer Health Data Aggregator Challenge had several objectives, the primary one being to increase the number of apps available to consumers that can aggregate their data from multiple sources. Specifically, this had to be done using the Fast Healthcare Interoperability Resources (FHIR) API, which is the most widely-known and developed open API for exchanging patient health data. Even as the open API with the highest level of awareness, the Challenge was also intended to raise this level higher, and to incentivize more developers to work with and familiarize themselves with FHIR.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Inform and educate the public; Engage new people and communities; Build capacity; Stimulate a market</td>
<td>Compared to a contract or other mechanism, a prize challenge provides the opportunity to reach out to the public for new ideas. Individuals and entities that work daily in the health IT and health care field, interacting with patients, can bring new viewpoints to issues that ONC policy specialists cannot. The Challenge also provides an opportunity to engage app and software developers who might not be familiar with the health IT world but can bring viewpoints and knowledge from other industries to bear.</td>
<td>The total prize purse offered was $175,000 and the total amount awarded was $160,000. In Phase 1, up to five prizes of $5,000 to $15,000 were available; four $10,000 prizes were awarded. In Phase 2, one $50,000 first prize, one $25,000 second prize, and an additional $25,000 prize for the app demonstrating the highest level of patient data exchange were available; all three were awarded, with one business winning both of the $25,000 awards. The primary non-monetary incentives were the publicity and recognition for winning an ONC challenge. Award funds were disbursed by a contractor acquired through the HHS COMPETES Blanket Purchasing Agreement.</td>
<td>Solicitation of submissions included an announcement of the Challenge at a major industry conference, a press release, social media outreach (Twitter, LinkedIn), email blasts, and several webinars. The 25 submissions indicate that the communications vectors worked, especially the main stage conference announcement, although the large prize purse was likely also a factor.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming</td>
<td>While the Challenge was open to all developers, the need to understand the intersection of electronic health records (EHRs), patient care, and patient data sharing made it most relevant to companies that already had working knowledge of those areas and were active in health IT. The Challenge was run under the authority of Section 105 of the America COMPETES Reauthorization Act and, therefore, had the eligibility criteria pursuant to it and to HHS policy guidance.</td>
<td>A combined review panel of Federal and non-Federal subject matter experts reviewed and scored all Phase 1 submissions; the Federal challenge managers selected the winners, factoring in those reviews. In Phase 1, equal co-winners were chosen rather than ranked winners because the submissions, written proposals, were steps toward the eventual outcome of the Challenge, not the outcome itself. The final outcomes of Phase 2, consumer apps, were ranked and awarded on the same evaluation criteria. Four evaluation criteria were used to review submissions: (1) the technical feasibility of the plan; (2) the adherence to data privacy and security best practices and applicable law, (3) the strength of the business/sustainability plan; and (4) the provider or health IT developer partnerships. These criteria captured the most important aspects that needed to be identified in the submissions.</td>
<td> A total of 25 entries were submitted in Phase 1 between March 1 and June 1, 2016 and four prizes were awarded. In Phase 2, entries were submitted between June 2 and November 7, 2016 and two prizes were awarded.</td>
<td>A small ONC team, with one primary challenge manager, developed and executed the Consumer Health Data Aggregator and Provider User Experience Challenges. Additional funds for the challenge prizes were required on top of the annual ONC challenge funding allocation; these were designated to the project from the national coordinator�s discretionary pool. A third-party contractor, acquired through the HHS COMPETES Blanket Purchasing Agreement, provided administrative, management, and communications assistance. Given the challenge manager�s extensive experience in running prize challenges, challenge development services were not needed.</td>
<td>N/A</td>
<td>The lack of interoperability between EHR systems remains a significant barrier to the modernization of health IT. FHIR is a standard designed to increase the liquidity of granular patient data. The FHIR API allows data to move between vendor systems both within and across different providers, not to mention through third-party applications for direct use by both clinicians and consumers. Among several opportunities now enabled by this interoperability standard are the new channels being opened up for improving a provider�s user experience when interacting with EHRs and the consumability of interrelated health data. The Provider User Experience Challenge, combined with its partner challenge, the Consumer Health Data Aggregator Challenge, is part of ONC�s Connecting and Accelerating a FHIR App Ecosystem initiative. This initiative calls on innovators to develop market-ready software apps for consumers and healthcare providers in an effort to improve the health and care of the country.</td>
<td>Software and apps; Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>Easy EHR Issues Reporting Challenge</td>
<td>ONC</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18.</td>
<td>Stakeholder feedback indicates there is a need for more efficient and user-friendly mechanisms that allow electronic health record (EHR) end users to report concerns quickly and easily with little or no disruption to their workflow. Mechanisms widely available on the market today normally require the end user to either exit the EHR system entirely or leave the current workflow process in order to report the problem. Some EHRs may include a separate error reporting module, but others require the end user to fill out a report through a totally separate mechanism. This workflow disruption is enough of a burden on users that they avoid reporting. The greater the workflow interruption the more likely they are to delay rather than report immediately while the experience is fresh and most accurately recalled, or to forego reporting entirely. Clinicians need better reporting mechanisms that are designed to address the end user�s needs and are complementary with the workflow processes and systems they use.</td>
<td>Solve a specific problem; Develop technology</td>
<td>Compared to a contract or other mechanism, a prize challenge provides the opportunity to reach out to the public for new ideas. Individuals and entities that work daily in the health IT and health care field, interacting with patients, can bring new viewpoints to issues that ONC policy specialists cannot. The Challenge also provides an opportunity to engage app and software developers who might not be familiar with the health IT world but can bring viewpoints and knowledge from other industries to bear.</td>
<td>The total prize purse offered is $80,000 and has not yet been awarded. First, second, and third place winners will receive $45,000, $25,000, and $10,000, respectively. Non-monetary incentives include public recognition and opportunities to showcase work at ONC-sponsored events.</td>
<td>Solicitation of submissions has included social media outreach (Twitter, LinkedIn), email blasts, and a live webinar.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Live video streaming</td>
<td>The Challenge is open to the public and targets technology developers and the health IT community. The Challenge is being run under the authority of section 105 of the America COMPETES Reauthorization Act and, therefore, has the eligibility criteria pursuant to it and to HHS policy guidance.</td>
<td>Submissions were evaluated in October 2018.</td>
<td>Entries were submitted between May 22 and October 15, 2018, and the Challenge is ongoing.</td>
<td>Challenge development and preparation duties were the responsibility of ONC employees. Once ready for launch, the Challenge began utilizing the services of a contractor that has been involved in such duties for ONC since 2010. The current contract is funded at $125,000 and structured to provide support for up to three challenges over a one-year period. These services include hosting of the challenge website, preparation of communications materials, ongoing day-to-day activities of challenge management, and support for reviewing and awarding functions. The Challenge utilized approximately 0.15 FTE in FY18.</td>
<td>N/A</td>
<td>As of 2015, 96% of hospitals and 78% of office-based physicians have certified EHRs. Clinicians and other members of the health care team routinely work in fast-paced, stressful, and challenging environments. As such, they have come to increasingly rely on EHRs to retrieve patient information, assist in making complex patient care decisions, and ultimately optimize patient safety and health care quality. Despite a growing body of evidence showing the use of advanced health IT being associated with safer care on the whole, it also poses new challenges and risks when deployed into complex clinical environments. Whether through design, development, deployment, operational, or other deficiencies, studies have also shown EHRs can contribute to adverse events and fall short of expectations for safety-related usability, in addition to frustrating end users and posing avoidable risks to patients. These issues are difficult to identify and correct unless the full array of end users� concerns are regularly captured and analyzed for trends and improvement opportunities. The more easily and consistently end users can capture and share their concerns, the better that safety programs and organizations will be able to spot trends and drive improvement.</td>
<td>Software and apps; Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>Move Health Data Forward Challenge</td>
<td>ONC</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>As health IT adoption continues to grow and mobile health technology becomes more accessible, consumers are playing an even greater role in how and when their health information is exchanged or shared. Unleashing this data is one of ONC�s top priorities with the aim of improving individuals� ability to send, receive, find, and use their health information in the near term. To stimulate this work, sometimes referred to as consumer-mediated exchange, between and among their clinicians, hospitals, or even family members, the Move Health Data Forward Challenge was launched. The objective of the Challenge was to create API solutions combined with new implementation specifications, known as Health Relationship Trust (HEART), that have the potential for individuals to securely and electronically authorize the movement of their health data to destinations they choose. This builds on ONC�s work with a number of security, privacy, and health information technology stakeholders to develop a set of privacy and security specifications that enable an individual to control the authorization of access to health data.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology</td>
<td>A prize competition was used to challenge the health IT industry to help find new technological ways to put consumers in the driver�s seat when it comes to how and when their health information can be shared. This choice helped to promote innovation in the area of consumer-mediated exchange by opening up the challenge audience to include health care providers, social service organizations, developers, entrepreneurs, start-ups, early-stage companies, venture capital firms, health information exchanges, incubators, and accelerators.</td>
<td>The Challenge had a prize purse of up to $250,000. In Phase 1, up to ten prizes of $5,000 were available. In Phase 2, up to five prizes of $20,000 were available. In Phase 3, up to two prizes of $50,000 were available. The primary non-monetary incentives were the publicity and recognition for winning an ONC challenge, in addition to opportunities to showcase work at ONC-sponsored events. Awards were disbursed by a contractor acquired through the HHS COMPETES Blanket Purchasing Agreement.</td>
<td>Five public webinars with over 400 attendees total were hosted throughout the duration of the Challenge, including two webinars launching the Challenge. ONC also identified and pitched top media outlets that covered the Challenge, including ONC Federal partners, the health IT community, local and community-based health care organizations, hospitals, health systems, hospital innovation centers, and consumer groups, and subject-matter related blogs, journals, and magazines. In addition, ONC leveraged HHS and external audiences on social media to publicize the Challenge and reach target stakeholders, fostering early engagement and organic team-building through social conversation.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The Challenge was open to the public and targeted technology developers and the health IT community. The Challenge was run under the authority of section 105 of the America COMPETES Reauthorization Act and, therefore, had the eligibility criteria pursuant to it and HHS policy guidance. Phase 1 required participants to describe the technical, operational, financial, and business aspects of their proposed solution, and the main goal was for participants to show feasible and executable plans for innovative solutions and prove its impact potential. Phase 2 required participants to demonstrate, via a live virtual webinar, a viable solution to achieve those goals by allowing for the safe and secure exchange of consumer or provider health records. Phase 3 required participants to implement their solutions through a mobile or web-based application and to conduct a real-time product demo.</td>
<td>For all three phases of the Challenge, a combined review panel of Federal and non-Federal subject matter experts reviewed and scored all submissions, and the Federal challenge managers selected the winners, factoring in those reviews. The review was based on adherence to submission requirements and the judging criteria outlined in the Federal Register Notice. Based on the quantitative results by the review panel and review of submissions by the Federal challenge managers, ten winners were selected in Phase 1, five winners were selected in Phase 2, and two winners were selected in Phase 3.</td>
<td>Of the 31 initial entries submitted by 31 participants between May 10 and September 8, 2016, 17 prizes were awarded throughout the three phases.</td>
<td>A small team of ONC Federal employees, with one primary challenge manager, developed and executed the Challenge. Sensis was acquired through the HHS COMPETES Blanket Purchasing Agreement. ONC worked with Sensis, a third-party contractor, who provided administrative, challenge development, management and communications assistance. The Challenge utilized approximately 0.35 FTE for challenge oversight and $200,000 over two year to fund contractor challenge management.</td>
<td>N/A</td>
<td>The Challenge emphasized the importance of ONC�s mission, which is to improve the health and well-being of individuals and communities through the use of technology and health information that is accessible when and where it matters most. Specifically, the Challenge advanced the agency�s mission by focusing on improving consumer-mediated exchange of individuals� health data. The winning solutions were able to demonstrate a consumer-facing solution that incorporated the HEART implementation specifications and used an API that empowers consumers to control the movement of their health data.</td>
<td>Software and apps; Technology demonstration and hardware; Business plans</td>
<td>N/A</td>
</tr>
<tr>
<td>Oh, the Places Data Goes: Health Data Provenance Challenge</td>
<td>ONC</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The goal of Phase 1 of the Data Provenance Challenge was for teams to identify real world provenance problems, understand why they are important to solve, and provide an opportunity for participants to develop practical and executable plans for innovative solutions. The goal of Phase 2 was to demonstrate a viable solution with high technological merit, test the scalability and feasibility of implementation, and assess the impact of the intended outcomes.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Stimulate a market</td>
<td>Compared to a contract or other mechanism, a prize challenge provides the opportunity to reach out to the public for new ideas. Individuals and entities that work daily in the health IT and health care field, interacting with patients, can bring new viewpoints to issues that ONC policy specialists cannot. The Challenge also provides an opportunity to engage app and software developers who might not be familiar with the health IT world but can bring experience and knowledge from other industries to bear.</td>
<td>The total prize purse offered and awarded was $180,000. Non-monetary incentives included public recognition and opportunities to showcase work at ONC-sponsored events.</td>
<td>ONC solicited submissions through the Federal Register Notice FRN, Challenge.gov, a contractor website, a HealthIT.gov blog post, the ONC Twitter account, a listserv announcement, email blasts, and an informational webinar. These methods appear to have been effective, having led to 19 Phase 1 submissions.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Other - Informational webinar</td>
<td>For Phase 1, teams were required to submit white papers that described their current capabilities and methods used to demonstrate provenance of health data. Teams were required to identify a problem they experienced that inhibited the desired or necessary amount of provenance data to be conveyed during clinical care and propose a solution. Participants were expected to articulate the technical, operational, and business aspects/impacts of their problem and solution, including but not limited to, the value proposition, key partners, implementation plan, timeline, key activities and resources, and metrics for success. Only Phase 1 winners were eligible to participate in the second and final phase, which involved the development and testing of their solution to the problem identified in Phase 1. As a condition of accepting the $20,000 award, Phase 1 winners were required to participate in Phase 2 of the Challenge. Participants submitted a recorded demonstration, solution guide and lessons learned focused on prototyping and testing the effectiveness of the solution.</td>
<td>Judges were a combination of ONC employees and outside subject matter experts who had previously worked or were currently working with ONC. Eligible challenge entries were judged by a review panel composed of Federal employees and experts in compliance with the requirements of the America COMPETES Act and the Department of Health and Human Services judging guidelines.</td>
<td>Of the 19 entries submitted in Phase 1 between April 6 and May 22, 2017, six prizes were awarded. Phase 2 entries were submitted between June 14, 2017 and January 22, 2018, and winners announced on February 21, 2018.</td>
<td>Challenge development and preparation duties were the responsibility of ONC employees. Once ready for launch, the Challenge began utilizing the services of a contractor which has been involved in such duties for ONC since 2010. This contract was funded to provide challenge support and services include hosting of the challenge website, preparation of communications materials, ongoing day-to-day activities of challenge management, and support for reviewing and awarding functions. The Challenge utilized approximately 0.6 FTEs in FY17 and FY18. Additionally, the Challenge utilized $180,000 in funding in FY18.</td>
<td>N/A</td>
<td>With growing HER adoption comes an increasing availability of digital health tools and growing demand among consumers who want to share their data with their providers. The need for health data provenance, and standard approaches to capture it, is an important priority. Additionally, the Health IT Standards Committee has issued recommendations to ONC in the past on data provenance. Data provenance is a complex issue that plays a role in almost everything related to electronic data use and exchange. Thus, finding innovative and standardized solutions to improve and capture data provenance will enable the health care industry to better maximize health data that is already digitized and ready to share.</td>
<td>Ideas; Technology demonstration and hardware</td>
<td>N/A</td>
</tr>
<tr>
<td>Patient Matching Algorithm Challenge</td>
<td>ONC</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The goal of the Patient Matching Algorithm Challenge was to bring about greater transparency and data on the performance of existing patient matching algorithms, spur the adoption of performance metrics for patient data matching algorithm vendors, and positively impact other aspects of patient matching such as deduplication and linking to clinical data.</td>
<td>Advance scientific research; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>Prizes were chosen with the scope to engage a broader stakeholder community including researchers, innovators and start-up or small entities to spur innovation, educate the larger community, spur adoption of metrics, and initiate future collaboration.</td>
<td>The total prize purse offered and awarded was $75,000. Non-monetary incentives included public recognition and opportunities to showcase work at ONC-sponsored events.</td>
<td>Groups specifically targeted for participation in the Challenge included algorithm researchers and vendors, informaticists, researchers, and start-ups.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release</td>
<td>The Challenge was open to the public and targeted technology developers and the health IT community. The Challenge was run under the authority of section 105 of the America COMPETES Reauthorization Act and, therefore, had the eligibility criteria pursuant to it and to HHS policy guidance.</td>
<td>Participants were evaluated on their algorithm performance in finding matched pairs in the data set provided. Each individual submission was scored automatically by a scoring server using a key for scoring and received a score for each of the following three metrics: F-Score (which is the harmonic mean between precision and recall), Precision (least mismatched patients), and Recall (least missed matches). The mathematical scoring, rather than the qualitative evaluation performed by human in most ONC challenges, may have been a contributing factor to the extremely high participation.</td>
<td>Of the nearly 7,000 submissions entries submitted by more than 140 teams between June 12 and October 12, 2017, six prizes were awarded to four individual teams (Vynca, PICSURE, Information Softworks, and Ocuvera). The winners for Best �F-score� were Vynca (first place, $25,000 prize), PICSURE (second place, $20,000), Information Softworks (third place, $15,000). The winner for  Best First Run was Information Softworks ($5,000), the winner for Best Recall was PICSURE ($5,000), and the winner for Best Precision was Ocuvera ($5,000). Each winner employed widely different methods. PICSURE used an algorithm based on the Fellegi-Sunter method for probabilistic record matching and performed a significant amount of manual review. Vynca used a stacked model that combined the predictions of eight different models. They reported that they manually reviewed less than 0.001 percent of the records. Although Information Softworks also used a Fellegi-Sunter-based enterprise master patient index (EMPI) system with some additional tuning, they also reported extremely limited manual review.</td>
<td>ONC utilized $15,000 for MITRE contract support for Amazon Web Services testing environment, and $140,000 for ongoing challenge contract support. The Challenge utilized approximately 0.8 FTEs in FY17.</td>
<td>ONC partnered with Adam Culbertson, the Healthcare Information and Management Systems Society (HIMSS) Innovator-In-Residence.</td>
<td>In 2014, ONC identified patient matching as central to interoperability, reporting that it �will also address critical issues such as data provenance, data quality and reliability, and patient matching to improve the quality of interoperability, and therefore facilitate an increased quantity of information movement.�</td>
<td>Analytics, visualizations, algorithms; Scientific</td>
<td>N/A</td>
</tr>
<tr>
<td>Privacy Policy Snapshot Challenge</td>
<td>ONC</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The Privacy Policy Snapshot Challenge was a call for designers, developers, and health data privacy experts to create an online Model Privacy Notice (MPN) generator. The MPN is a voluntary, openly available resource designed to help health technology developers who collect digital health data clearly convey information about their privacy and security policies to their users. Similar to a nutrition facts label, the MPN provides a snapshot of a product�s existing privacy practices, encouraging transparency and helping consumers make informed choices when selecting products.</td>
<td>Improve government service delivery; Solve a specific problem; Inform and educate the public</td>
<td>Compared to a contract or other mechanism, a prize challenge provided the opportunity to reach out to the public for new ideas. Individuals and entities that work daily in the health IT and health care field, interacting with patients, can bring new viewpoints to issues that ONC policy specialists cannot. The Challenge also provided an opportunity to engage app and software developers who might not be familiar with the health IT world but can bring viewpoints and knowledge from other industries to bear.</td>
<td>The total prize purse offered and awarded was $35,000. First, second, and third place winners were awarded $20,000, $10,000, and $5,000, respectively. Non-monetary incentives included public recognition and opportunities to showcase work at ONC-sponsored events.</td>
<td>ONC solicited submissions through social media outreach (Twitter, LinkedIn), email blasts, and a live webinar.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming</td>
<td>The Challenge was open to the public and targeted technology developers and the health IT community. The Challenge was run under the authority of section 105 of the America COMPETES Reauthorization Act and, therefore, had the eligibility criteria pursuant to it and to HHS policy guidance.</td>
<td>Submissions were evaluated based on the following criteria: (1) accurate use of MPN content, including appropriate modification of flexible language and no deviation from standardized language; (2) use and demonstration of best practices in developing and presenting web content for consumption, including consumer testing, web design, and accessibility; (3) visual appeal of the generated MPN; and (4) ease of use for a developer to implement and use the MPN generator, including ability to customize the MPN. The submission review panel was a combination of Federal and non-Federal subject matter experts.</td>
<td>Of the six entries submitted between December 13, 2016 and April 10, 2017, three prizes were awarded. The number of submissions fell slightly below expectations, although a smaller prize purse and an open source intellectual property policy may have contributed to the small number of submissions.</td>
<td>Challenge development and preparation duties were the responsibility of ONC employees. Once ready for launch, the Challenge began utilizing the services of a contractor which has been involved in such duties for ONC since 2010. This contract provided challenge support and services including hosting of the challenge website, preparation of communications materials, ongoing day-to-day activities of challenge management, and support for reviewing and awarding functions. The value of this support was estimated at $15,000. The Challenge utilized 0.4 FTEs.</td>
<td>N/A</td>
<td>In 2011, ONC collaborated with the Federal Trade Commission (FTC) to release a MPN; the project�s goals were to increase consumers� awareness of companies� personal health record (PHR) data practices and empower consumers by providing them with an easy way to compare the data practices of two or more PHR companies. In the last five years, the health information technology market has changed significantly and there is now a larger variety of products such as mobile applications and wearable devices that collect digital health data. ONC recognized a need to update the MPN to make it applicable to a broad range of consumer health technologies beyond PHRs. More and more individuals are obtaining access to their electronic health information and using consumer health technology to manage this information. As retail products that collect digital health data directly from consumers are used, such as exercise trackers, it is increasingly important for consumers to be aware of companies� privacy and security policies and information sharing practices. Health technology developers can use the MPN to easily enter their information practices and produce a notice to allow consumers to quickly learn and understand privacy policies, compare company policies, and make informed decisions.</td>
<td>Software and apps; Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>Provider User Experience Challenge</td>
<td>ONC</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The Provider User Experience Challenge had several objectives, the primary one being to increase the number of apps available to providers that can aggregate patient data from multiple sources into one place, and utilize modern web and information design to simplify and enhance the user experience. Specifically, this had to be done using the FHIR API, which is the most widely-known and developed open API for exchanging patient health data. Despite having a high level of awareness, the Challenge was also intended to raise awareness higher and to incentivize more developers to work with and familiarize themselves with FHIR.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Solve a specific problem; Inform and educate the public; Engage new people and communities; Build capacity; Stimulate a market</td>
<td>Compared to a contract or other mechanism, a prize challenge provided the opportunity to reach out to the public for new ideas. Individuals and entities that work daily in the health IT and health care field, interacting with patients, can bring new viewpoints to issues that ONC policy specialists cannot. The Challenge also provided an opportunity to engage app and software developers who might not be familiar with the health IT world but can bring experience and knowledge from other industries to bear.</td>
<td>The Challenge had a prize purse of up to $175,000. In Phase 1, up to five prizes of $5,000 to $15,000 were available; four $10,000 prizes were awarded. In Phase 2, one $50,000 first prize, one $25,000 second prize, and an additional $25,000 prize for the app demonstrating the highest level of patient data exchange were available; all three were awarded, with one business winning both of the $25,000 awards. The primary non-monetary incentives are the publicity and recognition for winning an ONC challenge. Award funds were disbursed by a contractor acquired through the HHS Competes Blanket Purchasing Agreement.</td>
<td>ONC solicited submissions through an announcement of the challenge at a major industry conference, a press release, social media outreach (Twitter, LinkedIn), email blasts, and several webinars. The 34 submissions indicate that the communications vectors worked, especially the main stage conference announcement, although the large prize purse was likely also a factor.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming</td>
<td>While the Challenge was open to all developers, the need to understand the intersection of EHRs, patient care, and patient data sharing made it most relevant to companies that already had working knowledge of those areas and are active in health IT. The Challenge was run under the authority of Section 105 of the America COMPETES Reauthorization Act and therefore had the eligibility criteria pursuant to it and to HHS policy guidance.</td>
<td>A combined review panel of Federal and non-Federal subject matter experts reviewed and scored all Phase 1 submissions; the Federal challenge managers selected the winners, factoring in those reviews. In Phase 1, equal co-winners were chosen rather than ranked winners because the submissions, written proposals, are steps toward the eventual outcome of the challenge, not the outcome itself. The final outcomes of Phase 2, health provider apps, were ranked and awarded on the same evaluation criteria. Five evaluation criteria were used to review submissions: (1) the technical feasibility of the plan; (2) the adherence to data privacy and security best practices and applicable law; (3) the strength of the business/sustainability plan; (4) the impact potential in a clinical setting; and (5) the provider and/or health IT developer partnerships. These criteria captured the most important aspects that needed to be identified in the submissions.</td>
<td>Of the 34 entries submitted in Phase 1 between March 1 and June 1, 2016, four prizes were awarded. Phase 2 entries were submitted between June 2 and November 7, 2016 and two prizes were awarded.</td>
<td>A small ONC team, with one primary challenge manager, developed and executed the Consumer Health Data Aggregator and Provider User Experience Challenges. Additional funds for the challenge prizes were required on top of the annual ONC challenge funding allocation; these were designated to the project from the national coordinator�s discretionary pool. A third-party contractor, acquired through the HHS COMPETES Blanket Purchasing Agreement, provided administrative, management, and communications assistance. Given the challenge manager�s extensive experience in running prize challenges, challenge development services were not needed. The Challenge utilized approximately 0.2 FTE in FY17.</td>
<td>N/A</td>
<td>The lack of interoperability between EHR systems remains a significant barrier to the modernization of health IT. FHIR is a standard designed to increase the liquidity of granular patient data. The FHIR API allows data to move between vendor systems both within and across different providers, not to mention through third-party applications for direct use by both clinicians and consumers. Among several opportunities now enabled by this interoperability standard are the new channels being opened up for improving a provider�s user experience when interacting with EHRs and the consumability of interrelated health data. The Provider User Experience Challenge, combined with its partner challenge, the Consumer Health Data Aggregator Challenge, was part of ONC�s Connecting and Accelerating a FHIR App Ecosystem initiative. This initiative called on innovators to develop market-ready software apps for consumers and healthcare providers in an effort to improve the health and care of the country.</td>
<td>Software and apps; Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>Proving the Potential: A Health Data and Standards Code-a-Thon</td>
<td>ONC</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>Teams were challenged to showcase their skills and vision using APIs, software development kits (SDKs), and other tools made publicly available by leading innovators in healthcare. Projects were intended to be forward-thinking, enhance interoperability, and focus on demonstrating the potential to seamlessly incorporate one or more of the assets into existing health IT systems. Contestants were to address one of the following use cases: (1) electronic quality measures and/or decision support; (2) secure and privacy preserving methods to aggregate patient data; (3) discovery of patients, providers, researchers or services.</td>
<td>Develop technology; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>Prizes were chosen with the scope to engage a broader stakeholder community, including researchers, innovators, start-ups, and small entities, to spur innovation, educate the larger community, spur adoption of metrics, and lay the groundwork for potential future collaboration.</td>
<td>The total prize purse offered was $15,000 and the total amount awarded was $8,000. Non-monetary incentives included public recognition and opportunities to showcase work at ONC-sponsored events.</td>
<td>ONC solicited submissions through social media outreach (Twitter, LinkedIn), email blasts, and a live webinar.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>The Challenge was open to the public and targeted technology developers and the health IT community. The Challenge was run under the authority of section 105 of the America COMPETES Reauthorization Act and, therefore, had the eligibility criteria pursuant to it and to HHS policy guidance.</td>
<td>A panel of judges assessed each solution based on the following criteria: (1) technical competence and capabilities (35%); (2) use of data to provide effective outcomes (20%); (3) creativity/innovation (20%); and (4) valuable information and insights regarding data (25%).</td>
<td>Entries were submitted between April 11 and April 21, 2017. Three monetary awards were issued in addition to four Honorable Mention designations. Participation was lower than anticipated, leading to partial rather than complete award of the full prize purse.</td>
<td>Code-A-Thon development and preparation duties were the responsibility of ONC employees. Contract funds were used to provide event support and logistics and to fund the cash awards. The Challenge utilized approximately 0.2 FTE and $145,000 in funding.</td>
<td>N/A</td>
<td>The Challenge intended to link patient data across research, claims and clinical data sets in order to standardize the sharing of patient data across organizations. As part of a Patient Centered Outcomes Research funding opportunity within HHS, a number of open source tools and services have been built to support the use of open APIs as a means to exchange clinical and health related data. This Code-A-Thon aimed to encourage developers to leverage these assets using these underlying services and platforms to build more advanced services on top of them and showcase their innovations.</td>
<td>Software and apps; Creative (design &amp; multimedia); Technology demonstration and hardware</td>
<td>N/A</td>
</tr>
<tr>
<td>Secure API Server Showdown Challenge</td>
<td>ONC</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The main goal of Stage 1 was for participants to implement the Substitutable Medical Applications, Reusable Technologies (SMART) standard on FHIR Authorization specification into an existing open source FHIR code base and to develop a secure FHIR server. The main goal of Stage 2 was to further harden the open source FHIR servers by enabling dedicated testing of the security components by participants. Participants tested the winning FHIR servers from Stage 1 and identified potential security vulnerabilities. This was intended to help improve the security of current and future open source FHIR servers and add to security best practices for use of SMART on FHIR authorization.</td>
<td>Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>Compared to a contract or other mechanism, a prize challenge provided the opportunity to reach out to the public for new ideas. Individuals and entities that work daily in the health IT and health care field, interacting with patients, can bring new viewpoints to issues that ONC policy specialists cannot. The Challenge also provided an opportunity to engage app and software developers who might not be familiar with the health IT world but can bring experience and knowledge from other industries to bear.</td>
<td>The total prize purse offered was $50,000 and the total amount awarded was $20,000. Non-monetary incentives included public recognition and opportunities to showcase work at ONC-sponsored events.</td>
<td>ONC solicited submissions through Challenge.gov, a contractor website, a HealthIT.gov blog post, the ONC Twitter account, a listserv announcement, email blasts, and university outreach. Despite a strong effort to advertise this Challenge, there was a small number of participants. This result was not unexpected because the Challenge was a very niche topic.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Other - University outreach</td>
<td>The Challenge was open to the public and targeted technology developers and the health IT community. The Challenge was run under the authority of section 105 of the America COMPETES Reauthorization Act and, therefore, had the eligibility criteria pursuant to it and to HHS policy guidance.</td>
<td>In Phase 1, submissions were evaluated as to whether they met the FHIR Server requirements as indicated on the Challenge website. A live demonstration of the FHIR server was held with judges evaluating their adherence to the requirements. In Phase 2, submissions were evaluated based on the most number of vulnerabilities discovered in FHIR server and two bonus categories.</td>
<td>Of the two entries submitted between October 10, 2017 and January 15, 2018, two prizes were awarded.</td>
<td>Challenge development and preparation duties were the responsibility of ONC employees. Once ready for launch, the Challenge began utilizing the services of a contractor which has been involved in such duties for ONC since 2010. The current contract is funded at $125,000 and structured to provide support for up to three challenges over a one-year period. These services include hosting of the challenge website, preparation of communications materials, ongoing day-to-day activities of challenge management, and support for reviewing and awarding functions. The Challenge utilized approximately 3 FTEs in FY17 and FY18 and $20,000 in FY18 funding.</td>
<td>N/A</td>
<td>The Challenge sought to engage the health IT industry to identify FHIR servers that reinforce the value of following technical security best practices on an industry-wide scale. These best practices ensure the most widely-accepted and effective measures are taken, resulting in a high-quality, secure FHIR server, further helping to protect the health information it contains.</td>
<td>Software and apps; Ideas; Technology demonstration and hardware</td>
<td>N/A</td>
</tr>
<tr>
<td>HHS Opioid Code-a-Thon</td>
<td>Office of the Secretary, Office of the Chief Technology Officer (CTO)</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>The purpose of the Code-a-Thon was to develop data-driven solutions to the opioid epidemic using Federal, State, and local (city, county) datasets. CTO�s goal was for solutions identified at the Code-a-Thon to be implemented and used to address the opioid crisis.</td>
<td>Find and highlight innovative ideas; Engage new people and communities</td>
<td>Prizes were used to engage new communities and expertise in answering questions about the opioid epidemic, and to develop data-driven solutions.</td>
<td>The total prize purse offered and awarded was $30,000. The $30,000 was in-kind support from co-sponsors: Socrata ($10,000), Tableau ($10,000), Alteryx ($5,000), and the University of Louisiana Lafayette ($5,000). Participants were also offered registration to attend the HHS Opioid Symposium that occurred the morning before the Challenge began.</td>
<td>CTO solicited submissions through social media and marketing emails. Non-Federal partners� outreach was critical to reaching communities that might not normally engage in government work.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Interested participants were required to form teams of three to five individuals. Team needed to attest to the following qualifications: (1) team skillsets: team indicates that they possess computer programming, data analytics, and end user design skillsets; (2) team multidisciplinary expertise: team indicates expertise in any two of the following areas relevant to the challenge tracks: health, analytics, social science, design, and/or engineering; and (3) team experience: the team indicates that they collectively have ten years of experience in their respective fields and/or previously participated in a public or private sector sponsored Code-a-Thon.</td>
<td>Participants performed a five-minute, in-person demo and provided the following information to be eligible for further review and a prize award on December 7, 2017: (1) team name, participant names, organization(s), and primary point of contact; (2) challenge track; (3) data resources utilized; (4) link to the solution, (5) written summary of the solution. The participants were judged by a group of judges from HHS, state, and private sector representatives. Solutions were judged based on design, potential for impact, technical achievement, and innovation.</td>
<td>Of the 50 team entries submitted by 300 participants on December 7, 2017, three prizes were awarded.</td>
<td>The Challenge utilized 2.5 FTEs in challenge planning and execution and $400,000 in FY18 funding for contract services for strategy and execution of the event.</td>
<td>Non-Federal partners sponsored prize money and provided in-kind donations for food, coffee, and snacks. Non-Federal partners also promoted the competition to increase participation. Finally, a non-Federal partner held an event prior to the Challenge. The partner convened a diverse set of stakeholders to develop design principles that helped guide challenge participants� solution development for the Challenge. Federal partners included numerous HHS subagencies (AHRQ, CMS, CDC, SAMHSA, HRSA) and other Federal agencies (Department of Transportation, Department of Justice, Department of Education, Department of Commerce, and Census Bureau). Non-Federal partners included the State of Indiana, the State of Louisiana, the State of North Carolina, the State of Virginia, Denver Health System, Socrata, Tableau, Alteryx, the University of Louisiana LaFayette, IEEE, Appriss Health, Google, Tamr, Stanford MedX. The estimated value of partner contributions is $35,000.</td>
<td>Teams used data from HHS and other Federal agencies, some of it released for the first time, to analyze trends and patterns and propose solutions in three challenge areas. The innovative ideas developed at the Code-a-Thon have led to solutions that are being tested in the field or to new companies being formed. Finally, the NIH NIDA Office of Translational Initiatives and Program Innovations developed a SBIR grant to support new solutions and business models relevant to the opioid epidemic.</td>
<td>Software and apps; Technology demonstration and hardware</td>
<td>There is a need to continue analysis of data to inform approaches to the opioid epidemic. There are also efforts within HHS to increase data sharing between agencies and analyses conducted using multiple data sources. Future plans will focus on answering questions about the opioid epidemic and other priority area topics through challenge competitions, some of which may specifically engage staff internal to HHS.</td>
</tr>
<tr>
<td>Hidden Signals Challenge-�Can you Identify Biothreats in Real-Time?�</td>
<td>DHS Science and Technology Directorate</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>The Hidden Signals Challenge called upon data innovators from a wide variety of fields�from data science, to civic tech, to epidemiology�to develop concepts (in Stage 1) and system designs (in Stage 2) for novel uses of existing data that will identify signals and achieve timelier alerts for biothreats in cities and communities. DHS intended for this work to be the first step in the design of a local and/or national-level system that could enable city-level operators to make critical and proactive decisions based on the most relevant and actionable insights. The Challenge focused on large metropolitan areas such as New York, Los Angeles, Washington D.C., Chicago, Boston, and Atlanta but was also open to solutions that address all geographic locations.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Solve a specific problem; Engage new people and communities</td>
<td>In the context of population health, understanding and utilizing nontraditional data as prognostic indicators provides an opportunity for earlier detection and better situational awareness of potential health threats. Previous and on-going research and development (R&amp;D) efforts have focused on obtaining personal health information; however, this information is difficult to access and not timely enough to enable early intervention. While DHS is aware of certain data sets that could be of value, a prize competition enabled solvers from a broader knowledge base to not only join unique data sets that might otherwise not be considered, but also to apply novel data-driven analytics to provide strategies and algorithms for anticipating and detecting biological threats in a timely manner. Further, surveillance and data integration are topic areas that span a broad range of industries, from commercial business intelligence to law enforcement, and a prize competition would potentially reach such needed expertise that might otherwise be missed. A prize competition enabled novel approaches to the problem.</td>
<td>The total prize purse offered and the total amount awarded was $300,000. The prize purse was divided into two stages. In Stage 1, five finalists received $20,000 each and in Stage 2, the first place winner received $150,000 and the second place winner received $50,000. Non-monetary incentives included mentorship for problem solvers in the development and implementation of their solutions during Stage 2. All prize funds were FY17 funds from the Real-Time Biothreat Awareness Apex Program. Cash prizes were paid directly to the winners by the DHS Science and Technology Directorate.</td>
<td>During Stage I open submissions, the Challenge sought to drive submissions from innovators and communicate the program�s value to the public and stakeholders. During Stage II, the Challenge sought to drive awareness of the program to the public and stakeholders such as city-level employees, healthcare professionals, and data technology influencers across the United States. Promotion included public press announcements and targeted outreach, influencer activation, and sharing messages through the Challenge, DHS Science and Technology (S&amp;T), and Challenge winners� channels. Press coverage included stories in 15 outlets including security (American Security Today), government (FedScoop), and healthcare (Fierce Healthcare). For targeted outreach, the vendor directly contacted over 350 validators, experts, and solvers and secured placement for Challenge.gov, NYC Open Data, Open Data Atlanta, Open Data D.C., and Harvard Business School Digital Initiative newsletter. A Challenge-specific newsletter (opened approximately 500 times via forwarding) and blog were also developed. Additionally, social media presence garnered more than one million impressions. Notable tweets included U.S. Chief Data Scientist DJ Patil (@DPatil), In-Q-Tel&#39;s B, Next Lab (@HarvardCIL), and data influencer (@KDNuggets). These efforts resulted in nearly 300 visitors to the Challenge website over three days, including tech giants Amazon and Microsoft, city-level employees from NYC Transit Authority and City of Palo Alto, and hospitals such as Longwood Medical and Academic Area, Children�s Hospital Colorado, London School of Hygiene and Tropical Medicine, and St. Jude�s Children�s Hospital.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The Challenge was open to all individuals over the age of 18 who have not been convicted of a felony. Individuals must be a United States citizen or legal permanent resident at the time of entry. In addition, the Challenge was open to all validly formed legal U.S. entities whose primary place of business was in the U.S. and have not declared or been declared in bankruptcy. Eligibility was subject to verification by the Department of Homeland Security, Science and Technology Directorate before cash prizes were awarded. For full eligibility details, visit: https://www.hiddensignalschallenge.com/rules-terms-conditions/#eligibility</td>
<td>Selecting the five Stage I finalists involved the following work streams: (1) preliminary vetting by the vendor, with confirmation by DHS of ineligible submissions; (2) assignment of submissions to a review panel of 17 expert review panelists; (3) review panel scoring against an established rubric (originality, impact, feasibility, sustainability, scalability, team); (4) advancement of the top 20 submissions to judges; (5) judges scoring (same criteria); (6) deliberation call; (7) finalist recommendation; (8) DHS vetted finalists; and (9) clearance by DHS Office of General Counsel (OGC). Selecting the grand prize winner and runner-up for Stage II involved judges scoring against established criteria (empathy, impact, feasibility, sustainability, scalability, and team), a deliberation call, a winner recommendation, and DHS vetting and clearance of winners.</td>
<td>The Challenge consisted of two stages. Stage I submissions opened October 17, 2017 and closed December 4, 2017. Stage I winners were announced February 14, 2018. Of the 37 submissions received in Stage I, five winners (three individuals and two teams) were selected to receive $20,000 each. Stage II was announced February 16, 2018 and submissions closed April 13, 2018. Stage II winners were announced May 30, 2018. Of the 5 submissions received in Stage II, two winners were selected. The first prize winner received $150,000 and the second prize winner received $50,000.</td>
<td>Funding for FY17 and FY18 totaled $507,071.48. Of the total funding, $452,772 was allotted to administer the prize through NASA�s Center of Excellence for Collaborative Innovation and $36,689.48 was allotted for NASA�s overhead. In addition, two full-time equivalent employees (FTEs) supported the planning stage of the Challenge in FY17 and 1.5 FTEs supported the execution stage of the Challenge in FY18. Funds provided were used to establish an interagency agreement (IA) with NASA and select a third-party prize administrator. Expenses were invoiced by NASA and prize funds were paid directly to winners by the DHS Science and Technology Directorate. Federal personnel supporting the Challenge performed activities such as preparing paperwork/documentation for the prize design, coordinating stakeholders, participating in meetings, providing subject matter expertise and services (e.g., communications and legal), and judging.</td>
<td>For this challenge, the DHS Office of Health Affairs National Biosurveillance Integration Center (NBIC) participated as the primary partner. NBIC offered in-kind support and expertise for the design and development of the Challenge, judging, and participation in the Challenge �virtual accelerator.� NBIC provided additional marketing and outreach through their own communication channels, monthly forum, and stakeholder newsletter. For future challenges, clearly defining the roles and responsibilities of all partners will be critical to avoiding conflict and ensuring smooth and successful execution of the challenge. Non-Federal partners included the U.S. Department of Health and Human Services, Insight Data Science, Plymouth University, Enigma Technologies, the City of San Francisco, and Google. Total estimated value of partner contributions was $100,000.</td>
<td>DHS� biodetection and biosurveillance programs have found that the current detection and surveillance methods for biological threats, whether intentional releases of biological agents or infectious diseases, are not timely enough to enable early warning and intervention. Extensive literature reviews and interviews with subject matter experts have resulted in the identification of numerous problems with existing systems and biosurveillance efforts, including barriers to access of relevant situational and health data (e.g., electronic health records); confidence in data sources; uncertainty about existing, evolving, and emerging biological threats; and absence of the infrastructure, technologies, policies, and knowledge needed to effectively collect and derive insights from data. To achieve a timelier bio-surveillance enterprise, local and State entities/operators, as well as DHS operational components, must have access to a system that enables heterogeneous data sets to be captured and analyzed in real-time. These disparate data sets must be analyzed to not only understand relationships among them but also possible correlations with biological threats. By harnessing new streams of nontraditional data and information, an emerging problem may be identified more quickly and confidently, ultimately resolving the problem faster. DHS S&amp;T challenged data innovators from a wide variety of fields to develop concepts for novel uses of existing data that will identify signals and achieve timelier alerts for biothreats in our cities and communities. Successful concepts explored connections between multiple readily accessible data sources to develop real-time insights that can improve public safety responses to emerging biothreats.</td>
<td>Technology demonstration and hardware; Analytics, visualizations, algorithms</td>
<td>During the upcoming two fiscal years, DHS will focus on a priority cross-cutting and topical area: the opioid epidemic. This topic has many problem spaces that are suitable for a challenge format, including technical approaches for detection/identification as well as big data analytics.</td>
</tr>
<tr>
<td>Passenger Screening Algorithm Challenge</td>
<td>DHS Science and Technology Directorate</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Original equipment manufacturer (OEM) developers have struggled to decrease the rate of false alarms of Advanced Imaging Technology (AIT) passenger screening systems deployed at airports. False alarms result in secondary screening and pat downs, reducing checkpoint throughput and adversely impacting the traveler experience. Improved image recognition algorithms have the potential to reduce false alarms and are also critical to enabling an effective response to rapidly evolving security threats. DHS Science and Technology Directorate (S&amp;T) and the Transportation Security Administration (TSA) used this Challenge to explore diverse and potentially more comprehensive solutions from many creative sources. Instead of partnering with OEMs on a one-on-one basis, the competition sought image recognition software (i.e., algorithms) that can be adapted into any number of hardware platforms. DHS S&amp;T and TSA are looking to grow the industry around third-party capability providers of threat recognition algorithms. There currently is a very small technical provider base in this field, which limits the number of companies who traditionally propose solutions. DHS S&amp;T and TSA are investigating interface standards that will allow third-party algorithms to be quickly implemented on deployed systems, allowing for rapid adaptation to changing threats in a non-proprietary way. This Challenge sought to identify third-party providers and how their creative approaches can be realized to improve security and provide a better passenger experience.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>Software algorithms are purchased traditionally through OEMs and are highly proprietary to the company. This Challenge aimed to improve the procurement process by engaging skilled algorithm developers. The end results were new approaches and capabilities that were developed faster and more cost-effectively than a traditional research and development contract.</td>
<td>The total prize purse offered and the total amount awarded was $1,500,000. Eight awards were made. The first place winner was awarded $500,000; the second place winner was awarded $300,000; the third place winner was awarded $200,000; and the fourth through eight place winners were awarded $100,000 each. DHS S&amp;T dispersed the monetary award payments to the winners after verifying eligibility.</td>
<td>Submissions were solicited through the Kaggle platform. The platform included automatic scoring and collaboration tools. Hosts could also view individual submissions for additional analysis. The platform allowed for both solvers and hosts to understand algorithm performance in near real-time, which resulted in strong platform engagement with significant host visibility into the algorithms. Competition marketing was used through the Kaggle platform including their website, blog, and social media. Additional marketing was done through Challenge.gov. Across these websites, there were over 300,000 page views. The Kaggle platform was determined to be the most effective marketing method.</td>
<td>Social media (e.g., Twitter, Facebook); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>All participants were required to agree to non-disclosure rules in order to protect the data used in the competition. Participants were bound by the rules under the America COMPETES Act with regards to prize eligibility. There were no additional restrictions on participation in the competition.</td>
<td>Submissions were evaluated using a quantitative log-loss metric. This metric compared the submitted confidence score for each of the 23,596 required predictions to the binary ground-truth (i.e., either an object was present or not). This comparison resulted in a quantitative metric that could then be ranked. Submissions were ultimately approved by evaluators from the DHS S&amp;T Apex Screening at Speed program, DHS S&amp;T Transportation Security Laboratory, and TSA.</td>
<td>Of the 9,339 entries submitted by 586 participants between June 22, 2017 and December 15, 2017, a total of eight awards were made.</td>
<td>DHS S&amp;T contributed a total of $1,122,000 through an interagency agreement with NASA�s Center of Excellence for Collaboration Innovation to plan and conduct the Challenge. This included $1,030,106.52 for the prize administrator contract to Kaggle, Inc., $81,893.48 for NASA overhead, and $10,000 for a required Client Accounting Advisory Services (CAAS) audit. The $1,500,000 prize purse was dispersed by DHS S&amp;T. The prize purse included a contribution of $1,000,000 from TSA and $500,000 from DHS S&amp;T. In addition, 0.85 full-time equivalent employees (FTEs) supported the Challenge in FY17 and in FY18. The source of funding for the $1,122,000 interagency agreement with NASA was from FY16 appropriated funds for Integrated Passenger Screening Systems. The source of funding for the $1,500,000 prize purse is as follows: $500,000 from FY16 appropriated funds for Integrated Passenger Screening Systems and $1,000,000 from TSA through an interagency agreement. All funding was obligated in FY17.</td>
<td>DHS S&amp;T partnered with NASA�s Center for Excellence for Collaborative Innovation. NASA provided subject matter expertise and contracting support to help execute the Challenge. In addition to NASA, DHS S&amp;T partnered with TSA�s Office of Acquisition Program Management, which provided $1,000,000 to help fund the prize purse and also provided subject matter expertise and judging support to the competition.</td>
<td>Over two million passengers are screened daily at U.S. airports using highly sensitive screening technology to detect potential threats and prevent them from getting through the checkpoint. While passenger security is TSA�s number one priority, it is also important to speed up the screening process to ensure an enjoyable travel experience. False alarms, resulting in pat-downs and secondary screening, is a significant contributor to delays at the checkpoint. The DHS Science and Technology Directorate and TSA are striving to reduce false alarm rates, as well as develop the capability to continue to protect against new and evolving threats. A passenger screening system with much lower false alarm rates will have a significant impact to aviation checkpoint operations, improving the passenger experience and overall passenger throughput. TSA will be able to repurpose TSA officers to other critical tasks as opposed to pat-downs. Finally, better algorithms are a critical part of a flexible and adaptable security posture, allowing TSA to rapidly respond based on real-time requirements.</td>
<td>Software and apps; Analytics, visualizations, algorithms</td>
<td>For FY19, three competitions are in planning stages and one in early exploration stage for execution by DHS S&amp;T. Crosscutting mission areas include chemical-biological defense, opioid detection in bulk mail, search and rescue, and emergency preparedness. Planned competitions include the development or enhancement of a new technology, opportunities for entrepreneurs to develop and market new technologies, and an educational game to educate and better prepare the public. Additional cross-cutting areas include first responder technologies. For FY20, cross-cutting areas that may be considered by DHS include critical infrastructure technologies, first responder technologies, cyber defense applications, chemical-biological detection technologies, algorithms, sensors, and screening technologies.</td>
</tr>
<tr>
<td>AIT FY18 Fishackathon</td>
<td>American Institute in Taiwan (AIT)</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>The goal of the prize competition was to bring together thousands of concerned designers, developers, and subject matter experts to build practical technological solutions to endemic problems faced by the global fishing industry. By attracting problem solvers across the globe and encouraging them to embrace collaborative problem solving efforts, the competition aimed to produce open-source solutions to global challenges on themes such as sustainability, marketplace, and enforcement.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity</td>
<td>A prize competition was seen as an effective means for rewarding innovation and technological advances while encouraging young coders to continue their work in this field and collaborate together to solve tough issues. Unlike more traditional methods such as contracts, grants, and cooperative agreements, the prize competition could promote project goals, engage younger audiences, and facilitate the exchange of ideas and networks across the globe.</td>
<td>The total prize purse offered and awarded was 180,000 New Taiwan dollars (NTD) in Taipei: and 130,000 NTD in Kaohsiung.</td>
<td>In FY18, the AIT utilized social media to gather interest for Fish Hackathon and learned that the competition was effective in attracting young people to showase their creativity and innovative ideas. In the end, there were 140 volunteer coders in teams of three to five in Taipei who spent a weekend developing usable mobile and technological solutions to real-world problems submitted by fisheries experts around the world. In Kaohsiung, approximately 50 participants in 17 teams participated. The AIT  was also able to advertise the core programs, increasing awareness of American Innovation Center events.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - IT; Other - Home Banner; Other - Youtube</td>
<td>N/A</td>
<td>Relevant experts from universities, institutions, and research centers were invited to evaluate the submissions for the prize competitions and assess different pitches by the teams. The judges represented a variety of stakeholders, including the Institute of Oceanography in National Taiwan University, Hope Bay Technologies, Inc., National Taiwan Ocean University, Cloudeep, FIH Mobile Limited, and Ocean Says.</td>
<td>N/A</td>
<td>AIT did not make monetary donations to the prize competitions for this event. However, AIT Taipei contributed $9,500 USD in grants for venue setup, translations, on-site support, and promotional materials. AIT Kaohsiung contributed $3,000 USD. AIT Taipei utilized eight Information Resource Center staff members, while AIT Kaohsiung partnered with National Sun Yat-sen University American staff to help with the program. All of the American Space staff was utilized for the event and provided grants to partners for venue set up, programming, and translations.</td>
<td>Non-Federal Partners for AIT Taipei included the Council of Agriculture�s Fisheries Agency, Taipei City Government, Microsoft Taiwan, and Syntrend Startup Foundation. Non-Federal Partners for AIT Kaohsiung included the Fisheries Agency, Kaohsiung Marine Bureau, and National Sun Yat-sen University. For FY18, the Fisheries Agency contributed 180,000 NTD in Taipei and 130,000 NTD in Kaohsiung. The rest of the special awards were donated by different partners such as Foundation for Women�s Rights Promotion and Development and Pixnet.</td>
<td>The prize competition advanced the agency mission by addressing transnational challenges, encouraging innovative problem solving, developing sustainable solutions to economic challenges, and facilitating AIT�s engagement with Taiwan�s emerging generation of coders and technology innovators.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware; Analytics, visualizations, algorithms</td>
<td>Over the next two FYs, AIT and AIT Kaohsiung will continue to conduct prize competitions to promote the Hackathons and work with Federal and non-Federal partners to provide greater incentives for participation. AIT has received positive feedback from the audiences and participants and gained great publicity for Taiwan. By bringing together coders and participants to develop solutions to unique challenges, the competition will continue to improve the sustainability of both Taiwan and the planet.</td>
</tr>
<tr>
<td>FY17 and FY18 NASA Hackathon</td>
<td>American Institute in Taiwan (AIT)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>The goal of the National Aeronautics and Space Administration (NASA) Hackathon prize competition was to produce open-source solutions to global challenges by attracting problem solvers across the globe and encouraging them to embrace collaborative problem solving efforts.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity</td>
<td>A prize competition was seen as an effective means for rewarding innovation and technological advances while encouraging young coders to continue their work in this field and collaborate together to solve tough issues. Unlike more traditional methods such as contracts, grants, and cooperative agreements, the prize competition could promote project goals, engage younger audiences, and facilitate the exchange of ideas and networks across the globe.</td>
<td>The total prize purse offered and awarded was 440,000 New Taiwan dollars (NTD) during the FY17 NASA Hackathon and 280,000 NTD during the FY18 NASA Hackathon. FY17 non-monetary incentives included a Discovery Channel film screening for participants, a one-page advertisement in the April issue of Scientific American, and social media publicity through Pixnet. FY18 non-monetary incentives included two internship opportunities and two Xbox consoles.</td>
<td>In both FY17 and FY18, social media platforms were utilized to gather interest for the NASA Hackathons. In FY18, Facebook granted advertisement credits to AIT, which allowed AIT to spend approximately $2000 to $3000 in promoting the Hackathon.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - IT; Other - Home Banner; Other - Youtube</td>
<td>N/A</td>
<td>Subject matter experts from universities, institutions, and research centers were invited to serve as judges for the prize competitions. The judges leveraged global criteria provided by NASA to evaluate the pitches by the competing teams.</td>
<td>N/A</td>
<td>Funding from AIT for FY17 totaled $7,500 in grants for venue setup, on-site support, translations, and promotional items. AIT also provided three airplane tickets to Orlando, Florida for NASA Hackathon winners. Funding from AIT for FY18 totaled 10,000 NTD in VR Special Awards through the American Innovation Center. AIT also contributed approximately $9,000 in grants for venue setup, on-site support, translations, and promotional items. Seven American Space staff members supported the FY17 Hackathon, and eight American Space staff members supported the FY18 Hackathon.</td>
<td>FY17 non-Federal partners included the Ministry of Science and Technology, Ministry of Economic Affairs, National Taiwan University, and Taipei City Government. FY18 non-Federal partners included the National Space Organization, Chunghwa Telecom, Taipei City Government, National Taiwan Normal University, IBM Taiwan, and Micron. Estimated value of partner contributions totaled 440,000 NTD in FY17 and 280,000 NTD in  FY18. In FY17, the Ministry of Science and Technology funded $180,000 NTD of the grand awards, Microsoft donated 60,000 NTD in food and two Xbox consoles, and Intel donated a few monetary awards. In FY18, the National Space Organization funded $180,000 NTD in cash rewards, Microsoft donated 60,000 NTD in food and two Xbox consoles, and IBM offered internship opportunities. The remaining special awards were donated by different partners.</td>
<td>The prize competition advanced the agency mission by addressing transnational challenges, encouraging innovative problem solving, developing sustainable solutions to economic challenges, and facilitating AIT�s engagement with Taiwan�s emerging generation of coders and technology innovators. There was an average of 50 groups that signed up in both years, which indirectly helped advertise AIT�s core programs and increased the target audiences� awareness of the American Innovation Center events.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware; Analytics, visualizations, algorithms</td>
<td>AIT will continue to conduct prize competitions to promote the Hackathons and work with non-Federal and Federal partners to provide greater incentives for participation.</td>
</tr>
<tr>
<td>Boldline P3 Accelerator � Cohort 1</td>
<td>DOS, Secretary�s Office of Global Partnerships (S/GP)</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>Boldline is the U.S. Department of State�s new partnership accelerator aimed to support and scale innovative public-private partnerships (P3s). One of the first programs of its kind, Boldline supported social good P3s that address pressing global challenges and focused on giving them tools to scale their missions. The main goal of Boldline was to build and deploy strategic connections and collaborations aimed at strengthening the global partnership building ecosystem, promoting and facilitating connectivity between the private sector and governments, and fostering innovative partnership business models. Boldline took the often dotted lines between government, private sector, and civil society and created a bold line between the sectors through partnerships.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity; Other - Build public-private partnerships</td>
<td>The U.S. Department of State, in close collaboration with industry leaders, organized a one-week partnership building accelerator program that brought together public institutions, corporations, innovation companies, entrepreneurship support organizations, and financial institutions to galvanize interest for the participating partnerships and to help build the framework for these partnerships in targeted countries. The program identified timely P3s in the early development stages of their partnerships and P3s ready to scale their operations and activities. Through a one week accelerator and ongoing support, Boldline provided the individuals and institutions behind these partnerships with mentorship, access to resources, government relations, and global networks needed to scale their impact. The accelerator took place in February 2018 in Washington, DC, and participation in the program was highly competitive.</td>
<td>Non-monetary incentives included mentorship, networking, and training by DOS employees and non-government subject matter experts on public-private partnerships, private sector engagement, and other relevant topics.</td>
<td>Submissions for Boldline were obtained from the Federal prize competition website, www.challenges.gov, and the DOS website, www.state.gov/partnerships.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>N/A</td>
<td>Submissions were evaluated by a selection committee of leadership in S/GP.</td>
<td>Applications for Boldline opened November 1, 2017 and closed November 21, 2017. The accelerator programming occurred between February 26 and March 2, 2018. Of the 52 entries submitted by nine participants, nine winners were selected.</td>
<td>Funding for FY18 totaled $15,991. Funds provided were used for the venue, participant lodging, supplies (printing and audio/video rental), and representative and sponsor funds for catering meals. Five permanent government FTEs and five contractor FTEs supported the challenge in FY18.</td>
<td>The DOS Office of International Religious Freedom within the Bureau of Democracy, Human Rights, and Labor served as a Federal partner during the first cohort.</td>
<td>Boldline advanced the mission of the U.S. Department of State�s Office of Global Partnerships by strengthening and deepening U.S. diplomacy and development around the world through partnerships that leverage the creativity, innovation, and core business resources of partners for greater impact. The Office is a center of excellence for collaboration between the U.S. Department of State, the public and private sectors, and civil society. The Department recognizes that it takes more than governments to address many global issues and believes that partnerships with the private sector, civil society, philanthropy, and other non-governmental organizations are necessary for our national security and diplomacy objectives.</td>
<td>Ideas; Other - Partner building; Other - Relationship building; Other - Networking</td>
<td>The DOS is planning to conduct more Boldline cohorts based on the Secretary�s priorities and the DOS� Mission and Goals. Each cohort will focus on a specific topic set and be supported by other State bureaus, offices, and posts (domestic and abroad). The second Boldline P3 Accelerator cohort focused on supporting partnership creation for International Religious Freedom. The third Boldline P3 Accelerator cohort, which is still in progress, will focus on supporting partnership creation for countering propaganda and disinformation abroad.</td>
</tr>
<tr>
<td>Boldline P3 Accelerator for Religious Freedom (RF) � Cohort 2</td>
<td>DOS, Secretary�s Office of Global Partnerships (S/GP)</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>Boldline Religious Freedom (RF) is the U.S. Department of State�s partnership accelerator aimed to support and scale innovative public-private partnerships (P3s) to promote and defend religious freedom around the world. Boldline RF supported stakeholders who are leading social good P3s that align with U.S. foreign policy priorities and focused on giving them tools to scale their missions. The main goal of Boldline RF was to build and deploy strategic collaborations aimed at advancing religious freedom globally by facilitating connectivity between the private sector and governments, fostering innovative partnership models, and providing mentoring and training. Through this accelerator program, Boldline RF took the often dotted lines between government, private sector, and civil society and created a bold line between the sectors through partnerships. The Department defines a partnership as a collaborative working relationship that includes non-governmental partners in which the goals, structure, and governance, as well as roles and responsibilities, are mutually determined and decision-making is shared. Successful partnerships entail shared objectives, transparency, mutual risks and benefits, and accountability.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity; Other - Build public-private partnerships</td>
<td>The U.S. Department of State, in close collaboration with industry leaders, will organized a three-day partnership building accelerator program that brought together civil society organizations, public institutions, corporations, innovation companies, entrepreneurship support organizations, and financial institutions to galvanize interest for the participating partnerships and to help build the framework for these partnerships in their respective countries. The DOS sought the participation of stakeholders representing partnerships in the early development stages or P3s ready to scale their activities and engage additional partners. The Boldline P3 Accelerator provided the individuals and institutions behind these partnerships with the mentorship, skills training, government relations, and global networks needed to scale their impact. The accelerator took place in October 2018 in Washington, D.C., and participation in the program was highly competitive.</td>
<td>Non-monetary incentives included mentorship, networking, training by DOS employees and non-government subject matter experts on public-private partnerships, private sector engagement, other relevant topics.</td>
<td>Submissions for Boldline were obtained from the Federal prize competition website, www.challenges.gov, and the DOS website, www.state.gov/partnerships.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>N/A</td>
<td>Submissions were evaluated by a selection committee of leadership in S/GP.</td>
<td> Applications for Boldline opened June 22, 2018 and closed August 23, 2018. The accelerator programming occurred between October 22 and October 24, 2018. Of the 31 entries submitted by six participants, six winners were selected.</td>
<td>Funding for FY18 totaled $38,160. Funds provided were used for the venue, participant lodging, supplies (printing and audio/video rental), third part mentor fees, and representative and sponsor funds for catering meals. Five permanent government FTEs and five contractor FTEs supported the challenge in FY18.</td>
<td>The DOS Office of International Religious Freedom within the Bureau of Democracy, Human Rights, and Labor and the Global Engagement Center served as Federal partners during the first cohort.</td>
<td>The U.S. Department of State�s Office of Global Partnerships and Office of International Religious Freedom worked in collaboration to provide the Boldline RF accelerator program. Boldline advanced the missions of both offices by strengthening and deepening U.S. diplomacy and development around the world through partnerships that leverage the creativity, innovation, and core business resources of partners for greater impact while also promoting and defending freedom of religion, conscience, and belief for all people around the world. The U.S. Department of State�s Office of Global Partnerships is a center of excellence for collaboration between the U.S. Department of State, the public and private sectors, and civil society. The Department recognizes that it takes more than governments to address many global issues and believes that partnerships with the private sector, civil society, philanthropy, and other non-governmental organizations are necessary for our national security and diplomacy objectives.</td>
<td>Ideas; Other - Partner building; Other - Relationship building; Other - Networking</td>
<td>The DOS is planning to conduct more Boldline cohorts based on the Secretary�s priorities and the DOS� Mission and Goals. Each cohort will focus on a specific topic set and be supported by other State bureaus, offices, and posts (domestic and abroad). The third Boldline P3 Accelerator cohort, which is still in progress, will focus on supporting partnership creation for countering propaganda and disinformation abroad.</td>
</tr>
<tr>
<td>DOS Fishackathon</td>
<td>DOS, Secretary�s Office of Global Partnerships (S/GP)</td>
<td>COMPETES Authority</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>The U.S. Department of State launched Fishackathon in 2014 to bring together amateur and professional volunteer coders to develop practical, technological solutions addressing challenges in sustainable fishing worldwide.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>A hackathon was utilized to engage atypical actors in the development of solutions to challenges facing fisheries worldwide and to promote awareness of sustainable fishing issues among populations unaware of these challenges. The hackathon model typically attracts students and young tech-focused individuals who can apply �outside-the-box� thinking to a sphere they aren�t typically involved with.</td>
<td>The total prize purse offered and awarded was $200,000 in Amazon Web Service (AWS) credits, provided by AWS. Non-monetary incentives included free .co and .us domain name registrations, provided by Hover.</td>
<td>DOS used a global hackathon model to solicit submissions for solutions to the challenges facing fisheries worldwide. Though the solutions proposed by participants have potential for further development and life beyond the competition, the most immediate result of the competition is the awareness of sustainable fishing issues spread to students and tech communities around the globe. The competition was advertised digitally through Hackernest�s extensive network and the networks of the regional hosts and sponsors.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Target solver audiences included coders, software developers, designers, subject matter experts, and students. Advanced registration for the event(s) was required, but open to all interested in participating.</td>
<td>Submissions were judged by a panel of subject matter experts assembled by Hackernest on creativity, feasibility, and impact.</td>
<td>Entries were submitted by more than 3,500 participants globally between February 10 and February 11, 2018. The Grand prize was awarded to one team of five individuals, and there were 35 regional winning teams.</td>
<td>The Department of State�s only financial commitment to the program was used to purchase promotional materials for the U.S. events. All other costs were covered by Hackernest and regional hosts. This amounted to one FTE in each FY17 and FY18, and funds of $1,289 in FY18.</td>
<td>Non-Federal partners include Hackernest, in both FY17 and FY18, and EachMile in FY18. Hackernest managed all logistics related to the 2018 event, including raising funds, recruiting regional hosts, and all promotion related to the competition. EachMile will take on the role of managing partner for the 2019 event. The total estimated value of partner contributions is $500,000 in kind.</td>
<td>N/A</td>
<td>Software and apps; Ideas</td>
<td>EachMile plans to revamp the focus of Fishackathon when they run the competition in 2019. They will emphasize developing solutions for capturing data using sensors and the Internet of Things, and sharing data using open platforms and blockchain technology. The global event, which takes place the weekend of October 5th and 6th of 2019, will home in on a select number of cities, rather than the widespread approach favored in past years of the hackathon.</td>
</tr>
<tr>
<td>Competition for the President�s Day</td>
<td>U.S. Embassy Astana</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>The goal of the competition was to learn more about American culture and holidays.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>Prizes were utilized to encourage participants to continue learning and share their knowledge on social media.</td>
<td>The total prize purse offered and awarded was $100. The prize came from the U.S. Consulate General. Non-monetary incentives included T-shirts.</td>
<td>The competition was announced on social media and monitored by an Information Assistant.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>N/A</td>
<td>Participant answers were evaluated on the basis of accuracy.</td>
<td>Ten winners were awarded prizes.</td>
<td>Over five days, an Information Assistant tracked the answers posted by participants.</td>
<td>N/A</td>
<td>The competition helped advance the agency mission to promote American culture.</td>
<td>Ideas</td>
<td>The U.S. Consulate tries to engage with online audiences by organizing quizzes or competitions to increase the number of followers, promote global engagement, and spread knowledge of U.S. customs and traditions. Similar competitions will be organized in the upcoming years.</td>
</tr>
<tr>
<td>3-2-1 GO!</td>
<td>U.S. Embassy Koror, Public Diplomacy</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The goal of 3-2-1 GO! was to raise awareness for the Olympic Sport Envoy visit. The challenge was to �like� the post highlighting the Olympic Sport Envoy visitor and download a free Olympic poster linked to a State Department promotion of the U.S. Olympic Team.</td>
<td>Inform and educate the public</td>
<td>A prize competition was utilized to measure the effectiveness of using social media to raise awareness and engage with the community of Palau.</td>
<td>Non-monetary incentives included a free Olympic poster.</td>
<td>The competition leveraged the U.S. Embassy Koror Facebook page.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>The target audience was the community of Palau.</td>
<td>Facebook Analytics was used to measure the number of engagements.</td>
<td>N/A</td>
<td>No funds were required for this challenge, and two hours of labor supported the project. A link to a free poster offered by the State Department was provided as an incentive for liking our Facebook post.</td>
<td>The State Department provided the five Olympic posters.</td>
<td>3-2-1 GO! acted in parallel with the �Plant, Eat and Move� campaign by working to educate Palau�s youth on noncommunicable disease (NCD) reduction and active lifestyle choices to combat Palau�s growing problem with NCD rates and obesity. Through outreach activities, such as highlighting the visit of U.S. Olympic Sport Envoy, the competition utilized social media to raise awareness and engage with the community of Palau.</td>
<td>Analytics, visualizations, algorithms</td>
<td>The lessons learned from 3-2-1 GO! will support the design and execution of future prizes and challenges.</td>
</tr>
<tr>
<td>E-Farmer Support App</td>
<td>U.S. Embassy Phnom Penh</td>
<td>COMPETES Authority</td>
<td>This competition was underway in FY18.</td>
<td>AMK Microfinance Institution Plc. (AMK) proposed a grant to develop an innovative approach to invest in farmer capacity building and technical assistance. The grant was awarded by Feed the Future Harvest II with the goal to improve the farming sector as a whole as well as contribute to AMK�s business objectives of increasing farmer productivity and reducing default rates. AMK demonstrated their ownership of this activity by investing in a feasibility study for this platform, seeking support in co-funding application development, content development, and marketing, and requesting expert advice for directly supporting farmers in the United States Government Zone of Influence. AMK anticipates that this initiative will be profitable by 2021, and Harvest II has requested that they provide lessons learned and a sustainability plan by the end of the grant period (June 2019) to analyze the business case for commercial viability, including costs (operation, content updates, and maintenance) and revenue sources.</td>
<td>Solve a specific problem; Develop technology; Build capacity; Stimulate a market</td>
<td>In order to achieve the goals, Harvest II issued a grant to AMK Microfinance Institution Plc. to implement the E-farmer Support App activity. Through this grant, farmers are expected to increase their productivity by incorporating appropriate improved technologies promoted through the app. Furthermore, this activity supports an innovative idea by a finance institution that is actively pursuing inclusive growth goals. Harvest II expects the project to have several important demonstration effects within the broader market system.</td>
<td>The total prize purse offered was $100,000 and the total amount awarded is expected to be $83,420. As of FY18, $13,000 of the cash prize amount was expended.</td>
<td>Harvest II published a Grant Program Statement (GPS) in the local newspaper advertising the E-Farmer Support App project. Of the concept papers submitted in response to the GPS, AMK Microfinance Institute Plc. was selected to implement the project. The GPS is considered a competitive grant solicitation method due to its full and open publication and the project�s clear and consistent application of identical, clearly stated evaluation criteria across all concepts/applications received.</td>
<td>Social media (e.g., Twitter, Facebook); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Through this E-solution, AMK expects to reach 3,000 farmers, 15% of which will be horticulture farmers.</td>
<td>AMK�s concept note scored high enough to pass to the application phase, which required scoring 70% or more against the grant criteria. The full grant application from AMK was then evaluated by Harvest II�s grants evaluation committee and scored in five categories: implementation plan, sustainability and replicability, measurable impact, budget, and budget contribution.</td>
<td>N/A</td>
<td>Funding in FY18 totaled $13,000 and was allocated between six AMK deliverables: (1) $4,000 for the AMK workplan, which outlined the planned activities during the grant period and the person responsible for each activity; (2) $1,000 for the summary of the planned design for database and app architecture, including wireframe; (3) $3,000 for the schedule of original content to be developed and released with Version 1 launch; (4) $1,500 for the list of recruited Agronomist and Community Facilitators in Bakan, Krokor districts, Pursat province, and Moung Russei, Sangke districts in Battambang province; (5) $3,000 for the summary of existing agronomic knowledge contents to be uploaded on mobile app version 1; and (6) $500 for the draft marketing materials, such as leaflets to promote app usage. In addition, one FTE employee supported the project in FY18. The total of non-cash prize amount expenditure, including Harvest II staff time, was $20,000.</td>
<td>The estimated value of partner contributions totaled $147,002.</td>
<td>The E-Farmer Support App is being created to freely share information and agronomic knowledge, as digital solutions can work to close some of the production-technical knowledge gaps of farmers. In addition, the app aims to ultimately expose farmers to business-related services, including finding sellers, buyers, and technical advisors, while helping to reduce default rates among AMK�s borrowers. Thus, the E-Farmer Support App contributes to Mission Objective 4.2 (CDCS DO 3): Strengthen sustainable and resilient pathways out of poverty.</td>
<td>Software and apps; Other - Agronomic knowledge transfer</td>
<td>If AMK deploys the mobile app version 1 successfully, AMK will further develop the app into version 2 and 3 to serve purposes beyond farming, including linking farmers to input supply companies, horticulture buyers, and other private sectors. Mobile app version 2 will be released by April 2019.</td>
</tr>
<tr>
<td>Centennial Logo Competition</td>
<td>U.S. Embassy Riga</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>The goal of the Centennial Logo Competition was to receive an attractive, eye-catching new logo for the Embassy to use to brand events during the Latvian centennial of independence, to increase our social media following, and to assist with Latvia�seconomic development by providing a professional graphic design tool as a prize.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Solve a specific problem; Inform and educate the public; Engage new people and communities</td>
<td>Using the incentive of a prize, and publicizing the contest widely through our social media was an effective and cost-efficient solution to obtain a new embassy logo. We received 34 submissions in the contest, and were able to choose the best one. The prize offering was a cost-efficient means of stimulating a considerable amount of graphic design work. Furthermore, the publicity that the contest received on social media was a very valuable side benefit of the competition format. The prize that we awarded (an iPad Pro) is a graphic design tool that enabled the winner of the competition to pursue more professional design work, thus stimulating innovation and economic development in Latvia.</td>
<td>The prize offered for the Competition was an Apple ipad Pro 9.7 (worth $912.74). The prize was procured using the Public Affairs Section�s 2018 program budget.</td>
<td>We announced the competition via social media posts which we pinned to the top of our social media pages throughout the duration of the Competition, for maximum exposure. The participants submitted their logo designs to the Embassy via email. We then posted all the submitted designs on our embassy social media for the public to vote on the best design. The ultimate selection was based on a jury of embassy staff, with the public vote counting in the case of a tie among jury members.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>The competition is open to anyone aged 16 and over and who is currently residing in Latvia. Employees of the U.S. Government and their immediate family members were not eligible to participate. There was no limit to the number of entries per person. Group entries were acceptable, but only one prize would have been awarded to the group. No registration or participation fee was required to enter this contest.</td>
<td>The ultimate selection was based on a jury of six embassy staff with the public vote counting in the case of a tie among jury members. This format left the ultimate decision on the winner in the embassy�s hands, but simultaneously stimulated a lot of interest and traffic on our social media platforms. This format worked very well, in retrospect. With regard to the online voting, it drove lots of interest and traffic on our social media platforms. However, we found that some of the logo designs received many more votes than others, mainly based on the energy with which the submitter of the design tried to share the Embassy posts with their friends online, rather than the quality of the submission. In other words, if we had left the decision on the logo purely up to an online vote, we might not have given the award to the best candidate. The system that we used was effective, in that it left the ultimate decision in the hands of the embassy judges, while also stimulating public interest and participation.</td>
<td>Of the 34 entries submitted by 18 participants between February 13, 2018 and March 4, 2018, 1 prize was awarded to 1 winner.</td>
<td>Our locally-employed social media coordinator spent approximately 40 working hours designing the social media post, collecting entries, and responding to participants, procuring the prize, and arranging the prize-giving ceremony at the Embassy. There was also a small amount of time spent by the jury in judging the contest submissions. We allocated $912.74 of PD Program funds toward purchasing the prize.</td>
<td>N/A</td>
<td>Latvia is currently celebrating its 100th year of independence, and the embassy public affairs section is branding its outreach programs this year under the theme Latvia and the U.S.: 100 Years of Friendship. To gain publicity for our programs and also to harness the graphic design skills of the Latvian public, we created this logo competition. We gained maximum exposure for the competition on social media by posting all of the entries publicly and encouraging online voting for the best logo. This gained the embassy many new social media followers and publicity for our programs. For a relatively small expense, we received many excellent graphic design submissions, the winner of which we are using as an official embassy logo during the Latvian centennial year. The contest prize, an Apple ipad Pro 9.7, served to increase the technological capacity of the Latvian public. Specifically, it provided a professional work tool to a young Latvian whose goal is to work in the graphic design field. The logo competition, therefore, directly contributed to two of our mission objectives: to strengthen the Latvian economy and economic ties to the U.S., and to promote partnership with the U.S. through our shared values.</td>
<td>Creative (design &amp; multimedia); Ideas</td>
<td>We have no specific plans for other competitions at the moment, but an interesting idea in light of Latvia�s centennial would be to use social media to publicize a competition among the Latvian and U.S. public to submit historical photos, documents or artifacts highlighting the U.S.-Latvian relationship over the past century.</td>
</tr>
<tr>
<td>Solving for Safety Visualization Challenge</td>
<td>USDOT, Bureau of Transportation Statistics</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>The Solving for Safety Visualization Challenge is designed to advance the use of data visualizations and visual analytics for answering analytical questions related to roadway and rail system safety. Currently transportation decision makers have a limited number of analytical visualization tools available that reveal insights, and even fewer focused on safety and prevention of serious crashes. Analytical visualization tools can cast new light on the data to reveal insights not seen though tabular analysis. A new opportunity lies in the rapid growth and advancement in technology and analytics markets combined with the volume and variety of transportation and other data now collected by the public and private sectors. Technology has already changed how we get around. USDOT seeks to harness the power of visualization technology to reduce surface transportation crashes.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>The Solving for Safety Visualization Challenge can act as an engine in driving serious crash reduction. By incentivizing innovation, USDOT is attracting the best Solvers from around the nation to come up with new tools for visualizing the risks of serious crashes. As with other government competitions, the Solving for Safety Visualization Challenge aims to create a vibrant community of thinkers and doers who drive revolutionary innovation. One goal of the Challenge is to empower traditional and non-traditional transportation groups to raise awareness about and take up the quest of improving road and rail user safety - an issue that impacts all lives. The transportation safety community has welcomed innovation, but will benefit futher from the perspective and skills of diverse subject areas. To foster new, novel, and innovative analytical visualization tools, USDOT is seeking Solvers and data from a variety of sectors. By hosting a prize competition rather than awarding grants or contracts, USDOT is alleviating traditional burden of entry issues and is inviting Solvers from outside the traditional transportation safety arena to use their innovative methods and techniques to solve for safety. In doing so, USDOT will expand its reach for raising awareness about transportation safety and will continue cultviating a culture of transportation safety.</td>
<td>The total prize purse offered is $350,000 and the challenge consists of three stages. Five semi-finalists will compete for a portion of the $100,000 interim prize and two final stage Solvers will compete for a portion of the $250,000 final prize. Non-monetary incentives include national recognition of their work by USDOT.</td>
<td>As part of its Safety Data Initiative, on June 14, 2018, the USDOT convened the Safety Data Forum to engage a diverse group of stakeholders in discussion about opportunities to leverage data analytics tools to predict and prevent transportation fatalities and injuries. The forum was attended by representatives of data and technology firms, universities, national safety organizations, and all levels of government. The forum included remarks and presentations from USDOT leaders and staff on Safety Data Initiative pilot projects, the announcement of the Solving for Safety visualization Challenge. On the same day, a Federal Register Notice was published and the Solving for Safety Visualization Challenge webpages went live.<br/>On June 15, 2018, the Bureau of Transportation Statistics began posting Tweets about the Challenge, which were reposted by other USDOT offices and partners. As part of a Safety Data Forum follow-up email, attendees were encouraged to participate in and share the Solving for Saferty Visualization Challenge with their networks. On June 25, 2018, USDOT published a Briefing Room web article describing the competition. Three Stage I webinars were hosted and recorded to connect with potential Solvers and provide additional information about the competition.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Day-long event(s) prior to the competition</td>
<td>Eligible Solvers are individuals or teams (United States and U.S. territories) from the business and research communities. This includes organizations such as: technology companies, analytics firms, transportation carriers, industry associations, research institutions, universities, mapping and visualization providers.</td>
<td>In Stage I, Ideation, all Solvers participating in the Challenge will develop ideas for an analytical visualization tool. Five Stage I semi-finalists will be invited to Stage II as semi-finalists to develop their ideations into proofs of concept and compete for a cash prize. If a selectee declines to participate in the next stage, an alternate may be selected. The Stage I judging criteria applying to all tools include: Benefits (appeal to user), Data (novel use), Technology (easily maintained), and Cost to Implement. Insights and Simulation criteria apply only to discover insight tools and simulation tools, respectfully. These criteria area weighted equally. The evaluation panels will consider each proposal&#39;s alignment with each of these criteria and make recommendations to the selecting official. In Stage II, Concept, the five semi-finalists from Stage I will develop their ideations into proofs of concept (i.e., detilaed system designs and prototypes) for an analytical visualization tool. The five semi-finalists will compete for part of a $100,000 prize purse for their proofs of concept. Stage II judging criteria applying to all tools include: Techincal Approach, Design and Desirability, Analytical Depth, Technology Transfer Readiness Level and Feasibility, Testing and Deployment Approach, and Team. Based on review of the Stage II submissions by the judges, two of the five semi-finalists will also advance to Stage III as finalists. An additional semi-finalist may also recive an honorable mention, but not advance to Stage III. If a selectee declines to participate in the next stage, an alternate may be selected. In Stage III, Tool, the two finalists from Stage II will further devleop their proofs of concept into full working analytical visualization tools. The two finalists will compete for a $250,000 prize purse, with each receiving a minimum of $50,000. The Stage III prize purse will be awarded to the winners based on the judges&#39; review of the Stage III submissions. Judging criteria for Stage III are preliminary. Final judging criteria for Stage III will be provided to finalists advancing to this stage and posted on the Challenge website.</td>
<td>During Stage I, 54 entries were submitted by participants between June 14, 2018 and July 31, 2018. Stages II and III are currently in development. In October 2018, five Stage I semi-finalists were invited to Stage II as semi-finalists to develop their ideations into proofs of concept and compete for a cash prize. Stage II is in progress and Stage III is currently in development. Prizes have not yet been awarded.</td>
<td>In FY18 the Bureau of Transportation Statistics (BTS) allocated $476,000 of the Agency&#39;s funds authorized in the FAST Act, sec. 6002 (a)(6). $350,000 was obligated for competition prizes as described in section 6. $63,000 was obligated for a BTS Fellow from the Department of Energy&#39;s Oak Ridge Institute for Science and Education Program. The BTS Fellow serves as the Challenge developer and coordinator. Approximately $44,000 of the $63,000 was expended in FY18 fo the Fellow. $63,000 was obligated for the DOT Volpe Center, a cost reimbursable unit of DOT that provides support for the evaluation of ideations submitted to the competition. All funds obligated to Volpe were expended. The .25 FTE represents the program management and oversight from the BTS Director of Spatial Analysis and Visualization, review of documents by counsel and the DOT staff who evaluated the ideations.</td>
<td>Challenge Innovation Agents are companies and organizations interested in providing real-world knowledge, guidance, insight, issues, and data to Solvers, especially those new to the transportation safety space. These groups do not enter into a partnership agreements with USDOT. Rather, Innovation Agents support the Challenge by providing Solvers with resources. Solvers are encouraged to seek support from Innovation Agents to strengthen their individual/team expertise. USDOT provides a public listing of two types of Challenge Innovation Agents: Technical Assistance and Data. Technical Assistance (T.A.) Innovation Agents can provide interested Solvers with knowledge, guidance, insight and issues related to transportation safety. T.A. Innovation Agents may be able to provide technial assistance related to key safety issues impacting their members or employees, transportation safety techniques, transportation system characteristics, users and operations, approaches from other industries and sectors. Data Innovation Agents can provide interested Solvers with access to data or analytic techniques that can be used in the analytical visualization tools. Use of a wide variety of disparate data is encouraged to gain insights into reduced fatalities and serious injuries on the U.S. road and rail systems.</td>
<td>Safety has consistently been USDOT&#39;s top strategic and organizational goal. USDOT is pursuing data-informed decision-making to help strategically prioritize and address transportation safety risks. One pillar of this approach is data visualization. USDOT is seeking clear, compelling data visualization tools that make data analysis and insights accessible to policy-makers, transportation providers and the public who make safety choices every day. The USDOT created the Safety Data Initiative (SDI) to support its high priority goal of reducing highway fatalities and serious injuries. The SDI seeks to strategically prioritize and address transportation safety risks through data-informed decision-making. The Solving for Safety Visualization Challenge is an SDI project that challenges innovators from across the nation to develop analytical visualization tools that can help reduce serious crashes on the US road and rail system. USDOT&#39;s vision for the Safety Data Initiative is to integrate data sources with each other and with new &#39;big data&#39; sources that are becoming available to enhance our understanding of crash risk and our ability to mitigate it. The initiative seeks to build USDOT&#39;s capacity to translate the successes of predictive data analytics tools used by private industry and universities to identify systemic factors contributing to serious crashes. It comprises three core components: data visualization, data integaration, and predictive insights.</td>
<td>Technology demonstration and hardware; Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>Advanced Septic System Nitrogen Sensor Challenge</td>
<td>EPA</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and is underway in FY18.</td>
<td>Conventional septic systems are not designed to remove nitrogen, which can lead to problems like excess nitrogen loading to waterways. This Challenge encourages the development and commercialization of an inexpensive nitrogen sensor designed to monitor the performance of innovative and alternative nitrogen removal onsite wastewater treatment systems (OWTS). Adding nitrogen sensors to advanced septic systems will help stakeholders know that their systems are performing as intended and protect valuable coastal resources. Ultimately, such a sensor will give regulators, communities and homeowners long-term assurance of onsite system performance.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Stimulate a market</td>
<td>Running this Challenge as a prize competition rather than a contract, grant, or cooperative agreement allows EPA to meet the goal of the Challenge in the most efficient manner. Rewarding only the teams who present the best sensor creates a level of competition that raises the expectations of each participating team. It was made clear at the beginning of the Challenge that only the top teams would win monetary prizes for Phase I, the Ideation Challenge, and an International Standards Organization Standard 14034 Environmental Technology Verification for Phase II, if their sensor successful performs during the six month field test in 2019.</td>
<td>For Phase I of the Challenge, the total prize purse offered was $55,000, and the total amount awarded was $52,500. The prizes allocated were $20,000 for first place, $15,000 for second place, $10,000 for third place, and $2,500 for three honorable mention awards. Non-monetary incentives included recognition on Challenge.gov and the Challenge support contractor page. For Phase II, selected sensors which successfully will receive International Standards Organization (ISO) Environmental Technology Verification (ETV) Standard 14034 verification statements and reports. These reports are internationally accepted as the highest level of testing for environmental technologies.</td>
<td>The methods used for solicitation of Phase I included tweets from the EPA Twitter account, emails to EPA listserves, one official EPA press release, posting and outreach through the challenge support contractor via www.innocentive.com. Outside organizations promoted the challenge in the same manner. For Phase II, the solicitation was limited to EPA tweets and social media, one EPA press release, EPA emails to Phase I proposal submitters, EPA Nutrient Challenge companies/teams and EPA listserves, outreach to water sensor technology list serves and posting on www.Verifiglobal.com.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - InnoCentive (for Phase I)</td>
<td>Phase I was open to companies, teams and universities, but prizes could only be awarded to U.S. entities or citizens. The submissions were written proposals with references to research conducted. Phase II is open to any team, company or university that has a wastewater sensor prototype for nitrate and ammonium or total nitrogen.</td>
<td>For Phase I, EPA selected a committee of 12 external judges drawn from non profits, USGS, academia, Suffolk County NY and state regulators, the Massachusetts Alternative Septic System Test Center and the septic system manufacturers� organization. EPA met with the judges before the Challenge was launched, and they all gave input on the challenge goals and the judging criteria. The judges made recommendations, which were shared with EPA senior management for final decisions. For Phase II, the sensor prototypes will be evaluated based on their performance during the 6 month ISO EVT 14034 field verification test in 2019. The testing will be conducted according to the test quality assurance plan, which was developed by EPA; the Challenge contractor, Battelle; and a Technical panel, which includes several of the Phase I judges.</td>
<td>For Phase I, the Ideation challenge, 18 entries were submitted by participants between January 17, 2017, and April 17, 2017, and prizes were awarded to six winners. Two entries have been submitted to date for Phase II, the prototype testing program, which  opened on December 18, 2017 and has submission due dates of January 31, 2018, August 31, 2019, and December 7, 2018. Phase II will conclude on February 21, 2020.</td>
<td>This Challenge used 1 FTE over each FY17 and FY18. FTE activities for Phase I and II included problem formulation; coordinating partners, input from 8 states, Suffolk County, NY and other stakeholders on the sensor performance goals, challenge design, launch, management, and judging; and organizing the Sensor Showcase Day awards ceremony on June 29, 2017. In addition, Phase II has included the development of the ISO ETV 14034 test quality assurance plan. Funding for contract support amounted to $20,000 in FY17, and $157,000 in FY18. For Phase I, contractor support was engaged for reviewing the challenge, posting it online, and managing the submissions. For Phase II, contractor support is being used for the ISO ETV 14034 testing process and also for research on water sensor data management best practices and standards.</td>
<td>For Phase I, the U.S. Geological Survey and the Nature Conservancy contributed their expertise on water sensors and onsite wastewater treatment systems and provided input on problem definition, design, and judging. These organizations have continued their involvement for Phase II through participation on the Technical Panel.</td>
<td>This Challenge advances the EPA�s mission by addressing nitrogen pollution in salt water from septic systems. Conventional on-site wastewater treatment systems, or OWTS (also referred to as septic systems) are not designed to remove nitrogen to the extent required for avoiding harmful algal blooms and for protecting and restoring many productive and valuable marine and coastal waters. While EPA does not directly regulate OWTS, the Agency works closely with States and coastal communities dealing with the difficult technical and economic issues posed by nitrogen pollution.</td>
<td>Ideas; Technology demonstration and hardware; Analytics, visualizations, algorithms; Scientific</td>
<td>This challenge will continue into FY20 and concludes on February 21, 2020.</td>
</tr>
<tr>
<td>Campus RainWorks Challenge</td>
<td>EPA</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17, and the FY18 competition is underway.</td>
<td>The Campus RainWorks Challenge is a green infrastructure design competition for American colleges and universities that seeks to engage with the next generation of environmental professionals, foster a dialogue about effective stormwater management, and showcase the environmental, economic, and social benefits of green infrastructure practices.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>Prizes incentivize participation in the challenge.</td>
<td>The total prize purse offered is $16,000, to be awarded to the first and second place winners in the demonstration project and master plan categories. First place teams in each category will receive a student prize of $2,000 and a faculty prize of $3,000 to support green infrastructure training and/or research. Second place teams in each category will receive a student prize of $1,000 and a faculty prize of $2,000. Non-monetary incentives included feedback on student green infrastructure designs from industry experts at EPA, the Water Environment Federation (WEF), the American Society of Landscape Architects (ASLA), and the American Society of Civil Engineers (ASCE).</td>
<td>Submissions are solicited through EPA�s green infrastructure webpage. Outreach is conducted through email, social media, press releases, and through cooperating organizations, including WEF, ASLA, and ASCE.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Student teams must be affiliated with an academic institution that meets the following description: A degree-granting, public or private institution of higher education located in the U.S., State and local governments, federally recognized Indian Tribal Governments, and U.S. territories or possessions.</td>
<td>Qualifying submissions will be judged by two rounds of reviewers that include EPA staff, industry professionals, and academics from noncompeting colleges or universities. First round judges will score submissions on a scale of zero to 100 using pre-identified criteria. Based on the average of all scores for each submission, the top submissions will be recommended to a Final Panel of judges. The Final Panel will then rank the top submissions and recommend finalists in each category to a lead judge in EPA�s Office of Water. The lead judge will assess the recommendations based on the criteria identified and select the first and second place winners in each category.</td>
<td>Registration for the Challenge takes place September 1 through September 30, 2018. Entries are due December 14, 2018. Judging occurs January through March 2019, and the four winners will be announced in April 2019.</td>
<td>EPA used one FTE in each FY17 and FY18 for this Challenge.</td>
<td>EPA has a memorandum of understanding with WEF, ASLA, and ASCE. These organizations volunteer time to publicize the Campus RainWorks Challenge in advance of registration. Members of these organizations also volunteer their time as judges to help evaluate entries.</td>
<td>The Campus RainWorks Challenge is a green infrastructure design competition for American colleges and universities that seeks to engage with the next generation of environmental professionals, foster a dialogue about effective stormwater management, and showcase the environmental, economic, and social benefits of green infrastructure practices. Stormwater runoff is a significant source of water pollution in communities across the United States. The Campus RainWorks Challenge invites students to create green infrastructure designs can protect public health and water quality today and in the future.</td>
<td>Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware; Scientific</td>
<td>The Campus RainWorks Challenge is an annual challenge that follows the same facilitation process and requires the same amount of funding and FTEs from one year to the next.</td>
</tr>
<tr>
<td>Nutrient Sensor Action Challenge - Stage I</td>
<td>EPA</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Many organizations and communities are interested in utilizing automated sensors to provide improved spatial and temporal data that can help inform decisions and actions to protect and restore our Nation�s water resources. The goal of this Challenge was for teams to develop plans that demonstrate their ability to deploy and effectively use low-cost continuous nutrient sensors to collect and manage data according to specified standards, and describe how collected information from the sensors may be used in decision-making pertaining to nutrient pollution.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>Running this Challenge as a prize competition rather than a contract, grant, or cooperative agreement encouraged multiple teams to compete to develop the best project plans. Since this was a challenge, the agency is only obligated to pay a prize if a solution is submitted that met the challenge criteria.  The notion of a competition created enthusiasm and brought attention to the issue of nutrient pollution.</td>
<td>The total prize purse offered was $50,000, which allowed five $10,000 prizes to be awarded. Non-monetary incentives included recognition, informational webinars, monthly newsletters, and the opportunity for peer networking.</td>
<td>Strategies to solicit participation included tweets from the EPA Twitter account, emails to listservs, an EPA press release as well as announcements at conferences and conference calls with relevant organizations. Partner organizations promoted the Challenge in similar ways.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Phase I of the Challenge was open to communities and organizations in the United States interested in deploying continuous nutrient sensors to address a nutrient pollution problem.</td>
<td>A panel of nine judges was convened to review and evaluate the submissions. Judges evaluated submissions based on the challenge criteria including monitoring, analytics and interpretation, communication, and use. The judges were from government and private organizations. The judges made recommendations to EPA senior management who made the final selection.</td>
<td>Of the 29 entries submitted by 29 participants between July 26, 2017 and September 20, 2017, 5 prizes were awarded to 5 winners. This is Stage I of a two stage challenge. Stage II is a separate challenge.</td>
<td>FY17 resources used to support the Challenge included $30,000 in funding and less than one FTE. Contract support was used for the development of communication materials.</td>
<td>Federal partners included NIST, USDA, USGS, and NOAA. Non-Federal partners included the Alliance for Coastal Technologies at the University of Maryland. The estimated value of in kind support received from partners was $40,000.</td>
<td>This Challenge advances the agency�s mission by addressing the need for better and more timely information pertaining to water quality, specifically nutrient pollution. The Challenge called on teams to create innovative partnerships to design a strategy for the successful deployment of sensors, manage resulting data, and demonstrate how collected information may be used in decision-making pertaining to nutrient pollution.</td>
<td>Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware; Analytics, visualizations, algorithms; Scientific</td>
<td>Potential expansion into use of artificial intelligence and machine learning to improve decision-making</td>
</tr>
<tr>
<td>Nutrient Sensor Action Challenge  - Stage II</td>
<td>EPA</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>This Challenge is Stage II of the Nutrient Sensor Action Challenge calls for teams to demonstrate effective and strategic deployment of nutrient sensors, management and use of the resulting data to inform a decision(s) and action(s) that result in improved nutrient management.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>Nutrient pollution is a very costly and complex issue. Traditional strategies and approaches have had limited results. This Challenge continues to build on the success and progress of the interagency Challenging Nutrients Coalition. Challenges and prizes offer new opportunities to generate interest around the problem of nutrient pollution. This Challenge has engaged teams and organizations that would typically not be working with EPA. A challenge also has the advantage of only paying out a prize if a team has met the requirements of the challenge.</td>
<td>The total prize purse offered was $100,000. Up to two prizes totaling $100,000 will be made in 2019. Non-monetary incentives include recognition, informational webinars, networking, and feedback from judges.</td>
<td>The methods used for solicitation of the Challenge included tweets from the EPA Twitter account,  emails to listservs, EPA press releases, and partnerships with outside organizations that promoted the Challenge in the same manner.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Stage II is open to communities, tribes, states, and other organizations in the United States interested in deploying nutrient sensors to address an important nutrient-related water quality issue. Participation in Stage I of the Challenge is not a requirement for participation in Stage II.</td>
<td>A panel of  judges will be convened for evaluating the submissions received; judging will take place in February 2019. Judges will evaluate submissions based on the requirements specified in the Challenge. The panel of judges will make recommendations that will be shared with EPA senior management for final decision.</td>
<td>Of the 7 entries submitted by 7 participants between March 1, 2018 and January 31, 2019, 2 potential prizes will be awarded.</td>
<td>Scientists, data specialists, administrative and communication support were provided by EPA and the partner agencies in support of this Challenge. In FY18, funding in the amount of $30,000 and less than one FTE supported this Challenge. Contract support was used to develop and design communication and outreach materials.</td>
<td>Federal partners include NIST, USDA, USGS, and NOAA. The estimated value of in kind support from partners is $40,000.</td>
<td>This Challenge advances the agency�s mission by helping to empower and incentivize communities to collect data and information that will enable them to make more effective decisions about water quality and specifically pertaining to nutrient pollution.</td>
<td>Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware; Business plans; Analytics, visualizations, algorithms; Scientific</td>
<td>Potential follow-on challenges focusing on using data networking, artificial intelligence, and machine learning to inform decisions about nutrient pollution.</td>
</tr>
<tr>
<td>IoT Home Inspector Challenge</td>
<td>FTC</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>Every day, American consumers use internet-connected devices to make their homes �smarter.� Consumers can remotely program their smart home devices to turn on their lights, start the oven, and turn on soft music so they return to a comfortable environment when they get home from work. While these smart devices enable enormous convenience and safety benefits, they can also create security risks. Lax internet of things (IoT) device security can threaten not just device owners, but the entire internet, as demonstrated by the Mirai botnet and other highly-publicized Internet attacks. The IoT Home Inspector Challenge encouraged the public to create a tool that consumers could deploy to guard against security vulnerabilities in software on the IoT devices in their homes. The tool sought would, at a minimum, help protect consumers from security vulnerabilities caused by out-of-date software. The primary objectives were to engage the public to think about the security risks and mitigations related to smart devices and to encourage the development of a technical tool to help protect consumers from security vulnerabilities caused by out-of-date software.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Inform and educate the public; Stimulate a market</td>
<td>Staff research and discussions with experts led the FTC to understand that out-of-date software presents a security issue. Device manufacturers do not always provide security updates for their products, but even when they do consumers may not know that they have been released, where to get the updates, and how to install them. Updating is a particular challenge for products that are low-cost and where consumers have not typically maintained an ongoing relationship with the manufacturer (for example, lamps). Finally, the IoT ecosystem is still evolving and there is no common standard for the technologies, so it is difficult to find a solution that applies across technologies. In sum, risks from old and unpatched software contained in home IoT devices will only increase. Many experts consulted agreed that this was an area where a challenge would be extremely useful.</td>
<td>The total prize purse offered was $34,000, and the total amount awarded was $28,000. The prizes allocated were $25,000 for first place and $3,000 for honorable mention. The original allocation included amounts for up to three honorable mentions, but the judges only awarded one.</td>
<td>The agency promoted the challenge to the general public through press releases announcing the contest and the official rules, along with multiple blog posts on the FTC�s consumer and business blogs, the use of social media, a special webpage for contest material and posting on the Challenge.gov website.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release</td>
<td>N/A</td>
<td>An expert panel of judges reviewed submissions using the following criteria, where each overall section was allocated a certain number of points. Section I: How well does it work? The instructions outlined a number of components for this section, including (1) Recognizing what IoT devices are operating in the consumer�s home; (2) Determining what software version is already on those IoT devices; (3) Determining the latest versions of the software that should be on those devices (with a feasible plan for finding sources of information about what version should be on the device and explaining the technical means by which that information would be procured); and (4) Assisting in facilitating updates, to the extent possible. Section II: How user-friendly is the tool? How easy is your tool for the average consumer, without technical expertise, to set up and use? Section III: How scalable is the tool?</td>
<td>Of the entries submitted between March 1 and May 22, 2017, two prizes were awarded.</td>
<td>In terms of manpower, the time dedicated to the project included the development of the subject for the contest, developing criteria, consulting a variety of subject-matter outside experts and selecting potential judges for the contest. FTC records indicate a total of 0.5 FTE were used in FY17 to execute the prize competition, however, there was likely an additional 0.25 FTE used that were attributed other activity codes.</td>
<td>N/A</td>
<td>As part of its mandate, the FTC has engaged in research, advocacy, education, policy work, and law enforcement activity to protect consumers in the United States. This work includes efforts aimed at protecting consumers in an ever-changing marketplace, and that includes IoT devices in the home. While IoT or �smart� devices may provide enormous benefits, such as convenience and safety benefits, they can also create security risks. One way the agency tackles these challenges has been through targeted law enforcement. The FTC has also worked to raise awareness about risks and possible mitigating measures through public discourse and through educational materials.  The FTC�s law enforcement, policy, and education efforts alone cannot address the issue for a number of reasons. First, there are an increasing number and variety of IoT devices today and updating each is complex. In addition, ordinary consumers cannot easily take action to secure their devices, or even just to discover if their software is up-to-date, unless they are aware of the risks, are very motivated to address them, and have a considerable amount of detailed technical know-how.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas</td>
<td>The FTC agency has held four challenges in the last four years and has found them to be valuable, but has no immediate plans to conduct another challenge.</td>
</tr>
<tr>
<td>Student Design Competition: New San Francisco Federal Building Plaza</td>
<td>GSA</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>This competition sought ideas that would activate the New San Francisco Federal Building plaza for the benefit of building users and the general public. The New San Francisco Federal Building located at 90 7th Street has become a landmark in San Francisco, California. Its layout and functions celebrate the importance of the city and the urban environment, combining amenities and public space that are designed to enhance the immediate area and the adjacent neighborhood. The offices support the energy and spirit of those who work there and those who visit. Its systems are outstanding examples of integrated engineering and sustainable design, reflecting the wise stewardship of limited resources. Together, these attributes make this a project that has stimulated critical interest.<br/>The original vision for the plaza was that it would be a welcome civic space that is flexible and allows for outdoor dining, concerts, and markets. Since the completion of the building�s construction 10 years ago, only the cafe uses the plaza for outdoor dining, and no concerts, markets, or any other public functions have used this space.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Solve a specific problem; Inform and educate the public; Engage new people and communities</td>
<td>Holding a design competition for architecture, landscape architecture, and urban design students supported and advanced GSA&#39;s mission in a number of ways.  The local community in the neighborhood surrounding the building were engaged in the entry evaluation process and, therefore, had their own voice heard.Students are not licensed architects and so provisions of the Brooks Act and FAR 36.601 do not apply because the competition limited entrants to students. In contrast, holding a design competition to hire a licensed architect or engineer would have required compliance with Brooks Act, FAR 36, and FAR 15, and so the source selection and evaluation board (SSEB) prohibited community stakeholders from participating directly in the evaluation of entries. The potential ideas generated by the competition included design and construction solutions or programming a new function for the plaza without changing it, or yet some other solution that does not necessarily require expensive renovation. This was unlike a competition to hire an architect or design-build team because the scope was undefined and may not have even involved renovation work to implement. Having a cash prize attracted far greater interest, improved the quality of the most successful entries and increased the opportunity for recognition.</td>
<td>The total prize purse offered and awarded was $1,750. Non-monetary incentives included public acknowledgement on the Challenge.gov website. Three individual cash awards were given to the three winners of the Challenge by sending pre-paid charge-cards (American Express) with a letter to the winners. These pre-paid charge-chards were purchased by the GSA in FY17 under the agency�s micro-purchase authority. The value of each card was $1000, $500, and $250, corresponding to 1st, 2nd, and 3rd place prizes, respectively. The honorable mention award-winner received a letter and their proposal was featured on the Challenge.gov website along with the prize-winners.</td>
<td>The entire solicitation and submission process was handled on the Challenge.gov platform. GSA published an article about the solicitation on the GSA.gov blog website which linked to the Challenge.gov website. GSA shared the links via its social media accounts on Twitter and Facebook. Additionally, GSA contacted several online architecture and design competition blogs that were not affiliated with any government agency to notify them about the Challenge and they chose to publish links to the Challenge.gov solicitation. These included www.archdaily.com, www.competitions.archi, www.aias.org, and www.archinect.com.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>The targeted solvers included students of architecture, landscape architecture, urban design, or related programs. The following statement was published in the rules, terms, and conditions for the Challenge: �Only individual submissions are allowed, no team submissions. One submission per contestant is allowed. Contestant certifies through entering the submission that they are currently full-time undergraduate or graduate student enrolled in an accredited architecture, landscape architecture, urban design, or related program. Contestant certifies through entering the submission that they are a citizen or permanent resident of the United States of America.�</td>
<td>The jury convened in person to evaluate the proposals based on the following evaluation criteria: (1) Creativity: The Guiding Principles for Federal Architecture state that the government should produce facilities that reflect the dignity, enterprise, vigor, and stability of the Federal Government, emphasizing designs that embody the finest contemporary architectural thought; that avoid an official style; and that incorporate the work of living American artists. With these Guiding Principles in mind, submissions that demonstrated greater creativity, coherence, and clarity of vision in achieving the goal of activating the plaza were considered more favorably. (2) Context: GSA recognized that good design is responsive to context. Special attention was paid to the general ensemble of streets and public places of which Federal buildings formed a part; and that, where possible, buildings should permit a generous development of landscape. Submissions that addressed and responded to the physical context of climate and the built environment were considered more favorably. (3) Community: GSA strived to leverage its real estate activity to support community goals. Submissions that demonstrated a superior understanding of local issues and community goals, and which addressed those issues and goals in compelling ways, were considered more favorably. (4) Feasibility: Designs should have adhered to sound construction practice and utilized materials, methods and equipment of proven dependability, and should be economical to build, operate and maintain, and should be accessible. Submissions that were technically feasible to implement were considered more favorably. (5) Value: Part of GSA&#39;s mission is to deliver the best value in real estate services to the Federal Government and the American people. Submissions that represented a high-value intervention that could be implemented more cost-effectively were considered more favorably.</td>
<td>Of the 63 entries submitted between August 28 and November 22, 2017, three prizes were awarded to three prize winners and one honorable mention award-winner was announced.</td>
<td>GSA allocated one project manager who devoted approximately 8-16 hours per week over a period of 4 months to develop the Challenge, coordinate the evaluation of proposals, and administer the close-out process. In addition, GSA allocated one communications officer to develop communications material and manage communications. The communications officer devoted between 8-16 hours per week for 3 months. Personnel resources amounted to 0.125 FTEs across FY17 and FY18. Agency funding provided in FY17 was $1,750 and $599.74 in FY18.</td>
<td>The U.S. Department of Health and Human Services (HHS) and the Central Market Community Benefit District each provided one person for the two-day proposal evaluation process, equal to approximately 16 manhours each.</td>
<td>The mission of GSA is to deliver the best value in real estate, acquisition, and technology services to the Federal Government and the American people. GSA also has an obligation to reach out to communities to discuss how GSA can support community goals. Holding a design competition for architecture, landscape architecture, and urban design students supported and advanced GSA&#39;s mission in two ways. First, the local community at the building were engaged in the entry evaluation process and communicated to GSA ideas that supported community goals. Second, the competition stimulated innovation by rewarding ideas for the scoping of a plaza intervention which GSA might not have thought of otherwise and which resulted in the best value for the Federal Government and taxpayers. These ideas included a broad range of solutions such as design and construction solutions, programming a new function for the plaza without changing it, and others.</td>
<td>Creative (design &amp; multimedia); Ideas</td>
<td>GSA considered this process a success and is evaluating other design-related opportunities throughout the country that could benefit from a challenge under the America COMPETES authority, but no specific opportunities have been identified that would occur within the next 2 fiscal years.</td>
</tr>
<tr>
<td>Earth &amp; Space Air Prize</td>
<td>NASA</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and underway in FY18.</td>
<td>NASA�s long-term technology roadmap calls for improvements to the technology for monitoring particles in the air to enable future long-term human space missions. This competition serves to catalyze the aerosol community and accelerate development of highly innovative approaches that may otherwise take years to achieve. The NASA Earth &amp; Space Air Prize, with support from the Robert Wood Johnson Foundation (RWJF), focused on identifying solutions that can catalyze the development of easy to maintain, small, and affordable aerosol sensor technology that has the potential to be useful in spaceflight as well as on Earth anywhere outdoors in a community where pedestrians may be exposed to airborne particle matter.</td>
<td>Solve a specific problem; Develop technology</td>
<td>A concept scan identified numerous communities pushing to build and enhance nascent community air quality sensor capabilities. This prize competition was launched to incentivize the relevant community to submit ideas and prototypes for solutions that would be beneficial to NASA and the Robert Wood Johnson Foundation (RWJF) goals in detecting particulates in the air on Earth and in space applications.</td>
<td>The total prize purse offered was $250,000. $150,000 was awarded to three finalists, and the $100,000 grand prize was awarded in November 2018. Non-monetary incentives included a reception and demonstration event at the Glenn Research Center.</td>
<td>The prize administrator, The Common Pool LLC, focused efforts on both primary and secondary outreach and communicated directly with potential participants and key influencers and organizations in science and technology. Outreach efforts kicked off on September 19, 2017 with an announcement of the launch of the Earth and Space Air Prize at the Udvar-Hazy facility of the National Air and Space Museum in conjunction with an event sponsored by Future Engineers. Efforts also included recruitment of potential submissions at the yearly meeting of the professional society of aerosol specialists. NASA used the NASA Solve website (www.nasa.gov/solve), which lists NASA�s participatory opportunities, to market this challenge. NASA also published a Web feature that was amplified by the RWJF through social media.</td>
<td>Social media (e.g., Twitter, Facebook); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other: Outreach conducted by commercial prize administrator, and NASA Solve website (www.nasa.gov/solve)</td>
<td>Individuals must be U.S. citizens or permanent residents of the United States and be 18 years of age or older. Organizations must be an entity incorporated in and maintaining a primary place of business in the United States. Teams must be comprised of otherwise eligible individuals or organizations, and led by an otherwise eligible individual or organization. U.S. government employees may participate so long as they rely on no facilities, access, personnel, knowledge or other resources that are available to them as a result of their employment except for those resources available to all other participants on an equal basis. U.S. government employees participating as individuals, or who submit applications on behalf of an otherwise eligible organization, will be responsible for ensuring that their participation in the Competition is permitted by the rules and regulations relevant to their position and that they have obtained any authorization that may be required by virtue of their government position. Failure to do so may result in the disqualification of them individually or of the entity which they represent or in which they are involved. Foreign citizens may only participate as (i) employees of an otherwise eligible US entity who reside in the US, (ii) full-time students at an otherwise eligible US university or college who reside in the US, or (iii) owners of less than 50% of the interests in an otherwise eligible US entity who reside in the US.</td>
<td>Submissions were evaluated using a set of criteria available at https://www.earthspaceairprize.org/#scoring. Additionally, the prize administrator uses a trait scoring rubric to ensure fairness in the evaluation process that prevents a tie in the scoring. Final testing occurred in the testing lab at the Glenn Research Center in November 2018 where the instruments must meet specified criteria along with final evaluation by the judging team.</td>
<td>Of the 20 entries submitted by 544 participants in Phase I between September 19, 2017 and January 31, 2018, three finalists were awarded $150,000 total. In Phase II, prototypes were developed and tested and the grand prize winner received $100,000. The three solutions named as finalists were AirSpeQ&#39;s Gravimetric PM Monitor Employing Thermophoresis; Applied Particle Technology&#39;s Optical particle speciation and counter; and the Volckens Group/Colorado State University&#39;s Mobile Aerosol Reference Sensor (MARS).</td>
<td>The RWJF provided the bulk of the funding for this challenge inclusive of prize administration and the prize purse for the three finalists. NASA provided funding for the final award. NASA FTE/WYE resources along with RWJF personnel supported development of the challenge, selection of the prize administrator, and judging of the submissions. Agency resources in FY17 was estimated at 0.4 FTE and 0.2 WYE, and 0.3 FTE and $100,000 in prize funding in FY18. The prize administrator was selected through the NASA Open Innovation Services Contract. Funding supported RFP development and award.</td>
<td>RWJF provided financial support, estimated at $350,000 for prize purse ($150,000) and prize administration ($200,000). RWJF also supported the prize with 0.2 FTE of their own personnel. This partnership was an incredibly positive relationship setting a framework for how public-private partnerships can be used to accelerate technology development. NASA entered into a formal agreement which clearly specified roles and responsibilities. NASA now has in place a template for future partnerships. Additionally, NASA laid the groundwork for the financial system that will support intake of funding from private partners. This allowed the acquisition of a professional prize administration team that has been a tremendous bonus to effective conduct of this competition.</td>
<td>NASA has identified particulate monitoring as a gap in its technology roadmap to enable future long-term missions. Current technology does not provide the level of sensitivity, the longevity, or the ability to operate in a reduced-gravity environment. In working with RWJF, NASA has the opportunity to close this gap. The added bonus of the outcome of this technology demonstration competition is the potential benefit to human health on Earth as well.</td>
<td>Technology demonstration and hardware</td>
<td>N/A</td>
</tr>
<tr>
<td>2017-2018 Community College Innovation Challenge</td>
<td>NSF</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The primary goal of the Community College Innovation Challenge (CCIC) was to create seats for community college students, often underrepresented in the research community, at the innovation table and cultivate confidence and skills. CCIC provided community college students with an opportunity to begin using science to make a difference in the world by transferring knowledge into action through the latest entrepreneurial and strategic communication techniques.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Inform and educate the public; Engage new people and communities; Build capacity</td>
<td>NSF�s traditional mechanism of crowdsourcing innovation, advancing STEM research, and developing a STEM workforce via solicitations and grants tends to attract a more established research community from four-year institutions and often leaves community colleges untapped. The modest prize money and all-inclusive four-day professional development boot camp helped attract students to participate in the CCIC. Participants gained greater awareness of opportunities in the sciences and developed an array of important scientific and professional skills. CCIC alumni have gone on to secure venture capital funding, launch start-ups, enter graduate school to pursue degrees in STEM, speak on National Science Board panels, land prestigious industry internships and apprenticeships, and launch local innovation competitions at their schools inspired by CCIC.</td>
<td>The total prize purse offered and the total amount awarded was $81,700. Non-monetary incentives, including a four-day Innovation Boot Camp experience for the ten finalist teams and a plaque for all finalist schools, came to $219,000.</td>
<td>Submission were solicited via social media (Twitter and Facebook posts); direct, targeted outreach (telephone calls); email (listservs); a press release; day-long event(s) prior to the competition; partnerships with outside organizations (including private companies, non-profit organizations, and other Federal agencies); sessions/announcements at appropriate conferences/workshops; promo toolkit on the website; and mailing materials (postcards, posters).</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The target audience for this Challenge was community college students 18 years old and older. Participants were required to be U.S. citizens, nationals, or permanent residents enrolled in and in academic good standing at a two-year, degree-granting institution. Teams were comprised of three to five students, one faculty mentor, and one community/industry partner. Students who previously advanced to finalist status and participated in a past Innovation Boot Camp were not eligible to re-enter.</td>
<td>NSF recruited different populations for three rounds of judging. Preliminary judging was conducted online by American Association for the Advancement of Science Policy Fellows and Science Assistants at NSF. Semifinal judging was also conducted online by NSF Program Officers with thematic scientific expertise. Final judging was conducted in person by high-profile academics, industry representatives, and entrepreneurs with broad STEM knowledge. Evaluation was based on three categories: (1) innovation and impact, defined as the proposed solution�s use of science to address a problem and its potential to be transformative in the areas of national security, economy, quality of life, education, and environment, among others; (2) feasibility, defined as the likelihood that the solution is technically feasible as well as economic, political, and social constraints; and (3) clarity of communication, defined as the team�s adherence to the entry guidelines, grammar, structure, organization of facts and data, and clarity and consistency of message.</td>
<td>Of the 41 entries submitted by 234 participants between October 18, 2017 and February 14, 2018, 53 participants each received $500 for making it to the final round and an all-expense paid trip to the Innovation Boot Camp. Of the 10 finalist entries, five received 1st-place prizes of $1,500 each and five received 2nd-place prizes of $1,200 each.</td>
<td>Funds totaling $416,000 were allocated in FY17, and 1.5 full-time equivalents (FTEs) managed and supported aspects of the competition in FY17 and FY18. Third-party vendors (including the American Association of Community Colleges) were funded using FY17 money that came from NSF�s Education and Human Resources Directorate (Division of Undergraduate Education). Entry platform company Skild received $139,000 for platform development and customization, client services support, creative design services, strategic consulting/oversight, engineering, QA testing, prize distribution, and direct outreach. The American Association of Community Colleges (AACC) received $219,000 to support the Innovation Boot Camp, including all logistics costs (travel, lodging, food, per diem, etc.) for student finalists and judges as well as providing essential curricula and other outreach material. Ninja Communications received $42,000 for developing curriculum, conducting pre-boot camp webinars, providing four days of on-site instruction for finalists, and managing the judging process, score sheets, and deliberation. Grant Warner, I-Corps Instructor, received $8,000 for developing curriculum, conducting pre-boot camp webinars, and providing four days of on-site instruction for finalists. MDR received $8,000 for listserv distribution.</td>
<td>NSF has partnered with AACC to run the CCIC competition since the program�s inception four years ago. AACC provided expertise with the community college population in challenge development and theme identification as well as recruitment of judges, outreach efforts, and in developing materials and curriculum for the Innovation Boot Camp. AACC coordinated logistics and travel for the Innovation Boot Camp, as well as arranged the finalists� reception, which involved interactive displays and was hosted by the White House�s Office of Science and Technology Policy and the Office of American Innovation at the Eisenhower Executive Office Building on June 13, 2018.</td>
<td>CCIC advanced NSF&#39;s mission by aligning with NSF�s strategic plan. Specifically, CCIC helped: (1) build the capacity of the Nation�s citizenry for addressing societal challenges through science and engineering; and (2) prepare and engage a diverse STEM workforce motivated to participate at the frontiers. In addition, the competition served NSF�s strategic goal for open innovation.</td>
<td>Software and apps; Ideas; Technology demonstration and hardware; Business plans; Scientific</td>
<td>N/A</td>
</tr>
<tr>
<td>Engineering Research Centers (ERC)-Wide Perfect Pitch Competition</td>
<td>NSF</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The objective of the ERC Perfect Pitch Competition was to help engineering students develop the communication skills critical to expressing their ideas in a clear, concise, and compelling manner. This competition was modeled after the elevator pitch competitions popular in business schools; however, in addition to stressing the importance of concise and persuasive communication, the judging criteria emphasized a culture of innovation and entrepreneurship and empowered students to lead.</td>
<td>Engage new people and communities; Build capacity</td>
<td>A cash prize provided a way to get students� attention while simultaneously sending a message about the importance of good communications skills. It was meant to generate an atmosphere of excited anticipation within the ERC community, both among students and the center leadership teams. It also provided a climactic focal point during regular ERC biennial meetings.</td>
<td>The total prize purse offered and the total amount awarded was $8,000 (1st Prize $5,000; 2nd Prize $2,000; 3rd Prize $1,000). Non-monetary incentives included a Perpetual Trophy awarded to the ERC Home of the 1st place winner.</td>
<td>Perfect Pitch Guidelines and the Competition scoring templates were posted on a website dedicated to the Perfect Pitch competition on August 16, 2017. On the same date, an email notification was sent to ERC Education and Outreach Directors and ERC Industrial Liaison Officers.</td>
<td>Email (e.g., listservs); Day-long event(s) prior to the competition</td>
<td>In FY17, the ERC Program mobilized all 15 ERCs that had active student leadership organizations to compete. Four ERCs had just begun in the month prior to the competition and did not participate. The competitions engaged their entire leadership teams, especially the Centers� Education Directors, Industrial Liaison Officers, and the ERC community. All ERC students (both graduate and undergraduate) engaged in research at one of the actively funded NSF ERCs were eligible to compete. A total of 129 students participated in local competitions, of which 78% were graduate students, 5% were undergraduate students, and 5% were post-doctoral students, who were allowed to compete in some local competitions to enlarge the pool of contestants. Since each ERC held its own competition to determine who would represent it in the ERC-wide competition, the quality of the finalists was quite impressive. Fifteen students represented fifteen ERCs from universities located around the country and across a wide spectrum of advanced technology fields. The contestant pool at the national level included seven women and eight men.</td>
<td>Each judging team consisted of one academic with entrepreneurship experience, a previous Perfect Pitch judge, two investment bankers, and one venture capitalist. Contestants in the ERC-wide competition were expected to pitch a compelling problem or opportunity connected with the ERC strategic vision in a clear, articulate, compelling manner within a 90-second window. Evaluation criteria considered the  proposed solution, its potential impact, the broader impact of technology, call to action, visual design of slide, and poise/style. At the ERC-wide competition, contestants presented their pitch to the judges one by one; a moderator introduced each speaker and kept time. After each presentation, each judge had 1.5 minutes to enter their score and notes on a spreadsheet. Following the presentations, the judges met to complete their notes and scoring, and a video of the entire competition was available for review to allow the judges to refine their scores and provide more detailed feedback. They then discussed and finalized their decisions, which were conveyed to the program organizer. After the awards ceremony, copies of the ballots with the judges� feedback were given to the students.</td>
<td>Of the 15 participants in the ERC-wide competition on November 2, 2017, three prizes were awarded. A total of 129 students competed locally to represent their home ERCs on September 29, 2017.</td>
<td>Total expenses were $13,600, which covered judges� expenses ($3,500), prize purse ($8,000), and overhead ($2,100) to the American Society of Engineering Education, which sponsored the meeting where the final competition took place. In FY17 and FY18, 0.1 full-time equivalent (FTE) was allocated to plan and manage the competition. In FY18, three American Association for the Advancement of Science Fellows also supported the competition.</td>
<td>N/A</td>
<td>The goal of the ERC Program is to integrate engineering research and education with technological innovation to transform national prosperity, health, and security. At the National-level, the Perfect Pitch competition generated excitement within the ERC community as well as interest in ERC innovations and their student champions among venture capitalists and angel investors. Stemming in part from the Perfect Pitch competition, some ERCs have begun to invest resources into improving their student�s communication skills.</td>
<td>Creative (design &amp; multimedia)</td>
<td>N/A</td>
</tr>
<tr>
<td>Generation Nano: Superheroes Inspired by Science</td>
<td>NSF</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Generation Nano challenged middle school and high school students to research science and technology advancements and then creatively apply those ideas to empower or drive a unique superhero. The competition was an opportunity to generate an early interest in and excitement for STEM topics among students as well as provide reputable resources to guide their research.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>NSF�s traditional mechanism of advancing STEM research and developing a STEM workforce is via solicitations and grants. Unfortunately, this method is not a readily available option for K-12 students. NSF uses prizes as a way to attract this younger audience and incentivize them to participate. The modest prize money and the trip to DC for the USA Science &amp; Engineering Festival has helped attract students and teachers, raising awareness of NSF and its mission as well as building confidence and skills that will help propel their future.</td>
<td>The total prize purse offered and the total amount awarded was $14,880 ($12,000 in cash prizes, $2,880 for final event logistics). Non-monetary incentives included travel to Washington, D.C. to participate in the USA Science &amp; Engineering Festival for the first place high school and middle school winners. First place received $1,500 per team member, second place received $1,000 per team member, and honorable mention received $500 per team member. In addition, $500 was awarded to teacher(s) who mentored the first place teams / individuals.</td>
<td>Entries were solicited through email outreach via listserves and MDR (a paid service); press release; social media (facebook/twitter/Instagram/etc.); social media advertisements; postcards distributed at various events; sessions/talks at various events; and a promo toolkit on the website.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Sessions/announcements at appropriate conferences, promo toolkit on the website, mailing materials (postcards, posters) to appropriate contacts</td>
<td>All entries had to be received during the competition submission window. Each submission had to be made by an individual. All students had to be enrolled in and be in good standing at a middle or high school or be home-schooled in the U.S., including U.S. territories and possessions, at the time of entry. Students had to be U.S. citizens, nationals, or permanent residents. Each entrant certified, through submission to the contest, that the entry was his or her own original creative work and did not violate or infringe the creative work of others, as protected under U.S. copyright law. Each entrant had to submit a Parental/Guardian Permission Form and Photo Consent Form.</td>
<td>Preliminary judging was done online by Fellows across agencies. Semifinal judging was also online by science researchers and members of the comic/entertainment community. Final judging was in person by high-profile science researchers and prominent education and entertainment leaders. Evaluation was based on three categories: (1) creativity (25 percent), defined by the originality and quality of both the superhero and the story, as well as the application of science and technology; (2) use of science and technology (50 percent), defined as how accurately the entrant incorporated science and technology into the story to address the chosen societal mission; and (3) artistic and technical quality (25 percent), defined as the visual appeal and refined execution of the comic or video.</td>
<td>Of the 388 entries submitted by 1100 participants between September 18, 2017 and January 10, 2018, nine entries (14 students) and two teacher honoraria received awards.</td>
<td>Funding for FY17 and FY18 totaled $58,000. Of the total funds, $53,000 went to Skild for platform development and customization, client services support, creative design services, strategic consulting/oversight, engineering, QA testing, prize distribution, and direct outreach. The remaining $5,000 went to MDR for marketing via listserv distribution. A total of 1.5 full-time equivalents (FTEs) were used to manage and help support aspects of the competition.</td>
<td>NSF partnered with the National Nanotechnology Initiative, benefiting from its technical knowledge base. NSF also reached out to State Science Teacher Associations and posted the competition on numerous websites, including NASA, The Connectory, and Johns Hopkins Center for Talented Youth. Prominent comic creator Stan Lee promoted the competition on social media. His support, and that of other science and pop-culture celebrities, helped NSF reach new populations and encourage their participation.</td>
<td>The competition advanced NSF&#39;s mission by aligning with its strategic plan. Specifically, Generation Nano helped: (1) build the capacity of the Nation�s citizenry for addressing societal challenges through science and engineering; and (2) prepare and engage a diverse STEM workforce motivated to participate at the frontiers. In addition, the competition served NSF�s strategic goal for open innovation.</td>
<td>Creative (design &amp; multimedia)</td>
<td>N/A</td>
</tr>
<tr>
<td>NSF Wireless Innovation for a Networked Society (WINS)</td>
<td>NSF</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The NSF WINS Challenges sought practical, new wireless solutions to help people connect to the internet in challenging circumstances, either after a disaster or in areas without sufficient connectivity, as wireless technology innovations should make the internet more accessible, resilient, and healthier. Two challenges were at stake: the Off-The-Grid Internet Challenge and the Smart-Community Networks Challenge: The Off-The-Grid Internet Challenge sought wireless solutions for communication that can be rapidly deployed in post-disaster situations where internet access is unavailable or compromised, while the Smart-Community Networks Challenge sought wireless solutions for communication that can be built on top of existing infrastructure to enhance internet connectivity in communities that need greater access.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>The prize competition was selected to draw from the large community of entrepreneurs and small business developers who could develop the solutions to this challenge but are not generally attracted to NSF�s traditional mechanisms (grants, contracts, cooperative agreements, etc.).</td>
<td>The total prize purse offered and the total amount awarded was $2,000,000. For Phase 1 (Design Concept Stage), first place received $60,000, second place received $40,000, third place received $30,000, and seven honorable mentions each received $10,000. For Phase 2 (Working Prototype Stage), first place received $400,000, second place received $250,000, third place received $100,000, and fourth place received $50,000.</td>
<td>The NSF WINS Challenges were open to all U.S.-based entrants, including non-profit and for-profit organizations and individuals ages 18 and over. Each participant had to fill out and submit an Intent to Apply form through the NSF WINS website at wirelesschallenge.mozilla.org between June 15, 2017 and October 15, 2017. Entrants then received information via email on how to register for an account at mozilla.fluxx.io. By submitting a full submission, each team�s leader accepted the challenge rules and all decisions of the organizer and judges as final and binding.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Participation was open to teams of one or more members with no maximum number of participants per team. Individual participants may be a member of more than one team. Participants must be individuals who are U.S. citizens or permanent residents, or organizations (whether nonprofit or for-profit) that are incorporated in and maintain a primary place of business in the U.S. Designated team leaders, responsible for sending and receiving communications on behalf of their team, had to be at least 18 years of age. Participants between the ages of 13 and 17 were permitted as long as they were not team leaders and obtained written permission to participate from their parent or legal guardian. Only teams that were selected to proceed at the end of the Design Concept Stage could participate in the Working Prototype Stage.</td>
<td>Each phase of the competition had a set of judges who evaluated each of the entries submitted in that phase.</td>
<td>Of the 20 entries submitted in Phase 1 between June 1, 2017 and November 15, 2017, eight prizes were awarded at the end of Phase 2 on September 26, 2018.</td>
<td>The competition budget for FY17 and FY18 totaled $250,000 in each fiscal year. Funds were used to hire a dedicated program staff, and 0.2 full-time equivalents (FTEs) from the Mozilla Foundation helped with community outreach events, website development, recruitment of judges, and arranging the demonstrations. The $2 million in prize money was paid out in FY18, with $400,000 paid out in January 2018 (Phase 1) and the balance paid out at the end of FY18.</td>
<td>Mozilla Foundation was recruited to help plan and run the Challenge, including outreach, recruitment of judges, and building the website to manage the communications and submission process.</td>
<td>The NSF-WINS Challenges helped identify a broad set of wireless technology solutions to increase access to the internet, bringing together the outcomes of many research activities funded by NSF into solutions that immediately impact society. This aligns with the agency�s mission to advance scientific understanding to benefit society.</td>
<td>Software and apps; Technology demonstration and hardware; Business plans</td>
<td>N/A</td>
</tr>
<tr>
<td>NSF-Hearables Challenge</td>
<td>NSF</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>This challenge sought to generate ideas for design concepts or technologies (including algorithms) that might be used to allow a person with a hearable technology to have an understandable conversation at normal volume within a noisy setting, such as a busy restaurant. This challenge sought solutions that are the most broadly accessible to the population.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity; Stimulate a market</td>
<td>The prize competition was selected to attract a wide range of non-traditional participants, as the traditional mechanisms (grants, contracts, cooperative agreements, etc.) were not seen as attractive to a large community of students, entrepreneurs, and small business developers capable of developing solutions to this challenge. Since challenges go to the public and are broadly shared on social media and other media outlets, NSF decided to use a challenge to move research in the area of hearables forward.</td>
<td>The total prize purse offered was $145,000 and the total amount awarded was $146,000 ($80,000 for first place, $60,000 for second place, and $3,000 for third and fourth places). Non-monetary incentives included a presentation at the IEEE UbiComp Conference.</td>
<td>The NSF Hearables Challenge was open to all U.S.-based entrants, including non-profit and for-profit organizations and individuals ages 18 and over. Each participant had to fill out and submit an Intent to Apply form through the NineSigma website between April 25 and June 22, 2017. A sample audio file was provided at the challenge launch to help competitors develop and train their proposed approach. The final test audio was available for download one week before the June 30 deadline, and participants received information via email on how to register for an account at mozilla.fluxx.io. By submitting a full submission, the team leader formally accepted on behalf of the team the challenge rules and all decisions of the organizer and judges as final and binding. It was a very open competition that attracted entries from a diverse range of individuals and organizations as well as heightening awareness in the computing research community of the potential value of hearing technology.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Participation was open to individuals or teams whose leader was a U.S. citizens or permanent resident.</td>
<td>All submissions were evaluated for accuracy, defined by the number of words correctly identified from the audio sample. The processed samples were also reviewed by a panel of four judges for clarity, latency, and understandability. Proposals with the highest overall ranking were awarded prizes.</td>
<td>Of the seven entries submitted between April 25, 2017 and June 30, 2017, four prizes were awarded.</td>
<td>In FY17, 0.2 full-time equivalents (FTEs) were used to provide oversight of the competition process and review submitted entries. In FY16, NSF entered into and funded a memorandum of understanding with the NASA Challenge Center of Excellence to use their contract with NineSigma to manage the competition. This included community outreach events, website development, recruitment of judges, arranging demonstrations, and paying out prizes. NSF paid out slightly more in prizes than originally planned. The additional funds resulted from budget efficiencies.</td>
<td>The NASA Challenges Center of Excellence supplied technical assistance and expertise in addition to managing the NineSigma efforts.</td>
<td>The prize competition was selected to attract a wide range of non-traditional participants, since the traditional mechanisms (grants, contracts, cooperative agreements, etc.) were not seen as attractive to a large community of students, entrepreneurs and small business developers who were envisioned as capable of developing solutions to this challenge building upon the outcomes of prior NSF-sponsored research.</td>
<td>Software and apps; Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>InnovateHER 2017 Challenge</td>
<td>SBA</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>InnovateHER provides an opportunity for entrepreneurs to showcase products or services that have a measurable impact on the lives of women and families, have the potential for commercialization, and fill a need in the marketplace. The goal of the InnovateHER competitions is to empower women entrepreneurs to pitch their products, to create local visibility for them, and to make sure that entrepreneurs connect with our resource partners for assistance in starting and growing their businesses.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Engage new people and communities; Build capacity</td>
<td>The purpose of the InnovateHER Challenge is to create local visibility for SBA and to make sure that entrepreneurs connect with our resource partners for assistance in starting and growing their businesses. Also, we were aiming at a combined total of at least 100 or more events nationwide during this competition, and the cash prizes were used as incentives for the participants.</td>
<td>The total prize purse offered and awarded was $70,000. The first place cash prize was $40,000, second place was $20,000, and third place was $10,000.</td>
<td>Building on the success of the inaugural 2015 InnovateHER Business Challenge, SBA and OWBO received the offer from the Sara Blakely Foundation to donate and support the initiative. The initial round of the InnovateHER Challenge took the form of local competitions that ran across the country beginning December 29, 2016 and ended June 3, 2017.  The host organizations running the local competitions selected and submitted one winner from each local competition to SBA, along with a Nomination package by June 23, 2017.  Winners were announced during the live pitch competition held on October 26, 2017, in Washington, D.C.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Partner organizations wanting to host a local competition as part of the initial round of this Challenge sent requests to the SBA at womenbusiness@sba.gov. SBA evaluated all requests to host a local InnovateHER competition under its sole discretion and confirmed a host�s participation in writing. Each host organization was responsible for determining the type of local competition, and ensured it was conducted in a manner consistent with the Challenge Rules. At a minimum, however, each application was required to contain a business plan covering the contestant�s proposed product or service and must satisfy the Challenge criteria. The local competitions were administered solely by the local host organizations and were judged by individuals selected by each host in their sole discretion. Host organizations selected and submitted only one winner from the local competition along with a Nomination Package to SBA. This Challenge was open only to: (1) citizens or permanent residents of the United States who were at least eighteen (18) years of age at the time of their submission of an entry (or teams of such individuals); and (2) private entities, such as corporations or other organizations, that are incorporated in and maintain a primary place of business in the United States. Individuals submitting on behalf of corporations, nonprofits, or groups of individuals (such as an academic class or other team) were required to meet the eligibility requirements for individual contestants. An individual could belong to more than one team submitting an entry in this Challenge. SBA employees were not eligible, nor were Federal entities or Federal employees acting within the scope of their employment. Individuals or organizations that were at the time suspended or disbarred by the federal government were not eligible for this Challenge.</td>
<td>All business plans were reviewed based on the same Scoring Matrix and rated numerically from 1 to 5 with 5 being the highest possible score in any given segment. The evaluation of each package was the same at the local level where the judges were external to the federal government, SBA level where the judges were internal and at the final pitch where the judges were from the private sector. The criteria were scored as follows: The specifics of the product or service having a measurable impact on the lives of women and families (30%). How the product or service will potentially be commercialized (40%). The specifics of the product or service filling a need in the marketplace (30%).Each finalist was offered the opportunity to participate in the InnovateHER Final Challenge where they made a live marketing pitch to a panel of expert judges drawn from the private sector. The panel of judges selected the three finalists whose pitches, in their sole judgment, best satisfy the Challenge criteria and present the greatest potential for success and rank them in descending order. SBA found this evaluation to be effective.</td>
<td>Of the 120 local competitions held nation wide between December 29, 2016 and June 23, 2017, $70,000 in cash prizes (1st Place - $40,000; 2nd Place - $20,000; and 3rd Place - $10,000) prizes were awarded to three winners.</td>
<td>The competition was possible through a generous donation from the Sara Blakely Foundation; SBA did not obligate any appropriated funding for this initiative, and limited agency resources were used to conduct the Challenge. Approximately 3 � SBA staff members collaborated with Sara Blakely Foundation and an event planner to plan and execute the event. Several other staff members attended and helped execute various portions of the challenge, including the final event.</td>
<td>The final competition was possible through a generous donation from the Sara Blakely Foundation, in the form of cash prizes of $70,000. The foundation also donated $30,000 for the final event, used to pay an event planner.</td>
<td>The InnovateHER Chellenge creates an opportunity for SBA to be more visible and engaged locally with women entrepreneurs. We promoted our resources and leveraged our partners, creating new public and private partnerships that benefit the small business community.</td>
<td>Creative (design &amp; multimedia); Ideas; Business plans</td>
<td>In FY 2019, SBA is planning another InnovateHER challenge, following the same goals and format.</td>
</tr>
<tr>
<td>Growth Accelerator Fund Competition</td>
<td>SBA</td>
<td>COMPETES Authority</td>
<td>This competition was completed in FY17.</td>
<td>The Growth Accelerator Fund Competition aims to stimulate markets that are not being served by traditional venture capital and investment hubs. By infusing operational capital into qualified accelerators and incubators, these entities in turn provide resources to boost the startup and entrepreneurship communities around them. For the 2017 competition, SBA strengthened its previously funded accelerators from all over the country including rural areas and areas outside traditional venture capital hubs. Similar to previous years, SBA sought applications from women and other underrepresented groups. In addition to providing funds to underserved groups and geographic areas with less access to capital, the 2017 competition had an emphasis on accelerator models supporting STEM/ Small Business Innovation Research (SBIR), women-owned or minority-owned small businesses, rural communities, and veteran communities.</td>
<td>Engage new people and communities; Build capacity; Stimulate a market</td>
<td>The utilization of prize competitions was the preferred method over contracts, grants, and cooperative agreements because it allowed SBA to be more nimble. Various options were reviewed but upon consultation with the prize and challenge community of practice, SBA determined prizes as the most appropriate method for implementation. Prize authority held fewer restrictions, which allowed more diverse models of accelerators and incubators to participate (NGOs, Private, individual-led, etc.). This allowed the Agency to test supporting riskier emerging accelerator and incubator ecosystem efforts that might have a valid chance at developing their local driven venture, while lowering risk due to the relatively small prize awards ($50,000 apiece).</td>
<td>The total prize purse offered was $1,000,000 and the total amount awarded was $1,000,000. The FY17 GAFC competition awarded $1,000,000 in FY17 dollars as cash prizes to 20 entities ($50,000 each). GAFC does not offer non-cash prizes. The entire sum originated from SBA�s Entrepreneurial Development appropriations.</td>
<td>The 2017 Growth Accelerator Fund Competition was limited to previous winners. As such, previous awardees were notified of the new prize competition via email. A press release was also sent out to announce the competition.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release</td>
<td>The 2017 prize pool was limited to prior winners of the Growth Accelerator Fund Competition.</td>
<td>Judging consisted of three rounds. For the first two rounds, two reviewers were assigned for every one application. The first round consisted of internal SBA cross-agency judges who evaluated 10-slide PowerPoint decks. Of the 63 initial applicants, 54 were chosen to advance to the next round. Applicants were notified of their semi-finalist status on August 15 and were given directions to create a two minute video pitch highlighting their organization, accomplishments to date, and goals they hoped to achieve with the prize money. The second round consisted of external judges with expertise in entrepreneurial ecosystems and promoting innovation who received both the slide deck and then a two minute video pitch. The second round judges recommended 30 finalists to the Office of Investment and Innovation�s Director of Innovation. The final round consisted of the Director of Innovation and program staff who evaluated the external judge�s recommendations to select the 20 prizes of $50,000 that were ultimately awarded.</td>
<td>Of the 63 entries submitted between June 23 and July 21, 2017, 20 prizes were awarded.</td>
<td>SBA�s Office of Investment and Innovation does not have a full-time FTE designated primarily to the Growth Accelerator Fund Competition. In FY17, two employees each contributed 0.2 FTEs to collaborate on the competition. These employees also managed a preliminary evaluation of the program in partnership with the Library of Congress Federal Research Division.</td>
<td>N/A</td>
<td>The mission of the U.S. Small Business Administration lies within helping Americans start, grow, expand, and recover their businesses. One of its core strategic objectives is to build healthy entrepreneurial ecosystems and create business friendly environments. The Growth Accelerator Fund Competition fits directly into this goal as it stimulates markets in rural and other areas outside of venture capital and investment hotspots.</td>
<td>Other - Solutions to stimulate innovation with tech-based startups, to include SBIR funding and underrepresented groups.</td>
<td>SBA decided to roll the FY18 funds into the FY19 competition. To ensure GAFC aligns with the needs of entrepreneurs and the innovation ecosystem, SBA is reviewing the results of the competition through its first four years, while also evaluating potential changes.</td>
</tr>
<tr>
<td>#SmallBusinessWeek Hackathon</td>
<td>SBA</td>
<td>COMPETES Authority</td>
<td>This competition was launched and completed in FY18.</td>
<td>The National Small Business Week Hackathon Challenge sought to develop a Solution that will help small businesses improve their operations by combining Visa or U.S. Government APIs (Federal, State, or Local) with other technology and other open APIs.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public</td>
<td>The purpose of the Hackathon is to promote SBA�s services to the public and to foster cooperation between the public and private sectors for the benefit of small business.</td>
<td>The total prize purse offered and the total amount awarded was $24,000. Visa provided cash prizes in the follwing amounts: $10,000 first prize, $7,000 second prize, $5,000 third prize, and $2,000 specialty Visa API prize.</td>
<td>The Hackathon event was hosted in Washington, DC on April 27-29, 2018.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The Challenge was open only to citizens or permanent legal residents of the United States who are above the age of majority in their state of legal residence (including the District of Columbia) as of April 27, 2018; and who register to participate in the Hackathon. The maximum team sizes was five people.</td>
<td>At the conclusion of the Hackathon, each team had three minutes to demonstrate the Solution that Participants have developed for the panel of judges, followed by two minutes of Q&amp;A. Demonstration time limits could be shortened or lengthened under Visa and SBA�s sole discretion depending on the number of teams. Participants chose how to present their Solution, but were encouraged to explain and demonstrate how their Solution meets the judging criteria. Participants acknowledged that the panel of judges could ask them questions regarding their Solution. The order of demonstrations was decided by the judges in their discretion. Visa and SBA awarded prizes to National Small Business Week Hackathon Challenge teams that, in Visa and SBA�s sole determination, best meet the following criteria: [1] Innovation - Is this Solution different and unique from what is already on the market? (30 points); [2] Market Potential - Will this Solution have viable reach, and market potential for small business owners and entrepreneurs? (30 points); [3] Technical Execution - How effectively are the available APIs used? Is your Solution viable and easy to navigate? (20 points); [4] Challenge Fit - Does this Solution effectively respond to the National Small Business Week Hackathon Challenge? (20 points).</td>
<td>Of the entries submitted by 75 participants on April 27, 2018, four prizes were awarded to winners.</td>
<td>Limited agency resources were used to conduct the Hackathon. Approximately three SBA staff members collaborated with Visa to plan and execute the event. Several other staff members attended various portions of the event to participate.</td>
<td>Pursuant to SBA�s Cosponsorship Authority, Visa serves as a cosponsor of National Small Business Week. They provided the cash prize for the Hackathon winners, assisted with promotion of the event and other elements of event planning, and made their APIs available to participants. The estimated value of partner contributions was $24,000.</td>
<td>Small businesses are critical to local economies and communities throughout the United States. Their owners are passionate about their trades, but they often don�t have enough time for the day-to-day financial elements of running a small business, such as making payments efficiently, building and accessing, business credit, optimizing, cash flow, payroll &amp; accounting, and processes. The hackathon aims to help business owners focus more on their true passion by reimagining small business financial management by making use of API&#39;s from Visa, the U.S. Government, and third parties to build a game changing new tool.</td>
<td>Software and apps</td>
<td>In FY19, SBA plans to conduct a second Small Business Week Hackathon with the specific theme of disaster recovery and preparedness for small business.</td>
</tr>
<tr>
<td>Sign on For Literacy Prize</td>
<td>USAID, All Children Reading: A Grand Challenge for Development (ACR GCD)</td>
<td>COMPETES Authority</td>
<td>This competition was launched in FY18 and is underway.</td>
<td>Of the estimated 32 million deaf children around the world, 80 percent do not have access to education, and only two percent receive education in sign language. Without early access to language, children fail to develop social and cognitive skills at the same rate as their peers, hindering their ability to learn to read and write and isolating them from society over the course of their lives. The Sign On For Literacy Prize, seeks technology-based innovations that will provide greater access to local sign languages, sign language supported early grade reading materials, and/or reading instruction by engaging families, schools, and communities. Through these solutions, the goal is that parents, educators, and communities will be better prepared to support the early childhood language outcomes of deaf children, access to and the usage of local sign languages will increase, and the literacy outcomes of deaf children will improve.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Engage new people and communities</td>
<td>We were seeking to attract innovators who likely would not be aware of or respond to other mechanisms. The ACR GCD based the rationale for a prize structure on the Round One experience: despite the numerous proposals received, very few focused on these thematic areas. Smaller prize awards structured around these neglected thematic areas will encourage organizations to innovate and take more risks in implementing new ideas. ACR GCD has used both the grant and prize mechanisms. One of the valuable aspects we�ve found in prize competitions, is that it provides an easier on-ramp for organizations to partner with ACR GCD for a competition for a shorter-term, one-off activity, and usually for a smaller financial contribution.</td>
<td>The total prize purse offered was $500,000 and the total amount awarded was $125,000. Prizes were awarded to five finalists ($25,000 each) to further develop their solution prototypes in alignment with the feedback provided by the judges. The awards were granted as a one-time lump sum. Non-monetary incentives included promotion by ACR GCD and the prize parnters via social media and other digtial platforms, as well as an invitation to present at events.</td>
<td>The competition was announced at the 3rd International Conference of World Federation of the Deaf (WFD) during a session streamed live on Facebook. At the same time, a communication package, outlined below, was shared by ACR GCD and all links to the competition site went live. InnoCentive Listed the Sign On For Literacy Prize in five editions of its Challenge Bulletin, which is sent weekly to approximately 150,000 Solvers. It was also promoted through InnoCentive�s social media accounts (Facebook &gt;12,000 likes, Twitter &gt;11,000 followers, LinkedIn &gt;6,400 followers). World Vision circulated a communications package at launch and throughout the competition to the prize partners, encouraging them to promote the Sign On For Literacy Prize to their networks, which included: social media content, a prize announcement video, flyer ad, website banner, press release, Sign on For Literacy infographic and promotional videos. All prize partners continued to promote the prize on social media and other communication channels throughout the competition. As a result, large geographical reach was achieved, with many registrations from developing countries. Potential applicants registered from all over the world, from six continents and 61 countries. Applications were submitted from 39 countries and six continents.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The prize targeted global solvers including individuals, teams and organizations with innovative technology-based solutions that demonstrated the ability to increase access to sign languages and literacy interventions for children who are deaf in low-resource contexts. Entrants were required to submit a written description in English of the proposed innovation and project plan explaining the methods, resources, potential technology platform(s), personnel, existing partnerships (if any), evidence of collaboration with the local deaf community in product design and implementation, and preliminary schedule to implement the proposed innovation. It was also noted that entrants must be able to work with ACR GCD partners and other collaborative organizations for prototype development in Phase 2 and implementation of the innovation in Phase 3. Suppliers of goods and services that did not meet the nationality and source definitions as referenced in 22 CFR 228.11 and 12, specifically geographic code 937 were ineligible for award. Geographic code 937 currently excludes Cuba, Iran, Libya, and North Korea.</td>
<td>The evaluation was conducted over five stages. The first two stages were prescreening first by InnoCentive and then by ACR GCD to remove entries that did not meet key requirements. Judging was conducted over three rounds. In the first round of judging 53 entries were scored against judging criteria by a panel of 10 expert judges that included a mix of the prize partners and external technical experts. Each entry was reviewed by 3 judges and the 19 top scoring submissions moved to the next round of judging. In the second round of judging, the 19 remaining entries were scored against the judging criteria by a panel of nine expert judges. This resulted in 8 top scoring submissions. These top 8 applicants were asked to provide written response to questions that surfed during the judging process. These submissions and questions were then reviewed by a steering committee consisting of representatives from the prize partners. Based on the scoring throughout the judging rounds, answers to the questions, and the recommendations of the steering committee members, the prize partners selected five entries to receive an award of $25,000 each and were moved to Phase 2 of the competition. Overall, this evaluation method was found to be very comprehensive and effective in identifying innovative solutions. It was however a very lengthy process.</td>
<td>Of the 104 entries submitted by participants between November 8, 2017 and February 16, 2018, five prizes have been awarded to the Phase 1 winners. Final winners have not yet been determined.</td>
<td>A prize design and administration firm, InnoCentive, was contracted to develop the prize requirements and administer the prize. A design-thinking consultant was hired to lead the prize parnters and technical experts through a collaborative process to identify the challenge statement and parameters of the prize. The five prize winners of Phase 1 of the competition were awarded $25,000 each. In 2017, the project funding was $88,855 and two ACR staff members comprised approximately 50% FTE status. In 2018, the project funding was $169,965 and three ACR staff members comprised approximately one FTE staff time.</td>
<td>Partnerships with World Federation of the Deaf (WFD), Deaf Child Worldwide (DCW), and Nyle DiMarco Foundation (NDF) have been critical to the success of this prize. Each provided credibility to the competition and enhanced communications with the global deaf community many of which competed in the competition. In the future, ACR GCD will seek to engage such technical partners such as these. WFD provided technical expertise throughout the design of the competition by attending the design workshop and providing subsequent reviews and feedback on the prize design. They announced the prize live and streamed it on Facebook at the 3rd International Conference of the WFD which has received over 14,000 views. They also promoted the prize through their social media and other communications channels. WFD also nominated judges that supported the review of the prize submissions. DCW contributed 20,000 GBP to the prize purse and provided technical expertise throughout the design of the competition by reviewing and providing feedback on the prize design. They promoted the prize their their social media and other communications channels and nominted judges that supported the review of the prize submissions. NDF provided technical expertise throughout the design of the competition by attending  the design workshop and providing subsequent reviews and feedback on the prize design. They announced the prize through their social social media channels and nominated judges to support the review of the prize submissions. ACR GCD is a partnership of the United States Agency for International Development, World Vision, and the Australian Government. The estimated value of partner contributions for this prize was $77,600 from USAID:, $77,600 from World Vision, $77,600 from the Australian Government:, $26,000 from DCW, and an estimated $10,000 in-kind communications and technical support from WFD.</td>
<td>Of the estimated 32 million deaf children around the world, 80 percent do not have access to education, and only two percent receive education in sign language, the most natural and accessible language for a deaf child. Early acquisition of a first language and access to education in sign language has been proven to greatly increase literacy outcomes in children, both hearing and deaf. However, children who are deaf often have limited access to local sign language, learning resources, or adults that are fluent signers. By providing children, parents, educators and communities a resource for learning the local sign language; children will have a greater opportunity to acquire language as a building block for learning to read and a first step in the child�s educational journey. True education for all depends upon inclusive education interventions and systems for people with disabilities and by sourcing new and inclusive approaches, this competition advances the ACR GCD partners� goals of inclusive education and the learning outcomes of all children.  The Sign On For Literacy prize also provided an opportunity to profile the lack of education and learning opportunities for children with disabilities around the globe.</td>
<td>Software and apps; Technology demonstration and hardware</td>
<td>All ACR Prize Activities will depend on the new strategy to be developed by the ACR Partners in Q1 FY2019.</td>
</tr>
<tr>
<td>DARPA Spectrum Collaboration Challenge (SC2)</td>
<td>Defense Advanced Research Projects Agency (DARPA)</td>
<td>10 USC 2374a</td>
<td>This competition was underway in both FY17 and FY18, but has not concluded.</td>
<td>The DARPA Spectrum Collaboration Challenge (SC2) is the first of its kind collaborative machine learning competition to overcome scarcity in the radio frequency (RF) spectrum. Today, spectrum is managed by dividing it into rigid, exclusively licensed bands. This human-driven process is not adaptive to the dynamics of supply and demand, and thus cannot exploit the full potential capacity of the spectrum. In SC2, competitors will reimagine a new, more efficient wireless paradigm in which radio networks autonomously collaborate to dynamically determine how the spectrum should be used moment to moment. The team whose radio design most reliably achieves successful communication in the presence of other competing radios could win as much as $3,500,000.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>The objectives of the Spectrum Collaboration Challenge warrant a prize competition format for a number of reasons. First and foremost, the �collaboration� aspect of the competition requires a sizeable field of unaffiliated performers creating a heterogeneous solution set. Further, it is unclear which approach will yield the most effective solution to the problem. The allure of prize money incentivizes teams with diverse backgrounds from academia, industry and independent entrepreneurs to develop creative, varied solutions to the problem. The government is then able to evaluate across the solution set and determine the best approach at a low investment threshold. Finally, SC2 seeks to create a community focused on developing autonomous spectrum management solutions. The current advances in artificial intelligence and machine learning as applied to software radio design create what DARPA believes is a critical inflection point in autonomous management of the wireless spectrum.</td>
<td>The total prize purse offered was $18.75 million and the total amount awarded was $7.5 million to date. In Phase I, a total of ten $750,000 prizes were awarded to the top ten performing teams at SC2�s Preliminary Event #1 in December 2017. In Phase II, a total of six $750,000 prizes were awarded to successful teams at SC2�s Preliminary Event #2 in December 2018 and four $375,000 prizes were awarded to successful teams that passed an extended evaluation in January 2019. In Phase III, three awards will be awarded to successful teams at SC2�s Championship Event in October 2019 (1st place: $2 million; second place: $1 million; third place: $750,000), a total of $3.75 million.</td>
<td>SC2 was advertised through various means. Prior to launching the challenge, the program manager visited various universities and industry locations in the wireless research community soliciting interest and feedback in the competition. The challenge was officially launched through a DARPA press release and publishing of the SC2 website. The proposal track was additionally advertised through a Broad Agency Announcement (BAA) posted to FedBizOpps. A Competitor�s Information Day was hosted at DARPA on August 10, 2016. Open track teams are able to enter at the beginning of each of the three phases of the competition by successfully completing technical entrance hurdles. These hurdles evaluate a team�s ability to develop software defined radios and demonstrate applicable machine learning techniques.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Other - FedBizOpps.gov</td>
<td>The target solver audience is a cross section of wireless researchers from academia, industry, and independent entrepreneurs. Successful teams will have a strong background in both software defined radio design and artificial intelligence/machine learning techniques. The competition is open to any entity that can provide a US Taxpayer ID number to receive prizes. As such, teams from around the world are currently competing, representing major universities, DoD, commercial contractors, and independent inventors.</td>
<td>For entrance to the competition, Open track teams are evaluated based on their successful performance in a series of hurdles, which evaluate teams� ability to develop software defined radios and demonstrate applicable machine learning techniques. Proposal track teams were evaluated based on the merits of their technical approach by a selection board consisting of DARPA program managers, AFRL, and NSF subject matter experts. A valuable lesson learned in establishing a capable competitor field was the use of entrance hurdles to deter and deny technically immature teams. This is essential since the competitor field all share access to a limited government-provided Colosseum resource (a RF emulator testbed that forms the backbone of the competition). To evaluate performance in prize award competition events (Preliminary Event #1, #2, and the SC2 Championship Event), teams submit their software defined radio code to DARPA for testing in Colosseum. Each team�s radio software is tested in a series of emulated RF scenarios in the presence of multiple other team radio solutions. Teams are judged on their ability to achieve performance thresholds in collaboration with other teams.</td>
<td>Phase I began July 19, 2016. Proposal track submissions were due September 2, 2016 and open track submissions were due December 2, 2016. Phase I winners were announced December 13, 2017. Phase II began January 1, 2018 and submissions were due April 30, 2018. Phase II winners were announced December 13, 2018 and January 24, 2019. Phase III submissions were due January 11, 2019.<br/>Phase I had 152 participants across 26 open track teams and six proposal track teams. A total of ten prizes were awarded in Phase I. Phase II had 134 participants across 15 open track teams (including one new team) and four proposal track teams. Ten prizes were be awarded in Phase II. Phase III had 109 participants across 912 open track teams (no new teams entered) and three proposal track teams. Phase III will have three prizes.</td>
<td>One FTE program manager was assigned to SC2 over FY17 and FY18. DARPA utilizes third party support vendors to perform various tasks for conducting SC2, including hardware procurement/maintenance, software development, RF scenario development, scoring, integrity, visualization, production, and logistics. In FY17, third party vendors were obligated $12.6 million, but expended $11.5 million. In FY18, third party vendors were obligated $5.9 million, but expended $4.1 million.</td>
<td>DARPA contracted with MIT Lincoln Labs to provide expertise in RF scenario design and scoring methodologies. Their considerable knowledge base in these two areas provided valuable inputs to the initial architecture of the competition. DARPA has also entered in a Cooperative Research and Development Agreement (CRADA) with Groupe Sp�cial Mobile Association (GSMA), to host the SC2 Championship Event at their annual Mobile World Congress Los Angeles conference in October 2019. This relationship with GSMA, a non-Federal partner, provides key synergy in capturing an interested, educated audience of the commercial wireless industry, government policy experts, and DoD entities for the culminating the SC2 Championship Event.</td>
<td>DoD operations increasingly rely on unfettered access to the spectrum in order to carry out their primary mission. Managing the spectrum is a tedious, laborious, and error-prone process. A spectrum manager must take into account the needs of their radio systems, the needs of allied and NATO force radio systems, and existing host nation infrastructure. This delicate planning can easily be disrupted by the rapid change in needs for spectrum services (both ours and allies�), changes in RF conditions, and variability of types of radios which need access based on changing mission needs. Due to inefficiencies in this process, currently available planning tools are unable to effectively allocate spectrum. Resulting SC2 radio technology will increase the efficiency and ability of communications networks to perform electromagnetic maneuver by allowing radio networks to autonomously and collaboratively perform tactical spectrum decision-making at the edge, faster than today�s human planning cycle.</td>
<td>Software and apps; Technology demonstration and hardware; Scientific</td>
<td>DARPA has seen immense success with the Grand Challenges hosted by the Agency since the initial Grand Challenge for autonomous ground vehicles in 2004. Currently, DARPA is running three separate prize challenge competitions, cross-cutting various research areas such as responsive small satellite launch, subterranean navigation, and of course SC2�s autonomous spectrum management. For SC2, the next two fiscal years cover the final two prize events, Preliminary Event #2 in December 2018 and the SC2 Championship Event in October 2019.</td>
</tr>
<tr>
<td>CubeSat Challenge</td>
<td>United States Special Operations Command (USSOCOM)</td>
<td>10 USC 2374a</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>USSOCOM is pursuing a development effort to determine the operational utility of using CubeSats and SmallSats to directly support special forces in austere and denied areas. The intent is to solicit operationally relevant and technically feasible payload concepts for USSOCOM CubeSats and SmallSats. Example areas that are relevant to USSOCOM missions include: advanced communications (including full orbit C2 and data exfiltration); electro-optical infrared sensing and imaging; propulsion systems capable of modifying or maintaining orbits; on-orbit data processing; multi-function payloads;. tagging, tracking, and locating capabilities; next-generation CubeSat and sensor technologies.</td>
<td>Find and highlight innovative ideas; Advance scientific research</td>
<td>Traditional development conducted over the past several years has not resulted in payloads which can provide satisfactory solutions for these problems. USSOCOM was seeking to find solutions by leveraging commercial and academic sources through the prize challenge solver ecosystem.</td>
<td>The total prize purse offered and awarded was $35,000. Under the 3U Satellite Category four $5,000 prizes were awarded, and under the 6U Satellite Category.two $5,000 prizes and one $5,000 People�s Choice Award were awarded.</td>
<td>Through an interagency agreement between USSOCOM and the National Aeronautics and Space Administration (NASA), USSOCOM employed NASA to solicit prize challenge providers to conduct this challenge. HeroX was selected as the best option to conduct this challenge. All parties used social media to advertise the challenge. This information was also provided to Challenge.gov for posting on their site. USSOCOM found that all of these methods were satisfactory in getting the word out to the general public based on the number of responses and registrants.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>All public submissions were accepted for this challenge.</td>
<td>Submissions were evaluated using a panel of subject matter experts selected from USSOCOM and other agencies who have extensive knowledge in the field of satellite communication technologies. NASA and HeroX provided the judging panelists with an automated evaluation product that automatically tabulated the score submissions.</td>
<td>Of the 35 entries submitted by 18 participants between August 15 and October 18, 2017, seven prizes were awarded to six winners.</td>
<td>USSOCOM provided $88,303.97 in funding by using FY17 Research Development Test and Evaluation Funds. $35,000 was awarded to six challengers through the HeroX prize challenge platform. Administrative costs of $41,907 were incurred by HeroX for their efforts in administering this challenge; and $11,396.97 was incurred by NASA via their existing prize challenge contract for their administrative costs.</td>
<td>N/A</td>
<td>Current over-the-horizon audio and video data exfiltration capabilities do not provide the consistent access, coverage, throughput, and flexibility required by U.S. forces. Therefore, USSOCOM executed a development and demonstration effort to determine the operational utility of using CubeSats to directly support U.S. forces in austere and denied areas. USSOCOM was seeking unique solutions to developing/delivering operationally relevant and technically feasible cubesat payload for missions such as advanced communications; tagging, tracking, and locating capabilities; and on-orbit data processing. The intent was to determine to what extent low-cost, tactically controlled small satellites can support over the horizon data exfiltration requirements.</td>
<td>Creative (design &amp; multimedia); Ideas; Scientific</td>
<td>N/A</td>
</tr>
<tr>
<td>Technology Challenges and Opportunities to SOF in 2027</td>
<td>USSOCOM</td>
<td>10 USC 2374a</td>
<td>This competition was completed in FY17.</td>
<td>USSOCOM was interested in understanding what global challenges or opportunities lay ahead for Special Operations Forces ten years into the future.</td>
<td>Find and highlight innovative ideas</td>
<td>The pace of technology change is arguably not slowing down and the proliferation of emerging technology-based capabilities to the global population is continuing to cause global effects. Previous efforts to understand the future Special Operation Forces (SOF) environment based on technological advances have taken many forms. The one glaring omission has been reaching out to a non-Department of Defense (DoD) community for their thoughts and perceptions. Through this challenge, USSOCOM aimed to look at the future in a non-traditional way.</td>
<td>The total prize purse offered was $25,000 and the total amount awarded was $22,000. Non-monetary incentives included a personal letter from the Special Operations Forces, Acquisition, Technology, and Logistics, Science and Technology (SOF AT&amp;L-ST) Director and a USSOCOM Coin.</td>
<td>Submissions were solicited on the InnoCentive web site and the challenge was also announced on the �Challenge.gov� website.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release</td>
<td>All public submissions were welcome.</td>
<td>Submissions were evaluated by four individuals from SOF and reviewed by the Director, SOF AT&amp;L-ST.</td>
<td>Of the 108 entries submitted between July 21 and August 10, 2017, 18 prizes (ten $1,000 prizes, and eight $1,500 prizes) were awarded to ten winners.</td>
<td>USSOCOM provided $25,000 for this challenge using FY17 Research Development Test and Evaluation funds. $22,000.00 was awarded in prizes through the InnoCentive platform and $3,000 was returned to USSOCOM.</td>
<td>N/A</td>
<td>USSOCOM is interested in the impacts of technological innovation in civilian society around the globe. The challenge sought perspectives on how people see the world in 2027 and the critical impacts it might pose for Special Operations Forces by asking the following questions: What new or evolved technology will have the greatest impact, either as a challenge or as an opportunity, for Special Operation Forces in 2027? How is daily life for humans around the world going to differ from today? What innovations will industry invent, which will shape society ten years from now? How will technologies become disruptive by themselves or converged with other technologies? What are the economic, social, and military effects created by this technological evolution?</td>
<td>Ideas</td>
<td>A challenge will be used to support USSOCOM�s Innovation Foundry (IF) #3 in the second quarter of FY19. USSOCOM will be contracting the challenge through the Capital Factory in Austin, Texas, who will also be hosting the event. The Capital Factory already conducts prize challenges within its ecosystem, and USSOCOM wants to focus on its ecosystem for the next IF. The same pattern for prize awards will be followed: $1,000 for a white paper and $1,500 for participation in person at the IF event.</td>
</tr>
<tr>
<td>Urban 3D Challenge</td>
<td>USSOCOM</td>
<td>10 USC 2374a</td>
<td>This competition was launched and completed in FY18.</td>
<td>USSOCOM is seeking an algorithm that provides reliable, automatic detection and delineation of building footprint outlines based solely on USSOCOM-provided 3D Digital Surface Model (DSM) and Red, Green, Blue (RGB) orthorectified imagery products. Specifically, USSOCOM sought concepts that: (1) are relevant to USSOCOM missions; (2) provide positive operational impact, efficacy, and utility; (3) advance the state of the art for automated detection and delineation of building footprint outlines from specified source data; (4) improve the quality of the data products of the SOFPREP workflow pipeline; and (5) can be integrated into the existing data processing workflow pipeline.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology</td>
<td>Extraction of building footprint outlines from satellite imagery is one of the first and most challenging steps in producing realistic textured 3D scene models to support the Special Operations Forces tactical mission set. While automated algorithms continue to improve, significant manual effort is still required to correct mistakes and ensure acceptable quality. Newly available near-global 3D DSM products along with conventional RGB orthorectified image products offer a wealth of information to enable more reliable automated building footprint extraction which, in turn, is expected to further enable an automated pipeline for 3D scene model production to support SOF missions. USSOCOM was seeking to find solutions by leveraging commercial and academic sources through the prize challenge community.</td>
<td>The total prize purse offered and awarded was $34,500. Prizes were awarded as follows: first place $10,000, second place, $8,000, third place $6,000, fourth place $5,000, fifth place $4,000, sixth and seventh places $500, and two additional prizes of $250 each.</td>
<td>Through an Interagency Agreement between USSOCOM and NASA, USSOCOM employed NASA to solicit prize challenge providers to conduct this challenge. Topcoder was selected as the best option to conduct this challenge. TopCoder created a marketing campaign which included a direct email campaign that ran for 30 days, where they developed a database of 1,564 contacts based on demographics of individuals and organizations who would be likely, and qualified, to participate in the challenge. In addition to the direct target email, they also reached out to their 5,225 subscribers via a monthly newsletter. In addition to the email campaign, a social media campaign ran for 30 days that directed persons to the Topcoder registration page. This challenge was also posted on the Challenge.gov site.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>All public submissions were welcome.</td>
<td>Finalists were selected by USSOCOM based on quantitative scores provided by TopCoder in coordination with USSOCOM technical subject matter experts. Evaluators worked independently to review the submissions and used a standard scoring methodology derived from baseline quantitative metrics. The results were then tallied and reviewed by TopCoder and USSOCOM before making the final award recommendations.</td>
<td>Of the 790 entries submitted by 217 participants between October 9 and December 4, 2017, eight prizes were awarded to nine winners.</td>
<td>USSOCOM provided $134,804 in funding using FY17 RDT&amp;E Funds. Of this, $72,936 was incurred by Topcoder for administering the challenge, $35,000 was awarded to nine challengers through the Topcoder prize challenge platform, $11,500 was provided to judging panelists for their participation in evaluating submissions, $10,608.95 was incurred by NASA for their administrative costs, and $5,000 was expended in supplemental advertising.</td>
<td>N/A</td>
<td>USSOCOM was seeking an algorithm that provides reliable, automatic detection and delineation of building footprint outlines based solely on USSOCOM-provided 3D Digital Surface Model and Red, Green, Blue orthorectified imagery products.</td>
<td>Software and apps; Analytics, visualizations, algorithms</td>
<td>USSOCOM plans to work with other software coders to experiment with the development of promising machine learning algorithms into emerging software capabilities. Experiments show great potential for improving the detection and delineation of building footprint outlines. USSOCOM may conduct another prize challenge, but this is yet to be determined.</td>
</tr>
<tr>
<td>Domestic Violence Awareness Month YouTube Challenge</td>
<td>Administration on Children, Youth and Families (ACYF), Family and Youth Services Bureau (FYSB), Division of Family Violence</td>
<td>15 U.S.C. � 3719 and 42 U.S.C. � 10401(a)(1)</td>
<td>This competition was completed in FY17.</td>
<td>FYSB envisions a future in which all of our nation�s youth, individuals, and families, no matter what challenges they may face, can live healthy, productive, violence-free lives. The Challenge goal was to learn more about, and bring attention to, new, emerging, and effective methods that go beyond traditional services, programs, and supports that communities are using with this special population. The Challenge was conducted in an effort to stimulate innovation and raise awareness of the services and supports for children and youth exposed to domestic violence and their abused parents. In this Challenge, FYSB asked the public to submit videos featuring their most innovative means of helping to improve safety, promote healing, and build the resilience of children and youth exposed to domestic violence and their abused parents. The Challenge sought innovative, creative, and inclusive practices, policies, programs, safe spaces, activities, and strategies to meet this end.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Inform and educate the public; Engage new people and communities; Build capacity</td>
<td>This YouTube Challenge was the first of its kind at FYSB. The Challenge was a pilot project to see if a challenge is an effective mechanism for reaching FYSB grantees and gathering information on innovation and promise. If competitions or challenges are found to be effective, this project may lead to larger challenges that create life-saving or life-changing benefits for victims of domestic violence and other populations that are served by Family Violence Program in the Family &amp; Youth Services Bureau (ACF) programs. This Challenge also helped FYSB build our knowledge and skills in running competitions, which will be helpful for future and larger scale competitions.</td>
<td>The total prize purse offered and awarded was $10,000. First, second, and third place winners were awarded $5,000, $3,000, and $2,000, respectively</td>
<td>N/A</td>
<td>Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Submissions were required to be (1) one to three minutes in length; (2) in a compatible YouTube format with the proper codecs: WebM files, MPEG4, 3GPP, MOV, AVI, MPEGPS, WMV, FLV with suggested aspect of 16:9; and (3) aligned with the vision of FYSB.  Entrants must (1) post their video submission to their favorite video sharing site and send the link to their video entry on the Domestic Violence YouTube Challenge listed on www.challenge.gov/domestic-violence-video-challenge by the deadline; (2) highlight one or more new, innovative, emerging, and effective approaches, practices, policies, programs, safe spaces, activities, strategies, and any other ways that help to improve safety, promote healing, and build resilience of children exposed to domestic violence and their abused parents; and (3) include a written transcript for the video for closed captioning purposes.</td>
<td>Evaluation criteria included weighted ratings of the following elements: (1) the video content highlighted one or more new, innovative, emerging, and effective approaches, practices, policies, programs, safe spaces, activities, strategies, and any other ways that help to improve safety, promote healing, and build the resilience of children exposed to domestic violence and their abused parents; (2) the video aligned with FYSB�s vision; (3) the video content increased awareness of domestic violence issues; (4) the video content was educational, imparts knowledge, or deepens understanding of supports for children, youth, and parents; (5) the video content was innovative; (6) the video content was creative.</td>
<td>Of the 26 entries submitted between October 12 and November 2, 2016, three prizes were awarded.</td>
<td>Prize money was awarded from the ACF. Administrative support provided by the Budget Office, Division of Grants Policy, ACF leadership at all levels, Office of the General Counsel, Office of Communications, among others, was critical to get the challenge started, published on the Federal Register, and awarded. The Challenge utilized 0.05 FTE in FY17 and used FY16 funding obligations to finish the Challenge.</td>
<td>N/A</td>
<td>The prize competition advanced our agency�s mission in our goals to inform and educate the public; engage new people and communities; learn about and share innovative ways the community is supporting this population.</td>
<td>Ideas</td>
<td>There are no future plans for this Challenge at the time of reporting.</td>
</tr>
<tr>
<td>Challenges in Computational Precision Medicine (CPM) 2018</td>
<td>National Institutes of Health (NIH), National Cancer Institute (NCI)</td>
<td>NCI considers the use of challenges and prize competitions within its statutory authority as a means to fulfill the Institute�s purpose.</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>The overall goal of CPM challenges is to promote development of medical image analysis algorithms for clinical decision support in diagnosis and staging of various cancers. In CPM 2018 these include (1) pancreatic cancer survival prediction: predict pancreatic cancer survival from computed tomography (CT) and clinical data from Memorial Sloan Kettering Cancer Center (MSKCC); (2) 18F-FDG PET radiomics risk stratifiers in head and neck cancer: predict local tumor control following radiation treatment of oropharynx cancer using an ensemble of radiomics and clinical data from MD Anderson Cancer Center (MDACC); (3) combined radiology and pathology classification: evaluate performance of automated classification algorithms that use a combination of imaging and digital pathology data from brain tumor collection of the Cancer Genome Atlas; (4) digital pathology segmentation of nuclei in images: evaluate performance of algorithms for segmentation of nuclei in digital pathology images of low- and high-grade glioma (brain tumor).</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>The use of incentivized challenge competitions allows agencies to cast a wide net to find innovative solutions through crowd- sourcing and open science. Furthermore, participants in a challenge agree to benchmark performance of their software tools against a common reference dataset. Such approaches are not typically provided through traditional grant mechanisms. NCI determined that the monetary prize is often secondary to the community�s interest to participate in an activity where they can find access to high quality data and the opportunity to benchmark their tools compared to other participants.</td>
<td>CPM offered non-cash prizes only. Three winners received a certificate of merit, the opportunity to give an oral presentation at the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2018 annual conference, and the opportunity to be a co-author on a scientific manuscript on one of CPM 2018 challenges.</td>
<td>CPM challenges were announced through MICCAI 2018 webpage on satellite events and emailed through several professional listservs. MICCAI has been running medical imaging challenges for over ten years and CPM has been offered regularly since 2014. As a result, NCI has had a growing number of international participants in CPM challenges over the years. Furthermore, given the emerging trends in data science, machine learning and artificial intelligence (AI), NCI expects participation in future will only increase. One factor that is of prime importance in offering a challenge in conjunction with the annual meeting of a scientific society is the timing of the opening and closing of the challenge and announcement of the winners who need enough time to plan their travel to the meeting.</td>
<td>Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Special challenge session at MICCAI annual meeting to highlight the challenge and facilitate presentations by the winners</td>
<td> N/A</td>
<td>Submissions were evaluated against the ground truth and summarized as an index. The ground truth is always provided by clinical experts who are familiar with the disease and the data.</td>
<td>NCI received 217 submissions for pancreatic cancer survival prediction; 65 submissions in 18F-FDG PET radiomics risk stratifiers in head and neck cancer; 223 submissions in combined radiology and pathology classification; and 314 submissions in digital pathology segmentation of nuclei in images. These submissions were received between June 12, 2018 and August 16, 2018, and 12 prizes were offered.</td>
<td>The NCI Program Director devoted 10% time to lead the development of the CPM challenges design and implementation, including an associated workshop. Outside collaborators from academia contributed data and managed individual challenges within the CPM offering. Datasets available through The Cancer Imaging Archive (TCIA), MSKCC, and MDACC were used in training and test phases of the CPM 2018 challenge. An existing challenge platform was used for submission of results and ranking of participants based on a set of evaluation metrics. The challenge platform was utilized under a blanket contract between the platform operator and NCI Center for Biomedical Informatics and Information Technology.</td>
<td>As mentioned, NCI partnered with various organizations which provided shared interest and expertise in development, advertisement, and completion of the Challenge. These partners included MICCAI 2018, Harvard University, MSKCC, MDACC, Stony Brook Cancer Center, and the University of Pennsylvania.</td>
<td>The NCI mission includes dissemination of information on cancer detection, diagnosis, and treatment, and support for innovative solutions to the cancer problem. CPM challenges, performed in collaboration with non-profit entities such as scientific societies and universities leverage existing shared datasets to drive algorithmic excellence and incentivize development of innovative analytic software methods in cancer detection, diagnosis, and staging.</td>
<td>Software and apps; Ideas; Analytics, visualizations, algorithms; Scientific</td>
<td>A great amount of high quality cancer data (imaging, pathology, genomics, proteomics, and clinical) are generated through NCI-funded grants and cooperative agreements. Often these constitute what is referred to as big data. Solvers in the community, who are typically graduate students or research fellows with innovative ideas usually lack access to such data. Challenges provide a great way to develop tasks related to existing data that are aimed to bring innovative approaches, such as AI, to solve long standing problems, or facilitate more accurate solutions toward clinical decision support. NCI plans to utilize new datasets (imaging and other types) to launch new challenges in 2019 and 2020. These include challenges related to pancreatic and brain cancers, two of the deadliest cancers.</td>
</tr>
<tr>
<td>ICGC-TCGA DREAM Somatic Mutation Calling - RNAChallenge (SMC-RNA)</td>
<td>NIH, NCI</td>
<td>NCI considers the use of challenges &amp; prize competitions within its statutory authority as a means to fulfill the Institute�s purpose.</td>
<td>This competition was completed in FY17.</td>
<td>The International Cancer Genome Consortium-The Cancer Genome Atlas (ICGC-TCGA) Dialogue for Reverse Engineering Assessments and Methods (DREAM) Somatic Mutation Calling - RNA Challenge (SMC-RNA) is an international effort to improve standard methods for identifying cancer-associated rearrangements in RNA sequencing (RNA-seq) data. NCI held the ICGC-TCGA DREAM Somatic Mutation Calling RNA Challenge (SMC-RNA), a community-based collaborative competition of researchers from across the world. The goal was to rigorously assess the accuracy of methods to perform two key tasks in cancer RNA-Seq data analysis: the quantification of known isoforms and detecting novel fusion transcripts. NCI generated synthetic RNA-Seq data and introduced a phase during which teams make predictions on real human-tumors. The SMC-RNA Challenge will analyze a couple of dozen samples created to have known alterations representing different tumor types, allowing confidence that the winning methods will be generalizable across the broad range of human cancers.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities</td>
<td>This was a unique way to get new participants to not only create new, better algorithms to solve an issue with RNA sequencing, but also utilize the NCI Cloud Pilots off of which the Challenge was run. The NCI Cloud Pilots are designed to explore innovative methods for accessing and computing on large genomic data. They aim to bring data and analysis together on a single platform by creating a set of data repositories with co-located computational capacity and an application programming interface (API) that provides secure data access. In this model, applications are brought to the data, rather than bringing the data to the applications. The goals of Cloud Pilots are to democratize access to NCI-generated genomic and related data and to create a cost-effective way to provide computational support to the cancer research community.</td>
<td>There were no cash prizes for this Challenge. All participants were invited as consortium co-authors on challenge marker papers and winners will receive speaking invitations at the next DREAM conference or Sage Congress.</td>
<td>The Challenge was advertised through NCI email groups and regularly scheduled meetings to contractors and grantees, specifically those scientists involved in the TCGA project (as this Challenge used TCGA data) were targeted. In addition, the Challenge was advertised on the DREAM Challenge site. The contractors funded to do this work also advertised the Challenge when they gave presentations at scientific meetings.</td>
<td>Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td> N/A</td>
<td>Submissions were ranked based on scoring metrics for each sub-challenge. In the Quantify Known Isoforms sub-challenge, the scoring metric was the Spearman and Pearson correlations calculated on the relative and true quantity of simulated isoforms or isoform spike-ins. In the Discover Gene Fusions Truth sub-challenge, the scoring metric was the sensitivity, precision and F1-score calculated for each simulated or spike-in tumor when applicable.</td>
<td>11 entries were submitted between June 29, 2016 and May 12, 2017.</td>
<td>Two contracts were awarded to Oregon Health Sciences University and Ontario Institute for Cancer Research for approximately $100,000 each to facilitate the Challenge by setting up the Challenge, the website, the rules, the test datasets, and to evaluate the results of the participants entries. A single Federal staff member oversaw the Challenge at about 5% FTE.</td>
<td>The partnership with the two contractors to run the Challenge was successful. The two contractors both had prior experience with running DREAM Challenges and this was critical in making the Challenge a success.</td>
<td>There is limited international efforts aimed at providing an unbiased and long-lived benchmarking of RNA-Seq Analysis Methods. This Challenge will help inform the standard approaches adopted across the cancer-research community due to the involvement of the organizers and participants in ICGC, TCGA and the Global Alliance for Genomics and Health projects.</td>
<td>Software and apps; Scientific</td>
<td>N/A</td>
</tr>
<tr>
<td>NCI-CPTAC DREAM Proteogenomics Challenge</td>
<td>NIH, NCI</td>
<td>NCI considers the use of challenges &amp; prize competitions within its statutory authority as a means to fulfill the Institute�s purpose.</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Characterization and analyses of alterations in the proteome has the promise to shed light on cancer development and may improve development of both biomarkers and therapeutics. Measuring the proteome is very challenging, but recent rapid technology developments in mass spectrometry are enabling deep proteomics analysis. Multiple initiatives have been launched to take advantage of this development to characterize the proteome of tumors, such as the Clinical Proteomic Tumor Analysis Consortium (CPTAC). This challenge used public and novel proteogenomic data generated by the CPTAC to try to answer fundamental questions about how different levels of biological signal relate to one another. In particular, the Challenge focused on understanding: (1) Can one impute missing values in proteomics data given observed proteins?; (2) Can one predict abundance of any given protein from mRNA and genetic data?; and (3) Can one predict the phosphoproteomic data, using proteomic, mRNA and genetic data?</td>
<td>Solve a specific problem; Advance scientific research; Engage new people and communities; Stimulate a market</td>
<td>The use of incentivized challenge competitions allows agencies to cast a wide net to find innovative solutions through crowd- sourcing and open science. Furthermore, participants in a challenge agree to benchmark performance of their software tools against a common reference dataset. Such approaches are not typically provided through traditional grant mechanisms. NCI determines that the monetary prize is often secondary to the community�s interest to participate in an activity where they can find access to high quality data and the opportunity to benchmark their tools compared to other participants.</td>
<td>The total prize purse offered was $25,000 and the total amount awarded was $25,000. NVIDIA Foundation provided the cash prize. Additionally, Nature Publishing supported submission of overview paper and insights that emerge from the Challenge.</td>
<td>NCI solicited submissions through emails and speaking presentations at scientific meetings.</td>
<td>Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td> N/A</td>
<td>Submissions were evaluated and peer reviewed based on the algorithmic performance comparing training data to test data sets.</td>
<td>504 participants were involved in submissions between June 26 and November 20, 2017. Three prizes were awarded to researchers from the University of Michigan and Korea University.</td>
<td>NCI staff worked closely with our scientific partners and a Challenge contractor to develop the scientific scope and requirements of the Challenge. NCI provided $250,000 in FY18 funding to manage the organization and logistics of the new Challenge.</td>
<td>The Defense Advanced Research Projects Agency (DARPA) contributed its SIMPLEX suite of scientific discovery tools. The NVIDIA Foundation provided the cash prize. NCI also partnered with Google, IBM, DREAM Challenges, and Nature Publishing.</td>
<td>NCI leads, conducts, and supports cancer research across the nation to advance scientific knowledge and help all people live longer, healthier lives. This crowdsourced Challenge highlighted the use of computational tools in cancer research to extract new information from the cancer proteome and to understand the association between the genome, transcriptome, and proteome in tumors to better efforts that improve cancer prevention, detection, diagnosis, and survivorship.</td>
<td>Software and apps; Analytics, visualizations, algorithms; Scientific</td>
<td>N/A</td>
</tr>
<tr>
<td>PROSTATEx Challenge</td>
<td>NIH, NCI</td>
<td>NCI considers the use of challenges and prize competitions within its statutory authority as a means to fulfill the Institute�s purpose.</td>
<td>This competition was completed in FY17.</td>
<td>The overall goal of the two PROSTATEx challenges (termed PROSTATEx I and II) was to promote development of medical image analysis algorithms for clinical decision support in diagnosis and staging of prostate cancer. The goal of PROSTATEx I was to determine the presence of cancer in each subject based in quantitative image analysis of multi-parametric magnetic resonance imaging (MRI) data. The goal of PROSTATEx II was to use multi-parametric MRI data to determine Gleason Grade Group in prostate cancer.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>The use of incentivized challenge competitions allows agencies to cast a wide net to find innovative solutions through crowd- sourcing and open science. Furthermore, participants in a challenge agree to benchmark performance of their software tools against a common reference dataset. Such approaches are not typically provided through traditional grant mechanisms. NCI determined that the monetary prize is often secondary to the community�s interest to participate in an activity where they can find access to high quality data and the opportunity to benchmark their tools compared to other participants.</td>
<td>PROSTATEx challenges offered non-cash prizes only. The top two teams received waived registration fees to attend SPIE 2017 or American Association of Physicists in Medicine (AAPM) 2017 annual conferences to present results. Both registration fee waivers were provided by the SPIE and AAPM.</td>
<td>NCI collaborated with SPIE and AAPM to announce the challenges through their communication channels, including their respective websites, press release, and listserv emails to society members. These methods were effective to get a critical mass of participants involved with each challenge. However, this was only the second time offering prize competitions for SPIE, and the first time for AAPM. Both societies are planning to offer challenges in the coming years. Given the general emerging interest in data science, machine learning, and artificial intelligence (AI), we expect that participation in the future will increase. One factor that is of prime importance in offering a challenge, in conjunction with the annual meeting of a scientific society, is the timing of the opening and closing of the challenge and announcement of the winners, who need enough time to plan their travel to the meeting.</td>
<td>Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Special sessions at scientific meetings (SPIE Medical Imaging and AAPM) to highlight the challenge and facilitate presentations by the winners</td>
<td> N/A</td>
<td>Submissions were evaluated through against the ground truth and summarized as an index. The ground truth was provided by clinical experts who are familiar with the disease and the data.</td>
<td>Entries for PROSTATEx I were submitted between November 21, 2016 and January 15, 2017. Entries for PROSTATEx II were submitted between May 15 and June 23, 2017.</td>
<td>The NCI Program Director devoted 5% time to guide the development of the Challenge design and implementation. Outside collaborators from academia contributed similar services. Datasets available through the Cancer Imaging Archive (CIA) were used in training and test phases of the Challenge. An existing challenge platform was used for submission of results and ranking of participants based on a set of evaluation metrics. The challenge platform was utilized under a blanket contract between the platform operator and NCI Center for Biomedical Informatics and Information Technology.</td>
<td>NCI partnered with the Food and Drug Administration, SPIE, AAPM, Harvard University, University of Michigan, and Radboud University to develop, advertise, and complete the Challenge. The estimated values of the waived registration fees provided by AAPM and SPIE is estimated at $300-1,000 per person.</td>
<td>The NCI mission includes dissemination of information on cancer detection, diagnosis, and treatment, and support for innovative solutions to the cancer problem. PROSTATEx challenges, performed in collaboration with non-profit entities (scientific societies and universities) leverages existing shared datasets to drive algorithmic excellence and incentivize development of innovative analytic software methods in cancer detection, diagnosis, and staging, using such datasets.</td>
<td>Software and apps; Ideas; Analytics, visualizations, algorithms; Scientific</td>
<td>A great amount of high quality cancer data (imaging, pathology, genomics, proteomics, and clinical) are generated through NCI-funded grants and cooperative agreements. Often these constitute what is referred to as big data. Solvers in the community, who are typically graduate students or research fellows with innovative ideas usually lack access to such data. Challenges provide a great way to develop tasks related to existing data that are aimed to bring innovative approaches, such as AI, to solve long standing problems, or facilitate more accurate solutions toward clinical decision support. NCI plans to utilize new datasets (imaging and other types) to launch new challenges in 2019 and 2020. These include challenges related to pancreatic and brain cancers, two of the deadliest cancers.</td>
</tr>
<tr>
<td>The U.S. Coast Guard Ready for Rescue Challenge</td>
<td>United States Coast Guard, Research and Development Center</td>
<td>Procurement Authority</td>
<td>This competition was launched in FY18.</td>
<td>The United States Coast Guard�s Research and Development Center (USCG RDC) in conjunction with the DHS Science and Technology Directorate (DHS S&amp;T) is seeking new solution based concepts that help make it easier to find and rescue people lost in the water. The best concepts will be effective, affordable, and hold the potential for wide adoption by recreational mariners. The competition will involve four phases: (I) Identify possible solutions; (II) Incentivize the development of working prototypes; (III) Assess the efficacy of the working prototypes to enable USCG search and rescue operations; (IV) Provide additional non-monetary support to encourage commercialization of the solutions.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public</td>
<td>The USCG is seeking a wide breadth of potential solutions and prototypes for testing in FY19. A wide variety of potential technologies and approaches will provide the best opportunity for success and eventual adoption of an improved inherent person-in-the-water (PIW) detectability standard. Using other authorities will result in a limited pool of solutions and likely be more expensive to produce and acquire by public boaters and mariners. Prizes and challenges also affords the opportunity for an innovator to have access to government and private sector mentors, limited user evaluation of their prototype, and assistance in commercializing their concept.</td>
<td>The total prize purse available for offer is $255,000, to be awarded across three phases. The purse for Phase I is $25,000 (five awards at $5000 each), the purse for Phase II is $120,000 (up to seven awards), and the Purse for Phase III is $110,000 (up to five awards). Non-monetary incentives include the ability to work with USCG RDC maritime subject matter experts and boating industry mentors in the development of ideas into products. The DHS Science &amp; Technology Directorate is helping to develop a path for Phase III winners to work with an accelerator or business to further develop and commercialize their prototype. Funding for Phase I is provided by DHS S&amp;T R&amp;D funds while funding for Phases II and III is provided by USCG RDC R&amp;D funds.</td>
<td>Phase I solicited the submission of ideas that have a high expectation for commercialization, affordability, and adoption by the boating and maritime community. Phase II will require selected Phase I winners and honorable mentions to present their concept and pathway for prototype development to a review panel. Successful participants will be provided incremental prize award milestones to assist in the development of their prototype. Phase II participants will be invited to participate in a Phase III challenge that evaluates their prototype with USCG search and rescue assets. Phase III participants will compete for a bonus prize purse of $110,000.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Conference promotional activities, outreach with accelerator networks</td>
<td>The contest seeks the following skill sets: Public Safety, Maritime Safety, Recreational Sports, Consumer Goods and Materials, Wearables, Textiles, Smart Technologies, and Internet of Things.</td>
<td>Submissions will be assessed by a diverse panel of judges from the government and the private sector against five criteria: (1) Effectiveness. The extent to which the solution demonstrates potential to improve detectability of PIW by search and rescue teams using existing Coast Guard search methods. Improved detectability is measured by the degree to which a reduced search time and/or success rate of search and rescue missions may be increased by the proposed solution. (2) Accessibility. The potential to be purchased and/or utilized by a broad set of recreational mariners (boaters, kayakers, Jet Ski, paddle craft, etc.). There are minimal companion purchases and is cost-effective from the consumer perspective (potential to be sold at a low, mass-market price point in the range of $25 to $35 if manufactured at scale). (3) User experience. The likelihood that the proposed solution would be utilized by recreational mariners on the water (boaters, kayakers, jet ski, paddle craft, etc.). The extent to which the solution addresses common barriers to use that limit existing solutions, such as comfort, convenience, or awareness. (4) Feasibility. The extent to which the proposed solution is viable and can be reasonably developed into a prototype within a nine-month period, with the potential to be manufactured at scale. (5) Team. The extent to which the entrant�s team demonstrates the appropriate level of experience, commitment, and ability to move from concept to prototype. If entrant is an individual, the level of experience, commitment, and ability to prototype to include access to non-team member assets and capabilities.</td>
<td>The competition is ongoing with entries for Phase I submitted by participants between September 5 and October 15, 2018.</td>
<td>In FY17, agency personnel supporting challenge included .25 FTEs. In FY18, agency personnel supporting the program included 0.6 FTE (DHS Prize Office and General Counsel: 0.1 FTE; USCG RDC: 0.5 FTEs). Greater clarity is needed to distinguish whether this amount includes the prize money total from Phase I or not.</td>
<td>In addition to partnering with the DHS Science and Technology Directorate, the competition sought judges and mentors from the private sector to include marine safety equipment manufacturers, distributors, designers, etc. The estimated value of partner contributions is $175,000.</td>
<td>One of the most challenging aspects of maritime search and rescue is finding a person in the water (PIW) because a PIW is often indistinguishable from the surrounding environment. In order to find people in the water more effectively and save more lives, a PIW�s inherent detectability must be increased. Examples include color/light for conspicuity, electronic/heat signatures, form factors, and personal floatation devices. Effective PIW detectability enhancements must be suitable for use with USCG sensors and methods. There have been incremental improvements  to UCSG rescue methods over time as technology advanced. Recently the USCG has upgraded sensors on aviation and surface assets; however, PIW detectability standards have lagged. The desired outcome of this challenge is effective concepts that increase conspicuity of a PIW and will likely be used by the public. A successful design, prototype and execution will make possible transition to market that will be low cost and easily adapted by the boating public. Results of this challenge may become part of an improved inherent PIW detectability standard.</td>
<td>Ideas; Technology demonstration and hardware; Analytics, visualizations, algorithms</td>
<td>In FY19, three competitions are in planning and one in early stage exploration for execution in 2019. Crosscutting mission areas include: chemical-biological defense, opioid detection in bulk mail, search and rescue, and emergency preparedness. Planned competitions include the development or enhancement of a new technology, opportunities for entrepreneurs to develop and market new technologies, and an educational game to better prepare the public. Additional cross-cutting areas include first responder technologies. In FY20, cross-cutting areas that may be considered by DHS include: critical infrastructure technologies, first responder technologies, cyber defense applications, chemical-biological detection technologies, algorithms, sensors, and screening technologies.</td>
</tr>
<tr>
<td>Diplomacy Lab</td>
<td>State, Secretary�s Office of Global Partnerships (S/GP)</td>
<td>State Department Basic Authorities Act of 1956</td>
<td>This competition was underway in both FY17 and FY18, but has not concluded.</td>
<td>Students participating in Diplomacy Lab explore real-world challenges identified by DOS and work under the guidance of faculty members who are authorities in their fields. This initiative allows students to contribute directly to the policymaking process while helping State tap into an underutilized reservoir of intellectual capital. Teams that develop exceptional results and ideas are recognized for their work and may be invited to brief senior State officials on their findings.</td>
<td>Improve government service delivery; Engage new people and communities</td>
<td>N/A</td>
<td>This Challenge provided university partners with real-world experience and State with free research and recruiting opportunities.</td>
<td>State provided participating universities with a list of proposed projects. Partner universities then identify faculty members to lead teams of students in Diplomacy Lab projects. Over the course of a semester, professors guide students in developing a final work product that accomplishes the goals outlined by State. Students have opportunities throughout the semester to discuss their research with State officials. Diplomacy Lab member institutions may bid on project proposals developed by State six months prior to each semester during the bidding window. Each university is encouraged to submit bids for its top four priority projects. It is also highly recommended that each university choose four alternate projects with an individual proposal in the event a particular project is over-subscribed</td>
<td>Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Diplomacy Lab is open to students and faculty at vetted and approved partner universities in the United States.</td>
<td>N/A</td>
<td>N/A</td>
<td>This Challenge utilized one FTE in both FY17 and FY18.</td>
<td>Partner universities are vetted and approved according to 2 FAM 970. Partner universities provide research to projects proposed by State offices and embassies worldwide. Non-Federal partners have included College of William and Mary, Florida International University, Georgetown University, Georgia Institute of Technology, Gettysburg College, Hunter College, Indiana University Bloomington, Indiana University � Purdue University Indianapolis, John Jay College of Criminal Justice, Miami University, Missouri University of Science and Technology, Montana State University, Stevens Institute of Technology, Stockton University, Syracuse University, Tufts University, University of California San Diego, University of Oklahoma, University of Kansas, University of New Mexico, University of Notre Dame, University of Pittsburgh, University of Tennessee, University of Virginia, University of Washington, Virginia Tech, Wilbur Wright College, Yale University, Oberlin College, and Columbia University.</td>
<td>Diplomacy Lab is designed to address two priorities: (1) State�s determination to engage the American people in the work of diplomacy; and (2) the imperative to broaden State�s research base in response to a proliferation of complex global challenges.</td>
<td>Ideas;  Other - Research</td>
<td>Diplomacy Lab will continue to operate as it has during the past two fiscal years, with an aim to grow its partner network to expand the geographic and academic diversity of research provided.</td>
</tr>
<tr>
<td>Almaty Mini Maker Faire�Pitching Challenge</td>
<td>U.S. Embassy Astana</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was launched and completed in FY18.</td>
<td>The goal of the competition was to identify ideas and projects with the potential to change social life related to science, technology, engineering and mathematics (STEM) education and ecological problems.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Engage new people and communities</td>
<td>Prizes were awarded to allow the winners to continue to work on the projects following the conclusion of the competition.</td>
<td>The total prize purse offered and awarded was $6,000. The prize came from the grant that was given to the local non-governmental organization.</td>
<td>The competition was announced on social media and monitored by an Information Assistant who collected all of the submitted applications. The judges selected the participants who would present their works during the Maker Faire, and those selected gave a presentation at the end of the event.</td>
<td>Social media (e.g., Twitter, Facebook); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Teams were required to pre-register for the competition by submitting a proposal, plan, and one minute video explaining the project.</td>
<td>On the day of the event, selected participants presented their projects in front of a panel of five judges and answered any follow-up questions.</td>
<td>Of the 12 participants who presented their solutions, three participants were each awarded a $2,000 prize.</td>
<td>Over five days, several people from the Public Affairs team worked to ensure the execution of the competition.</td>
<td>N/A</td>
<td>Almaty Mini Maker Faire promotes do-it-yourself activities, technology, innovation, science, and STEM education, specifically focusing on how individuals can use technology to solve social problems.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware; Scientific</td>
<td>The Almaty Mini Maker faire was well attended by both participants and the media. The competition proved to be an effective means to incite discussion around novel solutions by relating social issues to STEM topics and encouraging physical solutions to real problems. This type of event will be repeated during the next 2 fiscal years.</td>
</tr>
<tr>
<td>Spelling Bee</td>
<td>U.S. Embassy Astana</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was launched and completed in FY18.</td>
<td>The purpose of this Challenge is to invite students to come to the Spelling Bee competition and support each country. Active fans would have been awarded.</td>
<td>Engage new people and communities; Build capacity</td>
<td>Because the event was organized on a Saturday and before that it was a public holiday, therefore we wanted to attract more people to come and support and learn more about AmericanSpace�s services.</td>
<td>Winners were awarded T-shirts.</td>
<td>N/A</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td> N/A</td>
<td>Evaluation was through observation of participants who came to support the Spelling Bee competition and how active they were.</td>
<td>Of the 20 participants, five prizes were awarded to five winners.</td>
<td>This Challenge utilized three to four hours of time of one FTE and $15 in funding.</td>
<td>N/A</td>
<td>This Challenge intended to advance State�s mission through promotion of the English language.</td>
<td>Creative (design &amp; multimedia); Ideas</td>
<td>The event was very successful and well-attended by students and was covered by media. This project will be continued in the future as it also covers other Central Asian countries.</td>
</tr>
<tr>
<td>World Tourism Day Quiz</td>
<td>U.S. Embassy Astana</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was launched and completed in FY18.</td>
<td>The prize competition was launched on World Tourism Day to promote and inspire tourism in the United States. Through Facebook, the participants were asked to identify which city or state a person would need to travel to in order to enjoy something special (e.g., �the best beef bbq� or �the highest mountain peak in America�). The competition also sought to promote and applaud the use of English language; the competition was administered in English and required some light research to find the answers to the quiz questions.</td>
<td>Inform and educate the public; Engage new people and communities; Stimulate a market; Other - Promote tourism in the United States of America</td>
<td>N/A</td>
<td>Non-monetary incentives included a United States Consulate General (USCG) Almaty branded notebook, bookmark, and pen. Three sets of prizes were awarded.</td>
<td>The quiz was announced on the USCG Almaty Facebook Page.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>Participants needed to access and read the USCG Almaty Facebook page.</td>
<td>The first five people to answer all four quiz questions correctly were identified as the winners. The winners were notified to pick up their prizes the next day at the American Space.</td>
<td>Of the seven entries submitted between September 27 and September 28, 2018, five winners were selected.</td>
<td>Funding for FY18 totaled $15 to supply the prize package. In addition, 0.5 FTE employees, one American Eligible Family Member employee and one Locally Employed staff member, supported the planning and launching stages of the competition.</td>
<td>N/A</td>
<td>Promoting and advancing the English language is a priority for both the U.S. Embassy Astana and the government of Kazakhstan. Through tourism, the competition provides an opportunity to expose our young, social media audience to American values and perspectives.</td>
<td>N/A</td>
<td>Over the next two fiscal years, the U.S. Embassy Astana will continue to promote the English language, Western ideas and values, and tourism between the United States and Almaty.</td>
</tr>
<tr>
<td>Impact Video Competition</td>
<td>U.S. Embassy Lilongwe</td>
<td>Foreign Assistance Act</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>USAID aims to clearly and effectively demonstrate the impact of its development programs. Through this contest, contestants submitted one to two-page pitches attempting to show how their programs had a positive impact on Malawi. Entries were judged largely upon their ability to show quantitative evidence of their impact. For the winners, USAID hired a professional video production team to make a short film about their project and its impact. USAID and the partners will both retain copies of these videos for communications/marketing purposes respectively.</td>
<td>Find and highlight innovative ideas; Inform and educate the public</td>
<td>While partners submit regular reports to USAID, sometimes these only include standard, required indicators which do not adequately capture impact. Through this competition, partners were incentivized to take a deeper look at their programs and show evidence of substantial impact at a broad level based on quantitative evidence. This way, partners did the investigation on their own. By doing so, USAID saved the costs of awarding a new contract to determine this information.</td>
<td>A video was produced for each of the three winning entries. The videos described their USAID and President�s Emergency Plan for AIDS Relief (PEPFAR) funded projects in Malawi. USAID uses the videos to communicate the effectiveness of its programming and to convey ideas and information to the American and global public around issues related to foreign policy, such as HIV, deforestation, and economic growth).</td>
<td>Announcement at a partners meeting; subsequent email to partners</td>
<td>Email (e.g., listservs); Day-long event(s) prior to the competition</td>
<td>Organizations had to be current USAID/Malawi partners implementing development projects to participate in this Challenge. To win, organizations had to show that their program made a positive impact on U.S. Government foreign policy goals.</td>
<td>Evaluators were internal to USAID. Evaluation criteria included evidence of quantitative impact, sustainability, and the degree to which the story was compelling based on making a difference in the lives of Malawians and achieving the goals of the U.S. Government in Malawi. It worked well because USAID applied the same criteria across all submissions.</td>
<td>Of the 30 entries submitted by 30 organizations between October 30, 2017 and December 8, 2017, three prizes were awarded.</td>
<td>Staff time was utilized to organize, judge, and communicate regarding the contest. This Challenge had travel costs for USAID staff to ground truth claims of impact and accompany the film company during filming. Staff time was used to work with the video production company to develop films in advance of filming (storyboarding etc.), and to review production company editing and final film production. This Challenge utilized approximately 1 FTE throughout FY17 and FY18 and about $63,000 in FY18 funding.</td>
<td>Partners, on a voluntary basis, submitted a one to two-page pitch for their story. Once USAID selected the winners, those partners used staff time to work with USAID staff to hone the story. Partners worked with USAID and film production company staff to produce the video. Non-Federal partners included Pact, Inc.; Tetra Tech; Baylor University; and Johns Hopkins University. Partner contributions are estimated at $2,000 and travel costs.</td>
<td>This Challenge advances agency mission by showing how USAID programs are fulfilling U.S. foreign policy goals.</td>
<td>Creative (design &amp; multimedia)</td>
<td>The mission may hold another contest in subsequent years, with similar anticipated costs, but those plans are not confirmed at the time of reporting.</td>
</tr>
<tr>
<td>�150 Years of Cooperation and Friendship� Logo Contest</td>
<td>U.S. Embassy Montevideo, Public Affairs</td>
<td>Fulbright-Hays Act</td>
<td>This competition was completed in FY17.</td>
<td>This Challenge intended to obtain an official logo to be used in all official communications during 2017 for the 150th anniversary of diplomatic relations between the U.S. and Uruguay, and encourage the community to engage with the celebrations and gain new followers as well.</td>
<td>Solve a specific problem; Engage new people and communities</td>
<td>The Prize was offered to engage with a wider audience and to have as many logos as possible and professionally done, as the selected logo was going to be used in all official Embassy communications.</td>
<td>The total prize purse offered and awarded was a Nikon Coolpix AW130 and Sandisk 16GB memory card, valued at $271. Non-monetary incentives included having the winning logo be used in all official communications during 2017, a certificate signed by the Ambassador, and getting mentioned and participating in the 150th anniversary celebrations.</td>
<td>Participants were asked to send their designs to the Embassy Webmaster email account.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>Challenge requirements included: (1) the Challenge was only open to Uruguayan citizens; (2) there was no age limit; (3) more than one design by participant was accepted; (4) logos must be done by participants and no property rights could be violated during the creative process; (5) participants agree to give the U.S. Embassy in Montevideo full authorization to use the context, platform, and product.</td>
<td>After the closing date, all logos were printed and displayed in a conference room where Embassy staff was invited to vote for their preferred submission. The voting process ended with five finalists that were presented to the front office. The final decision was made considering not only the logo itself, but the different applications for which it was needed, including size, proportions, and use in both full-color and black-and-white applications.</td>
<td>Of the 182 entries submitted by 134 participants between February 27, 2017 and March 16, 2017, one prize was awarded to one winner.</td>
<td>Budget and resources were utilized to create contest regulations and graphics, promotion on social media, posting on the website and procurement of the waterproof digital camera. Additionally, budget and resources included collecting all submitted logos, presenting them to the jury, carrying out the selection, and announcing the winning logo and designer. Costs included three hours of time on behalf of the webmaster $59.47; three hours for the audiovisual tech assistant $35.56; camera supplier (i.e., vendor) $271.00; Facebook promotion $100.00. The Challenge also utilized $371 in FY17 funding and six FTEs.</td>
<td>N/A</td>
<td>DOS celebrated the long history of friendship and cooperation between the United States and Uruguay by inviting the members of the Uruguayan public to design a logo to recognize the 150-year anniversary of bilateral relations between both countries. This initiative was intended to improve the Mission�s image and popularity within the local community. Within the Mission, all employees, both American and local staff, were encouraged to work together to pick the winning logo as an activity which contributes to the development of a better working environment.</td>
<td>Creative (design &amp; multimedia); Ideas</td>
<td>N/A</td>
</tr>
<tr>
<td>#MEthroughUSeyes</td>
<td>U.S. Embassy Podgorica</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was launched and completed in FY18.</td>
<td>The contest objective was to show how American citizens spend their time in Montenegro and what are the most beautiful places in Montenegro according to people from the USA, thus showcasing that appreciating nature is a shared value.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>N/A</td>
<td>Non-monetary incentives included 10 branded bags containing U.S. Embassy�s branded materials.</td>
<td>Participants were asked to post their own picture of Montenegro landmarks on the Embassy�s social media properties.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>Contestants must have been at least 13 years old on the date of entry into the contest. Contestants must have been U.S. citizens or lawful permanent residents.</td>
<td>At the end of the submission period, the Public Affairs team evaluated the photos and selected favorites.</td>
<td>Of the 120 entries submitted by 50 participants between May 5, 2017 and May 25, 2017, 10 prizes were awarded to 10 winners.</td>
<td>The prize was a branded bag containing U.S. Embassy branded materials, including a t-shirt, an umbrella, a notebook, a pen, a pin, and a mug with American symbols. Best photos were exhibited at the American Corner - Podgorica. One staff member worked on the contest organization, execution and promotion for a total of five work days in FY18.</td>
<td>N/A</td>
<td>The contest served to advance U.S.-Montenegro partnership and highlighted the Montenegrin public support of the United States and its values and policies.</td>
<td>Other - Sharing a photo</td>
<td>N/A</td>
</tr>
<tr>
<td>#OscarsME2018</td>
<td>U.S. Embassy Podgorica</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was launched and completed in FY18.</td>
<td>Embassy Podgorica used the Academy Awards to engage and expand its social media following with the goal of increasing support for U.S. values.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>N/A</td>
<td>Winners received an invitation to the U.S. Embassy reception celebrating American film and the Academy Awards with Ambassador Uyehara.</td>
<td>Participants were asked to fill in a Google form by following a link from Embassy social media properties.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>Contestants must have been at least 18 years old on the date of entry into the contest. Contestants must have been residents of Montenegro and not U.S. citizens or lawful permanent residents.</td>
<td>Winners were randomly selected at the end of the polling period.</td>
<td>Of the 400 entries submitted by 250 participants between February 5, 2018 and February 26, 2018, five prizes were awarded to five winners.</td>
<td>One staff member worked on the contest organization, execution and promotion for a total of five work days in FY18. This Challenge required no additional financial resources.</td>
<td>N/A</td>
<td>The contest served to advance the Montenegrin public�s support of the United States and its values and policies. This program focused on educating the Montenegrin public about cultural events in the United States and related American values.</td>
<td>Other - Participating in a quiz</td>
<td>N/A</td>
</tr>
<tr>
<td>#USElections2016 - Official Trivia Contest Rules</td>
<td>U.S. Embassy Podgorica</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was completed in FY17.</td>
<td>As U.S. Presidential Elections were getting closer, DOS wanted to engage with social media followers and share knowledge about election rules, procedures, and trivia. DOS aimed to promote good democratic practices and explain to followers the historic developments that led to these practices. Sharing U.S. election stories and experiences would not only familiarize the audience with the U.S. electoral system, but let them think about what is similar in their country and what could be improved. The overall objective was not only to raise awareness about the 2016 elections, but to promote the value and the power of young people�s participation in process of choosing state representatives and decision makers.</td>
<td>Inform and educate the public</td>
<td>N/A</td>
<td>Winners received invitations to the Election Breakfast event and met with the Ambassador.</td>
<td>Participants were asked to fill in a Google form, and link answers to the Embassy social media properties.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>Contestants must have been at least 16 years old on the date of entry into the contest. Contestants must have been residents of Montenegro and not U.S. citizens or lawful permanent residents.</td>
<td>One winner was selected at random every day during the contest.</td>
<td>Of the 450 entries submitted by 450 participants between October 21, 2016 and October 31, 2016, 10 prizes were awarded to 10 winners.</td>
<td>One staff member worked on the contest organization, execution and promotion for total of 5 work days in FY17. This Challenge required no additional financial resources.</td>
<td>N/A</td>
<td>The contest served to advance the Montenegrin public�s support of the United States and its values and policies. This program focused on educating the Montenegrin public about the electoral process in the United States.</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>GIFT O�CLOCK 2016 - #MEholidaysWithUS</td>
<td>U.S. Embassy Podgorica</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was completed in FY17.</td>
<td>The goal of this contest was to expand the reach of the Embassy�s social media following by showcasing American holiday traditions.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>Prizes were used as an incentive to encourage participation and contribute to the goal of expanding social media following.</td>
<td>Each winner was awarded a branded bag containing U.S. Embassy�s branded materials, including a t-shirt, umbrella, notebook, pen, pin, and mug with American symbols.</td>
<td>Participants were asked to post a picture of their holiday decorations on the Embassy�s social media properties.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>Contestants must have been at least 13 years old on the date of entry into the contest. Contestants must have been residents of Montenegro and not U.S. citizens or lawful permanent residents.</td>
<td>One winner was selected randomly every day during the contest.</td>
<td>Of the 30 entries submitted by 50 participants between December 12 and December 22, 2016, 10 prizes were awarded to 10 winners.</td>
<td>One staff member worked on the contest organization, execution and promotion for a total of five work days in FY17.</td>
<td>N/A</td>
<td>The contest served to advance the Montenegrin public�s support of the United States and its values and policies.</td>
<td>Other - Sharing a photo</td>
<td>N/A</td>
</tr>
<tr>
<td>Montenegrin Summer in the States #USalumniMNE</td>
<td>U.S. Embassy Podgorica</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was underway in FY18.</td>
<td>This contest aims to strengthen people-to-people ties between the United States and Montenegro and provide a forum for current and past Montenegrin participants in the Summer Work Travel program to share their experiences through photographs.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>N/A</td>
<td>Each winner will be awarded with a branded bag containing U.S. Embassy�s branded materials, including a t-shirt, umbrella, notebook, pen, pin, and mug with American symbols, and an invitation to an Embassy reception. Thirteen branded bags containing U.S. Embassy branded materials and 13 invitations were awarded.</td>
<td>Participants were asked to post a picture of their experiences in the United States on the Embassy�s social media pages.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>Contestants must have been at least 18 years old on the date of entry into the contest. Contestants must have been Montenegrin citizens or lawful permanent residents.</td>
<td>At the end of the submission period, the Public Affairs team selected the best photos. Authors of the winning photos were contacted via direct message.</td>
<td>Of the 231 entries submitted by 70 participants between August 1 and September 10, 2018, 13 prizes were awarded to 13 winners.</td>
<td>Beyond the prizes, this Challenge required no additional financial resources. One staff member worked on the contest organization, execution, and promotion for a total of five work days</td>
<td>N/A</td>
<td>The contest served to advance the Montenegrin public�s support of the United States, and its values, and policies.</td>
<td>Other - Sharing a photo</td>
<td>N/A</td>
</tr>
<tr>
<td>Tis the season 2017 - #MEholidaysWithUS</td>
<td>U.S. Embassy Podgorica</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was launched and completed in FY18.</td>
<td>The goal of this contest was to expand the reach of the Embassy�s social media and showcase American holiday traditions.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>Prizes were used as an incentive to encourage participation and contribute to the goal of expanding social media following.</td>
<td>Each winner was awarded a branded bag containing U.S. Embassy�s branded materials, including a t-shirt, umbrella, notebook, pen, pin, and mug with American symbols. Five branded bags containing U.S. Embassy�s branded materials were awarded.</td>
<td>Participants were asked to post a picture of their holiday decorations on the Embassy�s social media properties.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>Contestants must have been at least 13 years old on the date of entry into the contest. Contestants must have been residents of Montenegro and not U.S. citizens or lawful permanent residents.</td>
<td>Public Affairs evaluated the submissions internally and selected winners.</td>
<td>Of the 45 entries submitted by 50 participants between December 13 and December 26, 2017, five prizes were awarded to five winners.</td>
<td>Beyond the prizes, this Challenge required no additional financial resources. One staff member worked on the contest organization, execution, and promotion for a total of five work days in FY18.</td>
<td>N/A</td>
<td>The contest served to advance the Montenegrin public�s support of the United States, and its values and policies.</td>
<td>Other - Sharing a photo</td>
<td>N/A</td>
</tr>
<tr>
<td>U.S. Embassy Podgorica: Give Away #1</td>
<td>U.S. Embassy Podgorica</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was launched and completed in FY18.</td>
<td>The contest objective was to share symbols of the United States across social networks and increase the number of followers of the Embassy�s Instagram account.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>Prizes were used as an incentive to encourage participation and contribute to the goal of expanding social media following.</td>
<td>The winner was awarded a branded bag containing U.S. Embassy�s branded materials including a t-shirt, notebook, pen, pin, and mug with American symbols.</td>
<td>Participants were invited to tag a friend.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>Participation was open to citizens of Montenegro of all ages, who reside in Montenegro. Each user could enter only one comment to qualify.</td>
<td>The winner was selected by a raffle.</td>
<td>Of the 68 entries submitted by 120 participants between July 30 and August 1, 2018, one prize were awarded to one winner.</td>
<td>Beyond the prize, this Challenge required no additional financial resources. One staff member worked on the contest organization, execution, and promotion for a total of two work days in FY18.</td>
<td>N/A</td>
<td>The contest served to advance the Montenegrin public�s support of the United States, and its values and policies.</td>
<td>Other - Tagging a friend</td>
<td>N/A</td>
</tr>
<tr>
<td>U.S. Embassy Podgorica: Give Away #2</td>
<td>U.S. Embassy Podgorica</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was launched and completed in FY18.</td>
<td>The objective of the contest was to increase the Embassy�s social media following, particular on its new Instagram account.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>Prizes were used as an incentive to encourage participation and contribute to the goal of expanding social media following.</td>
<td>The winner was awarded a branded bag containing U.S. Embassy�s branded materials.</td>
<td>Participants were invited to tag a friend.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>Participation was open to citizens of Montenegro of all ages, who reside in Montenegro. Each user might have entered only one comment to qualify.</td>
<td>The winner was selected by a raffle.</td>
<td>Of the 64 entries submitted by 89 participants between August 23 and August 25, 2018, one prize were awarded to one winner.</td>
<td>Beyond the prize, this Challenge required no additional financial resources. One staff member worked on the contest organization, execution, and promotion for a total of two work days in FY18.</td>
<td>N/A</td>
<td>The contest served to advance the Montenegrin public�s support of the United States, and its values and policies.</td>
<td>Other - Tagging a friend</td>
<td>N/A</td>
</tr>
<tr>
<td>U.S. Embassy Podgorica: Give Away #3</td>
<td>U.S. Embassy Podgorica</td>
<td>The United States Information and Education and Exchange Act of 1948, as amended (P.L. 80-402; 22 U.S.C. � 1431 et seq.), a.k.a. the Smith-Mundt Act</td>
<td>This competition was launched and completed in FY18.</td>
<td>The contest objective was to share symbols of the United States across the social networks and increase the number of followers of the Embassy�s Instagram account.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>Prizes were used as an incentive to encourage participation and contribute to the goal of expanding social media following.</td>
<td>A winner was awarded with a branded bag and a pair of U.S. Embassy�s branded headphones.</td>
<td>Participants were invited to tag a friend.</td>
<td>Social media (e.g., Twitter, Facebook)</td>
<td>The Challenge was open to citizens of Montenegro of all ages, who reside in Montenegro. Each user was restricted to one entry.</td>
<td>The winner was selected by a raffle.</td>
<td>Of the 36 entries submitted by 50 participants between October 12 and October 17, 2018, one prize were awarded to one winner.</td>
<td>Beyond the prize, this Challenge required no additional financial resources. One staff member worked on the contest organization, execution, and promotion for a total of two work days in FY18.</td>
<td>N/A</td>
<td>The contest served to advance the Montenegrin public�s support of the United States, and its values and policies.</td>
<td>Other - Tagging a friend</td>
<td>N/A</td>
</tr>
<tr>
<td>PseudoVet</td>
<td>VA</td>
<td>Space Act/Procurement Authority</td>
<td>This competition was launched in FY17 and FY18, and was completed in FY18.</td>
<td>Through this challenge, the VA sought the development of PseudoVet 1.0, a publically available, automated patient data fabrication engine that provides a set of active synthetic patients for healthcare software development and application testing. The target was to generate and perform continuous updates of mock provider, clinic, and scheduling entries to a subset of as many as 10,000 fabricated patients representing various clinical diagnoses based on template data.</td>
<td>Solve a specific problem; Develop technology</td>
<td>The VA was interested in crowd-sourcing the development of PseudoVet for a variety of reasons including the desire to broaden participation by Veterans in the gig economy to solve pressing problems for the VA. In this way we ensured development of a product for Veterans by Veterans. Few mechanisms aside from Prize competitions allow for this type of sourcing from citizens with talent and great ideas.</td>
<td>The total prize purse offered was $95,000 and the total amount awarded was $167,000. Non-monetary incentives included recognition via TopCoder and VA.</td>
<td>Solicitation was conducted by TopCoder on their platform. This solicitation specifically targeted the TopCoder community of solvers. Although VA pushed other solvers to the TopCoder platform, the agency relied heavily on this vendor�s existing community. A more aggressive communications push by VA would have likely led to a greater diversity of solvers beyond just the TopCoder community.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release</td>
<td>The target solver base for this challenge was those possessing deep development expertise. This challenge was highly complex and narrow in the type of solver skillset that would be required. Because of this, the VA did not limit eligibility exclusively to United States citizens.</td>
<td>The overall project was split into several individual challenges. Submissions were evaluated on a number of factors including: code quality, performance, requirements met, and documentation.</td>
<td>Of the 542 entries submitted between August 8, 2017 and February 1, 2018, 75 prizes were awarded.</td>
<td>The VA contracted with TopCoder to administer this prize competition and to disburse funds to winners. The total budget was $500,000. The National Aeronautics and Space Administration (NASA) received an approximate 8% servicing fee through the interagency agreement. The remaining $442,152 was budgeted as follows over both fiscal years: $167,000 for prizes and $277,152 for administration costs to TopCoder. In FY17, the funding total was $177,152, and 0.25 FTEs were used. In FY18, the funding total was $267,000, and 0.25 FTEs were used.</td>
<td>N/A</td>
<td>Electronic health record systems sometimes require realistic patient data in order to facilitate development, testing, and training. While it is possible to obfuscate patient data from production systems, this is risky and involves a large effort to ensure no real patient data are accidently exposed. The alternative is to secure the environments as production, but this often needlessly complicates development, testing, and training. Pseudovet was developed to create realistic, but fake patient data. This data can be used in non-production environments to facilitate development, testing, and training. If one of these systems were to be exploited or improperly accessed, the data contained would have no impact on real individuals.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>VA Gun Safety Matters Challenge</td>
<td>VA</td>
<td>Space Act/Procurement Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>NineSigma, representing the U.S. Department of Veterans Affairs, sought novel and effective approaches that offer enhanced gun safety mechanisms to prevent suicide, injury, and accidents. Specifically, the VA sought cost-effective options for a tangible device or system to be used voluntarily by a veteran or trusted friend or family member. The device or system was required to allow for 100% voluntary control (implementation, suspension, decommissioning) by the veteran. The goal was to provide safe firearm storage within or outside the home. Approaches were sought that addressed emotional distress or crisis, especially for those individuals who may not have a secondary support system such as family members or friends nearby, or who do not have the means for storing their guns safely.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Inform and educate the public; Engage new people and communities</td>
<td>Suicide prevention has been a top priority for years. Resources have been allocated to research, clinical intervention, and innovation. Much is known now about suicide decedents and the fact that the majority of veterans dying by suicide use a gun/firearm to do so needed to be addressed. The VA was interested in trying a new approach of crowd-sourcing to addressing some of the challenges facing the agency.</td>
<td>The total prize purse offered and awarded was $60,000. The first place award was $30,000, the second place award was $20,000, and the third place award was $10,000. Non-monetary incentives included access to VA resources, such as subject matter experts, for any potential follow-on design and development; recognition across VA media streams to highlight the winning concepts/design; and a communications push via NineSigma media streams.</td>
<td>Largely, the internet and social media were used to solicit submissions. The company contracted to administer the challenge, Ninesigma, Inc., also used email to solicit submissions. Overall, the judges anticipated more than the 40 submissions received, so one lesson learned is to request a more robust marketing plan in the future.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Webinar</td>
<td>Companies of all sizes, consultants, venture capitalists, entrepreneurs, or inventors were invited to respond to this request. Citizens or permanent residents of the US and its territories were eligible to participate. Responses were solicited via the online response form and included the following: (1) A description of the proposed approach, including a discussion of any technical aspects that enable an effective prevention mechanism for the use of a gun in a suicide attempt; (2) Any data or evidence to show or support the effectiveness of the approach in its current capability; (3) Availability of samples, prototypes, or demonstration of proposed technology; (4) Supporting data to show fit to stated criteria for the approach; and (5) Experience of the submitter or submission team in the proposed technology field.</td>
<td>A team of subject matter experts across the Department of Veterans Affairs was compiled. Among the panel of judges, who reviewed the submissions and rated each based on a series of questions directly from the challenge criteria, were both civilian and veteran employees. In the future, one lesson learned is to provide a timeline to the judges so that they know what to expect. Winners were selected after compiling the scores of all judges.</td>
<td>Of the 40 entries submitted between September 19, 2017 and January 8, 2018, three prizes were awarded.</td>
<td>A total of $135,000 was spent on this open innovation prize challenge. Three Department of Veterans Affairs subject matter experts worked together along with NASA staff in the entire process. There was no specific FTE allocated to this project, but in both FY17 and FY18 0.1 FTEs were used.</td>
<td>N/A</td>
<td>Suicide prevention has been among the top priorities for the Department of Veterans Affairs for several years. An average of twenty veterans die by suicide each day. In 2014, roughly 67% of all Veteran deaths by suicide were the result of firearm injuries. Statistics for that year also show that about 65% of all veterans who die by suicide are age 50 or older. Compared to their age-matched civilian peers, both male and female veterans have an increased risk for suicide. Research suggests that most suicidal crises pass within minutes to hours, and that building in time and space between a suicidal impulse and access to a gun reduces suicide deaths. In response, the VA Challenge Team was given the authority to seek solutions through an Innovation Challenge. The Gun Safety Challenge invited proposals for solutions that offer new options for enhanced safe gun storage to prevent suicide, injury, and accidents.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware</td>
<td>The VA Office of Mental Health and Suicide Prevention may pursue prize competition(s) again although there is no specific plan to at this time.</td>
</tr>
<tr>
<td>Veterans Online Memorial Challenge</td>
<td>VA</td>
<td>Space Act/Procurement Authority</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The online memorial will enable remembering, celebrating, and commemorating those buried at VA national cemeteries. This capability will allow remote participation in the grieving process, and extended celebration of veterans� lives, and can also serve a social memorialization function for students, researchers, and genealogists.</td>
<td>Improve government service delivery; Solve a specific problem; Develop technology</td>
<td>The purpose of this website is to provide an enhanced memorialization experience using user/public-driven content. Tapping the public to develop a tool that is both used and curated by the public seemed like a logical approach. Additionally, several of the micro-competition rounds of this challenge specifically engaged veteran solvers. As a result, this form of crowd-sourcing created an incentive structure that enabled meaningful contribution by veterans to develop a solution for veterans and their loved ones.</td>
<td>The total prize purse offered was $197,373 and the total amount awarded was $169,043. Non-monetary incentives included recognition in the TopCoder newsletter.</td>
<td>The VA relied primarily on HeroX and TopCoder to generate communications out to their robust solver communities. VA also released a blog post about the challenge and pushed information via the agency�s innovation social media streams.</td>
<td>Social media (e.g., Twitter, Facebook); Press release</td>
<td>For the HeroX ideation challenge, the VA was seeking ideas to help frame the ideal online memorialization platform and experience. Participation and eligibility was according to HeroX platform rules and guidance. For the TopCoder-assisted challenges, the VA also relied on the existing eligibility, rules, and requirements.</td>
<td>The VA team performed incremental reviews of wireframes, user interfaces, and final prototypes. VA reviewers conducted reviews and selections of winners across the stages of the challenge.</td>
<td>Of the 76 entries submitted by 563 participants between September 27, 2017 and June 30, 2018, prizes were awarded to 22 winners.</td>
<td>The overall budget was $500,000. Of this, the NASA Center of Excellence for Collaborative Innovation received a service fee of approximately 8% ($40,000). The amount awarded as prizes to winners was $169,043. The administration cost for this challenge was $290,000 to the prize vendor, TopCoder. This prize competition lasted approximately nine months from beginning (planning) to close-out and required approximately 1.25 FTEs over the life-cycle of the challenge.</td>
<td>N/A</td>
<td>Currently, 77 of VA National Cemetery Administration�s (NCA) national cemeteries are closed to burial, and that number will increase over time. NCA, in its commitment to memorialize Veterans in perpetuity, seeks to make available the stories of service and sacrifice of Veterans of all periods.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>Smart City Air Challenge</td>
<td>EPA</td>
<td>Clean Air Act Amendments, Section 103</td>
<td>This competition was launched in FY17 and is underway in FY18.</td>
<td>EPA needs to be ready to deal with the tremendous amount of data that will be produced from inexpensive air quality sensors. The main purpose of the Challenge is to learn how communities will manage large volumes of environmental data, yield a set of best practices for doing so, and encourage communities to share their practices with each other. A secondary purpose is to help people be more aware of air quality levels in their community.</td>
<td>Find and highlight innovative ideas; Engage new people and communities; Stimulate a market</td>
<td>Inexpensive sensors are not ready for regulatory use, but they are developing rapidly. EPA needs to be ready to deal with the tremendous amount of data they will provide. EPA can learn how communities manage the data from collecting it, to storing it, to making it available to the public. The Challenge provided EPA with real-world lessons about data management that could not have been learned using other approaches.</td>
<td>Of a total prize purse of $100,000, $80,000 has been awarded.</td>
<td>EPA used a website to describe the Challenge and posted frequent updates there. EPA reached out to potential applicants using social media, email, and webinars. Social media were particularly effective, especially EPA�s social media accounts, which were picked up by influential parties. Email and listservs were effective at engaging existing communities of interest. Webinars were useful in providing details and answering questions in real time about the challenge itself and about communities that had implemented similar projects. Finally, EPA reached out to journals and encouraged them to describe the Challenge to their readers.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Other - Webinars</td>
<td>The target audience was communities that could deploy hundreds of air quality sensors. Any group could enter as long as it included a U.S. local governmental party as a partner and all members of the team were over 15 years old. EPA defined community as anything from neighborhoods to counties to tribes. Applicants were not allowed to be a Federal entity or Federal employee acting within the scope of their employment. Employees of EPA, and/or any other individual or entity associated with the development, evaluation, or administration of the Challenge as well as members of such persons� immediate families (spouses, children, siblings, parents), and persons living in the same household as such persons, whether or not related, were not eligible to participate in the Challenge. Constraints included (1) the ability to deploy 250 to 500 sensors in a community; (2) community involvement in purchasing and using the sensors; (3) identification of partners and project sustainability; and (4) transparency in terms of making the data open and describing the data management plans.</td>
<td>EPA evaluated the submissions based on four criteria: data management, data use, sensor procurement and deployment, and project sustainability. The Challenge used judges who were knowledgeable in the fields of data management and air quality measurement. Judges included subject matter experts from the Office of Air and Radiation, the Office of Environmental Information, and the Office of Research and Development. Submissions were screened to determine if they met the constraints. If so, judges evaluated them based on the four criteria. Judges were trained so they could evaluate the submissions in a similar fashion on a scale of 1 to 10 for each criterion. The fifteen judges were divided into three groups of five judges that had a similar mix of types of expertise. Each group of judges evaluated five submissions. Then all of the judges reviewed the highest rated submissions. Finally the judges conferred and agreed about the best two submissions and the four honorable mentions.</td>
<td>Of the 22 entries submitted by over 100 participants between August 30 and October 28, 2016, two winners plus four honorable mentions were awarded.</td>
<td>Third-party vendors provided assistance with communications materials and planning the judging process. EPA staff tracked their activities and coordinated with the EPA project officer. In FY17, the competition was allocated $15,000 and 0.2 FTE; in FY18, no additional funding and only 0.05 FTE was used. Cash prize funds were provided in FY16 using a Miscellaneous Obligation Document (MOD). The funds were contributed by EPA�s Office of Air and Radiation and EPA�s Office of Environmental Information in the amount of $50,000 each. Such funds can be distributed once the MOD has been approved and do not have restrictions for distribution during a specific fiscal year.</td>
<td>N/A</td>
<td>The mission of EPA is to protect human health and the environment. The prize competition advanced the mission by learning how communities collect and use air quality data to understand local environmental conditions. This information will be used by individuals or agencies to protect themselves or the environment.</td>
<td>Other - Project plans</td>
<td>EPA plans to use what is learned how to help manage data that is collected and used at the local level.</td>
</tr>
<tr>
<td>Tox Test Challenge Stage II</td>
<td>EPA</td>
<td>Toxic Substances Control Act (TSCA)</td>
<td>This competition was completed in FY17.</td>
<td>Scientists from EPA, the National Center for Advancing Translational Sciences (NCATS), and the National Institute of Environmental Health Sciences� (NIEHS) National Toxicology Program (NTP) are using high speed, automated screening technologies called high-throughput screening (HTS) assays to rapidly test whether thousands of commonly used chemicals may affect human health. However, since current HTS assays do not fully incorporate chemical metabolism, they can miss chemicals that are metabolized to a more toxic form. In January 2016, EPA launched stage I of the Transform Toxicity Testing Challenge along with their partners, NCATS and the NIEHS NTP. The Transform Toxicity Challenge asked teams to develop prototypes that retrofit existing HTS assays to incorporate processes that reflect how chemicals are broken down and metabolized by the body. After selecting semi-finalists in May 2017, the EPA and its partners selected the Transform Toxicity Challenge Stage II winners.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Build capacity; Stimulate a market</td>
<td>The prize/challenge approach enabled the agency to reach scientists from multiple disciplines that may offer new and creative strategies to address the problem. The prize approach provided the agency with the opportunity to review multiple solutions and only make the award if one of the solutions met the criteria.</td>
<td>The total prize purse offered was $500,000, distributed in $100,000 awards to five winners. Non-monetary incentives included rigorous prototype testing, evaluation, and feedback on technology performance. Participants also received recognition and publicity and took part in peer networking.</td>
<td>Solicitation strategies for the Challenge included tweets from the EPA twitter account, emails to relevant listservs, and official EPA press releases. Partner organizations also promoted the Challenge using similar strategies.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td> N/A</td>
<td>A panel of five judges was convened to evaluated the prototypes against the requirements identified in the challenge. Rigorous testing was conducted. The judging panel made recommendations to EPA management who made the final selection.</td>
<td>Of the nine entries submitted by nine participants between January 30 and August 31, 2017 for phase two of this Challenge, five prizes were awarded to five winners.</td>
<td>Resources from EPA and partner organizations included scientists and technical staff as well as communication and administrative support. Contractor support was used to develop and host a website and provide communication support. In FY17, the challenge budget was $500,000 and required less than one FTE.</td>
<td>Federal partners included the NIH NCATS, and NIH�s NTP within the NIEHS.</td>
<td>EPA�s mission is to protect human health and to safeguard the natural environment. This Challenge helps to advance the agency�s mission by accelerating the market and incentivizing the development of technology and algorithms that will help to more accurately and effectively screen chemicals for toxicity.</td>
<td>Technology demonstration and hardware; Scientific</td>
<td>Plans for next steps are in discussion.</td>
</tr>
<tr>
<td>Wildland Fire Sensors Challenge</td>
<td>EPA</td>
<td>Clean Air Act, Section 103, 42 USC 7403</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>This Challenge addresses the need to advance air measurement technology used in wildland fire situations to provide more accurate information about smoke levels to state and local organizations so that citizens and first responders can minimize their exposure. The technical goal was to make air measurement technology in wildland fire situations easier to deploy, suitable for use in high concentration events, durable to withstand difficult field conditions, and able to report data continuously and wirelessly. Desired measurements were to include fine particles (PM2.5), ozone, carbon monoxide, and carbon dioxide.</td>
<td>Improve government service delivery; Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>A challenge/prize approach enabled us to reach technology developers from around the world and from disciplines who normally would not be focused on EPA research opportunities but could bring creative new approaches to the problem. In addition, the prize approach would create more excitement and visibility and be less bureaucratic than traditional contracting or grant mechanisms. Involvement of six Federal agencies also signaled that this is a priority for technology development. Using technologies that are already in development, a challenge had the potential to provide a wide range of solutions more cost effectively than was likely in-house or through a contract. A prize approach also provided an easy way to collaborate with multiple Federal agencies, now and in the future. Lastly, a competition provided a reasonably low-risk process because the agency only had to award prize funds if the challenge succeeded.</td>
<td>The total prize purse offered was $60,000, with $35,000 awarded to the first prize winner and $25,000 awarded to the second prize winner. Non-monetary incentives included rigorous testing, evaluation and feedback on technology performance. Winners were announced at a conference where they could receive recognition from peers, the public, and media.</td>
<td>A contractor was retained to share the Challenge with the international solver community. The Challenge announcement was posted on Challenge.gov. Federal partners amplified the announcement through social media, webinars, newsletters, list serves, flyers, announcements at professional meetings, etc.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Informational webinars</td>
<td>The target solver audience included engineers, technology developers, sensor developers, environmental scientists, computer scientists, telemetry experts, etc.</td>
<td>For the first stage, EPA technical staff reviewed the written submissions and identified those that addressed the challenge criteria. These were asked to submit prototypes. Not all did so. To evaluate the submissions that were received, EPA technical staff worked with technical colleagues in other agencies to agree on testing procedures. Rigorous technology testing was carried out at EPA and U.S. Forest Service laboratories. Using the agreed-upon criteria, an interagency judging panel, with participation from a non-Federal partner, Tall Timbers Research Station, reviewed the results of the testing, met by conference call, received a briefing on the results and evaluated the data based on the requirements in the Challenge. They made recommendations for challenge winners and an honorable mention. Finally, senior managers within EPA�s Office of Research and Development reviewed the recommendations and made the final decisions.</td>
<td>Twenty-seven preliminary submissions were received by November 22, 2017, and ten prototypes by January 5, 2018. Two prizes and one honorable mention prizes were awarded.</td>
<td>In FY17, $16,000 was provided for contractor support for communication and outreach and $25,000 was allocated for the award.  In FY18, $35,000 was spent for the award.  Less than one FTE was used in FY17, but 1.5 FTE was needed in FY18. Communications and administrative support involved preparing the communications plan, written materials, FAQs, press release, and social media for both the launch and announcement of the winners as well as development of a video to describe the challenge and the winners. Federal partners collaborated on the challenge design, technical review, testing, and judging involved review of written submissions, conducting laboratory testing of prototypes, and a multi-agency panel that met to review all of the results and develop recommendations for awards.</td>
<td>Federal Partners included the U.S. Forest Service, National Aeronautics and Space Administration, National Oceanic and Atmospheric Administration, Centers for Disease Control and Prevention, and National Park Service. The non-Federal partner was Tall Timbers Research Station. Partners provided technical expertise in challenge development and judging and monetary support for laboratory testing. In-kind support was provided for use of testing facilities and staff time for testing, marketing, outreach, and communications. The estimated value of partner contributions amounted to $30,000 in direct contributions and $30,000 in in-kind support.</td>
<td>EPA&#39;s mission is to protect human health and to safeguard the natural environment. Wildland fires are increasing in intensity and duration. Communities are exposed to dangerous levels of air pollutants from smoke for weeks at a time. The very young, the elderly, those with respiratory or cardiovascular health conditions are particularly at risk. To enable communities to reduce dangerous smoke exposures, they need near real-time information about smoke conditions. With information about where smoke and pollutant concentrations are highest, people can plan their daily activities to avoid the worst exposures and protect their health as much as possible. This Challenge helped advance EPA�s mission to protect public health by developing the technologies needed to address this new, longer lasting environmental health threat.</td>
<td>Technology demonstration and hardware</td>
<td>N/A</td>
</tr>
<tr>
<td>3D-Printed Habitat Challenge (Phases 2&amp;3)</td>
<td>NASA</td>
<td>51 USC � 20144</td>
<td>This competition was launched in FY17 and is currently underway in FY18.</td>
<td>The 3D-Printed Habitat Challenge seeks to develop housing solutions for extended duration missions on planetary surfaces (particularly on Mars) using advanced additive construction technology. This technology will use indigenous materials, mission recyclables, and the capabilities of 3D-printing to achieve efficient and sustainable building materials and construction. These developments will be applicable both to the fulfillment of the Mars mission and to the creation of cheaper and more sustainable housing solutions on Earth.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>3D-printing technology is maturing quickly, and there are inventors and entrepreneurs who are investing money to develop systems that can construct large structures the size of a house for potential profit or service in an emergency situation. The purpose of this competition is to see how NASA can push the technology and harness it for space exploration. A prize competition brings in experts from outside the space industry and ideas that are outside-the-box to engage the public in space exploration activities.</td>
<td>In FY17, the total prize purse offered was $1,100,000 and the total amount awarded was $701,000. For Phase 2 level 1, $100,000 was available, and a total of $100,000 was awarded to two teams; for Phase 2 level 2, $500,000 was available, and a total of $201,000 was awarded to four teams; and for Phase 2 level 3, $500,000 was available, and a total of $400,000 was awarded to two teams. In FY18, $100,000 was available for Phase 3 level 1 and a total of $100,000 was awarded to five teams. For Phase 3 level 2, $400,000 is available, and a total of $120,000 was awarded to three teams. Phase 3 continues into FY19 with additional prize purse available.</td>
<td>Public announcement of the Challenge was made on the FedBizOps website. For Phase 2, the Challenge was announced at Maker Faire in New York. Phase 3 was opened at the Building Information Modeling (BIM) Forum Conference in Dallas, Texas, in November 2017. Centennial Challenges has exhibited the Challenge at the American Concrete Institute (ACI) Conventions in Detroit and Los Angeles and also at the World of Concrete in Dallas. A website that is produced by Bradley University specifically for administering the Challenge is promoted in many correspondences and public press releases. The NASA Centennial Challenges Program and NASA Solve social media accounts (Facebook, Twitter, and Instagram) are used to bring attention to activities or videos to attract competitors and for general awareness.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The target solver audience is inventors, entrepreneurs, designers, architects, makers, and the construction industry. All U.S. citizens and foreign nationals are welcome to participate in the Challenge except for four countries currently on the designated country list that support terrorism. Only U.S. citizens are eligible to win prize money.</td>
<td>A lead judge was selected from one of the sponsors to bring expertise from the construction industry. In selecting judges, experts with a good mix of experience with both space and terrestrial projects were sought. The submissions were evaluated strictly according to rules and rubrics established prior to the competition�s start. Wherever possible, objective guidelines were established to help judges make evaluations.</td>
<td>For Phase 2, entries from seven teams were received for level 1, seven for level 2, and three for level 3 by October 06, 2017; total participation for Phase 2 was ~100 people. Two prizes were awarded for level 1 on March 31, 2017; six prizes were awarded for level 2 on May 31, 2017; and two prizes were awarded for level 3 on August 25, 2017. For Phase 3, which will conclude in May 2019, entries from 18 teams were received for level 1 and three for level 2 by November 07, 2017; total participation was 178 people. Five prizes were awarded for level 1 on May 16, 2018 and three prizes were awarded for level 2 on July 11, 2018.</td>
<td>Funding for the 3D-Printed Habitat Challenge in both FY17 and FY18 was $319,000. In FY17 and FY18, 1.4 FTEs were needed for the competition to provide subject matter experts from NASA who participated in the development of the rules, judging, and guidance of the allied organization (Bradley University) to direct the competition toward the correct technology that can make an impact for space exploration. Procurement and travel funds were utilized to help promote the competition to the communities that were most capable of advancing the technology and to conduct workshops to plan for the Challenge and invigorate challenge teams.</td>
<td>Bradley University is the allied organization conducting the 3D-Printed Habitat Challenge with support from sponsors Caterpillar, Bechtel, and Brick &amp; Mortar Ventures. Bradley University executes the competition and ensures that the outcomes meet the overall goals of NASA and the Centennial Challenges Program. Caterpillar, as a major sponsor of the Challenge, facilitates all coordination activities of the Challenge and provides facilities for the major head-to-head competition at the Edwards Facility near Peoria, Illinois. Construction Engineering Research Lab (CERL) of the U.S. Army Corps of Engineers has provided expert guidance under a Memorandum of Agreement for rules development and judging. The total value of Bradley University &amp; sponsors (Caterpillar, Bechtel, and Brick &amp; Mortar Ventures) contribution for 2017 was $747,000 and approximately $1,000,000 for 2018.</td>
<td>Advancements in 3D-Printing (i.e., additive manufacturing) will provide benefits to future NASA missions and may enable new mission scenarios. Using indigenous and recyclable material on a lunar or Mars mission will reduce overall payload requirements and reduce the risk for astronauts, making space exploration missions possible.</td>
<td>Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware; Scientific; Other - Space Exploration</td>
<td>The 3D-Printed Habitat Challenge Phase 3 is planned to run thru May 2019. The final level of the competition will be the autonomous 1:3 Sub-Scale Habitat at the Caterpillar Edwards Facility where eight teams will be invited to compete. NASA will evaluate whether to open a Phase 4 that would involve construction of the full-scale habitat.</td>
</tr>
<tr>
<td>Breakthrough, Innovative, and Game-Changing (BIG) Idea Challenge</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>The BIG Idea Challenge provides for the free flow of information, ideas, and concepts between NASA�s Game Changing Development (GCD) program and the university research, education, and industry communities, and achieves the following secondary objectives: (1) opportunities to inexpensively tap university talent on important challenges facing GCD with potential to more quickly advance technology readiness levels; (2) potentially introduce concepts into future NASA research and program planning; (3) provide opportunity for NASA GCD engineers to interact with faculty and students as well as explore workforce pipeline opportunities; (4) provide a real-world challenge for the aerospace industry and other stakeholders that results in the development of a highly talented future workforce pool; (5) demonstrate and leverage university-NASA GCD-industry cooperation; and, (6) provide students with the opportunity to develop highly transferable skills in collaboration, communication, and critical thinking, as well as the opportunity to engage in teamwork activities, which are relevant and highly desired skills for future NASA GCDP employees.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Engage new people and communities; Build capacity; Other - Educational outreach and engagement</td>
<td>This initiative uses a challenge/competition format but does not award monetary prizes. For a STEM education outreach effort, this format is useful because this initiative is designed to align with academic studies in multi-disciplines related to NASA�s mission and to foster exciting innovation and sharing of ideas from the best and the brightest students in the United States. By design, this program ties in with academic calendars and lends itself to become focal projects in senior capstone courses, student clubs, and graduate student studies within university environments.</td>
<td>No prize money is offered as part of this Challenge. Non-monetary incentives include opportunity to work on real-world, NASA-based research; expert feedback from judges; public recognition; tour of a NASA facility; opportunity to present in front of subject-matter expert judges; NASA internship opportunities offered to winning team to further advance promising designs.</td>
<td>The FY17 and FY18 BIG Idea Challenges were promoted using a robust email campaign targeting ~3,000 faculty with specified interest in aerospace engineering. Emails targeted directly to university professors have proven to be very effective, and we see a significant correlation between website visits and email distributions. The Challenge was also announced through NASA�s Education Express and Science Wow! to ~31,000 subscribers and ~90,000 NASA Education Twitter Followers. The Challenge was posted on the NASA Solve website and on the Institute for Broadening Participation�s Pathways to Science page. Additionally, an informational flyer was created and distributed to the National Institute of Aerospace�s (NIA) network of previous participants in other challenges to explain the challenge details and constraints. Press releases were issued by NASA for both the FY17 and FY18 Challenges. A website for the challenge is maintained and updated for each year�s challenge.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release</td>
<td>The BIG Idea Challenge is open to teams of three to five undergraduate and graduate students studying in fields applicable to human space exploration (i.e., aerospace, electrical, and mechanical engineering; and life, physical, and computer sciences). Eligibility is limited to students from accredited universities in the United States. Foreign universities are not eligible to participate in the BIG Idea Challenge.</td>
<td>Participating teams for the FY17 and FY18 BIG Idea Challenges were selected as finalists by a panel of judges using an evaluation rubric. Judges for the FY17 challenge were all from NASA while the FY18 challenge was a hybrid of government and external (industry) reviewers. In FY17, the criteria were: (1) feasibility of proposed concept or idea, including low system mass, design simplicity, and ground testability (40 percent); (2) innovative, unique and/or synergistic advanced concepts, modularity, and concept of operations for robotic assembly, module deployment and replacement, and extensibility (30 percent); (3) systems analysis of requirements, including identification of challenges and issues including Technical Readiness Level of mission-enabling technologies (20 percent); (4) evidence of credible and implementable project plan (5 percent); and (5) concept is supported by original engineering and analysis (5 percent). In FY18, the criteria were: (1) feasibility of proposed design, including low system mass, design simplicity, Mars environmental resiliency, and Earth ground testability (40 percent); (2) innovation of proposed ConOps for unattended installation/deployment and sustained, long-term power generation in the Martian environment (30 percent); (3) adequacy of proposed engineering analysis to support structural design and power output predictions (20 percent); (4) ability to fabricate an affordable proof-of-concept experimental prototype that addresses the key design and operational challenges (10 percent)</td>
<td>In FY17, 29 submissions were received from five teams. In FY18, 16 submissions were received from five teams. Winners were announced on November 30, 2016 and November 30, 2017, respectively.</td>
<td>The administrative cost for the BIG Idea Challenge activity was $110,980 in FY17 and $125,316 in FY18. These costs were for NIA program management and other direct costs including but not limited to university stipends provided to participating universities through their respective Office of Sponsored Programs to enable the teams to participate in the culminating NASA Forum/Design Review. Additional costs for FY17 included $80,000 for NASA internships awarded through the Challenge ($70,000 for internships and $10,000 for materials to build BIG Idea prototypes). Additional costs for FY18 included $70,000 for NASA internships ($60,000 for internships and $10,000 for materials to build BIG idea prototypes).</td>
<td>Through a cooperative agreement with NASA Langley Research Center, the NIA provides day-to-day administration of the BIG Idea Challenge for NASA. Their certified program managers, program coordinators, and meeting planners provided a robust marketing plan, extensive contact lists, in-kind challenge website hosting, graphics support, submission management, and event planning for the culminating Forum. Involving industry (Space Systems Loral) on the judging panel added value to the competition and opened additional avenues for future internships/jobs for the students.</td>
<td>The BIG Idea Challenge engages the university community with NASA�s GCD program efforts to rapidly mature innovative/high impact capabilities and technologies for infusion in a broad array of future NASA missions. It links academic institutes with the NASA Space Technology Mission Directorate, in which the GCD program resides, and multidisciplinary university teams are asked to provide innovative solutions to current GCD projects. Each year, the program theme is developed by one of GCD�s Principal Technologists (PT) and is fashioned in a way that allows the academic community to be an active, productive, and contributing part of the PT�s work at NASA.</td>
<td>Ideas; Analytics, visualizations, algorithms; Scientific</td>
<td>The FY19 BIG Idea theme currently seeks ideas from the academic community for the design and operation of a Mars Greenhouse that will complement the Mars Ice Home. Supplying reliable and effective food production systems on Mars will reduce the need to transport food from Earth and also promote crew health on long surface missions. A design review of the top five finalist teams will be conducted during the BIG Idea Forum in April 2019 at NASA Langley Research Center and features a robust panel of judges from NASA and industry.</td>
</tr>
<tr>
<td>CineSpace Film Competition</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This FY17 competition is complete, and the FY18 competition is underway.</td>
<td>The International Space Station (ISS) External Integration Office created a unique film competition inspired by the past, current, and future efforts of the United States and its global partners to expand human knowledge through the exploration of space. NASA and the Houston Cinema Arts Society (HCAS) offered filmmakers around the world a chance to share their works inspired by and using actual NASA imagery. The films of the finalists and winners were screened at the Houston Cinema Arts Festival in November of 2017 and 2018.</td>
<td>Inform and educate the public</td>
<td>Crowd-based challenges using a prize have been proven extremely effective for film development for use by NASA.</td>
<td>The total prize purse offered and awarded was $26,000. Non-monetary incentives included showing of the winning films during the HCAS Film Festival in Houston.</td>
<td>Tongal, the NASA Tournament Lab (NTL) vendor managing the Challenge, solicited submissions from its existing member community and the public through blog features, emails, and social media campaigns. Tongal promoted the Challenge heavily at the start and during the final month while maintaining consistent awareness throughout the campaign. Tongal reached out to its community and other film communities by posting to relevant websites and newsletter blasts.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Outreach by the vendor to existing platform members</td>
<td>Submissions from any restricted country list were not eligible to receive the award.</td>
<td>Judging was completed by the NASA/HCAS team.</td>
<td>In FY17, 689 entries were submitted by 646 participants. Five winners were announced November 11, 2017. In FY18, 242 entries were submitted by 222 participants. Five winners were announced November 13, 2018.</td>
<td>The full challenge budget ($56,000 in FY17 and $50,000 in FY18) was funded by the NASA ISS External Integration Office. The funds were disbursed to the vendor via the NASA Open Innovation Services contract. The vendor conducted the Challenge and awarded the prize money. Funds included prizes, vendor project management resources, and platform fees. NASA FTE/work year equivalent (WYE) resources (0.01 FTE and 0.02 WYE in both FY17 and FY18) supported challenge coordination activities including development of the Task Order Request for Proposal and award processes as well as oversight of challenge execution .</td>
<td>The HCAS participated in the evaluation of the submissions for selection as winners and provided the venue for showcasing the winning films.</td>
<td>This film competition supports NASA�s mission to expand human knowledge through the exploration of space as well as highlighting the significant amount of imagery available to the public from NASA�s repository.</td>
<td>Creative (design &amp; multimedia)</td>
<td>There is a plan to conduct this challenge for the next fiscal year.</td>
</tr>
<tr>
<td>Cube Quest Challenge</td>
<td>NASA</td>
<td>51 USC � 20144</td>
<td>This competition was underway in both FY17 and FY18, but has not concluded.</td>
<td>NASA�s Space Technology Mission Directorate (STMD)/Centennial Challenges program administers the Cube Quest Challenge to incentivize the advancement of CubeSat and nanosatellite capabilities to stimulate the small spacecraft market needed for conducting unique and more affordable science and explorations missions in deep space. The goal of the Challenge is to develop CubeSat technologies and missions with advanced capabilities needed for deep space operations and then to demonstrate their performance at the Moon (�Lunar Derby�) or beyond (�Deep Space Derby�).</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>The objective of the Challenge is to reward citizen inventors who successfully advance the CubeSat technologies needed for operations at the Moon and beyond, particularly long-distance communications, navigation beyond earth, and long-term survival. Our goal is to advance technologies and private industry for spacecraft whose small size and light weight will help NASA to explore and conduct science in deep space in novel, more affordable ways.</td>
<td>The total prize purse offered was $5,000,000. A set of eight challenge goals were set for the in-space competition that takes place after a competitor achieves lunar orbit (�Lunar Derby�) or a range of four million kilometers from Earth (�Deep Space Derby�). The total of all eight challenge goals comprises a prize purse of $4.5M. During a series of Ground Tournaments (GTs), $460,000 was awarded (GT-1: five prizes of $20,000 each were awarded in September 2015; GT-2: five prizes of $30,000 each were awarded in March 2016; GT-3: five prizes of $30,000 each were awarded in October 2016; and GT-4: three prizes of $20,000 each were awarded in June 2017). As a non-monetary incentive, each of the three winners of GT-4 were offered the opportunity to launch a 6U CubeSat via the Space Launch System as a secondary payload on NASA�s EM-1 mission.</td>
<td>Public announcement of the Challenge was announced in FedBizOps and to a small satellite mailing list maintained by the STMD Small Spacecraft Technology Program. An organizing summit, open public event was conducted with the purpose of announcing the Challenge and disseminating rules and answering questions. It was attended by more than 120 members of the interested public.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Live video streaming</td>
<td>The team leader had to be (i) a citizen or permanent resident of the United States, or (ii) an entity that is incorporated in and maintains a primary place of business in the United States. A competitor team was comprised of one or more team members. A team member could be an individual or an entity. If a team member was an individual, the individual had to be a citizen or permanent resident of the United States. If the team member was an entity, the entity must be a U.S. entity (i.e., incorporated in and maintains a primary place of business in the United States). Foreign nationals could only participate as either owners, employees, or students of an otherwise eligible U.S. entity. No team member could be a citizen of a country on the NASA Export Control Program list of designated countries. A Federal entity or Federal employee could not participate in the Challenge if acting within the scope of their employment. An entity employee, or entity, contracted by the US. Government and physically located at a federally owned facility could not participate if acting within the scope of the contract.</td>
<td>A panel of five judges was convened for each of the GT events. The judging panel comprised of three NASA subject matter experts, one expert from academia, and one expert retired from small spacecraft industry. Prior to each GT, judging instructions were updated and re-published. The goals and standards were raised as expectations for CubeSat design maturity increased at each successive milestone. Judges used a written set of detailed instructions for evaluating and scoring submittals according to a scaling system specified in the instructions. The scoring instructions were publicly available to competitors before each judged event. Judges also provided written, post-judging feedback summaries to teams after each judged event, for use by the teams to consider improvements before the next event.</td>
<td>Thirteen teams submitted 13 entries for GT-1, ten entries for GT-2, seven entries for GT-3, and five entries for GT-4.</td>
<td>The Challenge is part of NASA�s Centennial Challenges Program, which is part of NASA�s STMD. Challenge development, oversight, and prize purse were funded by NASA�s STMD. The FY17 FTE and procurement budget ($942,000 and three FTEs) was used for administration of the Challenge, enforcement of rules, and execution of GT-3 and GT-4. It included a prize award event at Ames Research Center including rental of facility for GT-4. The FY18 FTE and procurement budget ($761,000 and three FTEs) was used for administration of the Challenge, enforcement and updates of the rules, and preparations for the upcoming in-space competition scheduled for FY20-FY21.</td>
<td>N/A</td>
<td>Advancements in small spacecraft capabilities will provide benefits to future missions and may enable new mission scenarios, including future investigations of the Moon and near-Earth asteroids. If capabilities associated with larger spacecraft can be achieved in the smaller platform of CubeSats, a dramatic improvement in the affordability of space missions will result, greatly increasing science and research possibilities.</td>
<td>Technology demonstration and hardware</td>
<td>The Challenge continues in FY19 and FY20 with the in-space competition phase. In FY20, the top three CubeSat designs are scheduled to launch on NASA�s EM-1 mission. From the Moon or beyond, the CubeSat operating teams will compete for prizes by accomplishing any of a set of eight in-space competition goals. Other teams may choose to compete by obtaining their own launch to reach the Moon or beyond to compete in the in-space competition. The competition will end exactly 365 days after EM-1 launch (regardless of whether or when a team may have obtained their own launch), and prizes will be awarded after all accomplishments are judged at that time.</td>
</tr>
<tr>
<td>Future Engineers 3D Design Challenges</td>
<td>NASA</td>
<td>51 USC � 20113(e)</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>Through a series of Future Engineers 3D Space Challenges, students focused on solving real-world space exploration problems and submitted model designs for 3D printable objects for use by astronauts in space. In the Mars Medical Challenge, students were challenged to design an object that could be used by an astronaut to maintain physical health on a 3-year mission to Mars. Students submitted a digital 3D model intended to be 3D printed and used for a wide range of medical needs including diagnostic, preventative, first-aid, emergency, surgical, and/or dental purposes. In the Two for the Crew Challenge, students were challenged to create a tool that comingles the functions of two objects currently used by crew aboard the International Space Station. Students invented multi-use tools and customized equipment, including solutions used for maintenance, medical, trash management, and securing and storing items in microgravity.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Inform and educate the public</td>
<td>A challenge run through an agreement made with the American Society of Mechanical Engineers under the National Aeronautics and Space Act (a Space Act Agreement) provided NASA the opportunity to engage in a no-cost partnership arrangement to obtain solutions and to engage a broad range of student ideas from ages 5-19, thereby gaining out-of-discipline perspectives and a broad spectrum of possible solutions to NASA problems.</td>
<td>No cash prizes were offered. For the Two for the Crew Challenge, the teen winner had their design printed on the Made In Space 3D printer on the International Space Station (ISS) and got a trip to Washington D.C. for a VIP space experience, including participating in an ISS Downlink at the Smithsonian Air and Space Museum. The junior winner was awarded a trip to Washington D.C. for a VIP space experience, including participating in an ISS Downlink at the Smithsonian Air and Space Museum. Four finalists in each age group were awarded a Makerbot Replicator Mini+ donated to their school, library, or education organization. Sixteen semi-finalists in each age group were awarded a 3D printing-in-space prize pack. For the Mars Medical Challenge, the winner in each age group was awarded a trip to Houston, Texas and a tour of the NASA Johnson Space Center to learn about human exploration, space medicine, and the Journey to Mars. Four finalists in each age group were awarded a MakerBot Replicator Mini+ printer donated to their school, library or education organizations and a set of Giant Microbes plush cells. Sixteen semi-finalists in each age group were awarded a Mars-themed prize pack</td>
<td>The challenges were launched on the Future Engineers platform, an online education platform that hosts national innovation challenge for K-12 students. They have been extremely successful in engaging students and, as a result of the collaboration, received a Small Business Innovation Research award from the Department of Education to expand the platform to the in-school setting.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The 3D Space Challenge was open to eligible persons between the ages of 5-19 residing in the United States.</td>
<td>The competition is comprised of an open entry submission phase with two categories: junior engineers (ages 5-12) and teen engineers (ages 13-19). Submissions were initially judged to determine ten semifinalists and then culminated in a second round of judging to select four finalists followed by an interview round to select one winner in each age group. Submissions were judged using the following criteria: innovation and creativity of the solution (40%); quality of the 3D modeled geometry, and compliance with design guidelines (20%); usefulness of the design in a space environment (20%); ability to communicate the design through the text description, and finalist interview (20%).</td>
<td>The Mars Medical Challenge received 745 entries. A total of thirty prizes including semi-finalists, finalists, and winners were awarded. The Two for the Crew Challenge received 565 entries. A total of thirty-one prizes including semi-finalists, finalists, and winners were awarded.</td>
<td>NASA resources in both FY17 and FY18 were 0.25 FTE each.</td>
<td>The Challenge was conducted through a nonreimbursable agreement under the National Aeronautics and Space Act (the Space Act Agreement) with the American Society of Mechanical Engineers Foundation, which implemented the Challenge through the Future Engineers platform. The value of partner contributions was $400,000 in each fiscal year.</td>
<td>These challenges provide an opportunity for students to focus on real-world space exploration challenges and prepare our next generation of space explorers who will take the first step on Mars. The challenges also provide NASA with an opportunity to tap into the creativity and innovation of a new pool of solvers to obtain potential new designs for future space missions.</td>
<td>Creative (design &amp; multimedia); Technology demonstration and hardware</td>
<td>Continuation of challenges through a no-cost contract.</td>
</tr>
<tr>
<td>High Performance Fast Computing Architecture Challenge</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was cancelled in FY17.</td>
<td>NASA�s Aeronautics Research Mission Directorate (ARMD) sought an architectural analysis of the current processing configuration for the FUN3D software with recommendations on improving performance.</td>
<td>Solve a specific problem; Develop technology</td>
<td>The agency firmly supports the use of prize challenges to solve difficult problems and engage a broader community in agency activities.</td>
<td>The total prize purse offered was $35,000. The total amount awarded was $0 because the Challenge was cancelled.</td>
<td>As with all NASA Tournament Lab challenges, NASA worked with its vendor, Topcoder, to mobilize an international community specific to the Challenge, based on the curated community already existing for the particular vendor platform. For this Challenge, NASA chose to release its own web feature on the nasa.gov public website. Cancellation of the Challenge was also posted as a web feature.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Other - NASA web feature</td>
<td>Participation was limited to U.S. citizens only.</td>
<td>N/A</td>
<td>More than 1,800 people applied to receive a copy of the code base from both the ideation and architecture challenges. A total of 335 entries were submitted between May 03, 2017 and September 30, 2017, when the Challenge was cancelled.</td>
<td>The full challenge budget was funded by NASA�s ARMD. The funds were awarded to the crowdsourcing vendor TopCoder via the NASA Open Innovation Services (NOIS) contract. The awarded vendor received $107,000 of the originally awarded $141,500 for their effort in challenge design and launch prior to cancellation. NASA FTE/WYE resources (0.8 FTE and 0.1 WYE) supported the Challenge coordination activities needed prior to and up to the release of a NOIS task order as well as significant efforts involved in cancelling the Challenge.</td>
<td>N/A</td>
<td>This challenge was intended to support NASA�s aims to improve the performance and efficiency of aeronautical systems. NASA was seeking ideas for innovative architecture enhancements for the NASA FUN3D software while providing readily achievable benefits to the current ARMD program with minimal additional capital investment. However, the extremely high number of applicants, more than 1,800, coupled with the difficulty in satisfying the extensive vetting requirements to control the public distribution of the software made it unlikely the Challenge owner would achieve the Challenge�s original objectives in a timely manner. NASA looked at several alternatives to keep the challenge design intact like significantly extending the challenge performance period, and offering a much smaller portion of the code. None were considered viable options.</td>
<td>Software and apps; Ideas</td>
<td>N/A</td>
</tr>
<tr>
<td>High Performance Fast Computing Ideation Challenge</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was cancelled in FY17.</td>
<td>NASA�s Aeronautics Research Mission Directorate (ARMD) sought ideas to improve the performance of its existing FUN3D Computational Fluid Dynamics software to maximize innovation and decrease software execution time while providing readily achievable benefits to the current ARMD program.</td>
<td>Solve a specific problem; Develop technology</td>
<td>The agency firmly supports the use of prize challenges to solve difficult problems and engage a broader community in agency activities.</td>
<td>The total prize purse offered was $20,000. The total amount awarded was $0 because the Challenge was cancelled.</td>
<td>As with all NASA Tournament Lab challenges, NASA worked with its vendor, HeroX, to mobilize an international community specific to the Challenge, based on the curated community already existing for the particular vendor platform. For this Challenge, NASA chose to release its own web feature about the Challenge on the nasa.gov public website. Cancellation of the Challenge was also posted as a web feature.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Other - NASA web feature</td>
<td>Participation was limited to U.S. citizens only.</td>
<td>N/A</td>
<td>More than 1,800 people applied to receive a copy of the code base from both the ideation and architecture challenges. A total of 4,808 entries were submitted between May 03, 2017 and June 16, 2017, when the Challenge was canceled.</td>
<td>The full challenge budget was funded by NASA�s ARMD. The funds were awarded to the crowdsourcing vendor HeroX via the NASA Open Innovation Services (NOIS) contract. The vendor received $26,600 of the originally awarded $49,500 for their effort in challenge design and launch prior to cancelation. NASA FTE/WYE resources (0.8 FTE and 0.1 WYE) supported the challenge coordination activities needed prior to and up to the release of a NOIS task order as well as significant efforts involved in cancelling the Challenge.</td>
<td>N/A</td>
<td>This Challenge was intended to support NASA�s aims to improve the performance and efficiency of aeronautical systems. However, the extremely high number of applicants, more than 1,800, coupled with the difficulty in satisfying the extensive vetting requirements to control the public distribution of the software made it unlikely the challenge owner would achieve the challenge�s original objectives in a timely manner. NASA looked at several alternatives to keep the challenge design intact like significantly extending the challenge performance period, and offering a much smaller portion of the code. None were considered viable options.</td>
<td>Software and apps; Ideas</td>
<td>N/A</td>
</tr>
<tr>
<td>REALM User Interface Challenge</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was completed in FY17.</td>
<td>Radio-Frequency Identification (RFID)-Enabled Autonomous Logistics Management (REALM) is a system onboard the International Space Station (ISS) that uses RFID tags to locate and track various tools and inventory. The goal of this Challenge was to develop a software user interface for a complex event processing system using REALM to locate, track, and manage ISS inventory and tools as they are moved around the ISS. The solution for this Challenge was required to address all system user scenarios for the REALM system and the user application requirements.</td>
<td>Solve a specific problem</td>
<td>NASA�s Advanced Exploration Systems Logistics Reduction/RFID Auto Logistics Management Project needed a novel and cost-effective approach to harvest user interface designs that ensure a positive user experience for the ISS astronauts and mission controllers. The prize approach provided access to myriad solutions and met cost and schedule constraints.</td>
<td>The total prize purse offered and awarded was $11,025. Topcoder, the vendor, also offered participants the chance to gain Topcoder points toward attendance at its annual TopCoder Open event. The Open is Topcoder�s annual online and onsite tournament to celebrate and reward their community.</td>
<td>As with all NASA Tournament Lab challenges, NASA works with its vendor to mobilize an international community specific to the Challenge, often based on the curated community already existing for the vendor platform. NASA used the NASA Solve website (www.nasa.gov/solve), which lists NASA�s participatory opportunities, to market this Challenge.</td>
<td>Social media (e.g., Twitter, Facebook); Other - Outreach to vendor platform members; Other - NASA Solve website (www.nasa.gov/solve)</td>
<td>Winners were vetted to ensure they were not on any restricted country list and are, therefore, eligible to receive the award.</td>
<td>The user interface application submissions were evaluated against a number of technical and functional requirements including the ability to enable an on-demand search of the complex event processing (CEP) system to determine an item&#39;s location; ability to edit CEP scenarios of interest; ability to interface to a Unity 3D representation of the instrumented ISS modules to display location and location trajectories of item(s) queried; and enables on-demand searches for either a single or multiple items.</td>
<td>Of the 51 entries submitted by 129 participants between September 16, 2016 and December 02, 2016, nine prizes were awarded to nine winners.</td>
<td>The full challenge budget was funded by NASA�s Human Exploration and Operations Mission Directorate (Advanced Exploration Systems division). A total of $32,900 was awarded to the crowdsourcing vendor Topcoder via the NASA Open Innovation Services (NOIS) contract to execute the Challenge and fund the challenge purse. The awarded vendor conducted the Challenge and awarded the prize money per the task order. Fund allocations included prizes, vendor project management resources, and platform fees. NASA FTE/WYE resources (0.03 FTE and 0.1 WYE) supported the challenge coordination activities including the task order request for proposal development and award processes as well as oversight of challenge execution per the task order.</td>
<td>N/A</td>
<td>This Challenge supports NASA�s mission to work with industry to improve America�s aerospace technologies through the application of crowdsourcing as an innovative and cost-effective acquisition tool for solutions to specific operational needs. In this case, the solution contributed to the system that helps locate and manage the thousands of items and tools located on the ISS and helps to save the crew�s time locating critical items and resulting in valuable cost savings for the agency. The Topcoder community successfully designed a set of application wireframes (i.e., user interface prototypes) that met the technical and functional requirements defined in the task order. The user interface code was completed and delivered to NASA�s GitHub software repository at: https://github.com/NASA-Tournament-Lab/NTL-REALM-User-Interface.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>Human Exploration Rover Challenge</td>
<td>NASA</td>
<td>51 USC � 20113(e)</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>The Human Exploration Rover Challenge sought to (1) solicit ideas that stimulate innovation in a manner that has potential to advance NASA�s mission through collaboration with educational institutions and students; (2) contribute to solving tough problems related to NASA�s mission using challenges and prize competitions; (3) present high school and college students with a hands-on engineering design challenge that meets the foundation principles of NASA human exploration missions; (4) provide a team-based engineering project that emphasizes problem solving and the use of engineering systems and design processes; (5) meet the grades 9-12 national education standards and the college fields of study standards of science, technology, engineering, and mathematics (STEM).</td>
<td>Find and highlight innovative ideas; Inform and educate the public; Engage new people and communities</td>
<td>The nature of the activity and the age and experience level of this audience is not well suited to contracts, grants, and cooperative agreements. The teams engage in the Challenge to compete for corporate-sponsored prizes and bragging rights.</td>
<td>The total prize purse offered was $12,400 in 2017 and $12,900 in 2018. The total amount awarded was $12,400 in 2017 and $12,900 in 2018. Non-monetary incentives included participation and winner plaques and certificates. Cash prizes were provided by corporate sponsors through the U.S. Space &amp; Rocket Center Education Foundation. Non-cash prizes (i.e., plaques, trophies, banners, certificates) were provided by sponsors as well.</td>
<td>The Marshall Space Flight Center Public and Employee Communications media team produced and assisted with media advisories, news releases, web features, interviews, and stories for the center�s Marshall Star newsletter. In 2018, they focused on Facebook and Periscope. In only one day of competition, they received 192,212 views, just shy of 2017�s two day total of 204,190. In 2017, the Ustream broadcast was viewed 29,390 times.<br/>Coverage by 686 news stories received 59,596,488 views. The broadcast on Facebook Live was viewed 157,597 times with 4,953 engagements. The broadcast on Periscope (Twitter) was viewed 34,615 times with 72 engagements. Fifteen posts on the Rover Facebook page reached 376,004 and received 1,498 engagements. Twenty-three tweets on the Rover Twitter account reached 2,818,614 and received 547 engagements.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The competition targeted high school and college/university students. Each rover had to be the work of a student team from a high school or accredited institution of higher learning. The school or institution could enter up to two teams. A group of high schools could also collaborate in building a rover entry. An entity that promotes education, such as a museum, science center, planetarium, or youth-serving organization, could also enter up to two rover teams in each division. Teams could consist of up to six students.</td>
<td>In 2017, winning teams were determined based on run time and accumulated penalties. In 2018, teams had six minutes of �oxygen� to complete as many obstacles and tasks as possible. One minute of �reserve oxygen� was added, if necessary, for teams to journey back to home base. However, no additional points could be earned after six minutes or during the use of �reserve oxygen.� Teams returning to the home base within six minutes received bonus points. Teams arriving after seven minutes were not eligible for competition prizes. Participants could bypass many of the obstacles and tasks, but after six minutes they had to bypass all of them. Obstacles and tasks were assigned points based on difficulty. Teams were encouraged to implement a strategy based on the time remaining and the choices of obstacles or tasks to undertake. Additionally, points were given for meeting pre- and post-challenge requirements.</td>
<td>There were six hundred participants and 31 awarded prizes in both FY17 and FY18. In 2018, over 500 students comprising 88 teams from 22 states and Puerto Rico, along with nine international teams from Bangladesh, Bolivia, Brazil, Colombia, Germany, India, Lithuania, Mexico and Peru participated in the Challenge. Some prizes were awarded to both the winning high school and college teams. Other prizes were for a single category winner (i.e., either high school or college team).</td>
<td>NASA�s Human Exploration and Operations Mission Directorate provided funding for FTEs and WYEs ($196,000 and 0.4 FTE in both FY17 and FY18), web services, and logistics. Sponsor funding supported prizes.</td>
<td>The Challenge has evolved into a large community event. Partnerships have been formed with the Chamber of Commerce, the Huntsville/Madison County Convention and Visitor�s Bureau, and the U. S. Space &amp; Rocket Center. Corporate sponsors mainly provide monetary contributions. These include the Boeing Company, Lockheed Martin, Jacobs, Polaris, the American Institute of Aeronautics and Astronautics, Orbital ATK, Aerojet Rocketdyne, Davidson Technologies, Science Applications International Corporation, Teledyne Brown Engineering, Corporate Office Properties Trust, and the Tennessee Valley Chapter of the Systems Safety Society, Inc. Other corporate sponsors, such as Northrop Grumman Corporation and the National Space Club, contribute through in-kind support of trophies/plaques, tents, banners, and volunteers. The estimated value of partner contributions was $91,000 in 2017 and $94,700 in 2018.</td>
<td>This Challenge met multiple NASA Office of Education 2017 performance goals. The Challenge (1) assured that students participating in NASA higher education investments were representative of the diversity of the Nation. Of the more than 600 students who participated in the Human Exploration Rover Challenge, 197 were Hispanic, 71 were Black or African America, 10 were American Indian/Alaska Native, and 130 were Asian. Nine teams were from minority-serving institutions. The Challenge (2) continued to provide opportunities for learners to engage in STEM education through NASA-unique content provided to informal education institutions designed to inspire and educate the public. The Challenge, which was open to the public and was widely promoted in the media, was held at the U. S. Space &amp; Rocket Center, an Alabama state flagship museum and Smithsonian affiliate. And lastly, the Challenge (3) continued to provide opportunities for learners to participate in STEM education engagement activities that capitalize on NASA-unique assets and content.</td>
<td>Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware</td>
<td>In 2018, in an effort to better align with NASA�s mission, the competition moved away from being a timed race format to one driven by accomplishing mission objective tasks limited by a six-minute supply of �oxygen� with a one-minute reserve. The new format forced teams to make real-time decisions about which tasks to attempt and which to leave behind. Because the new requirements were substantially different from the past 24 years of the competition, no additional changes are planned for the next two years.</td>
</tr>
<tr>
<td>International Space Apps Challenge</td>
<td>NASA</td>
<td>51 USC � 20113(e)</td>
<td>This FY17 competition is complete, and the FY18 competition is underway.</td>
<td>The goal of the International Space Apps Challenge is to inspire communities of talented volunteers to use NASA data to solve some of the most exciting problems in space science and technology, to foster engagement in STEM topics with emphasis on Earth and space science and exploration, and to help improve the quality of life on Earth.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity</td>
<td>Space Apps is a free and open hackathon, and in the hackathon ecosystem, prizes are the prevailing award for participation.</td>
<td>There was no cash award prize offered for this Challenge. Non-monetary incentives included recognition of winning solutions and an invitation for winners to attend a launch event or tour of Kennedy Space Center at their own expense.</td>
<td>Space Apps is advertised through the spaceappschallenge.org website, and through social media, using #SpaceApps and @SpaceApps. Submissions occur at the end of hackathon weekend, via the spaceappschallenge.org website.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Anyone is welcome to register and participate in the Challenge. Participation is fully voluntary. Children under the age of 13 should be registered and accompanied at all times by a parent or legal guardian.</td>
<td>Submissions were evaluated by NASA civil servants and NASA contractors only.</td>
<td>More than 2000 entries were submitted by more than 25,000 participants.</td>
<td>Funding ($850,000 and 3.25 FTEs in FY17; $975,000 and 5.25 FTEs in FY18) supports contract staff who manage the event and website, create materials for use at local events, and serve as the interface with participants worldwide.</td>
<td>Local host organizations and their sponsors in several dozen locations around the world provided facilities and publicity for Space Apps in their respective locations.</td>
<td>Space Apps advances the Agency�s mission to drive advances in science, technology, aeronautics, and space exploration to enhance knowledge, education, innovation, economic vitality, and stewardship of Earth.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas; Technology demonstration and hardware; Analytics, visualizations, algorithms; Scientific</td>
<td>Space Apps in FY19 and FY20 will be closely aligned with and similar to Space Apps in FY17 and FY18. Based on past experience, the number of participants is expected to grow.</td>
</tr>
<tr>
<td>RASC-AL Special Edition: Mars Ice Challenge</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>To provide students with the opportunity to design and build prototypes that can extract water from simulated Martian subsurface ice testing environments. Currently the NASA in situ resource utilization (ISRU) community has focused on extracting water from hydrated Mars regolith, but recent discoveries of what are thought to be large ice deposits just under the surface on Mars have mission planners re-thinking how a sustained human presence on Mars could be enabled by a water rich environment. This Challenge is intended to cultivate innovative thinking from university students on a task that NASA has spent very little resources on, yet may be the true enabler of Earth independence on Mars.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Build capacity</td>
<td>This initiative does not use monetary prizes but does use a challenge/competition format. This format is useful because this initiative is intended to align with academic studies in multi-disciplines related to NASA�s mission for undergraduate and graduate students, and to foster exciting innovation and sharing of ideas from the best and the brightest students in the United States with NASA, the university community, and the space exploration industry. NASA technical and research programs directly benefit by tapping new approaches to space exploration, and students benefit by applying their academic knowledge to real-world problems and active engagement with NASA, industry experts and their peers.</td>
<td>There was no cash award prize offered for this Challenge. Non-monetary incentives included the opportunity to work on real-world, ISRU research for NASA that is among the first of its kind; expert feedback from subject matter experts; public recognition; tour of a NASA facility; opportunity to demonstrate technology in front of NASA and industry experts; developing capabilities, skills and hands-on experience. The most promising designs may result in invitations to present research at a technical conference. Subject to the availability of funds, such invitations may include an accompanying stipend to further advance development of the concept and to offset the cost of traveling to the event.</td>
<td>The 2018 RASC-AL Special Edition: Mars Ice Challenge Competition was announced and promoted through both NASA and the National Institute of Aerospace�s (NIA) Communications Teams (including NASA�s Education Express and Science Wow!) and through direct email to over 3,000 engineering faculty throughout the country. Additionally, emails and phone calls were made to engineering professors and robotics clubs at universities across the country to promote the Mars Ice Challenge. A Facebook group and Twitter account were also utilized to draw interest from students. Feature stories on the nasa.gov website also called for project plan proposals each year. A website for the challenge is maintained and updated by the NIA.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The RASC-AL Special Edition: Mars Ice Challenge is open to full-time undergraduate and graduate student teams and faculty advisors at accredited U.S. universities. Teams may include senior capstone courses, robotics clubs, multi-university teams, multi-disciplinary teams, etc. Multi-disciplinary teams are encouraged.</td>
<td>The Mars Ice Challenge steering (and judging) committee is comprised of NASA and industry experts who evaluate all submission deliverables using rubrics for project plan proposals, mid-project reviews, and on-site technology demonstrations. Mars Ice Challenge projects are evaluated and judged based on adherence to the system prototype design constraints and requirements and the following criteria. For the onsite competition, 50% of the team�s score was related to water extraction, and the remaining 50% was related to the technical paper and poster presentation, with points deducted from the total score for exceeding the volume, mass, current, or Newton limits, failure to provide a weight-on-bit data logger, misalignment of system with the technical paper, or excessive dirt thrown outside of their designated area. Paramount to the Challenge is how well the teams can describe their water extraction system�s path-to-flight (i.e., what modifications their system would need to operate on Mars). The path-to-flight portions of the technical papers and poster presentations received the bulk of the points available in the scoring matrix.</td>
<td>Twenty-eight entries were submitted in FY17 by 8 teams consisting of 109 individuals. Eighteen entries were submitted in FY18 by 10 teams consisting of 154 individuals.</td>
<td>Funding for the FY17 Challenge was $284,999 and 0.1 FTE. Funding for the FY18 Challenge was $285,500 and 0.15 FTE. These costs were for NIA program management and other direct costs including but not limited to testing materials and technology development participation stipends provided to participating universities through their respective Offices of Sponsored Programs.</td>
<td>NASA partners with the NIA, who provides day-to-day administration of the Challenge. They have extensive expertise in managing successful higher education STEM competitions for NASA and are well equipped with certified program managers that provide a well-rounded experience for participants. They provide a robust marketing plan, extensive contact lists, in-kind challenge website hosting, graphics support, submission management, simulated test bed creation, and event planning for the culminating technology demonstrations/Forum at NASA�s Langley Research Center. Industry partners also brought their unique expertise to this Challenge and incorporating industry involvement on the steering committee added value to the overall competition and enabled students to interact with the foremost experts in this field.  In FY17 and FY18, an expert from Honeybee Robotics served an integral member of the Challenge steering committee (with estimated value of $2500 in both FY17 and FY18). In FY17, an expert from SpaceX also participated in the Challenge and collected participant resumes for consideration of internships and jobs at SpaceX.</td>
<td>The Challenge provides university undergraduate and graduate engineering students the opportunity to assist NASA achieve its strategic goal of extending humanity�s reach into space. The Challenge fuels innovation for aerospace systems, analogs, and technology prototyping at the nation�s best collegiate institutions. The Challenge enlists teams of students to focus on ISRU technology demonstrations for harvesting water from subsurface ice, a focus for NASA over the next few decades. The Challenge also leverages interaction to explore workforce pipeline opportunities and attract a highly skilled, competent, and diverse workforce. MIC contributes to NASA�s goals to enhance STEM experience of undergraduate students and provide graduate-trained STEM professionals with basic and applied research expertise.</td>
<td>Ideas; Technology demonstration and hardware; Analytics, visualizations, algorithms</td>
<td>Maintaining its relevance to the agency�s shifted focus to return Americans to the Moon, the FY19 challenge has evolved into the Moon to Mars Ice &amp; Prospecting Challenge, which will provide university-level engineering students with the opportunity to design and build prototype hardware that can not only extract water, but can also assess subsurface density profiles relevant to both lunar and Martian ISRU. The purpose of updating the challenge in FY19 is to explore and demonstrate methods to identify different layers using system telemetry, and ultimately extract water from ice deposits that could be found in lunar or Martian ice deposits. In FY20, NASA and NIA plan to continue adding evolutionary, incremental elements to the challenge so that university-based student teams/participants can continue making significant, relevant contributions to advancing ISRU research and technology.</td>
</tr>
<tr>
<td>NASA Tournament Lab Micro-Purchase Challenges</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>This was a collection of challenges with small purses executed through the NASA Tournament Lab that sought to achieve goals such as developing graphics, videos, or animations to communicate a space project�s utility or function; developing portions of a course or curriculum for training software developers on how to use a particular computer code needed for a space project; and developing models, solutions, or designs to solve a variety of problems involving radiation shielding, spacecraft thermal protection systems, robotic cameras, and lunar and Martian sample return.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>These challenges utilized prizes as a way to incentivize members of large crowdsourcing communities to deliver their most creative ideas and designs. This method has been consistently shown to be successful in finding novel, high-quality concepts, designs, and creative products in a cost effective and schedule efficient way. These 25 challenges cost just over $50,000 total (averaging only $2000 per challenge) and yet resulted in savings of an estimated $100,000.</td>
<td>The total prize purse offered was $44,800 (over multiple challenges) and the total amount awarded was $44,000 (over multiple challenges).</td>
<td>These challenges were executed under the government�s micro-purchase program, which allows for the direct purchase of a product up to $3,500 in FY17 and $10,000 in FY18. The solicitation of submissions was executed by the vendor as part of the transaction. Some of the challenges were advertised on the NASA Solve website (www.nasa.gov/solve).</td>
<td>Other - Communications provided by the vendor; Other - NASA Solve website</td>
<td>NASA did not levy any specialized participation requirements. Each vendor maintains participation requirements in their user terms and conditions that ensured participation aligned with applicable laws such as banned country participants.</td>
<td>For completed challenges, the end products were reviewed and approved by each of the NASA technical teams to ensure all requirements were met.</td>
<td>Of the 1,514 (across all 25 challenges) entries submitted by 809 participants, 35 prizes were awarded.</td>
<td>All challenge budgets were fully funded by NASA�s Human Exploration and Operations Mission Directorate. The funds were paid to the crowdsourcing vendor via the government micro-purchase program and vendors conducted the challenges and awarded the prize money. In FY17, $5,290 and 0.1 FTEs were spent; in FY18, $46,707 and 0.2 FTEs were spent. Freelancer.com and GrabCAD.com were paid for a variety of delivered media ranging from training materials to videos. Budgets for individual challenges were (1) Delay/Distruption Tolerant Networking (DTN) Interplanetary Overlay Network (ION) Training course sample challenge: $574; (2) DTN imagery or animation challenge: $574; (3) Origami/Folding Radiation Shielding Concepts Challenge: $1,060; (4) Origami/Folding Radiation Shielding Models Challenge: $1,060; (5) Astrobee Robotic Arm Design Architecture Study Challenge Series (14 challenges): $25,000; (6) REALM Project Overview Animated Video Storyboard Challenge: $573; (7) REALM Project Overview Animated Video Challenge: $3,030; (8) 3D Model Development for Human Rated Spacecraft Thermal Protection System (TPS) 3D Printing Process Challenge: $3,500; (9) Model Animation for Human Rated Spacecraft Thermal Protection System (TPS) 3D Printing Process Animation Challenge: $6,000; (10) Sample Return Regolith Sorter Design Challenge: $10,000; (11) Autonomous Systems Operations-ISS-TEA Project Graphic: $317; and (12) In-Space Manufacturing Refabricator Mission Patch/Graphic Challenge: $310.</td>
<td>N/A</td>
<td>These challenges contributed to key projects at NASA: (1) developing the communications protocols required for deep space exploration at distances that incur significant light-time delays in communications; (2) enhancing mission operations for current ISS missions and future missions by building an automated inventory tracking system; (3) developing radiation shielding concepts and designs to protect humans in deep space exploration (one of the current key unsolved risks for deep space exploration); (4) developing autonomous systems necessary for human management of complex systems in deep space where time delayed communications constrain ground interactions; (5) developing new production processes for thermal protection systems required for human exploration due to high speed entries required upon return; (6) developing sample return sorting mechanisms so that robotic surface exploration and scientific return can be enhanced; and (7) developing recycling and in space manufacturing methods that enable more efficient and resilient human space exploration in deep space.</td>
<td>Software and apps; Creative (design &amp; multimedia); Ideas</td>
<td>The NASA Tournament Lab Micro-Purchase Challenges are a mechanism that most NASA projects can afford without special funding requests and therefore it is anticipated that their use will grow in the future.</td>
</tr>
<tr>
<td>Open MCT Notebook Challenge</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>This Challenge was launched to add a new user-creatable Notebook plugin component for the Mission Control Technology (MCT) software framework. A Notebook is a container for multiple Notebook entries, which are comprised of a timestamp, text, and optionally one or more embedded links to other objects in Open MCT. Embedded links themselves can optionally include a snapshot image capture of their linked object�s view state at a given point in time. For example, a user might be viewing a plot of a telemetry element that tracks temperature for a system in a rocket. They might see an anomalous temperature spike in the plot, and would be able to immediately create a new Notebook entry describing what they saw that also includes a visual image capture of the plot.</td>
<td>Solve a specific problem; Develop technology</td>
<td>Competitive crowd-based software development methods have proven effective for efficient generation of quality software especially when Government resources are limited.</td>
<td>The total prize purse offered and awarded was $12,900. Non-monetary incentives included points from the vendor, TopCoder, toward attendance at the yearly prestigious TopCoder Open, an annual online and onsite tournament to celebrate and reward the TopCoder community.</td>
<td>As with all NASA Tournament Lab challenges, NASA worked with its vendor to mobilize an international community specific to the Challenge, based on the curated community already existing for the vendor platform. NASA used the NASA Solve website (www.nasa.gov/solve), which lists NASA�s participatory opportunities, to market this Challenge. This Challenge was broken up into six distinct competitions and marketed directly to Topcoder members via challenge listing and Topcoder�s development newsletter.</td>
<td>Social media (e.g., Twitter, Facebook); Other - Outreach by TopCoder to its platform members; Other - NASA Solve website (www.nasa.gov/solve)</td>
<td>Winners are vetted to ensure they are not on any restricted country list and are, therefore, eligible to receive the award.</td>
<td>The NASA MCT team evaluated the products developed and selected by the TopCoder community to ensure a quality implementation of the requirements as provided in the NOIS contract task order statement of work.</td>
<td>Of the 35 entries submitted by 87 participants between September 28, 2017 and November 13, 2017, 3 prizes were awarded to 3 winners.</td>
<td>The full challenge budget was funded by NASA�s Human Exploration and Operations Mission Directorate. The funds ($34,952 in FY17) were awarded to the crowdsourcing vendor TopCoder via the NOIS contract. The awarded vendor conducted the Challenge and awarded the challenge purse per the task order. NASA FTE/WYE resources (0.01 FTE in FY17 and FY18; 0.014 WYE in FY17 and 0.01 WYE in FY18) supported the challenge coordination activities including the task order request for proposal development and award processes as well as oversight of challenge execution per the task order.</td>
<td>N/A</td>
<td>This challenge supports NASA�s mission to work with industry to improve America�s aerospace technologies through the application of crowdsourcing as an innovative and cost-effective acquisition tool for solutions to specific operational needs.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>Partnership Agreement Maker (PAM) Graphical User Interface (GUI) Updates</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was completed in FY17.</td>
<td>Develop a new user interface for NASA�s Partnership Agreement Maker (PAM) that is intuitive, user-friendly, and will render well on mobile devices. PAM is NASA�s online tool for the development, execution, and storage of all agreement types, whether with other domestic or foreign government agencies, non-governmental organizations, or commercial entities. The design should have reused existing functionality, not changed existing code, and improved the user experience for completing a workflow.</td>
<td>Improve government service delivery; Solve a specific problem</td>
<td>The NASA Partnerships Office is extending its approaches to acquisition.</td>
<td>The total prize purse offered and awarded was $15,684. Non-monetary incentives included points from the vendor, TopCoder, toward attendance at the prestigious TopCoder Open, an annual online and onsite tournament to celebrate and reward the TopCoder community.</td>
<td>The limited marketing approach for this challenge consisted of alerts to TopCoder members through weekly newsletters and RSS feeds/social media.</td>
<td>Other - TopCoder development newsletters; Other - RSS feeds/social media</td>
<td>As with all NASA Tournament Lab challenges, NASA worked with the vendor to mobilize an international community specific to the Challenge, based on the curated community already existing for the vendor platform. Winners were vetted to ensure they were not on any restricted country list and were, therefore, eligible to receive the award.</td>
<td>Three representatives (two technical and one managerial) from the NASA Partnerships Office evaluated submissions throughout the design and build phases and made award determinations based on aesthetic and functional capabilities that would support the defined system requirements. Success criteria include adherence to defined technical requirements for system integration and interoperability with the existing system code base and architecture, as well as select design enhancements to the graphic interface to improve the overall user experience.</td>
<td>Of the 60 entries submitted by 194 participants between November 21, 2016 and April 03, 2017, 12 prizes were awarded to 12 winners.</td>
<td>The full challenge budget was funded by NASA�s Mission Support Directorate. The funds were awarded to the crowdsourcing vendor via the NOIS contract. The awarded vendor conducted the Challenge and awarded the prize money per the task order. Fund allocations included prizes, vendor project management resources, and platform fees. NASA FTE/WYE resources used in FY17 ($34,990, 0.14 FTE, and 0.01 WYE) supported the challenge coordination activities including the task order request for proposal development and award processes as well as oversight of challenge execution per the task order.</td>
<td>N/A</td>
<td>The Challenge introduced a new approach for service acquisition to the NASA Partnerships Office and provided a refreshed user interface for a critical Agency-wide routing system, thereby supporting NASA�s mission to improve America�s aerospace technologies.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>REALM Location Tracking Algorithm Challenge</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>The Radio-Frequency Identification (RFID) Enabled Autonomous Logistics Management (REALM) project seeks to build a machine learning based algorithm to help find, identify, and track cargo on the International Space Station (ISS). Tracking items in space habitats can be more challenging than it might at first seem. The environment is predominantly closed, with the exception of the jettisoning of trash or the delivery of new cargo or return of some items by visiting vehicles. However, there are a number of factors that complicate tracking, including crews that change out in six-month intervals, laboratory space that doubles as living space, cargo transfer bags that are nearly identical in appearance, and limited stowage space.</td>
<td>Solve a specific problem; Develop technology</td>
<td>Expert communities such as those found on TopCoder have been shown repeatedly to respond to prize-based challenges to complete tasks such as developing high-performing algorithms based on machine-learning data science.</td>
<td>The total prize purse offered is $26,500. TopCoder provides gamified incentives such as point scores and badges to its members who participate.</td>
<td>This project was executed under the NOIS multi-vendor indefinite delivery, indefinite quantity (IDIQ) contract. TopCoder was selected as the NOIS contract vendor for this task order based on a NOIS solicitation within the NOIS contract. TopCoder executed the task order to develop and execute the Challenge, which included outreach to its members and the wider public about participation in the Challenge. Additionally, this Challenge was posted on Challenge.gov and on the NASA Solve (www.nasa.gov/solve) website.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>NASA did not levy any specialized participation requirements. TopCoder maintains participation requirements in their user terms and conditions that ensured participation aligned with applicable laws such as banned country participants.</td>
<td>This Challenge is in its early stages, and the evaluation plan is still in development.</td>
<td>No prizes have been awarded at this stage of the Challenge.</td>
<td>The funding for this project was provided by the NASA Human Explorations Operations Missions Directorate (HEOMD)/Advance Exploration Systems (AES) division�s Logistics Reduction (LR)/REALM Project. The total budget for the NOIS task order to TopCoder under the fixed price contract was $89,700. Of those funds, $26,500 was budgeted for the prize pool. This Challenge is still in progress.</td>
<td>N/A</td>
<td>This Challenge contributes to NASA�s mission for human space exploration. Specifically, an improved cargo location tracking algorithm would save significant crew time and effort operating in a zero-gravity environment with rotating crews.</td>
<td>Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>Rice Business Plan Competition</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>The Rice Business Plan Competition is an event that matches startup companies with potential funding sponsors. NASA/Johnson Space Center provides a small amount of prize funding which allows participation in the process and access to the proposals from the best teams. The support NASA provided for this competition was intended to encourage the development of commercial technologies that can address physical challenges of spaceflight, which also have benefits on Earth. It aimed to engage faculty and students in addressing key space flight challenges in the areas of life sciences, engineering, and commercial space. It also sought to identify technology innovations which may assist NASA in achieving its mission and objectives.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>This competition enabled NASA to learn about emerging technologies that the agency may not otherwise have known existed.</td>
<td>The total prize purse offered and awarded was $20,000 in FY17 and $50,000 in FY18. Non-monetary incentives included recognition by NASA Johnson Space Center.</td>
<td>Rice University solicited globally for applications to their overall Business Plan Competition.</td>
<td>Other - Rice University outreach</td>
<td>Only U.S. teams are eligible for the NASA award.</td>
<td>NASA established a scoring method and then evaluated the business plan teams and their technologies to select a winner.</td>
<td>Of the more than 400 submissions (1 per team) received in FY17 between November 1, 2016 and March 15, 2017, 42 teams were selected to compete. One prize was awarded to one winner. Of the more than 750 submissions (1 per team) received in FY18 between November 1, 2017 and March 15, 2018, 42 teams were selected to compete. One prize was awarded to one winner.</td>
<td>In FY17, the grant budget was funded by NASA Johnson Space Center�s Human Health and Performance Directorate. In FY18, the Chief Technologist in the Exploration Integration and Science Directorate put in place a new three-year grant and collected funding from different organizations within the Johnson Space Center. In FY17, $20,000 was allocated for the prize and $7,500 was provided to Rice University through a grant for management and administration of the competition; in FY18, $50,000 was allocated for the prize and $7,500 went to Rice University. NASA FTE (0.03 in both FY17 and FY18) supported competition activities including preparing the grant agreement with Rice University, managing logistics of the competition, and ensuring a multi-disciplinary team was available to judge the competition for the NASA Earth/Space Human Health and Performance Innovation Prize.</td>
<td>N/A</td>
<td>The Rice Business Plan Competition is an event that matches startup companies with potential funding sponsors. The support NASA provided for this competition was intended to encourage the development of commercial technologies that can address physical challenges of spaceflight, which also have benefits on Earth. It aimed to engage faculty and students in addressing key space flight challenges in the area of life sciences, engineering, and commercial space. It also sought to identify technology innovations which may assist NASA in achieving its mission and objectives. Even when the proposals did not align with NASA�s needs, they can provide a rare opportunity to see fresh ideas from startup companies at a point when NASA might still have the opportunity to influence their direction.</td>
<td>Ideas; Technology demonstration and hardware; Business plans</td>
<td>The final year for the Human Health and Performance grant was 2017. NASA has established a three-year grant with Rice University to continue participating in the Rice Business Plan Competition through 2020.</td>
</tr>
<tr>
<td>Robonaut 2 Tool Localization Challenge</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was completed in FY17.</td>
<td>The Challenge was launched to develop a general vision algorithm for Robonaut 2 (R2), NASA&#39;s dexterous humanoid robot, to improve the robot�s ability to manipulate objects. The R2 team was looking to find vision algorithms that would be effective with noisy stereo vision data for localizing a specific point on a variety of tools. The Challenge was comprised of three separate algorithm contests run on the vendor, TopCoder, platform.</td>
<td>Solve a specific problem; Develop technology</td>
<td>Crowd-based challenges incentivized with a monetary purse have proven extremely effective for algorithm development, particularly when a team is resource limited.</td>
<td>The total prize purse offered and awarded was $19,250. For the first contest, the following prizes were awarded: $5,000 for first place, $2,500 for second place, $1,500 for third place, and $750 for fourth place. For the second contest the following prizes were awarded: $4,000 for first place, $2,750 for second place, $1,750 for third place, and $1,000 for fourth place. The winner of the optimization round won a NASA swag bag and a one-hour talk and coffee with the Harvard Crowd Innovation Lab team. The winners also received points from TopCoder toward attendance at the yearly TopCoder Open, an annual online and onsite tournament to celebrate and reward the TopCoder community.</td>
<td>As with all NASA Tournament Lab challenges, NASA worked with its vendor to mobilize an international community specific to the Challenge, based on the curated community already existing for the particular vendor platform. In addition to soliciting submissions from its existing member community, TopCoder ran a blog feature, newsletter promotion, and forum promotion, as well as direct email campaigns and support for a NASA press release.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Other - Outreach by vendor Topcoder to its platform�s members</td>
<td>Winners were vetted to ensure they were not on any restricted country list and were, therefore, eligible to receive the award.</td>
<td>NASA and Harvard worked with TopCoder to establish scoring methods and then worked to verify the resulting algorithms to determine their relative performance and select winners. In order to win a prize, the submitter had to achieve a score in the top five, according to system test results. Within seven days from the announcement of the challenge winners, winning candidates had to submit a complete report at least two pages long outlining their final algorithm, explaining the logic behind and steps to its approach, and describing how to install any required libraries to run it.</td>
<td>Of the 222 entries submitted by 1,912 participants between February 23, 2016 and March 08, 2016 for Algorithm Contest 1 and October 05, 2017 and October 19, 2017 for Algorithm Contest 2, nine prizes were awarded to nine winners in the Optimization Algorithm Final Contest on October 26, 2017.</td>
<td>The full challenge budget ($59,500 for challenge execution and prize purse) was funded by NASA�s Human Exploration and Operations Mission Directorate. In addition, 0.014 FTEs were allocated to support the Challenge. The funds were awarded to the crowdsourcing vendor TopCoder via the NOIS contract. The awarded vendor conducted the Challenge and awarded the prize money per the task order.</td>
<td>N/A</td>
<td>This Challenge supports NASA�s mission to work with industry to improve America�s aerospace technologies. It provided the R2 team with several algorithmic approaches to this difficult problem of detecting points on a three-dimensional tool and recognizing that tool. Given the low cost of this challenge and the serial contests involved, the team was able to gain insight into some very effective approaches to building this algorithm.</td>
<td>Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>Robotic Mining Competition</td>
<td>NASA</td>
<td>51 USC � 20113(e)</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>This competition is for university-level students to design and build a mining robot that can traverse simulated chaotic lunar/Martian terrain, excavate the regolith and ice simulant (gravel), and deposit it into a collector bin to simulate an off-world mining mission. The complexities of the challenge include the abrasive characteristics of the regolith, weight and size limitations of the mining robot, and the ability to tele-operate it from a remote Mission Control Center. Teams also submit a systems engineering paper explaining their design philosophy, engage in K-12 Outreach in their communities, and give a project presentation to judges at Kennedy Space Center.</td>
<td>Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>Teams provide their best students, faculty advisors, robots, equipment, supplies, transportation, etc. to come to the competition at the Kennedy Space Center. Prizes inspire and motivate students to compete.</td>
<td>The total prize purse offered in both FY17 and FY18 was $17,000 and the total amount awarded in both FY17 and FY18 was $17,000. Three trophies were awarded in FY18 for the Judges� Innovation Award, the Solar System Exploration Research Virtual Institute (SSERVI) Regolith Mechanics Award, and Efficient Use of Communications Power Award. Non-monetary incentives included NASA bragging rights: schools and students got to say �We ran our robot at NASA�s Robotic Mining Competition� or �We successfully wrote a NASA peer-reviewed Systems Engineering Paper� or �We took home the Robotic Mining Competition�s �Joe Kosmo Award for Excellence�.�</td>
<td>The competition registration date was announced on the NASA RMC website, on social media (Facebook and Twitter), and in announcements sent to all the teams that competed the previous year.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs)</td>
<td>Teams from post-high school vocational/technical schools, colleges, and universities located in the United States, its Commonwealths, territories, and possessions were eligible to register for the competition (no more than one team per university campus was allowed). A team consisted of current faculty/staff members of the college or university and at least two undergraduate students. Students had to be enrolled during the current or previous school semester and submit transcripts demonstrating good academic standing. The number of team members was at the discretion of the school but had to be sufficient to successfully design, build, and operate their mining robot.</td>
<td>Both the first and second round of systems engineering papers judging was done by engineers from across NASA. Presentations and demonstrations during the week of the mining competition were judged by engineers from across NASA. Both the first and second rounds of the outreach report was judged by communications and education personnel from across NASA. Points during the on-site mining competition were awarded based on numerous factors including but not limited to the amount of regolith returned. This event was judged by engineers from across NASA. Points from all categories were tallied for the grand prize, The Joe Kosmo Award for Excellence.</td>
<td>Of the 48 entries (740 individuals) submitted for the FY17 competition, 22 prizes were awarded to 12 different teams. Of the 46 entries (810 individuals) submitted for the FY18 competition, 23 prizes were awarded to 11 different teams.</td>
<td>NASA�s Human Exploration and Operations Mission Directorate provided 1.0 FTE and $361,750 in FY17, and 1.0 FTE and $362,325 in FY18. This funding supported contractor labor as well as preparations, materials, supplies, and the NASA-funded awards for the competition.</td>
<td>Non-Federal partners in FY17 (Honeybee, Harris, Caterpillar, Moon Express, Igus, and Lockheed Martin) contributed $38,540. Non-Federal partners in FY18 (Honeybee, Harris, Caterpillar, Moon Express, and Boeing) contributed $41,500.</td>
<td>NASA directly benefits from the competition by encouraging the development of innovative robotic excavation concepts. These concepts may result in unique solutions applicable to an actual excavation device and/or payload on an in-situ resource utilization (ISRU) mission. Advances in off-world mining have the potential to significantly contribute to our nation�s space vision and NASA space exploration operations.</td>
<td>Software and apps; Technology demonstration and hardware; Scientific</td>
<td>In FY19, the objectives of the competition will remain the same; however, the playing field will have significant changes. Teams will be required to submit 60 mechanical data points about the robots. In FY20, the competition will incorporate a gravity offloading device to better simulate lunar and Martian gravity. In FY21, the competition will incorporate a 3-D printing component to keep the competition current and on task with new technology research needs.</td>
</tr>
<tr>
<td>Space Poop Challenge</td>
<td>NASA</td>
<td>31 USC � 6301, et seq.</td>
<td>This competition was completed in FY17.</td>
<td>The goal was to find viable concepts and designs for a urine and fecal management system for use in landing and entry space suits over a continuous duration of 144 hours in the event of a cabin depressurization or alternate contingency scenario. Currently space suits are worn for launch and entry activities and in-space activities to protect the crew from any unforeseen circumstances that the space environment can cause. An astronaut might find himself or herself in this suit for up to 10 hours at a time nominally for launch or landing, or up to 6 days if something catastrophic happens while in space. The current fecal-management solution is equipping the astronauts with diapers. However, the diaper is a low-tech and very temporary solution. Most significantly, it does not provide a healthy or protective option longer than one day.</td>
<td>Solve a specific problem; Develop technology</td>
<td>A crowdsourced competition provided the greatest possibility of identifying innovative solutions with the limited available budget.</td>
<td>The total prize purse offered and awarded was $30,000. Non-monetary incentives included official letters of recognition being sent to the top 25 submissions along with a Crew Survival Systems patch and NASA Tournament Lab stickers.</td>
<td>As is the case for all NASA Tournament Lab challenges, NASA worked with a vendor to mobilize an international community specific to the Challenge based on the curated community already existing for the vendor�s platform. The vendor solicited submissions from its existing member community and the public through blog features, emails, social media campaigns.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Other - Outreach by challenge vendor</td>
<td>Winners are vetted to ensure they are not on any restricted country list and are, therefore, eligible to receive the award.</td>
<td>Initial screening evaluation of the more than 5,000 submissions was done by HeroX based on the stated evaluation criteria. Eighty-four submissions were provided to a NASA evaluation panel. This panel recommended a list of finalists that included the top 25 submissions along with the list of recommended first, second, and third place submissions.</td>
<td>Of the 5,170 entries submitted by 20,129 participants between October 11, 2016 and December 20, 2016, 3 prizes were awarded to 3 winners.</td>
<td>The full challenge budget ($58,000) was funded by NASA�s Human Exploration Operations Mission Directorate. The funds were awarded to the crowdsourcing vendor HeroX via the NOIS contract. The awarded vendor conducted the Challenge and awarded the challenge purse per the task order. NASA FTE/WYE resources (0.025 FTE and 0.002 WYE) supported the Challenge coordination activities including the task order request for proposal development and award processes as well as oversight of Challenge execution per the Task Order.</td>
<td>N/A</td>
<td>This Challenge supports NASA�s mission to work with industry to improve America�s aerospace technologies through the application of crowdsourcing as an innovative and cost-effective acquisition tool for solutions to specific operational needs. This Challenge resulted in the submission of many novel and interesting ideas for dealing with human waste in a space suit environment over an extended time period. The three winners provided some unique solutions including an airlock and internal suit manipulation tool that was based on laparoscopic surgical techniques and tools. This approach allows for the removal of waste material, entry of wipes and underwear, and manipulation required for cleaning in the space suit. Another concept included a design for self-inflating air pumps to help dry the skin that used emergency air bagging technology to save power and complexity while providing high rate airflow. The winning submission also included a compact wiping mechanism that provided a novel approach to skin cleaning and infection prevention.</td>
<td>Other - Design</td>
<td>N/A</td>
</tr>
<tr>
<td>Space Robotics Challenge</td>
<td>NASA</td>
<td>51 USC � 20144</td>
<td>This competition was completed in FY17.</td>
<td>The goal of the Space Robotics Challenge (SRC) was to foster innovations in technology to advance robotic autonomy in manipulation and perception in humanoid robots to help astronauts on the journey to Mars and other deep-space destinations. Autonomy is critical for space flight missions to Mars and beyond due to the time it takes to send and receive commands from Earth. As missions grow longer and more complex, robots could be used as precursor explorers, helpers in space, and caretakers of assets left behind. There are also potential Earth applications for autonomous capabilities, including disaster relief and clean-up and/or maintenance of areas with conditions hazardous to humans.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>The competition gave access to the complex NASA R5 robot, providing multiple entities with access to advance the technology for both space and Earth applications. Also, partnering on the competition with Space Center Houston gave NASA the opportunity to engage and inspire the broader public, including K-12 and educators.</td>
<td>The total prize purse offered was $900,000 and the total amount awarded was $570,000. As non-monetary incentives, the top four teams were awarded a code implementation partnership with an R5 Host Team for at least two weeks.</td>
<td>Soliciting competitors was conducted mainly by NineSigma from their database of solvers. Potential competitors were engaged via direct email and a customized newsletter. Social media efforts were coordinated between NASA, Space Center Houston, and NineSigma. Postings were made on LinkedIn, Twitter, and Facebook. Feedback from competitors was that social media was the main attractor. Two webinars were executed in order to engage the public. Four videos were made to promote the Challenge on social media, the first of which was used to tease the release of the Challenge, and the remaining three to further explain the goals of the Challenge and the current state of technology.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Anyone could participate in the SRC as long as they were not a citizen of a country on the NASA Export Control Program List. Only U.S. citizens or permanent residents were eligible to win a cash prize; non-U.S. citizens were allowed to participate and be recognized as winners. Teams with foreign participation were only eligible to receive cash awards from NASA if the overall composition of the team was at least 51% U.S. citizens and entity team members were incorporated in and maintained a primary place of business in the U.S. or were full-time students at an accredited U.S. institution, had a valid student visa, and submitted a signed foreign participation acknowledgement form.</td>
<td>Since the competition was completed in a simulation environment, a large portion of the scoring was based on an established algorithm. For the qualification round, the scoring from the algorithm was reviewed by the Open Source Robotics Foundation (OSRF) and validated by the NASA Centennial Challenges program team. For the Virtual Competition Round, once the teams completed their runs, their log files were generated and uploaded. OSRF then executed a double-blind peer review process for each team and each round (i.e., each team was only known to the reviewers by a randomly designated number) and created a summary of how each team performed. Two additional people at OSRF then approved these summaries or offered refinement. The outcome of this verification process was the metric score and time. The videos of the simulations were then passed to the judging panel for subjective scoring. The expert judges did not see the teams� computed scores in order to remove any bias.</td>
<td>A total of 405 teams (754 people) registered to participate, 92 teams (290 people) were selected to compete in the qualifying round, and 20 teams (100 people) reached the final round. Each of the 20 teams in the final round received $15,000; the first place team received $125,000, the second place team received $100,000, the third place team received $50,000, and the fourth place team received $25,000.</td>
<td>One FTE and funding in the amount of $306,000 in FY17 provided by the NASA Space Technology Mission Directorate/Centennial Challenges Program were used to support the vendor, OSRF, to develop and execute the simulation environment for the challenge tasks; workforce to develop and execute the Challenge; travel to the challenge meetings and events; and for the subject matter expert and NASA project team at Johnson Space Center.</td>
<td>Non-Federal partners included Space Center Houston (allied organization), NineSigma Inc. (challenge sponsor), Florida Institute of Human and Machine Cognition � R5 Software, Open Source Robotics Foundation Inc., and Gazebo Design and Support. Space Center Houston contributed $985,202, and NineSigma Inc. contributed $362,627.</td>
<td>The SRC aligns the needs of NASA�s Space Technology Mission Directorate and Human Exploration and Operations Mission Directorate.</td>
<td>Software and apps; Analytics, visualizations, algorithms</td>
<td>Phase 2 of the SRC is currently in development. The goal of phase 2 will be to advance autonomous surface mobility for NASA exploration robotic systems. This new phase will push the technology even further by striving for fully autonomous operations.</td>
</tr>
<tr>
<td>Student Launch Initiative</td>
<td>NASA</td>
<td>51 USC � 20113�</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>The NASA Student Launch Initiative (SLI) is a research-based, competitive, experiential exploration activity intended to provide relevant, cost-effective research and development of rocket propulsion and ground support systems. SLI connects learners, educators, and communities in NASA-unique opportunities that align with STEM Challenges under the NASA Office of Education�s STEM Engagement. The activity reaches a broad audience of middle schools, high schools, colleges and universities across the nation through an eight-month commitment to design, construct, and fly payloads and vehicle components. Teams launch the experiments on high-power rockets and share the research results, which could be used in future design and development of NASA projects.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>Student Launch has been conducted for more than 15 years. The challenge/competition allows NASA to reach a different demographic than usually reached with grants and contracts. It also allows participants to propose more easily because there is no grant or contract paperwork.</td>
<td>The total prize purse offered was $9,500 in both FY17 and FY18 and was contributed by partners. The total amount awarded was $9,500 in both FY17 and FY18. Non-monetary incentives included trophies.</td>
<td>The request for proposal was announced on the Student Launch website. Former teams and any interested teams were emailed. NASA posted a press release and announced the opportunity on social media.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>For universities and colleges, the opportunity to propose was open to all. For middle schools and high schools, proposal opportunity was open to the top 25 performing teams from the Team America Rocketry Challenge and the top three teams from Rockets4Schools.</td>
<td>Submitted proposals were scored by a panel of NASA Marshall Space Flight Center (MSFC) subject matter experts using a rubric.</td>
<td>For 2017, 68 entries (810 participants) were submitted between August 15, 2016 and April 24, 2017. For 2018, 75 entries (879 participants) were submitted between August 21, 2017 and April 27, 2018. In both 2017 and 2018, 19 prizes (3 cash awards; 16 trophies) were awarded.</td>
<td>In both FY17 and FY18, $377,000 went to personnel (FTE and contract support) for challenge design, proposal review, four design reviews throughout the eight-month process, launch week activities, safety review and monitoring, website development, social media and press releases, and interaction with teams and appropriate NASA entities (Office of Education, Human Exploration and Operations Mission Directorate, Center management). A total of $102,000 went to contracts for launch services (National Association of Rocketry), launch week services (meeting rooms, emergency vehicle support, port-o-lets and other necessities), transportation for teams to NASA�s Marshall Space Flight Center, and to launch field. $15,000 was budgeted for materials and $55,000 was used for stipends for team mentors. Mentors were required to have level 2 high powered rocketry certification and to travel to launch and were responsible for rocket for safety purposes.</td>
<td>Partners provided prize money, trophies, and items that the Federal Government does not provide, including an awards banquet and stipends to the team. In both years, Orbital ATK provided $5,000 sent directly to the first place winner and $4,669 in trophies (i.e., prize trophies for winners and a participation trophy for each team). The Huntsville Chapter of the National Space Club provided $2,500 to the second place overall winner; $2,000 to the high school/middle school winner (delivered through NASA MSFC contractor, Aetos); $183.71 for trophies; and $16.29 in contractor overhead fees.</td>
<td>SLI provides relevant, cost-effective research and development of rocket propulsion and ground support systems. Additionally, SLI connects learners, educators, and communities in NASA-unique opportunities that align with STEM Challenges under the NASA Office of Education�s STEM Engagement.</td>
<td>Technology demonstration and hardware</td>
<td>Plan to continue the Challenge for FY19 and FY20, using NASA�s Space Launch System as the research emphasis.</td>
</tr>
<tr>
<td>Swarmathon</td>
<td>NASA</td>
<td>FAR</td>
<td>This competition was completed in both FY17 and FY18.</td>
<td>The NASA Swarmathon is a challenge to develop cooperative robotics to revolutionize space exploration. Students from minority serving institutions (MSIs) are challenged to develop search algorithms for robotic swarms. Swarmathon participation is designed to improve students� skills in robotics and computer science, and further advance technology for future NASA space exploration missions. The NASA Swarmathon project used small, robotic vehicles called Swarmies to challenge programming skills of students at select minority-serving institutions. Swarmies were equipped with a Wi-Fi antenna, GPS, webcam, and sensors developed to search for resources. There was a physical competition (with sets of three robots) and a virtual competition. Virtual teams had their code run in a simulation environment. Physical teams had their code installed on Swarmie robots which were run at the physical competition at NASA Kennedy Space Center in April. The physical layout and format were reproduced in a simulated environment for the virtual competition.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity</td>
<td>Prize competitions reach far more students and institutions than could be reached through direct pay mechanisms. Instead of one funded school and their results, over 30 provided proof of concept algorithms for search methods. Competitions allow students and faculty to engage with NASA research and training in a way that gives them flexibility for the amount of time they spend on the project. Prize awards provide an incentive for students to expand their learning, gain valuable hands-on experience, and utilize their skills to solve a real-world problem.</td>
<td>The total prize purse offered and awarded in FY17 was $15,000 and $17,000 in FY18. Non-monetary incentives included trophies.</td>
<td>One of the goals of the NASA Swarmathon was to recruit a sizeable and diverse pool of applicants from MSIs across the United States and its territories. The project sought diversity in the form of MSI types, geographic distribution, and school sizes. To support the goal of making every computer science department at every MSI aware of this opportunity, the following marketing efforts were undertaken: constant updates of the nasaswamathon.com website; postcard mailers to computer science faculty at MSIs; publication in NASA Education Express electronic newsletter; dissemination through Penn Center for MSIs; recruitment webinar; and promotion through social media.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Reviewers evaluated each application using a rubric based on seven different criteria and awarded a score ranging from one to four for each criterion. The criteria were as follows: (1) faculty technical qualifications; (2) faculty teaching experience; (3) goals and objectives to accomplish project; (4) description of student engagement; (5) description of plan to deadlines and milestones; (6) number of students engaged; (7) other strengths. All the faculty team mentors established various methods to convene students and provide them with the instruction necessary to prepare for the NASA Swarmathon. These methods included offering advanced topics courses for credit, offering special topic courses for credit, working with campus clubs and societies, and hosting weekly or monthly meetings.</td>
<td>Student teams were challenged to develop search algorithms for robotic swarms. These algorithms were written in Robot Operating System (ROS) with Java and C++ and submitted about four weeks before the actual competition. These search algorithms were run on �house� Swarmies on the week of competition. The objective was to find resources in the form of cubes with software tags on them. Judges monitored the software and the robots during their runs, which were 20-40 minutes long. Winning teams were those that obtained and returned the most resources to the home collection nest. Each team was also required to submit a five page technical report that described the algorithms and approaches they developed using pseudo-code, equations, flow charts, figures, or descriptions. These reports were judged for most innovative and functional solutions.</td>
<td>In FY17, 34 university teams (400 students) and 30 high school teams (300 students) participated. In FY18, 30 university teams (360 students) and 20 high school (200 students) participated. In FY17, 27 prizes were awarded to 19 different teams; in FY18, 28 prizes went to 19 different teams.</td>
<td>Funding was provided through a grant from the NASA Minority University Research Program within the NASA Office of Education (now Office of STEM Engagement) to the University of New Mexico (UNM), as a cooperative agreement. Expenses were paid by UNM through the grant. In both FY17 and FY18, 1.0 FTE and $824,000 were used to support the competition</td>
<td>The NASA Swarmathon was funded from NASA Office of Education, through a cooperative agreement grant. This project was overseen by a management team consisting of the grant principle investigator at the UNM computer science department and NASA Kennedy Space Center. The estimated value of partner contributions was $25,000 in both FY17 and FY18.</td>
<td>In situ resource utilization of water or ice to provide hydrogen and oxygen for fuel, breathing, and drinking and other resources in support of human missions to the Moon and Mars is a stated goal of NASA. Being able to send robots to gather these resources rather than sending tons of fuel, oxygen, and water required to support extended missions makes them not just cheaper but, in many cases, feasible. To make robots a realistic option for supporting human missions we have to understand how to organize teams of lightweight robots so they can find and collect resources efficiently. This competition has set hundreds of students, who would not normally have access to a robotics environment, on career paths as roboticists, computer programmers, and engineers.</td>
<td>Software and apps; Creative (design &amp; multimedia); Technology demonstration and hardware</td>
<td>For FY19, Swarmathon will utilize the current Swarmies. For FY20, Swarmathon plans to utilize for its new robots a ground version of the Pop-Up Flat Folding Explorer Robot (PUFFER), a robot concept being developed by the Jet Propulsion Laboratory (JPL) through NASA funding. A letter of interest has been provided to Swarmathon from the JPL PUFFER development leads. The JPL PUFFER team is interested in making the hardware and autonomy available to more institutions through potentially open-sourcing its design, firmware, and software. NASA Swarmathon provides a framework for JPL�s objective by utilizing the PUFFER design in the Swarmathon autonomous competition. JPL would benefit by getting the PUFFER into the academic community to help JPL solve technology challenges. The goals for Swarmathon will be to evolve the competition search arenas over the years to increase the challenge level and thereby provide usable software for JPL testing.</td>
</tr>
<tr>
<td>Vascular Tissue Challenge</td>
<td>NASA</td>
<td>51 USC � 20144</td>
<td>This competition was launched in FY17 and is underway in FY18.</td>
<td>The goal of the Vascular Tissue Challenge (VTC) is to break through one of the critical obstacles in developing medically useful 3D-engineered heart, lung, kidney, liver, and pancreas tissues for pharmaceutical research, organ bandages, and ultimately organ transplants on Earth or in space. Specifically, the VTC goal is to inspire the successful creation of thick (1 cm x 1 cm) human vascularized organ tissue in an engineered environment while maintaining the function of the tissues similar to those within the human body through a 30-day survival period. Teams must demonstrate three successful trials with at least a 75% trial success rate to win an award. Current state of the art is 2 mm for tissue size with no vascular system or a vascular system where tissues do not behave as they do in the body. No one has achieved the combination of increase in size with a vascular system that functions as organ tissues do in the body. Because there are data indicating that engineered tissues can grow larger and more medically relevant in space, the Center for the Advancement of Science in Space (CASIS) also offers the opportunity to fly winning strategies on the ISS.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Stimulate a market; Other - Provide lifesaving medical advances</td>
<td>In the context of the VTC, prizes are accelerants that inspire focus, new innovators, and non-traditional collaborations to solve a problem of exceptional difficulty that has escaped resolution with conventional practices. Prizes enable new and highly innovative approaches, including those that conservative organizations consider to be too risky.</td>
<td>The total prize purse offered is $500,000. Non-monetary incentives included the opportunity to fly the winning entry to the ISS.</td>
<td>Solicitation mechanisms included a White House kickoff event; website announcements from multiple organizations (NASA Centennial Challenges, NASA Solve, the Methuselah Foundation, and the New Organ Alliance); presence at professional conferences, workshops, and symposia; advertisement through NASA and Methuselah Foundation webinars, videos, and other public outreach mechanisms; and word of mouth recruiting through the growing VTC scientific network. In addition, because of its profound importance to medicine, both the National Science Foundation and Veterans Administration contributed resources and personnel, and the National Institutes of Health participated in the workshops. These agencies� networks have also been used to solicit submissions.</td>
<td>Social media (e.g., Twitter, Facebook); Day-long event(s) prior to the competition; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - White House kickoff event;  Other - NIH and NSF networks</td>
<td>Participation is open to teams from organizations incorporated in the United States. Team leads must be U.S. citizens or permanent residents.</td>
<td>An expert judging panel was recruited, and criteria and decisions are informed by a large group of subject matter experts and oversight committee members who can provide additional support for judging the adequacy of a submission.</td>
<td>Twelve teams have indicated intention to participate since June 13, 2016. Closing date is September 30, 2019.</td>
<td>The VTC is part of NASA�s Centennial Challenges Program, which is part of NASA�s Space Technology Mission Directorate. The challenge development and oversight and prize purse are funded by NASA�s Space Technology Mission Directorate. The VTC budgets ($270,000 in FY17 and $400,000 in FY18, not including prize purse) and civil servant resources (1.2 FTE in both FY17 and FY18) are used primarily for workshops where experts from multiple disciplines are assembled to work with the competitors to identify key obstacles and how to overcome them. A secondary investment is in the preparation of workshop reports and its development into publications, which began in FY18 and will be completed in FY19.</td>
<td>Non-Federal partners include the Methuselah Foundation, the New Organ Alliance, and CASIS. The Methuselah Foundation is the implementing partner in the VTC and has been outstanding in raising companion funds for judges and teams to travel to workshops, symposia, and conferences as well as to advertise the competition and recruit judges and other subject matter experts. The Methuselah Foundation also recruited National Science Foundation and Veterans Administration support. In addition, CASIS is offering to fly prize winners� investigations on the ISS. CASIS was selected by NASA in 2011 to be the sole manager of the ISS National Laboratory. The estimated value of partner contributions in FY18 is $102,000, which includes $60,000 for management and implementation and $26,000 for workshops and other events.</td>
<td>NASA�s objective for this Challenge is to produce technologies capable of creating viable, thick (&gt;1 cm) metabolic tissues that can be used to advance research on human physiology, fundamental space biology, and medicine on both the Earth and the ISS. VTC is responsive to a mandate in the 1958 Space Act (as amended), the foundational legal document governing NASA: �Congress declares that the general welfare of the United States requires that the unique competence of the &lt;National Aeronautics and Space&gt; Administration in science and engineering systems be directed to assisting in bioengineering research, development, and demonstration programs designed to alleviate and minimize the effects of disability.�</td>
<td>Technology demonstration and hardware; Analytics, visualizations, algorithms; Scientific; Other - Science and Technology Breakthrough in medically important 3D tissue engineering</td>
<td>The VTC ends September 30, 2019. Over the next year, because of the humanitarian potential and the unique insights obtained via the workshops, the VTC team, both paid and volunteer, plan to write articles that capture the state of the art of 3D tissue engineering, describe critical research issues and recommendations, and articulate the role of spaceflight in potentially overcoming the significant gravitational issues constraining successful development of tissues large enough to be medically useful. Two more workshops are planned, one in January 2019 and another as a closeout workshop in September 2019. A closeout report will be prepared.</td>
</tr>
<tr>
<td>The NSF 2026 Idea Machine</td>
<td>NSF</td>
<td>NSF Act of 1950, as amended</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>The goal of the NSF 2026 Idea Machine is to engage a broad swath of stakeholders in the science, technology, engineering, and mathematics (STEM) and STEM education research enterprise to identify grand challenges for future, long-term investment by NSF (i.e., to identify the next set of big ideas). The competition will help set the U.S. agenda for fundamental research in science and engineering by asking entrants to suggest the pressing research questions that need to be answered in the coming decade, the next set of big ideas for future investment by NSF in anticipation of the Nation�s 250th anniversary in 2026 and beyond. It is an opportunity for researchers, the public, and other interested stakeholders to contribute to NSF&#39;s mission to support basic research and enable new discoveries that drive the U.S. economy, enhance national security, and advance knowledge to sustain the country&#39;s global leadership in science and engineering.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Engage new people and communities</td>
<td>A prize competition was chosen in order to maximize excitement, engage the public, and incentivize participation by a wide range of potential contestants, including thinkers inside and outside the academic and industrial research communities. The NSF 2026 Idea Machine prize competition is based on the premise that scientific creativity and innovation have no bounds. Its premise is that everyone in the science and engineering community, from high school students to emeritus professors, as well as anyone who loves science in the general public have ideas about the future and what might be possible. NSF wants to harness those rich imaginations through an ideation prize competition that extends the agency�s tradition of reaching out to the community to find fresh, new ideas that have the potential to benefit science and society.</td>
<td>The total prize purse offered is $164,000 (to be awarded summer 2019). Non-monetary incentives included public recognition (posting entries on website), thank-you letters from NSF leadership, and acknowledgment of honorable mentions at winner recognition event. Grand prize winners (up to four indivduals or teams comprised of up to five individuals) will receive travel support to attend the recognition event in summer of 2019 in the Washington, D.C. area.</td>
<td>The NSF 2026 Idea Machine was announced at meetings of the National Science Board, other NSF events (e.g., NSF Days), and scientific disciplinary organization meetings attended by NSF staff. A toolkit of materials for outreach available to NSF staff members included postcards, posters, sample social media posts, sample emails, and slide presentations. The NSF 2026 website went live prior to launch of the competition, and announcements went out over all NSF social media platforms. The competition was announced via email to current and former principal investigators, representatives of scientific organizations, NSF directorate advisory committees, non-profit organizations, industry groups, independent research institutes and centers, heads of science and engineering research departments at universities, and STEM high-school teachers. The launch of the competition was also announced by press release, the NSF Director�s Newsletter, and on social media platforms.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Other - Paid advertising</td>
<td>All contestants (including individual entrants and all team members) must be at least 14 years of age by September 1, 2018, and be U.S. citizens or permanent residents, or residing legally in the U.S. on September 1, 2018. Only one entry per individual or team is permitted. A contestant may submit an entry as an individual or as a member of a team, but not both. A contestant may only be on at most one team. Entries may be submitted by individuals or by teams comprised of up to five individuals, one of whom must be designated as the team leader. Restrictions apply to people working at NSF, Idea Machine judges, and Federal contractors.</td>
<td>Entries will be screened by NSF staff for responsiveness to the competition call and consistency with the competition rules. Entries that meet the initial screening criteria will be judged by NSF staff who will select approximately 30 for the next phase of the competition. Those entrants continuing to the second phase will be invited to make video submissions. The second phase entries will be judged by a Blue-Ribbon panel of external experts in two stages. The Blue-Ribbon panel will make recommendations to NSF. The final selection of winning entries will be at the discretion of NSF and will include consideration of additional factors such as the Foundation�s current and planned investments, the unique suitability of NSF to lead research activities on the proposed big idea, risk/reward balance of investing in the idea, readiness of the relevant research communities to take on the idea, and the scope and scale of the idea.</td>
<td>The competition is still active and results have not yet been determined. The competition opened for submission on August 31, 2018 and closes on September 30, 2019. The competition has received 801 entries.</td>
<td>The NSF 2026 Idea Machine is led by the Office of Integrative Activities (OIA) and is managed by a working group representing all the directorates and four offices within NSF. For FY18, one FTE and $311,000 have been allocated. The Office of Legislative and Public Affairs supports inreach and outreach (creating graphics and materials, developing and maintaining the Idea Machine website, and announcing the competition via social media platforms, email updates, press releases, leadership blogs and speeches, etc.). Post Modern Company (subcontract to SKILD) was contracted to build, operate, and maintain an online platform that facilitates the submission of entries (text and video), collection of public comments, and judging of competition entries. The contractor is also providing technical support to contestants and marketing the competition, and will distribute cash prizes for winning entries. The contract price was valued at $303,000 (including funds for cash prizes) in FY18. The NSF 2026 Idea Machine is being advertised throughout the entry submission window via on-line leaderboard ads in Science, Science New, and Science Advances (all products of the American Association for the Advancement of Science). The cost for advertisement was $8,000 in FY18. In FY19, OIA will support a one-day virtual meeting and a three-day in-person meeting of the Blue-Ribbon panel at NSF. The estimated cost for this is $33,000.</td>
<td>N/A</td>
<td>Thematic initiatives informed by the NSF 2026 Idea Machine will advance NSF�s mission to �promote the progress of science; to advance the national health, prosperity, and welfare; to secure the national defense.� The NSF 2026 Idea Machine exemplifies a new way of eliciting the most forward-looking ideas and enabling a broad consensus with respect to major initiatives that require and deserve support over the next decade to sustain America�s global leadership in science and engineering.</td>
<td>Ideas; Scientific</td>
<td>This is the pilot year for the NSF 2026 Idea Machine, and depending on the response and quality of entries, it will continue in FY19 and FY20 as an annual competition. Several NSF programs that ran challenge competitions during FY17-FY18 are considering hosting new competitions to build on prior successes.</td>
</tr>
<tr>
<td>The Vizzies Challenge</td>
<td>NSF</td>
<td>NSF Act of 1950, as amended</td>
<td>This FY17 competition is complete, and the FY18 competition is underway.</td>
<td>In the Vizzies Challenge, NSF asks participants to submit creative, science visualizations that promote understanding of scientific and engineering research. As the need to increase science literacy grows more urgent, visualizations can provide immediate and influential connections between scientists and other citizens. Utilizing these visualizations may be the best hope for nurturing popular interest, as well as helping scientists explain complex problems, while also demonstrating to the public the illustrative aspects of science and engineering. This national contest intends to recognize outstanding achievement by academic scientists, engineers, and the public in the use of visual media to promote understanding of research results.</td>
<td>Inform and educate the public; Engage new people and communities</td>
<td>Traditional methods such as the grants-approval process would be ill-suited to recognizing the outstanding performance and creation of participants� visual media. Running the Vizzies as a prize competition allows NSF to engage the general public in an interactive manner, and it allows us to partner with outside organizations to more fully realize the reach and potential of the Challenge.</td>
<td>In FY17, the total prize purse offered and awarded was $11,250. Experts� Choice winners were awarded $2,000 for each category and People�s Choice winners were awarded $250 in each category. In FY18, the total prize purse was $11,500. Up to five Experts� Choice will receive $2,000 and up to three People�s Choice will receive $500. Non-monetary incentives include featuring winning entries on PopSci.com and on NSF.gov.</td>
<td>Entries were solicited via email listservs, social media (facebook/twitter/Instagram/etc.) and social media advertisements, postcards distributed at various events, sessions/talks at various events.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Eligibility requirements stipulated that team leads must be U.S. citizens, nationals or permanent residents; all entrants must be 18 years or older; entries must convey science, technology, engineering, and/or mathematics principles; and entries must not advertise or promote a commercial product visually or orally.</td>
<td>Vizzies judging is completed in three phases. In each phase, judges evaluated visual impact (50%), effective communication (30%), and freshness and originality (20%). For the first and second rounds, judges were primarily program officers, science assistants, and American Association fo the Advancement of Science Fellows at NSF. For the third round of judging, experts in scientific visualization, art, publishing, and media evaluated entries. As part of the third round, members of the public were also invited to vote on their favorite entry.</td>
<td>A total of 372 entries were submitted between January 15, 2018 and April 18, 2018. Ten prizes were awarded in 2017 and eight prizes will be awarded in 2018, one prize was later retracted.</td>
<td>One FTE (in both FY17 and FY18) was responsible for managing the Vizzies competition. This included answering inquiries, working with contractors on setup, editing and working with other office members to update the website, as well as managing the application, submission, and evaluation processes. In FY17, $35,000 for the competition was disbursed through a contract with PostModern to entry platform company WizeHive. In FY18, $40,000 was disbursed through PostModern to entry platform company Skild. An additional $3,000 left over from a previous competition NSF had run with Skild was transferred to the Vizzies account.</td>
<td>Popular Science magazine provided social media support and advertising for the competition. Additionally, the magazine has published the winners in its online edition, and will do so again for the 2018 winners. The value of this contribution is estimated at $10,000-$30,000.</td>
<td>The mission of the National Science Foundation is to fund fundamental and basic research in science and engineering across all fields of study. The Vizzies Challenge helps us to advance that mission by increasing awareness of the agency and our work. The Vizzies Challenge has historically been a valuable asset for interacting with non-traditional audiences, since the competition is open to all US citizens, nationals, and permanent residents, not just academic researchers. By combining an expert panel and a popular choice aspect to the Challenge, the public can engage with NSF in a new and novel way.</td>
<td>Software and apps; Creative (design &amp; multimedia); Technology demonstration and hardware; Analytics, visualizations, algorithms; Scientific</td>
<td>N/A</td>
</tr>
<tr>
<td>3D Multi-View Stereo Challenge</td>
<td>Intelligence Advanced Research Projects Activity (IARPA)</td>
<td>National Security Act, 50 USC 3024(n)</td>
<td>This competition was completed in FY17 and prizes were distributed in FY18.</td>
<td>There were several goals for the Multi-View Stereo Challenge.  The main goal was to encourage the development of an algorithm better than the current state of the art. The winning algorithm would then be provided as an open source baseline for generating 3D point clouds for others to use and try to improve, and  the top algorithm, along with the competition data, would be hosted online indefinitely to encourage further algorithm development. Thus, this challenge will allow individuals outside the IC in the computer vision community to develop algorithms for satellite imagery.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>IARPA uses prize challenges to reach a broad audience of scientific thinkers, including those in other parts of the world, and have them participate in research problems of interest to the Intelligence Community (IC). The prize challenges are a way to quickly identify new research methods, ways of thinking, and perspectives that can be applied to IC problems and IARPA programs. Prizes can be awarded in a more agile way than a traditional grant or procurement contract, and challenge problems are posed so that participants can deliver results and prototypes on shorter timelines.</td>
<td>The total prize purse offered and awarded was $100,000. $84,000 of the prize purse was paid out in FY17 and the remainder was distributed in FY18. Prize awards in the Explorer Challenge break down as follows: First Place - $5,000, Second Place - $4,000, Third Place - $3,000, Fourth Place - $2,000, Fifth Place - $1,000, Best Feedback - $1,000. Prize awards in the Master Challenge break down as follows: First Place - $20,000, Second Place - $16,000, Third Place - $11,000, Fourth Place - $7,000, Fifth Place - $5,000, Bonus Opportunities - $12,000, Open Source Award (x3) $5,000. Non-monetary incentives included the opportunity for winners to present their solutions at a government and industry workshop on the challenge.</td>
<td>A presentation was made at the Conference on Computer Vision and Pattern Recognition to solicit feedback and participation. Additionally, members from academia, the computer vision field, and other computer vision entities were targeted for participation. The challenge attracted a wide audience of competitors from various fields, as well as participation from within the Topcoder community.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition</td>
<td>The target audience for this challenge was data scientists, computer vision programmers, and others interested in the realm of data satellite imagery. Solvers 18 and over were eligible, including those from around the globe, with the exception of those who reside in Iran, Cuba, North Korea, Crimea Region of Ukraine, Sudan, or Syria. In addition, those who are on the Specially Designated Nationals list promulgated and amended, from time to time, by the United States Department of the Treasury were ineligible.</td>
<td>For this data science competition, there was a data set released with training data and test data for solvers to work with. They created their algorithms and submitted results to a holdback data set that calculated a provisional leaderboard that alerted people to progress over the duration of the challenge. At the end of the challenge, the algorithms were run against a final data set the solvers had not seen or interacted with. This final score and review of their code resulted in the winning solution being selected. Solvers were also asked to document their algorithms and code for final evaluation to ensure that the code was understandable and doing what was intended in the challenge. There was in introductory Explorer Challenge Phase and an advanced Master Challenge Phase to the competition.</td>
<td>Between July and October 2016, the Explorer Challenge drew 686 registrants with 16 active competitors and the Master Challenge drew 369 participants with 24 active competitors. Thirteen prizes were awarded to 10 winners.</td>
<td>N/A</td>
<td>N/A</td>
<td>This IARPA public prize challenge has resulted in immediate major outcomes of benefit to the intelligence community and also the public community of remote sensing researchers. Three Open Source solutions were made public via the challenge and posted on the challenge website. Results of the prize challenge indicate the best performing research solutions are based on the Satellite Stereo Pipeline (S2P), the RPC Stereo Processor, and the NASA Ames Stereo Pipeline (ASP). As a result of prize incentives from the challenge, multi-view stereo solutions based on S2P and ASP are being open sourced. All source imagery, ground truth LIDAR, and metric analysis software for the prize challenge has been publicly released as a commercial satellite benchmark to support the research community. This data is made available at http://www.jhuapl.edu/satellite-benchmark.html. The best research solutions from the challenge are based on variations of the Semi-Global Matching dynamic programming algorithm first published by Hirschmuller in 2008. This establishes a baseline for further research.</td>
<td>Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>Disguised Faces in the Wild Competition</td>
<td>IARPA</td>
<td>National Security Act, 50 USC 3024(n)</td>
<td>This competition was launched and completed in FY18.</td>
<td>The goal of the Disguised Faces in the Wild Competition was to advance the performance of face recognition on disguised or obfuscated faces. With recent advancements in deep learning, the capabilities of automatic face recognition have been significantly increased. However, face recognition in an unconstrained environment with non-cooperative users is still a research challenge, pertinent for users such as law enforcement agencies. While several covariates such as pose, expression, illumination, aging, and low resolution have received significant attention, �disguise� is still considered an arduous covariate of face recognition.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Other - Benchmark state of the art</td>
<td>IARPA uses prize challenges to reach a broad audience of scientific thinkers, including those in other parts of the world, and have them participate in research problems of interest to the intelligence community (IC). The prize challenges are a way to quickly identify new research methods, ways of thinking, and perspectives that can be applied to IC problems and IARPA programs. Prizes can be awarded in a more agile way than a traditional grant or procurement contract, and challenge problems are posed so that participants can deliver results and prototypes on shorter timelines.</td>
<td>The total prize purse offered and awarded was $25,500. Six prizes were awarded: first ($6,000) and second ($2,500) place in Overall Recognition Accuracy, Impersonation Recognition, and Obfuscation Recognition. Non-monetary incentives included the opportunity to present at the 2018 Institute of Electrical and Electronics Engineers (IEEE) Computer Vision and Pattern Recognition Conference.</td>
<td>The prize challenge was advertised through challenge.gov and http://iab-rubric.org/DFW/dfw.html with all rules and participation instructions. Organizations signed a participation agreement with Indraprastha Institute of Information Technology (IIIT)-Delhi and submitted executable software to them for evaluation. The target audience for this challenge were academic and industry researchers in face recognition.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td> N/A</td>
<td>IIIT-Delhi evaluated the performance of submitted algorithms by conducting standardized biometric tests involving a sequestered test and evaluation dataset. Metrics and evaluation conditions were published in the prize challenge rules ahead of time.</td>
<td>Of the 12 entries submitted between January 20 and May 1, 2018, six prizes were awarded to two winners.</td>
<td>N/A</td>
<td>Non-Federal partners included the University of Maryland, IBM, and IIIT-Delhi.</td>
<td>Face recognition is used in many U.S. Government missions, including counter terrorism, criminal justice, and national security. This prize challenge allowed IARPA to engage the wider academic and commercial research communities developing face recognition software to stimulate advances in unconstrained face recognition as well as to benchmark the state of the art of existing solutions.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>Functional Map of the World (FMOW) Challenge</td>
<td>IARPA</td>
<td>National Security Act, 50 USC 3024(n)</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>Recent advances in computing capabilities have led to deep learning algorithms and great advances in computer vision and machine learning. The goal of the Functional Map of the World Challenge was to encourage researchers to apply such techniques to provide an understanding of satellite images and develop machine learning algorithms that would successfully predict the functional use of buildings and land use.  To satisfy the desired data driven techniques, one million annotated images were generated and placed online.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>IARPA uses prize challenges to reach a broad audience of scientific thinkers, including those in other parts of the world, and have them participate in research problems of interest to the Intelligence Community (IC). The prize challenges are a way to quickly identify new research methods, ways of thinking, and perspectives that can be applied to IC problems and IARPA programs. Prizes can be awarded in a more agile way than a traditional grant or procurement contract, and challenge problems are posed so that participants can deliver results and prototypes on shorter timelines.</td>
<td>The total prize purse offered was $112,500 and the total amount awarded was $107,500. Prize awards in the FMOW Challenge break down as follows: First Place - $25,00, Second Place - $16,000, Third Place - $12,000, Fourth Place - $8,000, Fifth Place - $5,000, Undergrad - $5,000, Open Source (x3) - $5,000, Best POI - $5,000, Progress Prizes (x3) - $3,000, Workshop Presenter (x5) $2,500. The Prizes covered participation in the challenge, with a set aside of travel money awarded for those selected to travel to the final workshop held by IARPA in conjunction with SpaceNet. At the final workshop, the winners were able to present their solution to a government group interested in Geospatial Imagery.</td>
<td>Participants in the previous Multi-View Stereo 3D Challenge were solicited along with members from academia, the computer vision field, and other computer vision entities. The challenge attracted a wide audience of competitors from various fields, as well as participation from within the Topcoder community.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition</td>
<td>The target audience for this challenge was data scientists, computer vision programmers, and others interested in the realm of satellite imagery data. Solvers 18 and over were eligible, including those from around the globe, with the exception of those who reside in Iran, Cuba, North Korea, Crimea Region of Ukraine, Sudan, or Syria. In addition, those who are on the Specially Designated Nationals list promulgated and amended, from time to time, by the United States Department of the Treasury were ineligible.</td>
<td>For this data science competition, there was a data set released with training data and test data for solvers to work with. They created their algorithms and submitted results to a holdback data set that calculated a provisional leaderboard that alerted people to progress over the duration of the challenge. At the end of the challenge, the algorithms were run against a final data set the solvers had not seen or interacted with previously. This final score and review of their code identified the winning solution. Solvers were also asked to document their algorithms and code for final evaluation to ensure that the code was understandable and doing what was intended in the challenge.</td>
<td>A total of 858 registered participants generated 1408 entries (submitted by 69 participants) between September and December 2017. Ten prizes were awarded to 11 winners.</td>
<td>N/A</td>
<td>N/A</td>
<td>IARPA released the full data set, including the sequestered data, on SpaceNetTM after the challenge in order to further scientific research on the data. See https://spacenetchallenge.github.io/datasets/fmow_summary.html for more information. Data is now available for free to download, removing the cost burden to efficiently accessing the data. Three open source solutions released to the public to allow the computer vision community to keep working on improved solutions.</td>
<td>Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>Fusion of Face Recognition Algorithms (FOFRA)</td>
<td>IARPA</td>
<td>National Security Act, 50 USC 3024(n)</td>
<td>This competition was launched and completed in FY18.</td>
<td>How can the data outputs of multiple face recognition algorithms be leveraged to improve overall accuracy? There is a large literature on biometric fusion intended to improve accuracy via fusion of multiple modalities (e.g., face + fingerprint), multiple algorithms, or multiple samples. However, most of the research has only addressed one-to-one (1:1) verification at the score level. This prize challenge is aimed at stimulating research into methods to improve one-to-many (1:N) identification accuracy via template-level fusion. Further accuracy gains could be realized by fusing feature-level templates or through more innovative score-level fusion methods informed by modern data science.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology</td>
<td>IARPA uses prize challenges to reach a broad audience of scientific thinkers, including those in other parts of the world, and have them participate in research problems of interest to the intelligence community (IC). The prize challenges are a way to quickly identify new research methods, ways of thinking, and perspectives that can be applied to IC problems and IARPA programs. Prizes can be awarded in a more agile way than a traditional grant or procurement contract, and challenge problems are posed so that participants can deliver results and prototypes on shorter timelines.</td>
<td>The total prize purse offered was $70,000, but no working submissions were received. There were five prizes available, though none were awarded: Verification Score-level Fusion ($8,000), Verification Template-level Fusion ($16,000), Identification Score-level Fusion ($11,000), Identification Template-level Fusion (Two-way) ($18,000), and Identification Template-level Fusion (Three-way) ($17,000).</td>
<td>The prize challenge was advertised through iarpa.gov, challenge.gov, and nist.gov with all rules and participation instructions. Organizations signed a participation agreement with the National Institute of Standards and Technology (NIST) and submitted executable software to NIST for evaluation. IARPA is in the process of evaluating the prize challenge to determine lessons learned so as to inform how or if to proceed with re-launching the challenge. The challenge received 16 requests for the training/validation data, which is low for a biometrics challenge but still significant enough that more submissions were expected.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td> N/A</td>
<td>No evaluation was performed due to a lack of functioning software submissions. NIST was to evaluate the performance of submitted algorithms by conducting standardized biometric tests involving a sequestered testing and evaluation dataset. Metrics and evaluation conditions were published in the prize challenge rules ahead of time. Results were to be presented to a panel of U.S. Government employee judges who then would select winners based on technical performance.</td>
<td>One entry was submitted between May 23 and August 6, 2018. No prizes were awarded.</td>
<td>N/A</td>
<td>IARPA partnered with NIST for this challenge.</td>
<td>Face recognition is used in many U.S. Government missions, including counter terrorism, criminal justice, and national security. Face recognition error rates, particularly on uncontrolled face imagery, are well above zero. While algorithm development has seen considerable investment, other mechanisms for improving accuracy are known. Among them, there is a large academic literature on biometric fusion, covering multimodal and multi-algorithmic fusion. It shows that substantial accuracy gains can be made over using a single mode, or a single algorithm alone, and this can be achieved, in large part, using quite simple methods. The gains decrease when the fused inputs are correlated. The vast majority of the literature addresses biometric verification, rather than identification. Moreover, the literature covers score-level fusion rather than feature (i.e. template) level fusion. The latter, on information theoretic grounds, offers greater accuracy gains at the expense of some complexity.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>Geopolitical Forecasting Challenge</td>
<td>IARPA</td>
<td>National Security Act, 50 USC 3024(n)</td>
<td>This competition was launched in FY18 and is underway.</td>
<td>Decision makers rely on the Intelligence Community (IC) to provide accurate and relevant geopolitical forecasts, and IARPA is working to identify methods to maximize the quality of these forecasts. The Geopolitical Forecasting (GF) Challenge sought to crowdsource innovative algorithms for integrating crowdsourced forecasts and other data into accurate, timely forecasts on worldwide issues. The effort was run in parallel to IARPA�s geopolitical forecasting research program Hybrid Forecasting Competition (HFC). Challenge Solvers competed on a largely overlapping set of Individual Forecasting Problems (IFPs) as HFC research teams and were given access to the same human forecaster data stream. In addition to the provided data stream, solvers were free to use other data streams and existing/developed models for the challenge.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research</td>
<td>IARPA uses prize challenges to reach a broader audience of scientific thinkers, including those in other parts of the world, and have them participate in research problems of interest to the IC. The prize challenges are a way to quickly identify new research methods, ways of thinking, and perspectives that can be applied to IC problems and IARPA programs. Prizes can be awarded in a more agile way than a traditional grant or procurement contract, and challenge problems are posed so that participants can deliver results and prototypes in shorter timelines.</td>
<td>The total prize purse offered amounts to $200,000. The first place overall prize is $20,000, and the second through fifth place overall prizes are $12,000, $10,000, $7,000, and $4,000, respectively. A bonus �Ultimate Forecaster� award with a total value of $40,000 was available to the solver who finished in first place. Additional bonus awards included the Star Forecaster awards, which provides for $30,000 split amongst all eligible solvers/teams. Additional incentives and milestone prizes include a Best in Domain/Region Pair prize purse of $25,000 (five awards of $5,000 each), a Best Undergraduate award of $4,000, a Milestone 1 award of $7,500 (ten awards of $750 each), a Milestone 2 award of $10,000 (ten awards of $1,000 each), a Milestone 3 award of $12,500 (ten awards of $1,250 each), an Election Forecaster Award of $10,000, a Spring Forecaster award of $2,400 (three awards of $800 each), an Interim Prize of $2,600, and a Workship Presenter Prize of $2,500. Non-monetary incentives included an opportunity to interact with IARPA Program Manager Dr. Seth Goldstein, and attendance at the IARPA Hybrid Forecasting Competition Principal Investigator meeting/GFChallenge workshop.</td>
<td>GF Challenge Solvers submitted their forecasts via a platform built by Cultivate Labs. They were able to access the IFPs, submit their forecasts, view a leaderboard, and view their scores on the various IFPs through this platform. Solvers were also required to submit a Final Solver Document, where they provided greater context and explanation for their solutions in a narrative format.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>To be eligible to win a prize under this competition, an individual or entity: (1) Must have completed and submitted a registration form at HeroX GF Challenge; (2) Must be an individual or team each member of which is 18 years of age or over, or an incorporated entity; and (3) May not be a Federal entity or Federal employee acting within the scope of their employment. An individual or entity shall not be deemed ineligible because the individual or entity used Federal facilities or consulted with Federal employees during a competition if the facilities and employees are made available to all individuals and entities participating in the competition on an equitable basis. Some participating individuals or organizations were not eligible for prizes. However, these solvers did have the opportunity, upon IARPA approval, to participate in the challenge and be eligible for ranking on the leaderboard.</td>
<td>For most of the prize categories, the score was the sum of solvers� Net Brier Points (NBPs) over all germane IFPs for that category. NBPs measure solver performance versus a baseline based on current state-of-the-art human forecast collection and aggregation methods derived from the IARPA ACE program. To be eligible for overall prizes, solvers needed to have attempted at least 70% of all IFPs and have positive NBPs (i.e., beat the state-of-the-art baseline) on more than 50% of IFPs attempted. For overall performance prize bonuses, solvers needed to meet qualifying criteria listed above and additionally beat the GF Challenge Baseline and HFC Top score. To be eligible for milestone or domain/region prizes a solver must have submitted forecasts for at least 80% of the IFPs considered for that prize. For Milestone Prizes, only the IFPs that were resolved during that time period counted for that Milestone�s prizes. IFPs that were opened, but not resolved, during a Milestone did not count. Those IFPs were counted towards the Milestone period in which the IFP resolves. Net Brier Points were calculated using a metric, based on the Brier score, which incorporates forecast accuracy, timeliness, and confidence in contrast to the state-of-the-art baseline. This baseline was available to solvers via the Cultivate Labs platform. HFC Top Score was the top scoring method, coming out of the parallel HFC research program; it was visible on the leaderboard during the challenge.</td>
<td>There were 17 participants in this challenge.  A total of 46 prizes were awarded to 10 participants, totaling $125,150.  One challenge participant, a University Affiliated Research Center, relinquished prizes in order to be eligible for the competition.  Eight participants had forecast methods that outperformed the benchmark, which was the prior state of the art in forecast aggregation from the IARPA ACE program.  These methods also outperformed the best HFC methods, albeit with relaxed participation rules as compared with the HFC Performers.</td>
<td>N/A</td>
<td>N/A</td>
<td>IARPA�s mission is to envision and lead high-risk, high-payoff research that delivers innovative technology for future overwhelming intelligence advantage. The GF Challenge invited Solvers from around the world to develop solutions that produced probabilistic forecasts in response to numerous closed-ended forecasting questions that concerned specific, objectively verifiable geopolitical events containing timeframes with deadlines and locations. Questions like: Who will win the upcoming presidential election in Egypt? What will the spot price of Brent Crude oil be on [date]? This challenge directly advanced IARPA�s mission to engage the public by challenging them to develop solutions that are capable of processing data and making forecasts. Methods that outperformed the state-of-the-art or HFC Performer methods overall, or on specific subsets of forecasting questions (e.g., for particular regions or topics) have the potential to inform geopolitical forecasting within the intelligence community.</td>
<td>Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>Mercury Challenge</td>
<td>IARPA</td>
<td>National Security Act, 50 USC 3024(n)</td>
<td>This competition was launched in FY18, and is underway.</td>
<td>In an effort to provide early warning capabilities, the Department of Defense�s Integrated Crisis Early Warning System and IARPA�s Open Source Indicators programs want to leverage novel statistical and machine learning techniques using publicly available data sources to forecast societal such as civil unrest and disease outbreaks with a high degree of accuracy. Participants are encouraged to develop and test innovative forecasting methods that ingest and process publicly available data sources to predict military activity, non-violent civil unrest, and infectious disease in specific places of interest.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Engage new people and communities</td>
<td>IARPA uses prize challenges to reach a broad audience of scientific thinkers, including those in other parts of the world, and have them participate in research problems of interest to the intelligence community (IC). The prize challenges are a way to quickly identify new research methods, ways of thinking, and perspectives that can be applied to IC problems and IARPA programs. Prizes can be awarded in a more agile way than a traditional grant or procurement contract, and challenge problems are posed so that participants can deliver results and prototypes on shorter timelines.</td>
<td>The total prize purse offered is $100,000. During the first scoring period, $21,000 will be given out to six total winners. During the second scoring period, $79,000 will be given out to nineteen total winners.</td>
<td>The challenge was marketed through press release, media hits, social media, email outreach, two early Q&amp;A sessions, and a community day. The challenge was also marketed to the Topcoder community.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Other - WeWork; Other - Topcoder</td>
<td>To be eligible to win a prize under this competition, an individual or entity: must be an individual or team each of whose members are 18 years of age and over, or an incorporated entity; may not be a Federal entity or Federal employee acting within the scope of their employment. An individual or entity shall not be deemed ineligible because the individual or entity used Federal facilities or consulted with Federal employees during a competition if the facilities and employees are made available to all individuals and entities participating in the competition on an equitable basis. Federal grantees may not use Federal funds to develop challenge solutions unless consistent with the purpose of their grant award. Federal contractors may not use Federal funds from a contract to develop challenge applications or to fund efforts in support of a challenge submission.</td>
<td>For military activity forecasts, the effectiveness of each participant�s methods will be judged using the following metrics: (1) Lead Time, the number of days between the date the forecast was produced and the date the actual event was reported; (2) F-Score, the harmonic mean of Precision; and (3) Recall Quality Score (QS), the similarity of warning details to event details in terms of the distance between the warning location and the event location, the number of days between the warning Event Date and the actual Event Date, and agreement between warning and event actor and event subtype. QS is measured on a scale of 0.0 to 4.0. For count forecasts, which include civil unrest (CU) events and disease, the effectiveness of each participant�s methods will be judged using the following metrics: (1) Lead Time, the average number of days between the date the forecasted count was submitted and the effective Event Date; (2) Weekly Counts, where the week is defined as the International Organization for Standardization week, which starts on Monday and ends on Sunday; (3) Monthly Counts, where the effective Event Date is the 15th of the month; and (4) Quality Score, the average quality score of each valid forecast (ranges from 0 to 1), which is based on the difference between the forecast count and the actual count. Ranking of participants who achieve these two thresholds will be done using Quality Score carried to three significant digits. In the event of a tie additional significant digits will be used to determine the final winners. The Mercury Challenge will compare participant submissions against a �base rate� model. Base Rate models are models that only use information included in the history of observed events. It is expected that Participant models will score better than the base rate models. The top scorers who beat the baseline will be awarded the Best Overall prize(s).</td>
<td>At the time of this report, no prizes have been awarded. The challenge is broken up into two separate scoring periods: (1) August 7 to October 31, 2018, and (2) November 1, 2018 to January 31.</td>
<td>N/A</td>
<td>N/A</td>
<td>IARPA�s mission is to lead high-risk, high-payoff research that delivers innovative technology for future overwhelming intelligence advantage. The Mercury Challenge invited technologists, data scientists, and machine learning engineers who are skilled at breaking down complex data to participate. Surprise events such as the fall of the Berlin Wall, Iraq�s invasion of Kuwait, the civil unrest that gave rise to the Arab Spring, and Russian incursions into Ukraine, forced rapid responses in the absence of data related to the underlying causes of these events. IARPA aims to connect the dots that lead up to events such as these. This challenge directly advances IARPA�s mission to engage the public by challenging them to develop solutions by making forecasts.</td>
<td>Ideas; Analytics, visualizations, algorithms</td>
<td>N/A</td>
</tr>
<tr>
<td>MORGOTH�S CROWN (Modeling of Reflectance Given Only Transmission of High-Concentration Spectra for Chemical Recognition over Widely-Varying Environments)</td>
<td>IARPA</td>
<td>National Security Act, 50 USC 3024(n)</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The aim of MORGOTH�S CROWN challenge was to crowdsource breakthroughs in infrared (IR) spectral modeling that could enable predictions of trace chemical spectra on a surface from bulk reflectance or absorption spectra. A major hurdle for active/passive-standoff detection in real-world settings is compensating for spectral changes due to chemical or physical interactions of chemicals with a substrate and/or from physical characteristics of the chemical (e.g., particle size and shape, deposition, thickness, etc.). An improved or breakthrough IR spectral model would enable easier construction of more comprehensive and robust chemical detection libraries that would enhance passive or active infrared chemical detection probabilities in complex environments. Participants were asked to generate an algorithm that would predict the spectra of combinations of chemicals and substrates that were not used in the training data. For example, if the training set involved caffeine layered on aluminum, participants could have been asked to predict the spectra of caffeine on glass or acetaminophen on aluminum.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity</td>
<td>IARPA uses prize challenges to reach a broad audience of scientific thinkers, including those in other parts of the world, and have them participate in research problems of interest to the intelligence community (IC). The prize challenges are a way to quickly identify new research methods, ways of thinking, and perspectives that can be applied to IC problems and IARPA programs. Prizes can be awarded in a more agile way than a traditional grant or procurement contract, and challenge problems are posed so that participants can deliver results and prototypes in shorter timelines.</td>
<td>The total prize purse offered was $50,000 and the total amount awarded was $49,500. The top five awards were distributed as follows: First Place: $20,000, Second Place: $15,000, Third Place: $10,000, Fourth Place: $2,000, and Fifth Place: $1,000. Three bonus prizes were offered, to include: Progress Prize 1: $1,000, Progress Prize 2: $500, Progress Prize 3: $500 (not awarded). Non-monetary incentives included the opportunity to present solutions at a government workshop.</td>
<td>The target audience were members of academia, small businesses, and experts across the globe who deal with spectroscopy, chemistry, physics, etc. We reached out via email and social media and marketed through the Topcoder platform in addition to listing on Challenge.gov. Outreach hit over 2,000 email contacts.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Other - Topcoder solvers pool</td>
<td>The challenge targeted chemists, computer scientists, the machine learning community, and anyone else who may want to participate in a data analysis challenge. U.S. and foreign participants were solicited. The only limitation on participation was that anyone affiliated with either a SILMARILS (Standoff ILluminator for Measuring Absorbance and Reflectance Infrared Light Signatures) program performer or test and evaluation team member had to recuse themselves from winning prizes, but could participate and be scored.</td>
<td>An automated scoring function based on a non-linear combination of Spectral Information Divergence and Spectral Angle Mapper metrics was used to provide an overall �closeness of fit� score between the predicted spectra and the measured ground truth data (test data set), with higher scores indicating better fits. Challenge participants were provided with their composite score, and allowed to submit multiple predictions of the test data set over the course of the challenge in order to iteratively improve their algorithms. At the conclusion of the challenge the ten highest scoring participants submitted their algorithm code to the MORGOTH�S CROWN challenge team, where the algorithms were run to provide predictions of an additional 18 different substrate and chemical morphology combinations which the participants had never seen or been able to score their algorithm against during development (validation data set). Scores against this validation set were used to determine the final challenge rankings and prizes.</td>
<td>Of the 664 entries submitted by 37 participants between July 26 and September 20, 2017, seven prizes were awarded to five winners.</td>
<td>N/A</td>
<td>N/A</td>
<td>IARPA�S MORGOTH�S CROWN prize challenge was a crowdsourced effort to encourage new approaches in infrared spectral modeling to quantitatively predict trace spectra on surfaces from bulk reflectance spectra. All algorithm development methods and algorithm types were allowed, ranging from traditional first-principle physics based models to pure machine learning approaches. After developing and training their algorithm using the training data set, which was provided with full characterization and metadata, performers were asked to submit spectral predictions for 18 different substrate and chemical morphology combinations. The results of the MORGOTH�S CROWN challenge showed that machine-learning based approaches were better able to quantitatively predict new spectra than physics-based models. This indicates that new approaches to chemical spectral prediction, which is important for detecting traces of explosives, narcotics, and other chemical hazards on surfaces are needed.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>Nail-to-Nail (N2N) Fingerprint Challenge</td>
<td>IARPA</td>
<td>National Security Act, 50 USC 3024(n)</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The goal of the N2N Challenge was to improve biometric fingerprint collection and recognition systems by eliminating plain fingerprint captures. IARPA was looking for new and innovative approaches to developing an N2N fingerprint capture device that: (1) Does not require a human operator (though verbal instructions can be provided); (2) Is capable of collecting full nail-to-nail friction ridge surfaces that lead to biometric recognition that is as good or better than existing standard human operator assisted methods; (3) Is able to capture the information in the same or less time as existing approaches; (4) Enables fully- or semi-cooperative subject interaction; (5) Uses contact or contactless capture methods; and (6) Uses novel or conventional fingerprint sensor hardware.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Engage new people and communities; Stimulate a market</td>
<td>IARPA uses prize challenges to reach a broad audience of scientific thinkers, including those in other parts of the world, and have them participate in research problems of interest to the intelligence community (IC). The prize challenges are a way to quickly identify new research methods, ways of thinking, and perspectives that can be applied to IC problems and IARPA programs. Prizes can be awarded in a more agile way than using a traditional grant or procurement contract, and challenge problems are posed so that participants can deliver results and prototypes in shorter timelines.</td>
<td>The total prize purse offered was $290,000 and the total amount awarded was $255,000. Prizes were awarded in the following manner: Print Provider (x8) - $8,000, Master Builder (x8) - $2,000, Workshop Presenter (x5) - $5,000, Best Latent Accuracy - $25,000, Fastest Scan - $25,000, Best Gallery Accuracy - $25,000, Grand Prize - $100,000. In the event that no one met the metrics for the Grand Prize, a Second Place of $15,000 and Third Place of $10,000 were to be awarded in the following categories: Best Latent Accuracy, Fastest Scan, and Best Gallery Accuracy. Non-monetary incentives included the opportunity to present findings at the N2N Workshop held at the Biometrics Congress Conference in Washington, DC.</td>
<td>The challenge was promoted on challenge.gov and iarpa.gov along with press releases, an email campaign and a social media campaign. As this was a three-stage downselect challenge, marketing was only done at the start of the challenge as new solvers could not join the challenge after the first downselect period.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>The challenge was open to all U.S. and foreign citizens, companies, teams, and any organization or single participant. Solvers were required to submit a write up, as well as safety review documents in order to participate in the Live test and undergo a safety evaluation as well as Human Subjects Training.</td>
<td>The first round of submissions were evaluated and feedback provided to participants on considerations and pros and cons of their devices in preparation for Stage 2. During Stage 2, Solvers submitted a device documentation review as well as a video demonstrating their device in action. Solvers were then judged by a government panel and those whose devices were feasible were invited to the Live Test event. During the Live Test event, Solvers captured fingerprints from human test subjects. The same human test subject prints were also captured by the baseline station run by professional hands-on print collectors as well as a set of latent prints collected by forensic examiners. At the end of the challenge, the prints were sent through a government matching system and compared against the baseline rolls for each human test subject. The matching results were used to calculate the final results of the challenge.</td>
<td>Of the 15 entries submitted by nine participants between February 2 and September 22, 2017, seven prizes were awarded to eight winners.</td>
<td>N/A</td>
<td>N/A</td>
<td>The challenge produced a new public fingerprint dataset containing 41,177 fingerprint images and 13,644 latent images, a subset of which will be released for scientific research. New methods were discovered for fingerprint scanning from academic research and prototype design using new materials and ways of thinking. The challenge compared the efficacy of current state-of-the-art COTS (commercial off the shelf) products to understand their strengths in three areas: live matching, latent matching, and speed. Areas of improvement in large-scale latent print processing and capture were identified. Finally, the challenge shed new light on the comparison of current gold-standard methods of fingerprint collection.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>OpenCLIR (Open Crosslingual Information Retrieval)</td>
<td>IARPA</td>
<td>National Security Act, 50 USC 3024(n)</td>
<td>This competition was launched in FY17 and is underway in FY18.</td>
<td>The goal of the OpenCLIR (Open Cross Language Information Retrieval) evaluation is to develop methods to locate text and speech content in documents (speech or text) in low-resource languages using English queries. This capability is one of several expected to ultimately support effective triage and analysis of large volumes of data in a variety of less studied languages. Successful systems will be able to adapt to new languages and new genres.</td>
<td>Advance scientific research; Develop technology</td>
<td>IARPA uses prize challenges to reach a broad audience of scientific thinkers, including those in other parts of the world, and have them participate in research problems of interest to the intelligence community (IC). The prize challenges are a way to quickly identify new research methods, ways of thinking, and perspectives that can be applied to IC problems and IARPA programs. Prizes can be awarded in a more agile way than using a traditional grant or procurement contract, and challenge problems are posed so that participants can deliver results and prototypes on shorter timelines.</td>
<td>The total prize purse offered is $30,000, which includes $10,000 for the Text Award and $20,000 for the Auditory Award.</td>
<td>Email lists of natural language processing practitioners, IARPA Twitter (hashtag #OpenCLIR), and a Keynote Address at a machine translation conference were used to advertise the challenge. Participants did not specify how they learned of the challenge so we have no data on which approach was most effective.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Other - Announcement in conference keynote address</td>
<td>Participants should have a background in natural language processing technology.</td>
<td>Participants were judged on two criteria: (1) performance on the CLIR detection metric, Actual Query Weighted Value (AQWV), weighted 80%, and (2) comprehensiveness of system description, weighted 20%.</td>
<td>The challenge is not yet complete. The challenge evaluation period is from March 11, 2019 to March 15, 2019 with system descriptions due March 29, 2019.</td>
<td>N/A</td>
<td>The Federal Bureau of Investigation�s National Virtual Translation Center provided annotated data for the evaluation. The National Institute of Standards and Technology provided visiting foreign researchers to run the challenge at their cost, approximately $40,000.</td>
<td>When the challenge is complete, it should advance the state of the art in low resource machine translation, cross-lingual information retrieval and automatic speech recognition.</td>
<td>Software and apps; Ideas; Scientific</td>
<td>N/A</td>
</tr>
<tr>
<td>The ODNI-OUSD(I) Xamine Challenge: Machine Verification of Collected Information</td>
<td>ODNI</td>
<td>N/A</td>
<td>This competition was launched in FY18 and is underway.</td>
<td>Machine-based approaches to generating and evaluating analytic products from disparate structured and unstructured data types are emerging areas of research for the U.S. Intelligence Community (IC). As these approaches mature beyond demonstration systems with controlled data sources, such IC systems will require a means for inspecting and ensuring the integrity of the data that are ingested by these systems. These considerations will become particularly critical as the information available to the IC�s analytic community continues to exceed the ability for traditional, human vetting.  Accordingly, the ODNI and the Office of the Under Secretary of Defense for Intelligence [OUSD(I)] are seeking ideas and descriptions of a viable technical approach for enabling the automated validation of information prior to the dissemination of machine-generated intelligence products.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>ODNI decided to use prize competitions for this topic in order to leverage funding and reach as large an audience as possible. Competitions allow more individuals and companies to be engaged and involved than traditional contracts or grants. The Xamine Challenge attracted 119 registrants.</td>
<td>The total prize purse offered is $75,000. This prize pool reflects an initial phase, with a $25,000 prize purse, and a second phase, with a $50,000 prize purse. Awards for the first phase are under evaluation, and the second phase has not yet launched. The competition is solely funded by the government and no other private sector or philanthropic funds contribute to the competition prize.</td>
<td>On 4 May 2018, the competition went live on the InnoCentive prize competition website and was posted on Challenge.gov. ODNI issued a press release and publicized the Challenge on social media. InnoCentive promoted the prize competition through their social media platforms (LinkedIn, Twitter, Facebook, and Google+) and weekly email blasts to over 140,000 solvers during the competition posting period. As a result of this outreach, 119 teams from 32 countries registered for the competition.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release</td>
<td> N/A</td>
<td>This competition has received 15 submissions that at the time of this report are being evaluated by ODNI and OUSD(I) representatives.</td>
<td>15 entries were submitted between May 4 and July 2, 2018, and at the time of this report prizes have not been awarded.</td>
<td>OUSD(I) representatives were involved in evaluating Xamine submissions. The Air Force Research Laboratory (AFRL) and Ball Aerospace managed the contracts and sub-contracts for this prize competition. InnoCentive, Inc. was utilized as a third party vendor to help plan and conduct the prize competition.</td>
<td>For this prize competition, ODNI partnered with OUSD(I), AFRL, and Ball Aerospace. ODNI used the Economy Act to ensure economical and efficient services.</td>
<td>As previously stated, as machine-driven approaches to generating and evaluating analytic products mature beyond demonstration systems, IC systems will require a means for inspecting and ensuring data integrity. Through this competition, ODNI and OUSD(I) are seeking a viable technical approach to rapidly and objectively determine the trustworthiness of input information prior to the dissemination of machine-generated intelligence products that support IC missions.</td>
<td>Software and apps; Ideas; Analytics, visualizations, algorithms</td>
<td>In FY19, the office of the Director of Science and Technology (DS&amp;T) within ODNI in partnership with OUSD(I) will sponsor two public prize competitions��Xplore� and �Xpect��to explore opportunities, using artificial intelligence techniques, to revolutionize the IC�s finished intelligence production processes. These challenges are part of a series of efforts exploring technical approaches to accelerate and automate the production of intelligence, and build on the �Xpress�, �Xtend�, and �Xamine� challenges launched in Fiscal Years 2017 and 2018. Through the Xplore Challenge, solvers will be asked to describe artificial intelligence-based approaches for enabling the automated and predictive discovery of information. The Xpect Challenge will ask solvers to describe artificial intelligence-based approaches for automating model-based indications of change.</td>
</tr>
<tr>
<td>The ODNI-OUSD(I) Xpress Challenge: Machine Generation of Analytic Products</td>
<td>ODNI</td>
<td>N/A</td>
<td>This competition was launched in FY17 and completed in FY18.</td>
<td>The primary objective of this prize competition was to determine the state-of-the-art in natural language processing (NLP). ODNI wanted to examine the feasibility of using NLP and related artificial intelligence technologies to craft analytic products with national security implications.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>ODNI decided to use prize competitions for this topic in order to leverage funding and reach as large an audience as possible. Competitions allow more individuals and companies to be engaged and involved than traditional contracts or grants. The Xpress Challenge engaged over 8,000 people with 387 registrants.</td>
<td>The total prize purse offered was $500,000, which included a top award of $100,000 for the best overall submission and $30,000 in Early STEM Education awards for high school student team submissions. The total amount awarded was $200,000, with $150,000 awarded to the first place submission, and $50,000 awarded to the second place submission. The competition was solely funded by the government and there were no other private sector or philanthropic funds contributed to the competition prize.</td>
<td>On April 6, 2017, the competition went live on the InnoCentive prize competition page and was posted on Challenge.gov. ODNI issued a press release and publicized the Challenge on social media. The Armed Forces Communications and Electronics Association interviewed ODNI and published an article promoting the Challenge on May 10, 2017. InnoCentive promoted the prize competition through their social media platforms (LinkedIn, Twitter, Facebook, and Google+) and weekly email blasts to over 140,000 solvers during the competition posting period. As a result of this outreach, over 8,000 people expressed interested in the competition and viewed the prize competition page, and 387 people from 42 countries registered for the competition.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td> N/A</td>
<td>This competition received 15 submissions that were evaluated using ODNI�s Rating Scale for Evaluating Analytic Tradecraft Standards (RSEATS). RSEATS was created and finalized before the competition launched and solvers were given access to the evaluation methodology and award schedule. The rating scale was based on how solvers demonstrated the success of their proposal, used clear and logical argumentation, and provided the source code for validation. Of the 15 submissions, 11 were asked to provide their source code and documentation in order to reproduce the submitted analytical product. InnoCentive ran validation tests on the provided source codes. The results of these tests were sent to ODNI for final review and award decision. Literal, Inferential, and Evaluative awards were based on the top Automated Indicator Sharing (AIS) scores in each category using the RSEATS evaluation criteria. An Overall Best Solution award was to be given to the solver who produced the best cumulative scores from AIS evaluation. The final category was a Creativity award. Two submissions were selected for the awards.</td>
<td>Of the 15 entries submitted between April 6 and July 5, 2017, prizes were awarded to 2 winners.</td>
<td>OUSD(I) representatives were involved in code validation in September. AFRL and Ball Aerospace managed the contracts and sub-contracts for this prize competition. ODNI�s AIS completed a blind review of the submissions and scored them based on RSEATS evaluation criteria. InnoCentive, Inc. was utilized as a third party vendor to help plan and conduct the prize competition. AFCEA International provided SIGNAL Magazine content for use by the solvers participating in the competition.</td>
<td>For this prize competition, ODNI partnered with OUSD(I),  AFRL, and Ball Aerospace. ODNI used the Economy Act to ensure economical and efficient services.</td>
<td>ODNI and OUSD(I) issued this challenge in order to understand the state of scientific advancement towards machine-generated intelligence, as advances in this area promise to reduce the amount of time devoted to thinking, understanding, and acting on the intelligence rather than just generating it. To do this, the  challenge posed a representative question and asked respondents to use a completely automated system to sift through text reports and generate a finished intelligence product. ODNI and OUSD(I) did not seek any rights in the systems used to generate the product, as the focus is on assessing the state of the art in the area of machine-generated intelligence. Systems capable of winning this Challenge would be of use not just within the intelligence community, but across government agencies and the business worldwide.</td>
<td>Software and apps; Technology demonstration and hardware; Analytics, visualizations, algorithms</td>
<td>In FY19, the office of the Director of Science and Technology (DS&amp;T) within ODNI in partnership with OUSD(I) will sponsor two public prize competitions��Xplore� and �Xpect��to explore opportunities, using artificial intelligence techniques, to revolutionize the IC�s finished intelligence production processes. These challenges are part of a series of efforts exploring technical approaches to accelerate and automate the production of intelligence, and build on the �Xpress�, �Xtend�, and �Xamine� challenges launched in Fiscal Years 2017 and 2018. Through the Xplore Challenge, solvers will be asked to describe artificial intelligence-based approaches for enabling the automated and predictive discovery of information. The Xpect Challenge will ask solvers to describe artificial intelligence-based approaches for automating model-based indications of change.</td>
</tr>
<tr>
<td>The ODNI-OUSD(I) Xtend Challenge: Machine Evaluation of Analytic Products</td>
<td>ODNI</td>
<td>N/A</td>
<td>This competition was launched in FY18 and is underway.</td>
<td>The evaluation of analytic products is an area ripe for exploring new technological capabilities and approaches. Currently, intelligence products are reviewed�prior to publication�by numerous levels of management and edited against an IC agency�s signature style using essentially the same methods as publishers have used for generations. The ODNI and OUSD(I) sought ideas and descriptions of a viable technical approach for enabling the automated evaluation of finished intelligence products.</td>
<td>Find and highlight innovative ideas; Advance scientific research; Develop technology; Inform and educate the public; Engage new people and communities</td>
<td>ODNI decided to use prize competitions for this topic in order to leverage funding and reach as large an audience as possible. Competitions allow more individuals and companies to be engaged and involved than traditional contracts or grants. The Xtend Challenge attracted 186 registrants.</td>
<td>The total prize purse offered was $75,000.  This prize pool reflects an initial phase, with a $25,000 prize purse and a second phase, with a $50,000 prize purse. Awards for the first phase have been completed, and the second phase is underway. The competition was solely funded by the government and there were no other private sector or philanthropic funds contributed to the competition prize.</td>
<td>On November 16, 2017, the competition went live on the InnoCentive prize competition page and was posted on Challenge.gov. ODNI issued a press release and publicized the Challenge on social media. InnoCentive promoted the prize competition through their social media platforms (LinkedIn, Twitter, Facebook, and Google+) and weekly email blasts to over 140,000 solvers during the competition posting period. As a result of this outreach, 186 teams from 32 countries registered for the competition. The prize competition press release was issued on November 16, 2017.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release</td>
<td> N/A</td>
<td>This competition received 18 submissions that were evaluated by ODNI and OUSD(I) representatives. Of the 18 submissions, 3 were selected for initial awards from the $25,000 prize pool and asked to provide additional information regarding their solution.  Final determination of awards from the remaining $50,000 prize pool is still pending.</td>
<td>Of the 18 entries submitted between November 16, 2017 and January 15, 2018, three prizes were awarded in the first phase. At the time of this report, prizes for the second phase have not been awarded.</td>
<td>OUSD(I) representatives were involved in evaluating Xtend submissions. AFRL and Ball Aerospace managed the contracts and sub-contracts for this prize competition. InnoCentive, Inc. was utilized as a third party vendor to help plan and conduct the prize competition.</td>
<td>For this prize competition, ODNI partnered with OUSD(I),  AFRL, and Ball Aerospace. ODNI used the Economy Act to ensure economical and efficient services.</td>
<td>The ODNI and OUSD(I) issued this challenge to determine a viable technical approach for enabling the automated evaluation of finished intelligence products. The evaluation of analytic products is an area ripe for exploring new technological capabilities and approaches. Currently, intelligence products are reviewed�prior to publication�by numerous levels of management and edited against an IC agency�s signature style using essentially the same methods as publishers have used for generations.  This human-based approach is highly subjective and introduces latency that constrains the IC�s ability to produce effective and timely intelligence products, and may inhibit potential gains offered by advanced analytics and computational methods. For this Ideation Challenge, Solvers are asked to submit their ideas along with a well-supported, technology-based justification for how the proposed approach could evaluate analytic intelligence products. An additional award pool was available for solvers who were able to provide more detailed information such as a pseudo-code implementation of their proposed solution.</td>
<td>Software and apps; Ideas; Analytics, visualizations, algorithms</td>
<td>In FY19, the office of the Director of Science and Technology (DS&amp;T) within ODNI in partnership with OUSD(I) will sponsor two public prize competitions��Xplore� and �Xpect��to explore opportunities, using artificial intelligence techniques, to revolutionize the Intelligence Community�s (IC) finished intelligence production processes. These challenges are part of a series of efforts exploring technical approaches to accelerate and automate the production of intelligence, and build on the �Xpress�, �Xtend�, and �Xamine� challenges launched in Fiscal Years 2017 and 2018. Through the Xplore Challenge, solvers will be asked to describe artificial intelligence-based approaches for enabling the automated and predictive discovery of information. The Xpect Challenge will ask solvers to describe artificial intelligence-based approaches for automating model-based indications of change.</td>
</tr>
<tr>
<td>UG2 Prize Challenge</td>
<td>IARPA</td>
<td>National Security Act, 50 USC 3024(n)</td>
<td>This competition was launched and completed in FY18.</td>
<td>This challenge sought to answer important questions for general applications related to computational photography and scene understanding, such as: What is the current state-of-the art for image restoration and enhancement applied to images acquired under less than ideal circumstances? Or, can the application of enhancement algorithms as a pre-processing step improve image interpretability for manual analysis or automatic visual recognition to classify scene content? As a well-defined case study, the challenge aimed to advance the analysis of images collected by small unmanned aerial vehicles (UAVs) by improving image restoration and enhancement algorithm performance using the UAVs, Glider and Ground data (UG2) Dataset.</td>
<td>Solve a specific problem; Advance scientific research; Develop technology; Other -Benchmark state of the art</td>
<td>IARPA uses prize challenges to reach a broad audience of scientific thinkers, including those in other parts of the world, and have them participate in research problems of interest to the intelligence community (IC). The prize challenges are a way to quickly identify new research methods, ways of thinking, and perspectives that can be applied to IC problems and IARPA programs. Prizes can be awarded in a more agile way than a traditional grant or procurement contract, and challenge problems are posed so that participants can deliver results and prototypes on shorter timelines.</td>
<td>The total prize purse offered and awarded was $75,000. This includes two award categories, Image Enhancement to Facilitate Manual Inspection and Image Enhancement to Improve Automatic Object Recognition, each with first and second place prizes of $25,000 and $12,500, respectively. Non-monetary incentives included an opportunity to present at the 2018 IEEE Computer Vision and Pattern Recognition Conference.</td>
<td>The prize challenge was advertised through iarpa.gov, challenge.gov, and http://www.ug2challenge.org/ with all rules and participation instructions. Organizations signed a participation agreement with the University of Notre Dame and submitted executable software to them for evaluation.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td> N/A</td>
<td>The University of Notre Dame evaluated the performance of submitted algorithms by conducting standardized tests involving a sequestered test and evaluation dataset. Metrics and evaluation conditions were published in the prize challenge rules ahead of time. Results were presented to a panel of subject matter expert judges who then selected winners based on technical performance.</td>
<td>Of the 12 entries submitted by six participants between January 31 and April 15, 2018, four prizes were awarded to three winners.</td>
<td>N/A</td>
<td>The University of Notre Dame was the non-Federal partner for this challenge.</td>
<td>The advantages of conducting visual surveillance from a platform like a small UAV are clear. Man-portable systems can be launched from safe positions to penetrate difficult or dangerous terrain, acquiring hours of video without putting human lives at risk. What is unclear is how to automate the interpretation of these images, a necessary measure in the face of millions of frames from individual flights. Human analysts cannot manually sift through data of this scale for actionable intelligence information. Ideally, a computer vision system would be able to identify objects, events, and human identities of interest to analysts, surfacing valuable data out of a massive pool of largely uninteresting or irrelevant images. To build such a system, one could turn to recent machine learning breakthroughs in visual recognition, which have been enabled by access to millions of training images from the Internet. However, such approaches cannot be used as off-the-shelf components to assemble the system IARPA desires, because they do not take into account artifacts unique to the operation of the sensor and optics platform on a small UAV.</td>
<td>Software and apps</td>
<td>N/A</td>
</tr>
<tr>
<td>EduApp4Syria Prize Competition</td>
<td>Norwegian Agency for Development Cooperation (Norad)</td>
<td>Implementing partner ran the challenge</td>
<td>This competition was completed in FY17.</td>
<td>The Syrian conflict caused disruption to the education of millions of children, in addition to threatening their physical safety and psychosocial well-being. At the time the prize was launched, almost three million Syrian children were out of school. Achieving reading and writing fluency (i.e., literacy) is foundational for lifelong learning. As such, it is important to provide opportunities to develop this skill for children who may be transient. Smartphones have been a survival tool used by many refugees, and reports and findings from field trips indicate high availability among Syrian refugees. A factor that compounds the learning challenge is that Syrian children, both inside and outside of school and inside and outside of Syria, are living under the extreme stress of protracted conflict. Elevated and prolonged stress levels can impede brain development and result in learning disabilities, memory problems and emotional regulation difficulties. The EduApp4Syria competition catalyzed the development of a smartphone application that can be used to increase literacy levels in Arabic and improve psychosocial well-being for children (ages 5�10). The app is primarily meant to supplement the formal and non-formal educational programs that exist, even though it could also be used within these programs. The two winning apps, Antura and the Letters and Feed the Monster, are now available for free on the App Store and Google Play.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Engage new people and communities</td>
<td>USAID was seeking to attract innovators who likely would not be aware of or respond to other mechanisms. Additionally, this competition was conducted in partnership with Norad, who chose the mechanism. The All Children Reading Grand Challenge for Development (ACR GCD) has used both grant and prize mechanisms. One of the valuable aspects of prize competitions is that it provides an easier on-ramp for organizations to partner with ACR GCD for a competition for a shorter-term, one-off activity, and usually require a smaller financial contribution.</td>
<td>The total prize purse offered and total amount awarded was 15 million Norwegian Kroner (NOK) (approximately U.S. $1,700,000). For Phase 1, Norad paid up to the sum of 2.5 million NOK (approximately U.S. $300,000), distributed evenly among up to five suppliers. Upon entering into contract, the selected suppliers received 150,000 NOK of these funds to work towards the initial deliverables. For Phase 2, Norad paid up to the sum of 7.5 million NOK (approximately U.S. $900,000), distributed evenly among up to three suppliers. For Phase 3, Norad paid up to the sum of 5 million NOK (approximately U.S. $600,000), distributed evenly among up to two suppliers. All awards were funded directly by the Norwegian government under a tender process by Norad. Non-monetary incentives included gaming technical expertise provide by Zynga; alpha testing conducted in Norway and beta field testing conducted in Amman, Jordan in December 2016; funding and technical advise for field testing of select applications by the United Nations International Children�s Emergency Fund (UNICEF) Ventures� Office of Innovation; technical and impact evaluation of the two winning games by ACR GCD; promotion by ACR GCD and Norad via social media and other digital platforms; and invitations to present at events.</td>
<td>ACR disseminated information about the Challenge through social media (e.g., Twitter and Facebook); the ACR GCD monthly newsletter; press releases; a dialogue conference in Oslo, Norway and Washington D.C. to attain feedback on the prize design; live video streaming that was later shared via social media; partnerships with outside organizations; and the Norad and ACR GCD websites. Competition documents and a short video about the competition were available in English and Arabic. The competition also received media coverage by Voice of America (VOA), The Guardian, ReliefWeb, Devex, and EdSource The Buzz.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - the Norad and ACR GCD websites; Other - competition documents in English and Arabic; Other - videos about the competition in English and Arabic; Other - the winning apps produced in English and Arabic</td>
<td>The supplier entering a bid must have been a legally established enterprise. If several suppliers were cooperating, only one, regarded as the main supplier, supplied necessary documentation. Legally established enterprises included (amongst others) sole proprietorships and non-profit organizations.</td>
<td>A jury led by a professor in game-based learning at the Norwegian University of Science and Technology (NTNU) selected the solutions to proceed at each stage. The collaboration advisory group sent comments on the proposed solutions to the jury for its consideration, but the jury made an independent decision. The solutions were judged by established criteria at each phase: Phase 0 evaluated the bidder�s design of the prototype and plan for project execution; Phase 1 and Phase 2 evaluated the alpha and beta versions of the product, respectively, in relation to the testing specifications, the competence of project management, the project�s capacities and resources, and bidder�s plan for developing a functioning solution within the signaled timeframe; and Phase 3 evaluated the product&#39;s results with comprehensive testing through market release, outreach strategies, and improvements based on market feedback. All phases compared the product to the functional requirements listed in Part 2, �Appendix 1: Specification of Requirements� of the competition reference document.</td>
<td>Of the 78 entries submitted by 78 participants between January 29, 2016 and April 1, 2016, five prizes were awarded to two winners.</td>
<td>A total of 1 full-time equivalent (FTE) was used to support the Challenge; 0.5 FTE was used in FY17 and 0.5 FTE was used in FY18. The total funding by ACR GCD in FY18 was $200,000, which was used for the technical and impact evaluation of the two games.</td>
<td>Partners included the Norwegian Government, which funded the competition. Norad coordinated the competition, coordinated and hosted the competition dialogue conference in Norway, and managed the tender process. The Department of Computer and Information Science at NTNU, contributed research and expertise in game technology, game-based learning, e-learning, m-learning, and software engineering. NTNU�s main responsibilities included leading and coordinating the competition and jury process, monitoring app development and maintenance, and leading the research related to the effects of using the chosen app(s). Thee ACR GCD, in a partnership with USAID, provided prize design technical expertise, led the communication strategy and activities, coordinated and hosted a competition dialogue conference (Washington D.C.), hosted the prize runner-up and finalists� profiles on the ACR GCD website, promoted the competition, managed U.S. media relations support, served on the submission review panel, and funded the technical and impact evaluation. Orange assisted in extensive outreach to potential competitors and promoted the winning application(s) through communication campaigns with the help of other divisions like StarAfrica (For more information, please visit http://en.starafrica.com/.). INEE served as an important source of knowledge of education in crises and conflict for the EduApp4Syria-competition. INEE provided input and quality assurance to specifications and selection processes; generated knowledge and awareness about the project among humanitarian organizations and other relevant stakeholders working on education in emergencies; and used its professional and communications network to inform potential users of the application about the learning resource once it was developed. World Vision and the Australian Government were also partners. The estimated value of partner contributions was approximately $1.7 million.</td>
<td>The EduApp4Syria competition sought to catalyze the development of a smartphone application that could significantly increase literacy levels in Arabic and improve psychosocial well-being for children (ages 5�10) in Syrian households that use the application. The application is primarily meant to supplement the formal and non-formal educational programs that exist, even though it could also be used within these programs. The EduApp4Syria competition also profiled the critical education crisis many Syrian children face. It was a unique competition in that it not only sought to address literacy but also to improve psychosocial well-being for children greatly affected by the conflict. The two winning games, Antura and the Letters and Feed the Monster, can be downloaded for free on Google Play and the App Store. Feed the Monster has also been reversioned into over 20 languages (with more anticipated), and Antura and the Letters is now available in English. The code is also available on GitHub. Advancing USAID�s Mission to improve reading scores for students and provide access to reading materials in local languages, the Apps have now been downloaded on more than 125,000 devices.  Impact evaluation results showed for each subtest, letter sounds, syllable reading, invented word and oral reading fluency, the treatment group gains were greater than the control group.</td>
<td>Software and apps</td>
<td>All future prize commitments will be determined by the ACR Round 3 strategy, which currently in development.</td>
</tr>
<tr>
<td>Book Boost: Access for All Challenge</td>
<td>USAID</td>
<td>ADS 302.3.4.13 Grants Under Contracts (GUCs)</td>
<td>This competition was launched in FY18 and is underway.</td>
<td>Ensuring children have books in the language(s) they use and understand and in formats they can access is critical to building foundational literacy skills and learning to read. The Book Boost: Access for All Challenge, a challenge under All Children Reading: A Grand Challenge for Development, seeks innovative business models that incorporate accessibility components from the onset, reducing the costs of retrofitting an inaccessible book after production and thus creating a more efficient and cost-effective process. This optimization of the title development phase of the book value chain can contribute to an increased number of accessible titles as well as increased quality of accessible titles. Successful applicants will demonstrate strategies to optimize content creation by using innovative, cost-effective strategies that illustrate potential production growth of high-quality, accessible titles.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Build capacity; Stimulate a market</td>
<td>ACR GCD based the rationale for the Book Boost prize structure on the Round 1 experience of implementing challenge competitions. Despite the numerous proposals received, very few focused on the thematic areas. Smaller prize awards structured around the neglected thematic areas will encourage organizations to innovate and take more risks in implementing new ideas. ACR GCD sought to attract innovators who likely would not be aware of or respond to other mechanisms. ACR GCD has used both the grant and prize mechanisms. One of the valuable aspects USAID has found in prize competitions is that they provide an easier on-ramp for organizations to partner with ACR GCD for a competition for a shorter-term, one-off activity, and usually require a smaller financial contribution.</td>
<td>The total prize purse offered was $360,000 and the total amount awarded was $348,000. The top four submissions were awarded a prize of $12,000 each before advancing to Phase 2 of the competition; the two winners of the competition were awarded a prize of $150,000 each. The funding was equally pooled from ACR and Pearson. Non-monetary incentives included promotion by ACR GCD and the prize partners via social media and other digital platforms and invitations to present at events. Pearson also offered in-kind business planning and brainstorming sessions.</td>
<td>Submissions were solicited online (www.allchildrenreading.org) and promoted to over 2,900 subscribers via the ACR social media outlets (Facebook and Twitter) and monthly newsletter. The competition was also announced via USAID, World Vision, DFAT, and Pearson and Project Literacy listserves. Submissions were accepted via Submittable, an online proposal submission management site. The solicitation overview was available in Arabic, French, Hindi, Portuguese, Spanish, and International Sign.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Eligible applicants include, but are not limited to, for-profit and nonprofit organizations, non governmental (NGO) organizations and associations, academic and education research institutions, faith-based organizations, civil society organizations, and foundations. Government entities are ineligible for this opportunity, but partnerships with governments are encouraged. USAID is unable to award cash prizes to suppliers of goods and services that do not meet the nationality and source definitions as referenced in 22 CFR 228.11 and 12, specifically geographic code 937. Geographic code 937 currently excludes Cuba, Iran, Libya, and North Korea.</td>
<td>Business plans will be evaluated across the eight key areas outlined in the Business Model Enhancement Plan Requirements.The maximum score for a business plan is 100 points: up to 5 points can be given for summary, concept and team management; 10 points for market analysis; 25 points for strategy; 10 points for collaboration; 15 points for finances; 15 points for timeline and project planning; and 20 points for sustainability.</td>
<td>Of the 15 submissions received, eight met the basic requirements for the Challenge. The top four submissions were awarded a prize of $12,000 each before advancing to Phase 2 of the competition. The two winners of the competition were awarded a prize of $150,000 each. The Challenge is separated into three phases. Phase 1 is the submission of the solver�s business model enhancement plan. Phase 2 consists of virtual presentations by the finalists on the viability of their business plans to a panel of judges. Phase 3 is the implementation of the business model enhancement plan.</td>
<td>A third party prize vendor, Submittable, was used to accept submissions and manage the judging process for a total cost of $4,250. Technical assistance was provided by a contractor to set-up and manage the platform at a total cost of approximately $3,000. The leading organization in creating accessible content was contracted for technical assistance to support the design and evaluation of the prize for $10,000, and a literacy expert was contracted for $1,000. Approximately $10,000 was allocated for communications support, including the translation of the prize call into multiple languages and the development of promotional and press materials. Five experts in accessible publishing and early grade reading content creation provided 15 hours of time each to evaluate all prize submissions for an estimated total of $3,000 in in-kind support. In FY18, one FTE was used to support the competition design, launch, evaluation and testing. The total funding in FY18 to support the Challenge was $77,301.</td>
<td>Challenge partners included World Vision, USAID, DFAT, and Pearson, who each shared their respective strengths, expertise, technologies, methodologies, and resources (including in-kind services, in-kind goods, and monetary) on specified activities in order to contribute to the shared goal of closing the global literacy gap. Specifically, the Challenge partners increased awareness and mobilized action; advanced best practices; and   innovated for new solutions. These partnerships have been critical to the success of the Challenge. Each provided credibility to the competition and enhanced communications with publishers and content developers. The total estimated value of partner contributions is $332,500, of which $130,000 is from ACR and $202,500 is from Pearson. In the future, ACR GCD aims to engage similar technical partners.</td>
<td>Learning to read is transformative and impacts a child�s lifelong opportunity to reach their full potential. However, around 250 million children of primary school age around the world are unable to recognize basic letters and numbers, even though half of them have spent at least four years in school. Despite the importance of books in boosting foundational literacy skills, there is a global shortage of books for children in many mother languages. For the estimated 19 million children globally that are blind or have low vision or the millions of children with other disabilities that impact their use of traditionally printed material, the shortage of quality books in accessible formats is even more severe. Current technologies provide the potential for publishers to produce books that are accessible and designed for reading by everyone, including those with print disabilities, but these are not being leveraged at scale. ACR GCD and Pearson�s Project Literacy launched the Book Boost: Access for All Challenge to drive innovation in the publishing space to address these gaps. The Challenge seeks business models that are rooted in optimizing and increasing the number of accessible books in the title development phase of the book value chain. The competition partners believe innovative solutions in title development will improve the overall book value chain, resulting in a more cost-efficient process. An efficient value chain will increase the number of new, high-quality, accessible titles available to stakeholders involved in book distribution. As part of ACR GCD�s commitment to ensuring all children learn to read, it also sources solutions that address barriers preventing children with disabilities from learning to read.</td>
<td>Software and apps; Technology demonstration and hardware; Business plans</td>
<td>Additional grant-funded activities will be determined by the ACR Round 3 strategy in development in FY19.</td>
</tr>
<tr>
<td>Data-Driven Farming Prize</td>
<td>USAID</td>
<td>USAID Innovation Incentive Award Authority in Section 7034(d)(4) of Division K of the FY16 Department of State, Foreign Operations, and Related Programs Appropriations Act at P.L. 115-131</td>
<td>This competition was completed in FY17.</td>
<td>Industrial agriculture benefits from digital tools and data that provide information on how much water to use for irrigation, when to harvest crops, and what price to sell crops. Smallholder farmers could benefit from this information too. The Challenge had eight specific goals: (1) attract new approaches and tools to source, organize and translate data into actionable farming insights; (2) improve opportunities for more effective and efficient agricultural decision making in situ; (3) mobilize new talents towards the Nepali agricultural market; (4) build new partnerships in the agricultural value chain in Nepal; (5) build context specificity capacity and responsiveness to local user needs in innovators; (6) support scaling new product/services in the agricultural market in Nepal; (7) leverage investments across stakeholders to support solutions entry into the market; and (8) raise awareness on the potential of data to generate useful information for the agricultural production.</td>
<td>Solve a specific problem; Develop technology; Build capacity; Stimulate a market</td>
<td>Prize competitions are a tried and tested method for supporting innovation, offering a reward to those who can first or most effectively meet a defined challenge. Rather than being a reward for past achievements, prize competitions act as an incentive for meeting a specific challenge. Prizes are also a means of expanding a challenge beyond the usual participants and thus facilitate the engagement and participation of anyone who can solve the challenge. The Feed the Future initiative sees this open innovation approach as a critical tool in its work to improve agricultural productivity, expand markets and trade, and increase the economic resilience of vulnerable rural communities in all partner countries.</td>
<td>The total prize purse offered and the total amount awarded was $300,000. Two $100,000 awards and two $50,000 awards were issued. The four cash prizes were distributed using Digital Development for Feed the Future�s FY16 funds. Funds were distributed via a miscellaneous obligation using the USAID Innovation Incentive Award Authority. Non-monetary incentives included enrollment in a ten-week bespoke Microsoft Innovation Center accelerator program, mentorship, and introductions to potential partners. In addition, finalists participated in Microsoft BizSpark, a global program that helps startups succeed by giving them free access to Microsoft Azure cloud services, software, and support. BizSpark startups received five Visual Studio Enterprise with MSDN subscriptions, each with a $150 monthly Azure credit. This totaled $750/month across all five developers to spend on Azure services. These benefits were available for one year. Microsoft BizSpark services were distributed directly to finalists by USAID�s prize partner, the Microsoft Innovation Center Nepal.</td>
<td>To recruit qualified competitors, USAID relied on extensive research of promising data-driven agriculture innovations. USAID also relied on an active social media campaign; personal outreach (which was very effective, as three finalists stated they applied because a trusted contact encouraged them to do so); a webinar to coach competitors through the application process; several in-person workshops hosted in Nepal to encourage and coach applicants through the application process (which proved to be very effective for Nepali competitors); and attendance at related agriculture conferences.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Live video streaming; Other - Newspaper advertisements; Other - Participation in conferences; Other - Panels during the competition; Other - Direct outreach to promising innovators</td>
<td>In order of priority, the target solver audience was innovators working in Nepal�s agricultural technology space; innovators from around the world working in agricultural technology; and Nepali innovators working in other data communication endeavors. However, the Challenge was open to all interested individuals, groups, organizations, companies, and sources and sectors, particularly local innovators from South Asia. Though the call was global and solvers could come from all over the world, the solutions were tested and applied to Nepal. All entrants needed to demonstrate a willingness to share their experiences and help establish a body of knowledge that can bring about a sustained change in the use of data to improve agriculture productivity. Applicants needed to ensure they have the capacity to develop a prototype of the solution over the challenge time frame. Some support was provided to help achieve this, but if selected, applicants had to be able to develop and test prototypes during the course of the prize. Any intellectual property in the submission belonged to the applicant. Applicants retained the intellectual property rights to their entry to the prize. Intellectual property had to be clearly marked as proprietary, and it was the applicant�s responsibility to ensure they were not infringing on the intellectual property of others. Entries were not assessed if required fields were not complete. Entries must have been submitted in English. USAID conducted a responsibility determination prior to the award to ensure that the award to the organization met applicable U.S. laws, including regulations administered by the Office of Foreign Assets Control (OFAC) of the U.S. Department of Treasury (for more information, see http://www.ustreas.gov/ofac, including the list of Specially Designated Nationals).</td>
<td>After applicants submitted their written applications, an internal eligibility screening and assessment was performed by subcontractors. The first round of judging was based on the written applications and performed by a judging panel. Judges from the panel came from USAID Bureau for Food Security, USAID US Global Development Lab, USAID Nepal, International Maize and Wheat Improvement Center (CIMMYT), International Center for Integrated Mountain Development (ICIMOD), Microsoft Innovation Center-Nepal, Global Open Data for Agriculture and Nutrition (GODAN), and DAI. Thirteen finalists submitted their innovations. Innovation field testing was conducted by USAID�s partners, International Maize and Wheat Improvement Center (CIMMYT), and International Center for Integrated Mountain Development (ICIMOD). Test results were summarized by the field test partners and assessed by subcontractors. Thirteen finalists submitted their written development plans and pitch videos. During the second round of judging, judges reviewed the field test results, assessments, development plans, and pitch video. Four winners were recommended by the judges. Lessons learned included that judges need to see the solutions to believe that they worked; judging panels were best conducted in person; and judges should be carefully separated from the mentoring and testing process to prevent bias.</td>
<td>Of the 143 applicants who provided submissions between February 9, 2017 and April 6, 2017, two $100,000 awards and two $50,000 awards were given. PEAT and Db2Map won the $100,000 awards and ICT 4 Agri and Spero Analytics won the $50,000 awards.</td>
<td>The Challenge had a $1.2 million budget. The $300,000 cash prize was funded through the Innovation Incentive Award Authority in FY17. A total of 0.5 FTE was also used to support the Challenge in FY17. The following items were funded through a USAID implementing partner mechanism and subcontract: seed funding at $30,600; staffing at $658,160; travel for innovators at $76,500; events at $110,000; testing and assessment at $46,600; online platform at $7,650; communications and outreach at $50,490; and Monitoring, Evaluation, Research and Learning (MERL) at $30,000.</td>
<td>Strong partnerships were the core of the Data-Driven Farming Prize. USAID Nepal buy-in for the program was key to the success of the Prize, and its endorsement of the activity ensured that the right networks of stakeholders were involved in the Prize. Similarly, the Prize was built in strong collaboration with local partners such as Feed the Future Initiative; GODAN; the Nepal office of CIMMYT, which provided in-kind support, mentorship, expertise, testing support, and facility use; ICIMOD, which provided in-kind support, mentorship, expertise, testing support, and facility use; and the Microsoft Innovation Center Nepal, which provided in-kind support, marketing and outreach support, Microsoft BizSpark, facilitation support, a bespoke accelerator program, mentorship, expertise, testing support, and partnership brokering. The estimated value of partner contributions is $246,000. Such strong field partners presence, as well as the prize activities ran in the country (including the launch event, co-creation workshop, innovation marketplace to showcase solutions, and the award ceremony), attracted the interest of the Nepali agricultural private sector in witnessing the development of new effective solutions. All finalists confirmed the Prize was a tremendous platform to boost new partnerships, and more than 22 partnerships have been attributed to the Prize. USAID also found that the co-creation approach at the center of the Prize deepened partnerships between partners. For example, one of the prize partners stated �I liked seeing different agricultural stakeholders have a-ha moments about how these innovators, or these partners, or these other convened value chain actors, or these datasets could unlock a new possibility in their ability to deliver more value for smallholder farmers.�</td>
<td>USAID is the world&#39;s premier international development agency and a catalytic actor driving development results. USAID&#39;s work advances U.S. national security and economic prosperity, demonstrates American generosity, and promotes a path to recipient self-reliance and resilience. This prize sought to catalyze local solutions to the local challenges of food security and secure livelihoods. Feed the Future believes in helping farmers extract maximum value from local agricultural production by increasing their access to the data and information needed to make more effective farming decisions. Democratizing access to data and information can drive the transformation of commercially-driven agriculture in targeted regions. As a result, the Prize aimed to support solutions for farmers and value chain actors to make effective choices to enhance their productivity, on-the-ground decision-making, and market planning.</td>
<td>Software and apps; Technology demonstration and hardware; Business plans</td>
<td>Following the Prize in FY17, USAID undertook a year long assessment of the Prize�s impact and learned that following the Prize, the thirteen finalists and winners were able to develop 22 partnerships and leverage $5 million in additional funding. In addition to the Prize-specific outcomes, the Prize also built a case for the value of prizes within USAID and catalyzed two additional prizes: Feed the Future�s Fall Armyworm Tech Prize (FY17) and USAID/Nepal�s forthcoming Counter Trafficking in Persons Tech Prize (FY18).</td>
</tr>
<tr>
<td>Fall Armyworm Tech Prize</td>
<td>USAID</td>
<td>Innovation Incentive Award Authority in Section 7034(d)(4) of Division K of the FY17 Department of State, Foreign Operations, and Related Programs Appropriations Act at P.L. 115-131</td>
<td>This competition was underway in FY18.</td>
<td>The fall armyworm (FAW) is not a new pest but is new to the African context. Smallholder farmers may misidentify the insect and select an improper treatment method in an effort to save their crops. Farmers urgently need clear and actionable pest identification information and a series of reasonable treatment options that take regional contexts and limitations into account. The FAW Tech Prize is seeking digital tools and approaches that provide timely, context-specific information that enable smallholder farmers and those who support them to identify, treat, and track incidence of FAW in Africa. Primary outcomes include enabling smallholder farmers and those who support them to accurately identify incidence of FAW in their crops; produce timely, context-appropriate, and empowering insights for smallholder farmers to treat the incidence of FAW; reduce productivity losses caused by FAW among those using the tool or approach; and ensure the appropriate and responsible use of pest management assessments, tools, and interventions.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities; Build capacity</td>
<td>Prize competitions are a tried and tested method for supporting innovation, offering a reward to those who can first or most effectively deliver a defined result. Rather than being a reward for past achievements, prize competitions act as an incentive for meeting a specific challenge. Prizes are also a means of expanding a challenge beyond the usual participants and thus facilitate the engagement and participation of anyone who can solve the challenge. The Feed the Future initiative sees this open innovation approach as a critical tool in its work to improve agricultural productivity, expand markets and trade, and increase the economic resilience of vulnerable rural communities in all partner countries.</td>
<td>The total prize purse offered will be $400,000, $300,000 of which comes from USAID�s FY17 DA funds, $50,000 of which comes from the Foundation for Food and Agriculture Research, and $50,000 of which comes from Land O�Lakes International Development. Five prize awards will be given. One grand prize winner will receive $150,000; two most promising solutions will receive $75,000 each; and two up-and-comers will receive $50,000 each. Of USAID�s $300,000 prize purse contribution, $100,000 will be contributed to the grand prize winner, and $50,000 will be contributed to each of the remaining four awards. Non-monetary incentives for the 20 prize finalists will include funded travel to Kampala, Uganda for the Co-Creation event; participation in the 4-day Co-Creation event with mentors, subject matter experts, and end-users; ongoing mentorship and support to refine finalists� products/solutions; funded travel to Cape Town, South Africa for the awards event; and participation in a 3-day awards event to showcase products/solutions, network with investors/others, and attend the final awards event.</td>
<td>The FAW Tech Prize solicited applications primarily through its associated online platform: https://fallarmywormtech.challenges.org/. The website contained a description of the Prize along with an applicant handbook. USAID also promoted and communicated the application timeline and procedures through the platform�s blog and by hosting a webinar with interested individuals/organizations. The webinar was effective at answering questions on the criteria and application process among interested individuals from around the world. The Prize was also promoted through social media, email, and in-person events. On the latter, several events were held in Uganda with groups of entrepreneurs and innovators, among others. These in-person events were very effective in promoting the Prize, sharing information, and engaging new actors in a USAID competition.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Webinar</td>
<td>The Prize was open to all individuals, groups, organizations, and companies, particularly local innovators from Africa. Though the call was global and solvers can come from all over the world, the solutions will be tested and applied in field contexts in Africa. Applicants need to demonstrate a willingness to share their experiences and help establish a body of knowledge that can bring about a sustained change in smallholder farmer outreach, awareness, and action with respect to digital tools and plant health, pest management, and disease management. Applicants need to ensure they have the capacity to either adapt their existing solution to address FAW or develop a prototype of the solution within the prize time frame. Any intellectual property in the submission entry must belong to the entrant. Entrants will retain the intellectual property, and such intellectual property must be clearly marked as proprietary. It is the entrants� responsibility to ensure that they are not infringing on the intellectual property of others. Entries will not be assessed if all required fields have not been completed. This applies to any stage of submission for the Prize and also relates to missing documentation that may have been requested. Entries need to be submitted in English. USAID will conduct a responsibility determination prior to the announcement of the award to ensure that selected organizations meets applicable U.S. laws, including regulations administered by the Office of Foreign Assets Control (OFAC) of the US Department of Treasury.</td>
<td>All applications were evaluated on whether the digital tool solution proposed by the applicant can be used by smallholder farmers or stakeholders who work with smallholder farmers; whether the submission provides timely, context-appropriate, and actionable advice to users to enable them to select among available best practices in treating incidence of FAW; whether the proposed solution demonstrates a clear understanding of end-user needs; whether the proposed solution presents a tangible response to farmers� unique experience with FAW in sub-Saharan Africa; whether the applicant has considered the commercial, sustainability (i.e., financial and environmental considerations), and growth potential of their solution; and whether applicants consider international norms with respect to digital development and FAW in their proposals. Applications went through four phases of evaluation. During Phase 1 (Assessment), every application submitted was reviewed by two assessors against the evaluation criteria above. Assessors were a hybrid group consisting of both USAID staff and external members. During Phase 2 (Judging panel), the top 36 highest-scoring applications from Phase 1 were then shared with the judging panel. Each application was reviewed by three judges, scores were compiled, and all 36 were discussed by the judging panel to determine the ultimate 20 finalists. These judges were also a hybrid group from USAID and external agencies. During Phase 3 (Field testing), the 20 finalists submitted prototypes to be tested in the field by the Centre for Agriculture and Bioscience International (CABI), a prize partner. Testing included functionality testing in CABI offices in Kampala as well as user testing among farmer and extension worker focus groups at field sites in Uganda. For Phase 4 (Judging panel), the judges will review a final development plan and video summary from each of the 20 finalists and score their final submissions against the evaluation criteria above. All 10 judges will review all 20 finalists. Their scores will be combined with the field testing results from Phase 3, and these total scores will be discussed among the judges at an in-person meeting to determine the five prize award winners.</td>
<td>A total of 228 applications were submitted between March 28, 2018 and May 14, 2018. The Prize is still ongoing, so no awards have been awarded yet. Five prizes will be awarded.</td>
<td>In FY18, USAID obligated $1,000,000 of FY17 funds for the implementation of the FAW Tech Prize to an existing mechanism, Digital Frontiers, ran by DAI in the U.S. Global Development Lab. Through an open solicitation ran by DAI, Nesta was awarded a contract to implement the Prize. The contract covers all implementation costs of the Prize, including managing the application process, overseeing the web platform, facilitating a 4-day co-creation event, hosting an awards ceremony, and supporting all travel and accommodation costs of participants. In addition, $300,000 of FY17 funds have been obligated for the prize purse. The equivalent of approximately 1 FTE from USAID has also been contributed and will provide guidance, oversight, and management of the Prize. The FTE will be split across two to three individuals in the Bureau for Food Security and U.S. Global Development Lab.</td>
<td>Partners of the FAW Tech Prize include Land O�Lakes International Development; Foundation for Food and Agriculture Research (FFAR); International Maize &amp; Wheat Improvement Center (CIMMYT); CABI; Syngenta Foundation; MEST; BRAC; and the Overseas Private Investment Corporation (OPIC). Land O�Lakes International Development, FFAR, and OPIC provided support in promoting the Prize and helping to attract applicants during the launch of the Prize. CABI and CIMMYT provided subject matter experts, and MEST and BRAC provided mentors to meet and help the 20 finalists further refine their solutions. Partners helped innovators learn about the impact of FAW, determine if their technologies would be feasible, and enhance their solutions to make sure they achieve the intended goal (i.e., to provide timely, context-specific, information about FAW). FFAR, Land O�Lakes International Development, and Syngenta Foundation also met with the finalists to provide support and expertise. During the testing phase, CABI lead the development of a testing protocol and implemented against it via functionality testing in Kampala and user experience testing among farmer focus groups. During the judging process, Land O�Lakes International Development, FFAR, OPIC, and Syngenta Foundation participated as judges. Once the final winners are announced, Land O�Lakes International Development and FFAR will contribute a total of $100,000 in prize awards, and Syngenta will provide AgTech acceleration support for all winners.</td>
<td>At present, FAW in Africa threatens harvests and economic growth on a continental scale and could harm the progress of USAID. Through Feed the Future, USAID has helped aid agriculture-led growth, nutrition, and resilience developments on the continent. Feed the Future, America�s global hunger and food security initiative, aims to transform lives toward a world where people no longer face extreme poverty, undernutrition, and hunger. To achieve this, Feed the Future works hand-in-hand with partner countries to develop their agriculture sectors and break the cycle of poverty and hunger. Feed the Future, specifically the FAW Tech Prize, is part of the USAID response to the FAW outbreak and aims to equip farmers to protect their yields and incomes.</td>
<td>Software and apps; Creative (design &amp; multimedia); Technology demonstration and hardware; Business plans; Analytics, visualizations, algorithms</td>
<td>Not applicable in regards to the Fall Armyworm Tech Prize.</td>
</tr>
<tr>
<td>Global Lighting and Energy Access Partnership (Global LEAP) Off-Grid Refrigerator Competition</td>
<td>USAID</td>
<td>Innovation Incentive Award Authority in Section 7034(d)(4) of Division K of the FY16 Department of State, Foreign Operations, and Related Programs Appropriations Act at P.L. 115-131</td>
<td>This competition was underway in both FY17 and FY18 but has not concluded.</td>
<td>Refrigeration holds unique potential to unlock economic and social progress for billions of people globally who have no or limited access to power. The market, however, remains nascent. The Global Lighting and Energy Access Partnership (Global LEAP) Off-Grid Refrigerator Competition seeks to catalyze new technological and design advancements in high-efficiency, low-cost refrigeration solutions. By inspiring greater participation and innovation in the market, the competition will improve access to affordable refrigeration technology for those living off-grid in developing countries. The Off-Grid Refrigerator Competition was competed under Global LEAP, a partnership that includes the U.S. Department of Energy and Power Africa. The Off-Grid Refrigerator Competition is one component of the Scaling Off-Grid Energy Grand Challenge for Development, which will contribute to increased utility of off-grid energy systems for consumers.</td>
<td>Find and highlight innovative ideas; Solve a specific problem; Develop technology; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>Prize competitions are a tried and tested method for supporting innovation, offering a reward to those who can first or most effectively deliver a defined result. Rather than being a reward for past achievements, prize competitions act as an incentive for meeting a specific challenge. Prizes are also a means of expanding a challenge beyond the usual participants and thus facilitate the engagement and participation of anyone who can solve the challenge.</td>
<td>The total prize purse offered is $600,000. Three $100,000 innovation incentive awards from USAID have been matched by the U.K. Department for International Development (DFID) funding for a total of $200,000 for each of the three awards. Awards for Overall Value ($200,000) and Energy Efficiency ($200,000) were made in January 2018. The prize for User Appeal and Field Performance ($200,000) is still underway and will be awarded November 2018. Non-monetary incentives included complimentary testing for all competitors, which provides vital data on product performance in both lab and field conditions. In addition, finalists receive mention in the Global LEAP catalog of finalist and award-winning products, networking opportunities with manufacturers and distributors, and enrollment in a results-based financing procurement incentives program.</td>
<td>Submissions were sought through Global LEAP, Challenge.gov, and other standard channels.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies); Other - Webinar</td>
<td> N/A</td>
<td>Applications were initially screened by CLASP, the implementing partner, and USAID before evaluated for award by a panel of expert judges based on data from industry-approved lab testing. USAID confirmed the analysis. The field test was conducted by implementing partners using industry-leading testing standards in Uganda, with judges then evaluating the results to identify a winner.</td>
<td>Of the 55 applications received between September 22, 2016 and January 20, 2017, two prizes were awarded to Sundanzer: Energy Efficiency and Overall Value. The award for Appropriate Design and User Experience will be selected in November 2018.</td>
<td>USAID provided $300,000 in funding to support the Prize in FY17. In addition, 1 FTE was used to support the Prize in FY17 and 0.5 FTE was used to support the Prize in FY18.</td>
<td>Partnerships played a critical role across the Prize. The U.S. Department of Energy was a Federal partner. Non-Federal partners included the U.K. Department for International Development, which contributed $300,000 to the Prize; Global CLASP; IMC Worldwide; and Energy 4 Impact. Multiple donors partnered under an existing umbrella prize program (Global LEAP) to coordinate funding and design. All partners had different implementing partners who collaborated effectively to deliver the prize.</td>
<td>USAID is the world&#39;s premier international development agency and a catalytic actor driving development results. USAID&#39;s work advances economic prosperity and promotes a path to recipient self-reliance and resilience. Refrigeration can prolong the nutritional value of food, diversify diets, enable income-generating activities, and reduce the time that households spend shopping or gathering food. Thus, a prize to develop the off-grid refrigeration market and unlock economic and social progress for the 600 million people living off the grid in sub-Saharan Africa advances USAID�s mission.</td>
<td>Technology demonstration and hardware; Business plans</td>
<td>Partners may continue prize program in outyears without USAID funding.</td>
</tr>
<tr>
<td>No Lost Generation Prize Competition</td>
<td>USAID</td>
<td>ADS 302.3.4.13 Grants Under Contracts (GUCs)</td>
<td>This competition was launched in FY17 and is underway in FY18.</td>
<td>The No Lost Generation (NLG) EdTech Summit agenda included three breakout sessions designed to bring all participants together to collaborate and form partnerships. To encourage collaboration, the NLG Prize seed funding opportunities, a prize under the All Children Reading: A Grand Challenge for Development, were provided by key sponsors, and all participants had the opportunity to apply for seed funding during the event. Basic early grade readers often focus on similar topics that could be replicated through development of Science, Technology, Engineering, and Mathematics (STEM) early reader story templates. These templates would include basic story lines but allow authors to add in images accordingly and easily translate and contextualize. Seed funding would be awarded for an innovative solution that would drive this content. The storyline templates would be made available on the Global Digital Library, providing a digital, accessible, and open source solution.</td>
<td>Solve a specific problem; Inform and educate the public; Engage new people and communities; Stimulate a market</td>
<td>USAID was seeking to attract innovators who likely would not be aware of or respond to other mechanisms. All Children Reading (ACR) based the rationale for a prize structure on its initial challenge funding experience; despite the numerous proposals received, very few focused on thematic areas. Smaller prize awards structured around these neglected thematic areas will encourage organizations to innovate and take more risks in implementing new ideas. Over time, ACR has used both the grant and prize mechanisms. One of the valuable aspects USAID has found in prize competitions is that they provide an easier on-ramp for organizations to partner with ACR for a competition for a shorter-term, one-off activity, and usually for a smaller financial contribution.</td>
<td>The total prize purse offered and total amount awarded was $100,000. Non-monetary incentives included engagement with partners, such as the Global Digital Library, which will host these stories on their platform in both Arabic and English. This will extend the reach of this content beyond the Asafeer app and to a global audience, with the possibility of translating these stories into many different languages.</td>
<td>The NLG Prize was designed to encourage participants to attend the EdTech Summit expecting to develop action plans during breakout sessions to be put into action following the event. Only Summit participants had the opportunity to apply for seed funding during the event, and any other organizations not participating in the Summit were ineligible. Participants were encouraged to develop action plans resulting from the creativity inspired in the breakout sessions and in partnership with other organizations wherever possible. However, the eligibility parameters, though created to inspire and maximize partnerships, may have limited opportunities to engage other viable partners or create new partnerships outside the summit.</td>
<td>Social media (e.g., Twitter, Facebook); Press release; Day-long event(s) prior to the competition; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Only those attending the EdTech Summit were eligible to compete for the seed funding.</td>
<td>A hybrid team of evaluators from World Vision and USAID judged the submissions. Top proposals were selected based on their scores (out of a total of 100 points). The criteria for judging was based on four categories: Innovation (30 points), based on if the approach demonstrated innovation through engagement of traditional and non-traditional writers such as youth, those with disabilities, or children in the Arab region; Feasibility (20 points), based on if the approach demonstrated feasibility by outlining a clear mechanism for engaging writers, revising content, and ensuring the production of quality STEM story templates; Scalability (25 points), based on if pitches put forward a proposed business model that could continue engagement with writers for further contribution to book/stories creation; and Diversity of themes (25 points), based on if pitches put forward proposed STEM themes and the estimated number of templates per theme.</td>
<td>Of the six entries submitted between March 2017 and April 25, 2017, two prizes were awarded. A $50,000 prize award was made for illustrations and a $50,000 prize award was made for story development. Both prize components were awarded to Asafeer Education Technologies FZ LLC.</td>
<td>In FY17, USAID provided $50,000 and 0.25 FTE to support the Prize. In FY18, USAID provided $50,000 and 0.125 FTE to support the Prize. In addition, World Vision allocated roughly 20 hours a month in support of the Prize. World Vision International also contributed educational and linguistic technical expertise to support the material development.</td>
<td>This prize was made possible in partnership with the NLG Initiative, which hosted and promoted the seed funding prizes. Non-Federal partners included the Australian Government and World Vision. The estimated value of partner contributions totals $100,000.</td>
<td>The All Children Reading (ACR) partners� goals are to improve early grade reading outcomes. The NLG Prize incentivize participation in the NLG EdTech Summit. This Prize and Summit advanced each partners� goals to reach children in crisis, proving an excellent opportunity to leverage the NLG Ed Tech Summit to fulfill partner goals.</td>
<td>Software and apps; Creative (design &amp; multimedia)</td>
<td>Additional grant-funded activities will be determined by the ACR Round 3 strategy in development in FY19.</td>
</tr>
<tr>
<td>Tracking and Tracing Books Prize Competition</td>
<td>USAID</td>
<td>ADS 302.3.4.13 Grants Under Contracts (GUCs)</td>
<td>This competition was completed in FY17.</td>
<td>The objective of this competition was to seek innovations to track books destined for early grade classrooms and learning centers in low-income countries and allow stakeholders, ranging from parents to the Ministry of Education, to easily access tracking information. Desired outcomes included decreasing the number of books lost; improving government service delivery; finding and highlighting innovative ideas; solving a specific problem; developing technology; informing and educating the public; engaging new people and communities; and building capacity.</td>
<td>Improve government service delivery; Solve a specific problem; Develop technology; Engage new people and communities</td>
<td>The All Children Reading Grand Challenge for Development (ACR GCD) sought to attract innovators who likely would not be aware of or respond to other mechanisms. The ACR GCD based the rationale for a prize structure on the Round 1 experience that despite receiving numerous proposals, very few focused on the thematic areas. Smaller prize awards structured around the neglected thematic areas will encourage organizations to innovate and take more risks in implementing new ideas. ACR GCD has used both the grant and prize mechanisms. One of the valuable aspects USAID has found in prize competitions is that it provides an easier on-ramp for organizations to partner with ACR GCD for a competition for a shorter-term, one-off activity, and usually for a smaller financial contribution.</td>
<td>The total prize purse offered was $100,000 and the total amount awarded was $220,000. Non-monetary incentives included global recognition from the ACR GCD; communications and marketing support; invitations to exclusive events; exposure to new partnerships through the ACR GCD partner network; and expert feedback on the proposed software from child development and digital education specialists. In FY17, both tracking and tracing books solutions were alpha tested, and recommendations were made to the finalists to refine the softwares. Final tranche payments of $25,000 each, for a total $50,000, were paid to the two finalists in FY17.</td>
<td>InnoCentive hosted the prize competition and designed a marketing and communications plan on behalf of ACR. InnoCentive not only marketed to their network of over 100,000 solvers but also targeted the broad software and mobile app development community. InnoCentive recommended expanding efforts through targeted outreach and social media outlets to attract experts, industries, and networks in areas such as big data and predictive analytics, logistics and warehouse management, freight and transport, library sciences, and engineering. ACR simultaneously used websites, social media, webinars, information sessions, and workshops to reach a large and varied audience. A few examples of methods used to market the prize competition, mobilize potential participants, and ensure high quality submissions included marketing the prize in three editions of the InnoCentive Challenge Bulletin, which goes out to around 100,000 Solvers; posting information about the Challenge several times on InnoCentive�s social media accounts; sending targeted emails to international supply chain management university professors, logistics management organizations and societies, and those working with various kinds of educational technology; and posting and engaging with social media groups and organizations related to supply chain, logistics, and educational technology.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Eligible applicants included, but were not limited to, for-profit and nonprofit organizations, non-governmental organizations and associations, academic and education research institutions, faith-based organizations, civil society organizations, and foundations. Government entities were ineligible for this opportunity, but partnerships with governments were encouraged. USAID was unable to award cash prizes to suppliers of goods and services that did not meet the nationality and source definitions as referenced in 22 CFR 228.11 and 12, specifically geographic code 937. Geographic code 937 currently excludes Cuba, Iran, Libya, and North Korea.</td>
<td>There were four stages of the judging process. Stage I took place between April 27 and May 15, 2015. Assessors received access to the platform and training assistance for questions. Each team, consisting of three members, assessed 10 submissions. Team members within a team reviewed submissions in different orders. Nine semi-finalists were produced in Stage I. Stage II took place between May 18 and May 22, 2015. All team members across the three teams rescored the nine top submissions. Stage III took place between May 25 and May 29, 2015. All team members were made aware of the Stage II rankings and scores of the nine semi-finalists. During this stage, any team member could make a case for either moving a lower-rated submission into the top three or removing one submission from the top three. Stage IV took place between June 1 and June 5, 2015. Representatives of the partners met in-person and virtually to discuss the rankings and decide on the three top winners.</td>
<td>Of the 10 entries submitted between January 23, 2015 and April 1, 2015, two prizes were awarded.</td>
<td>In FY17, 0.5 FTE supported the competition through alpha testing, solution refinement, and final payment. A total of $25,000 in funding was used to support alpha testing in the form of travel and accommodations for finalists, testing logistics, technical consulting, and reporting.</td>
<td>The prize was conducted in partnership by the USAID, World Vision, and the Australian government. The estimated value of partner contributions is $50,000. The competition was managed by InnoCentive. With over 12 years of experience pioneering the fostering of innovation and technology from external networks, in addition to previous work with ACR on the Enabling Writers Prize Competition, InnoCentive had capable staff and a highly-relevant solver community to effectively manage the Track and Trace Prize Competition. Building off of InnoCentive�s expertise in running prize competitions, ACR was able to run the competition as efficiently and effectively as possible. ACR recommends this model to other prize competitions.</td>
<td>Each of the ACR GCD partners� goals is to improve reading. Books are essential to early grade reading instruction. However, both textbooks and supplemental reading materials ordered for low income countries often do not end up in the hands of the students who need them. Textbooks and materials can go astray at any stage in the delivery process, including at the point-of-entry for imported textbooks; at the central warehouses for nationally-produced materials; during transportation across difficult and sometimes insecure routes; or during final distribution to regional offices and classrooms. The Tracking and Tracing Books Prize Competition spurred development of four tracking software systems tested in over 1,000 school sites in Malawi, Nigeria, and Afghanistan. To advance the mission, further integration of tracking systems requirements will be embedded into program solicitations.</td>
<td>Software and apps; Technology demonstration and hardware</td>
<td>All future prize activities will depend on the ACR GCD Round 3 Strategy.</td>
</tr>
<tr>
<td>WomenConnect Challenge</td>
<td>USAID</td>
<td>ADS 302.3.4.13 Grants Under Contracts (GUCs)</td>
<td>This competition was launched in FY17 and is underway in FY18.</td>
<td>Technology is revolutionizing the world by providing tools for entrepreneurship as well as access to critical health, education, and life-enhancing information. However, women increasingly have limited access to technology, resulting in a digital gender divide. There are 1.7 billion women in low- and middle-income countries who still do not own mobile phones, and the gap between the number of men and women using the internet has grown steadily over the past 3 years. The persistent digital gender divide is reinforcing or even exacerbating existing socioeconomic gaps between men and women. By reducing this divide, women and girls will have access to life-enhancing information, networks, and services, reducing poverty and driving inclusive economic growth. The WomenConnect Challenge (WCC) is a global call for solutions to improve women&#39;s participation in everyday life by meaningfully changing the ways women and girls access and use technology. USAID is looking to identify and accelerate comprehensive solutions that empower women and girls to access and use digital technology to drive positive health, education, and livelihood outcomes for themselves and their families.</td>
<td>Solve a specific problem</td>
<td>Given the anticipated number of awards and interest in this topic, a challenge seemed like the most favorable and fair way to address the incoming proposals. USAID also received input from teams that have previously done Grand Challenges who believed the WCC was a fit for the challenge model.</td>
<td>The total prize purse offered was $1,000,000 and the total amount awarded was $900,000. Non-monetary incentives included acceleration support at a semi-finalist workshop in Washington, D.C.</td>
<td>The Challenge call was announced online and through a social media campaign launched from USAID in Washington, D.C. in conjunction with missions around the world. There was also a launch event on International Women�s Day where the USAID Administrator, the USAID Senior Deputy Assistant Administrator, and the Advisor to the President spoke. The launch garnered a large amount of attention and produced a distribution list of 10,000 interested people. Partner organizations and several newsletters also mentioned the launch.</td>
<td>Social media (e.g., Twitter, Facebook); Email (e.g., listservs); Press release; Day-long event(s) prior to the competition; Live video streaming; Partnership with outside organizations (e.g., private companies, non-profit organizations, other Federal agencies)</td>
<td>Government entities were not allowed to participate. In addition, countries needed to have USAID presence.</td>
<td>The initial judging narrowed down the 531 proposals to 40 proposals. The evaluation was done by a recruited group of judges across USAID and private sector organizations with domain expertise in either gender, technology, and/or development. Diversity was key in recruiting judges, and at least 45% of the judges were from the Global South. The judging criteria was set by the implementing partner and approved by the WCC manager. From the top 40 proposals, a five-person Technical Evaluation Committee (TEC), consisting of higher-level experts, scored proposals and whittled the number to 20 semi-finalists using a judging matrix also developed by the implementer and approved by the WCC manager. Semi-finalists were able to rewrite proposals based on feedback, and the same TEC used a third judging matrix to select nine awardees.</td>
<td>Of the 531 entries submitted between March 8, 2018 and May 20, 2018, a total of nine prizes were awarded. Winners included AfChix, Equal Access International, Gram Vaani, Humanitarian OpenStreetMap Team, Innovations for Poverty Action, Institute for Financial Management and Research, Mali Health, Gapi and Bluetown, and Viamo.</td>
<td>In FY17, $1.4 million and one FTE were used to support the Challenge. In FY18, $96,000 and one FTE were used to support the Challenge. A total of $500,000 was used to support a third-party company to manage the challenge design and operations.</td>
<td>Georgetown Business School donated classroom space for the semi-finalist workshop and reception.</td>
<td>This award advances USAID�s mission by demonstrating the positive impact that digital technology can have on the gender digital divide, which affects approximately 1.7 billion women who are not able to use phones or the internet, through gender equity programming and the creation of new evidence to close the divide. Without this new evidence and programming, this divide will continue to grow and make it impossible for women, who are key to sustainable community development, to take advantage of all the digital international development programming that agencies are moving towards.</td>
<td>Software and apps; Creative (design &amp; multimedia); Technology demonstration and hardware</td>
<td>The next phase of WomenConnect Challenge is to make the first payments to awardees and start conducting field visits with the desire to collaborate more with local missions who may be interested in augmenting these programs or making a country-specific challenge. There is interest in scaling the positive outcomes of the WCC, which would require additional USAID and partner commitment to provide the necessary funds.</td>
</tr>
</tbody></table>
</div>
</div>
</div>
