I"ö<p><strong>Assessment Criteria and Simulation Environment</strong></p>

<p>We seek innovative technologies to optimize networks operating in dynamic, low-capacity environments. This challenge focuses on low overhead routing protocols. Participants should generalize their approaches since all technologies will be tested and evaluated beyond the SBE, in higher fidelity and operationally relevant environments. At a minimum, the routing protocol should support User Datagram Protocol (UDP) unicast flows and Transmission Control Protocol (TCP) flows. Support for UDP multicast is desired, but not necessary for this challenge. In the following sections we describe the assessment criteria and the provided SBE.</p>

<p><strong>Assessment Criteria â€“ Networks Prize Challenge Invitations</strong></p>

<p>Conforming white paper and quad chart submissions will be evaluated by a panel of qualified networking experts using the following criteria which is in descending order of importance:</p>

<ul>
  <li>Operational impact of the technology/engineering innovation in the intended mission scenarios and operational environment</li>
  <li>Estimated technical performance (weighted network goodput; network overhead; end-to-end network latency) of the technology/engineering innovation</li>
  <li>Integration complexity of the technology/engineering innovation</li>
  <li>Technical maturity of the technology/engineering innovation</li>
</ul>

<p>When conducting the assessment, the Government reserves the right to take other significant factors as required into consideration, such as:</p>

<ul>
  <li>Limitations to use due to Intellectual Property ownership</li>
  <li>Ease of fielding the technology in existing legacy Naval platforms (e.g. solution that requires many large software dependencies or are require significant compute/memory resources, or that run on very specific hardware architectures would be viewed less favorably).</li>
  <li>Required out-of-band information needed for the networking technology to operate</li>
</ul>

<p>Based on this initial assessment of the white papers and quad charts, participants will be invited to participate in the Challenge. Selected participants will be notified via email communication and will receive invitations to the Challenge question and answer (Q&amp;A) Sessions and iRIL Integration Workshops.</p>

<p><strong>Assessment Criteria â€“ Networks Prize Challenge</strong></p>

<p>Challenge participants will be evaluated throughout iRIL Integration Workshops and Challenge demonstrations by a panel of qualified networking experts and using the following criteria which is in descending order of importance:</p>

<ul>
  <li>Operational impact of the technology/engineering innovation in the intended mission scenarios and operational environment</li>
  <li>Technical performance â€“ Network Overhead</li>
  <li>Technical performance â€“ Total network goodput</li>
  <li>Technical performance â€“ Average End-to-end latency and network convergence time after topology changes</li>
  <li>Integration complexity of the technology/engineering innovation</li>
  <li>Technical maturity of the technology/engineering innovation</li>
</ul>

<p>Goodput is defined as the fraction of available capacity that is used to deliver application traffic, and implicitly factors in the overhead consumed by the routing protocol.</p>

<p>End-to-end latency is defined as the average transit time of packets for the duration of a flow over the network.</p>

<p>Network convergence time is defined as the time taken to successfully route a packet after a network topology change.</p>

<p><strong>iRIL Simulation Environment</strong></p>

<p>Participants will be provided a virtual machine (VM) which contains the SBE. The iRIL uses a group of Linux containers connected to a network simulator, hosted on a virtual machine (VM). The test scenario will be scripted in the simulator, which will determine connectivity, link latency and link loss rates at any given time. Participants do not need a detailed understanding of the network simulator beyond how to start, stop and reset the scenario. The simulator will provide real-time feedback about the network connectivity and performance metrics. This feedback is for ease of observability and should not be used by the routing technology.</p>

<p>Submitted technologies must be compatible with Linux Centos7 which will host the network simulator. Technologies will be run within Centos7 containers in the VM. The operating systems will have the following additional user software installed as a baseline:</p>

<ul>
  <li>Free Range Routing (FRR)</li>
</ul>

<p>The routing agents must be Linux VM compatible (e.g., a GUI, console, or powershell using standard Linux installation procedures). Documentation inclusive of installation procedures should also be provided when submitting the tool, in accordance with the tool submission guidelines provided above. Participants may install additional software within the containers, as long as it is included in the submission package.</p>

<p>Additionally, the scenario will contain a set of application traffic flows that will start and stop automatically as the scenario progresses.</p>

<p>The iRIL platform used at AINet ANTX includes monitoring, visualizations and metrics tracking, and participants do not need to dedicate resources to provide this functionality.</p>

<p>Technologies that require specific hardware, proprietary components, or on-premises management appliances or consoles will not be considered.</p>

<p><strong>Prize Award Details</strong></p>

<p>Winners will be announced at the conclusion of the Challenge event. NAVWAR will also announce the winners on the Challenge.gov website, the NAVWAR LinkedIN page, media outlets, and social media channels.</p>

<p>NAVWAR has established $100,000 as the total amount set aside for cash prizes under this Challenge. A $75,000 first place cash prize will be awarded to the winning entry. A $25,000 second place cash prize will also be awarded. In the unlikely event of a tie, NAVWAR will determine an equitable method of distributing the cash prizes. In the event that an entity ineligible of receiving the cash award wins first and/or second place, NAVWAR will determine the equitable method of distributing the cash prizes.</p>

<p>If a prize goes to a team of participants, NAVWAR will award the cash prize to the individual/teamâ€™s point of contact registered via the challenge website, for further distribution to the team, as the team members see fit.</p>

<p>NAVWAR is executing two simultaneous but independent prize challenges the AINet ANTX. This prize challenge announcement, and the details within, refer specifically to the Networks Prize Challenge. A companion prize challenge, titled the Artificial Intelligence (AI) Prize Challenge, has been announced separately on Challenge.gov.</p>
:ET