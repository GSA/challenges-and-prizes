I"&<p><strong>CONGRATULATIONS TO PHASE 2 WINNERS:</strong></p>

<ul>
  <li><strong>Team iAI Tech-NJIT</strong> (Innovative AI Technologies, LLC and New Jersey Institute of Technology): Phase 2 award ($6,000), CDVL Distribution Prize ($12,000), and Best in Show: Best Dataset Prize ($5,000)</li>
  <li><strong>Team CalAster</strong> (CalAster, Inc.): Phase 2 award ($6,000), CDVL Distribution Prize ($12,000), and Best in Show: Best Dataset Prize ($5,000)</li>
  <li><strong>Team LIVE</strong> (University of Texas): Phase 2 award ($6,000), CDVL Distribution Prize ($12,000)</li>
  <li><strong>Team IUPUI</strong> (Indiana University-Purdue University Indianapolis): Phase 2 award ($6,000), CDVL Distribution Prize ($12,000)</li>
  <li><strong>Dr. Burak Ozer</strong>: Phase 2 award ($6,000)</li>
</ul>

<p>Check out the <a href="https://pscompvischallenge.com/">challenge website</a> for the latest information or for questions related to this challenge, email us at <a href="psprizes@nist.gov">psprizes@nist.gov</a>.</p>

<h4 id="overview">Overview</h4>

<p>The Public Safety Communications Research (PSCR) Division of the National Institute of Standards and Technology (NIST) is hosting the Enhancing Computer Vision for Public Safety Challenge focused on advancing the capacity of no-reference (NR) metrics and computer vision algorithms for image and video quality analysis, to support public safety missions. PSCR will award prizes valued up to $240,000 to winning contestants. The First Responders Network Authority is partnering with PSCR on this challenge. The contestants will provide: 1) datasets of images or videos showing impairments that cause computer vision applications to fail, and 2) innovative methods to estimate the failure rate of computer vision algorithms on these images or videos. These solutions will provide the computer vision and NR metric research communities training datasets to ultimately improve analytics for public safety.</p>

<h4 id="challenge-background">Challenge Background</h4>

<p>A roadblock to the deployment of public safety computer vision and video analytics is the myriad problems cameras have when deployed in real world environments.</p>

<p>First responders operate in environments that are very challenging for cameras. Frequently problems include low light, night with bright lights, and the rising or setting sun shining directly into the camera. Obscurants like rain, snow, and airborne dust obscure distant objects. Bodycams and in-car cameras produce severe camera jiggle. First responders often rely on a third party’s outdated camera systems that provide low resolution video feeds or low-quality compression. Lenses may be obscured by spider webs, restaurant grease, or other grime. First responders need robust computer vision systems that can operate in these difficult environments.</p>

<p>To develop robust systems for public safety, computer vision researchers need an algorithm that predicts the quality of images and videos and performs root cause analysis (RCA). These are referred to as NR metric for image quality assessment (IQA) or video quality assessment (VQA). The NR metric would supplement the camera feed with extra information, such as noting areas of the image where the camera cannot “see.” Deployed systems could implement complex strategies, such as dynamically selecting the optimal video analytic or adjusting camera settings.</p>

<p>Today, NR metrics emulate the human perceptual system. This requires subjective testing, where large groups of people assess the quality of images or videos, so the training datasets are small and expensive. Consequently, NR metrics are too inaccurate for computer vision applications. An additional problem is that most NR metrics only predict overall quality. Computer vision applications need RCA to identify and respond to specific image and video quality problems. Therefore, PSCR is seeking image and video datasets to train NR metric RCA algorithms, as well as strategies for creating this training data. The dataset creation strategies could enable a new line of research.</p>

<h4 id="challenge-goals-and-objectives">Challenge Goals and Objectives</h4>

<p>The goal of this challenge is to enhance the research capacity of NR metrics, computer vision algorithms, and image quality analysis for public safety officials. This challenge also seeks to convene members of these disparate research communities to advance the state of image and video quality analysis for public safety.</p>

<p>PSCR hypothesizes that developing new training datasets for NR metric research can replace expensive subjective testing with accuracy estimates from computer vision algorithms. This will help PSCR achieve the development of robust image and video analytics for public safety applications. Each dataset solution can either focus on a Specific Camera Impairment (e.g., lens flare) or a Specific Computer Vision Application (e.g., automated driving). Each dataset will include the following elements:</p>

<ol>
  <li>250+ images or videos (5 seconds duration or less) that portray a wide range of visual quality, subject matter, and environmental conditions</li>
  <li>Numerical data that estimates the likelihood that a computer vision application will fail</li>
  <li>Category data that can be used to subdivide the images into useful subsets</li>
  <li>A short document that describes the dataset and assessment method</li>
</ol>

<p>After the challenge, the datasets will be used for image quality research and development (R&amp;D) purposes. This will provide the research community with valuable datasets. If the contestant chooses to distribute the images or videos, the datasets will be distributed via the National Telecommunications and Information Administration’s (NTIA) Consumer Digital Video Library (CDVL). NTIA, a part of the U.S. Department of Commerce, conducts NR metric research and provides PSCR with video quality assessment expertise.</p>

<p>Contestants will:</p>

<ol>
  <li>Create and distribute a set of images or videos (5 seconds duration or less) that represent either a) one Specific Camera Impairment with content suitable for various computer vision applications, or b) a variety of camera impairments with content suitable for a Single Computer Vision Application. All images and videos must be from modern cameras (i.e., no synthetic or simulated impairments). At the contestant’s discretion, these images or videos will be freely distributed for research and development purposes following the conclusion of the challenge.</li>
  <li>Create a method to assess the failure rates of a specific computer vision algorithm and apply this method to the contestant’s images or videos. Possible solutions include but are not limited to correct classification rate, misclassification rate, likelihood score, image ambiguity, image difficulty, and meta-recognition. The failure rates must be expressed as a percentage or fraction. The method must be described in sufficient detail that another researcher or developer could apply the method to their own images or videos, using their own computer vision algorithm. At the contestant’s discretion, the contestant may optionally identify areas of the image or video where the computer vision algorithm fails.</li>
</ol>

<p>For this challenge, failure rate is whether or not the computer vision algorithm can make a reliable decision. Contestants should choose a method to assess failure rate that is synergistic with this challenge’s goal of understanding how camera impairments impact computer vision algorithms. Contestants should apply the reliability measure that is most appropriate to the application of choice based on the current state of the art. Of most interest are (a) failure rate assessment methods that can be applied to any computer vision system, and (b) failure rate assessment methods designed for computer vision algorithms that specifically target public safety and first responder needs.</p>

<h4 id="phases">Phases</h4>

<p><strong>Phase 1: Concept Paper</strong></p>

<p>The Concept Paper phase invites all eligible contestants to submit a concept paper outlining their proposed solution, approach, capabilities, knowledge, and skills for this contest. Contestants must document their proposed solution structure for either of the two dataset categories. Contestants will also need to demonstrate their experience with image quality analysis, video quality analysis, computer vision, engineering, photography, or other abilities to create the proposed solution. Contestants who propose using a computer vision algorithm to create assessment data will need to demonstrate their experience with computer vision.</p>

<p><strong>Phase 2: Dataset Submission</strong></p>

<p>During Phase 2 of the challenge, invited contestants will implement their proposals and submit datasets according to the Requirements below. Datasets will consist of images or videos that contain different scenes or different impairments to quality. The datasets will also include a computer vision failure rate for each image or video, and a general description of how the failure rates were derived. During evaluation, the Judging panel will score each submission based on the evaluation criteria.</p>

<p><img src="blob:https://www.challenge.gov/85a9bbf0-8e95-4bf8-8e44-747d5f035d45" alt="Challenge Timeline" title="Challenge Timeline" /></p>

<p><strong>Summary of Important Dates</strong></p>

<p><strong>Phase 1, Concept Paper</strong>: Open for submissions beginning September 8, 2020, with concept papers due October 20, 2020; Winners will be notified by October 30, 2020.</p>

<p><strong>Phase 2, Dataset Submission</strong>: Open for submissions on November 3, 2020, with datasets due May 4, 2021; Winners will be notified by May 19, 2021.</p>
:ET