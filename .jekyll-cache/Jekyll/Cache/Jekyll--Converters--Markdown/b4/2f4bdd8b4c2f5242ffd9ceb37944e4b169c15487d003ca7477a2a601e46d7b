I"I<h4>Judging Panel</h4>
<p>Submissions will be reviewed by experts in technology, open data, product development community engagement, user centered design, and the policy issues covered in the prize categories, from federal agencies as well as external organizations. </p>
<h4>Judging Criteria</h4>
<p>View the final <a href="{{ site.baseurl }}/assets/document-library/TOP-Prize-Evaluation-Rubric.pdf" target="_blank" rel="noopener">scoring rubric.</a></p>
<p>Each submission will be scored by multiple reviewers on the following five (5) criteria:</p>
<ul> <li><strong>Quality + Technical Evaluation (20%):&nbsp; </strong>This score focuses on the overall user experience and user interface (UX/UI) design of the product, designing and implementation of product functionality, visual design if applicable, and generally how well the product achieves its stated functionality. This includes questions such as:</li> <ul> <li>Does the product have a sufficient number of well-functioning features to serve the end user/use case?</li> <li>Is it user friendly?</li> <li>Does the product employ user interface and code best practices?</li> </ul> <li><strong>Cross-Sector Collaboration and Diversity (15%):&nbsp; </strong>This score focuses on the team’s build process, and the extent to which “user advocates” and diverse end user perspectives were included in developing the product. This includes questions such as:</li> <ul> <li>Was user research conducted to identify specific community or end user needs, and does the product’s functionality reflect those needs?  </li> <li>Has the product been tested and iterated upon based on feedback from end users? </li> <li>Do the partner/collaborating end user organizations represent diverse perspective within the overall user audience? Does the product account for diverse needs across communities and offers a solution that is inclusive of many end users within the target audience? </li> </ul> <li><strong>Use of Federal Open Data (25%):</strong> This score focuses on the extent to which the product uses federal open data creatively and effectively. This includes questions such as:</li> <ul> <li>Does the product meaningfully use federal open data sets from the Census Bureau and other federal agencies to solve a problem or deliver value for the end user?</li> <li>Does it creatively align federal data alongside state, local, or other types of data?</li> <li>Does the product present or analyze the data in a new or creative way? </li> </ul> <li><strong>Implementation + Sustainability (20%):</strong> This score focuses on the team’s stated or demonstrated plans for deploying the tool to end users or an existing user base. This includes questions such as:</li> <ul> <li>Does the product have a thorough and realistic implementation plan that includes deploying the product to end users</li> <li>What is the product’s time to market, if it is not currently live and available to users?</li> <li>How sustainable is this product for the team in terms of maintenance and operation, and other considerations?</li> <li>Has the product team deployed the tool to end users, whether directly or via a partner, or have they described a compelling, specific, and feasible plan to do so? </li> <li>Is this product well designed to scale and grow with increasing users? </li> </ul> <li><strong>Impact (20%):&nbsp; </strong>This score focuses on the team’s documented or planned impact on the target issue and end user community. This includes questions such as:&nbsp; </li> <ul> <li>How compelling and realistic is this product’s ability to achieve important outcomes for end users?</li> <li>Does the product directly address the problem statement and community it was built for?</li> <li>If this product is deployed to end users, has it or will it deliver meaningful improvement on an important problem?</li>   <li>Has the product team described what metrics it will use or is using to measure the product’s tangible social impact</li> </ul> </ul>
<p><strong><em>The Census Bureau reserves the right to choose not to award prizes in one or more categories if a quality threshold is not met.</em></strong></p>
:ET