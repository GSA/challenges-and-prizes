---
layout: front-matter-data
permalink: /challenge/diu-xview2-assessing-building-damage/
challenge-id: 1074
status: open
sidenav: true
card-image: /assets/images/cards/DIU_logo.png
agency-logo: dod_seal.jpg
challenge-title: DIUâ€™s xVIEW2 - Assessing Building Damage
tagline: Computer Vision for Building Damage Assessment - Automate damage assessment to accelerate recovery from natural disasters
agency: Department of Defense
partner-agencies-federal: 
partners-non-federal: 
external-url:
total-prize-offered-cash: $150,000
type-of-challenge: 
submission-start: 2019/09/18 08:00 AM
submission-end: 2019/11/22 07:59 AM
submission-link: 
prizes: true
fiscal-year:
legal-authority:
challenge-manager:
challenge-manager-email:
---



<!-- Description start -->
### Description
{: .text-accent-warm-dark .font-heading-lg .challenge-section}

<p><strong>xVIEW2</strong></p>
<p>When a disaster strikes, quick and accurate situational information is critical to an effective response. Before responders can act in the affected area, they need to know the location, cause and severity of damage. But disasters can strike anywhere, disrupting local communication and transportation infrastructure, making the process of assessing specific local damage difficult, dangerous, and slow.</p>
<p><strong>Raw Imagery is Not Enough</strong></p>
<p>Satellite imagery can provide unbiased overhead views, but raw imagery is not enough to inform recovery efforts. High-resolution imagery is required to see specific damage conditions, but because disasters cover a large ground area, analysts must search through huge swaths of pixel space to localize and score damage in the area of interest. Then annotated imagery must be summarized and communicated to the recovery team. It is a slow and laborious process.</p>
<p><strong>Solving a Common Problem</strong></p>
<p>Recognizing an opportunity to solve a key analytical bottleneck, the Defense Innovation Unit, together with other Humanitarian Assistance and Disaster Recovery (HADR) organizations, is releasing a new labeled, high-resolution satellite dataset and a challenge to the computer vision community.</p>

<!-- Prizes start -->
### Prizes
{: .text-accent-warm-dark .font-heading-lg .challenge-section}

<p><strong>Total Prize Pool</strong></p>
<p>$150,000</p>
<p><strong>Submission Tracks</strong></p>
<p>The pace of innovation in both computer vision and satellite imagery have been increasingly rapidly. Much of that innovation is happening at universities, startups, and the commercial sector. To maximize the community of solvers who are able to participate in the Challenge, we have implemented three separate submission tracks for this Challenge. Solvers may choose to participate in whichever track best suits their needs:</p>
<p><strong>Track 1: Open Source</strong></p>
<p>If you choose to participate in Track 1, you agree to release your code under one of the approved permissive open source licenses: Apache 2.0, BSD, LGPL, or MIT. Participants in this track are eligible for both the main award pool and additional incentives reserved for Open Source submissions only.</p>
<p>Additional award: $25,000</p>
<p><strong>Track 2: Government Purpose Rights</strong></p>
<p>If you choose to participate in Track 2, you agree to grant non-exclusive Government Purpose Rights for your solution, and will be eligible for the main award pool.</p>
<p>1st - $37,950; 2nd - $28,750; 3rd - $23,000; 4th - $17,000; 5th - $8,300</p>
<p><strong>Track 3: Evaluation Only</strong></p>
<p>If you choose to participate in Track 3, you grant us only the minimal rights required to evaluate your submission and display results on the Challenge leaderboard. Track 3 participants are eligible for a special award pool, which is smaller than the main award pool.</p>
<p>1st - $3,000; 2nd - $2,500; 3rd - $2,000; 4th - $1,500; 5th - $1,000</p>
<p>All tracks are eligible for follow-on acquisition opportunities. For more detail on submission tracks and requirements</p>

<!-- Rules start -->
### Rules 
{: .text-accent-warm-dark .font-heading-lg .challenge-section}

<p>View the official <a href="https://xview2.org/rules" target="_blank" rel="noopener">rules</a> for this challenge.</p>
<p>View the <a href="https://xview2.org/terms" target="_blank" rel="noopener">terms</a> for this challenge.</p>

<!-- Judging start -->
### Judging Criteria
{: .text-accent-warm-dark .font-heading-lg .challenge-section}


<!--  How To Enter start -->
### How To Enter
{: .text-accent-warm-dark .font-heading-lg .challenge-section}

<p>View instructions on how to <a href="https://xview2.org/signup" target="_blank" rel="noopener">sign up</a> for this challenge.</p>
