---
ideaSubmitFormInstruction: 'A full description of rules, submissions, and evaluations
  are at: <a href="http://www.ug2challenge.org">http://www.ug2challenge.org</a>.    <strong>SUBMISSIONS</strong>    <span
  style="text-decoration: underline;"><strong>Development Kit</strong></span>    The
  <u>Development Kit</u> consists of a Docker file containing the basic structure
  for the algorithms submission, as well as instructions on how to pull and run a
  supplemental quantitative classification module for the second challenge. The images,
  annotation, and lists specifying the training/validation sets for the challenge
  are provided separately.    Each team must submit one algorithm for each challenge
  they wish to participate in. Participants who have investigated several algorithms
  may submit up to 3 algorithms per challenge. All submissions (per challenge) will
  be held within one single Docker container to be uploaded to <u>Docker Hub</u>.
  The Docker container will container all dependencies and code required to perform
  the model’s operation and will execute the model(s) contained upon run.    The input
  images will be provided to the container at run time through Docker’s mounting option,
  as will the output folders for the model(s) to save their results. Each model must
  be run on all images contained within the input folder and must save the new images
  to their respective output folder locations, without any name changes or missing
  images.    <span style="text-decoration: underline;"><strong>Requirements</strong></span>    <strong>Software</strong>:  <ul>    <li>Docker-CE</li>    <li>NVIDIA
  Docker</li>    <li>CUDA 8.0</li>    <li>cuDNN v5.0</li>  </ul>  <strong>Hardware</strong>:    The
  proposed algorithms should be able to run in systems with:  <ul>    <li>Up to and
  including Titan Xp 12 GB</li>    <li>Up to and including 12 cores</li>    <li>Up
  to and including 32gb memory</li>  </ul>  If you have any questions please feel
  free to email <a href="mailto:ug2challenge@gmail.com">ug2challenge@gmail.com</a>.'
startDate: '2018-11-26T07:14:20'
votingAllowed: false
newCampaign: false
status: closed
commentCount: 0
challenge-id: 941
moderatorAdminOnlyIdeasEnabled: false
funnelId: 4
ideaFromUnauthorizedMemberAllowed: true
tagline: Bridging the Gap Between Computational Photography and Visual Recognition
groupName: Office of Director of National Intelligence - Intelligence Advanced Research
  Project Activity
hideIdeaAuthor: false
template: ideation
campaignAttributes:
attributes:
total-prize-awarded-cash: ''
external-url: http://www.ug2challenge.org
submission-end: 04/15/2018 11:59 PM
why-use-prizes: ''
submission-start: 01/31/2018 12:00 AM
fiscal-year: FY18
public-voting-end-date: ''
budget-and-resources: ''
total-prize-offered-cash: '$75,000'
campaign-owner: Dr. Christopher Boehnen
public-voting-start-date: ''
legal-authority: Other
total-number-of-prizes-awarded: ''
evaluation-of-submissions: ''
agency-id: '4901'
solicitation-of-submissions: ''
total-submission-received: ''
total-number-of-participant: ''
show-winners-instead-of-prizes: 'No'
estimated-value-of-partner-contributions: ''
non-monetary-incentives-awarded: ''
partner-agencies-federal: ''
judging-end-date: ''
solicitation-methods: ''
advancing-the-agency-mission: ''
rules: 'A full description of rules is available at: <a href="http://www.ug2challenge.org">http://www.ug2challenge.org.</a>'
submission-start-date-1: ''
hide-challenge-timeline: 'No'
judging-start-date: ''
winners-announced-date: 06/18/2018 06:00 PM
cash-prizes-and-non-cash-prize-awards: ''
campaign-owner-email: christopher.boehnen@iarpa.gov
solution-type: Software and apps
partner-agencies-non-federal: ''
original-post-id: '172995'
total-number-of-winners-awarded: ''
hosting: Hosted on this platform
hide-challenge-funnel: 'Yes'
type-of-challenge: Software and apps
participation-requirements: ''
number-of-phases: ''
how-to-enter: "A full description of rules, submissions, and evaluations are at:
  <a href=\"http://www.ug2challenge.org\">http://www.ug2challenge.org</a>.\r\n\r\n<strong>SUBMISSIONS</strong>\r\n\r\n<span
  style=\"text-decoration: underline;\"><strong>Development Kit</strong></span>\r\n\r\nThe
  <u>Development Kit</u> consists of a Docker file containing the basic structure
  for the algorithms submission, as well as instructions on how to pull and run
  a supplemental quantitative classification module for the second challenge.
  The images, annotation, and lists specifying the training/validation sets for
  the challenge are provided separately.\r\n\r\nEach team must submit one algorithm
  for each challenge they wish to participate in. Participants who have investigated
  several algorithms may submit up to 3 algorithms per challenge. All submissions
  (per challenge) will be held within one single Docker container to be uploaded
  to <u>Docker Hub</u>. The Docker container will container all dependencies and
  code required to perform the model’s operation and will execute the model(s)
  contained upon run.\r\n\r\nThe input images will be provided to the container
  at run time through Docker’s mounting option, as will the output folders for
  the model(s) to save their results. Each model must be run on all images contained
  within the input folder and must save the new images to their respective output
  folder locations, without any name changes or missing images.\r\n\r\n<span style=\"text-decoration:
  underline;\"><strong>Requirements</strong></span>\r\n\r\n<strong>Software</strong>:\r\n<ul>\r\n
  \t<li>Docker-CE</li>\r\n \t<li>NVIDIA Docker</li>\r\n \t<li>CUDA 8.0</li>\r\n
  \t<li>cuDNN v5.0</li>\r\n</ul>\r\n<strong>Hardware</strong>:\r\n\r\nThe proposed
  algorithms should be able to run in systems with:\r\n<ul>\r\n \t<li>Up to and
  including Titan Xp 12 GB</li>\r\n \t<li>Up to and including 12 cores</li>\r\n
  \t<li>Up to and including 32gb memory</li>\r\n</ul>\r\nIf you have any questions
  please feel free to email <a href=\"mailto:ug2challenge@gmail.com\">ug2challenge@gmail.com</a>."
partnerships: ''
groupAttributes:
judging-criteria-description-0: 'A full description of challenge evaluation is
  available at: http://www.ug2challenge.org/challenges.html.'
judging-criteria-percentage-0: '100'
judging-criteria-0: Image Enhancement to Facilitate Manual Inspection
judging-criteria-description-1: 'A full description of challenge evaluation is
  available at: http://www.ug2challenge.org/challenges.html.'
judging-criteria-percentage-1: ''
judging-criteria-1: Image Enhancement to Improve Automatic Object Recognition
judging-criteria-description-10: ''
judging-criteria-percentage-10: ''
judging-criteria-10: ''
judging-criteria-description-11: ''
judging-criteria-percentage-11: ''
judging-criteria-11: ''
judging-criteria-description-12: ''
judging-criteria-12: ''
judging-criteria-percentage-12: ''
judging-criteria-description-13: ''
judging-criteria-13: ''
judging-criteria-percentage-13: ''
judging-criteria-percentage-14: ''
judging-criteria-14: ''
judging-criteria-description-14: ''
judging-criteria-percentage-15: ''
judging-criteria-15: ''
judging-criteria-description-15: ''
judging-criteria-16: ''
judging-criteria-percentage-16: ''
judging-criteria-description-16: ''
judging-criteria-17: ''
judging-criteria-percentage-17: ''
judging-criteria-description-17: ''
judging-criteria-description-18: ''
judging-criteria-percentage-18: ''
judging-criteria-18: ''
judging-criteria-description-19: ''
judging-criteria-percentage-19: ''
judging-criteria-19: ''
judging-criteria-description-2: ''
judging-criteria-2: ''
judging-criteria-percentage-2: ''
judging-criteria-description-3: ''
judging-criteria-3: ''
judging-criteria-percentage-3: ''
judging-criteria-percentage-4: ''
judging-criteria-4: ''
judging-criteria-description-4: ''
judging-criteria-percentage-5: ''
judging-criteria-5: ''
judging-criteria-description-5: ''
judging-criteria-6: ''
judging-criteria-percentage-6: ''
judging-criteria-description-6: ''
judging-criteria-7: ''
judging-criteria-percentage-7: ''
judging-criteria-description-7: ''
judging-criteria-description-8: ''
judging-criteria-percentage-8: ''
judging-criteria-8: ''
judging-criteria-description-9: ''
judging-criteria-percentage-9: ''
judging-criteria-9: ''
prize-description-0: An evaluation of the qualitative enhancement of images
prize-cash-amount-0: '25000'
prize-name-0: Image Enhancement to Facilitate Manual Inspection - 1st Place
prize-description-1: An evaluation of the qualitative enhancement of images
prize-cash-amount-1: '12500'
prize-name-1: Image Enhancement to Facilitate Manual Inspection - 2nd Place
prize-cash-amount-10: ''
prize-name-10: ''
prize-description-10: ''
prize-cash-amount-11: ''
prize-name-11: ''
prize-description-11: ''
prize-name-12: ''
prize-cash-amount-12: ''
prize-description-12: ''
prize-name-13: ''
prize-cash-amount-13: ''
prize-description-13: ''
prize-description-14: ''
prize-cash-amount-14: ''
prize-name-14: ''
prize-description-15: ''
prize-cash-amount-15: ''
prize-name-15: ''
prize-description-16: ''
prize-name-16: ''
prize-cash-amount-16: ''
prize-description-17: ''
prize-name-17: ''
prize-cash-amount-17: ''
prize-cash-amount-18: ''
prize-name-18: ''
prize-description-18: ''
prize-description-2: An evaluation of classification improvement
prize-name-2: Image Enhancement to Improve Automatic Object Recognition - 1st
  Place
prize-cash-amount-2: '25000'
prize-description-3: An evaluation of classification improvement
prize-name-3: Image Enhancement to Improve Automatic Object Recognition - 2nd
  Place
prize-cash-amount-3: '12500'
prize-cash-amount-4: ''
prize-name-4: ''
prize-description-4: ''
prize-cash-amount-5: ''
prize-name-5: ''
prize-description-5: ''
prize-name-6: ''
prize-cash-amount-6: ''
prize-description-6: ''
prize-name-7: ''
prize-cash-amount-7: ''
prize-description-7: ''
prize-description-8: ''
prize-cash-amount-8: ''
prize-name-8: ''
prize-description-9: ''
prize-cash-amount-9: ''
prize-name-9: ''
winner-solution-description-0: ''
winner-solution-link-0: ''
winner-name-0: Honeywell - ACST
winner-solution-title-0: ''
winner-solution-link-1: ''
winner-solution-description-1: ''
winner-name-1: Northwestern University
winner-solution-title-1: ''
winner-solution-description-2: ''
winner-solution-link-2: ''
winner-solution-title-2: ''
winner-name-2: Honeywell - ACST
winner-solution-link-3: ''
winner-solution-description-3: ''
winner-solution-title-3: ''
winner-name-3: Texas A&M University, Peking University
winner-name-4: ''
winner-solution-title-4: ''
winner-solution-description-4: ''
winner-solution-link-4: ''
winner-name-5: ''
winner-solution-title-5: ''
winner-solution-link-5: ''
winner-solution-description-5: ''
winner-solution-title-6: ''
winner-name-6: ''
winner-solution-description-6: ''
winner-solution-link-6: ''
winner-solution-title-7: ''
winner-name-7: ''
winner-solution-link-7: ''
winner-solution-description-7: ''
winner-solution-description-8: ''
winner-solution-link-8: ''
winner-name-8: ''
winner-solution-title-8: ''
winner-solution-link-9: ''
winner-solution-description-9: ''
winner-name-9: ''
winner-solution-title-9: ''
memberIdeaSubmissionAllowed: false
showTitle: true
description: 'What is the current state-of-the art for image restoration and enhancement
  applied to images acquired under less than ideal circumstances?  Can the application
  of enhancement algorithms as a pre-processing step improve image interpretability
  for manual analysis or automatic visual recognition to classify scene content? 
  The Intelligence Advanced Research Projects Activity (IARPA), within the Office
  of the Director of National Intelligence (ODNI), is sponsoring the UG<sup>2</sup>
  Prize Challenge.  This challenge seeks to answer these important questions for general
  applications related to computational photography and scene understanding. As a
  well-defined case study, the challenge aims to advance the analysis of images collected
  by small unmanned aerial vehicles (UAVs) by improving image restoration and enhancement
  algorithm performance using the UG<sup>2</sup> Dataset    <strong>Who We Are:  </strong>IARPA
  focuses on high-risk, high-payoff research.  The UG<sup>2</sup> Prize Challenge
  will engage the wider research community to advance image restoration and enhancement
  of low quality unconstrained imagery for computer vision applications, such as imagery
  captured from UAV-mounted sensors.    <strong>What We’re Doing:  </strong>The challenge
  consists of two parts: (1) image restoration and enhancement to improve image quality
  for manual inspection; and (2) image restoration and enhancement to improve the
  automatic classification of objects found within individual images.  The winners
  of each category will be invited to present at a workshop to be held at the 2018
  IEEE Computer Vision and Pattern Recognition (CVPR) Conference (<a href="http://cvpr2018.thecvf.com/">http://cvpr2018.thecvf.com/</a>).    <strong>Why
  We’re Doing This:  </strong>The advantages of conducting visual surveillance from
  a platform like a small UAV are clear. Man-portable systems can be launched from
  safe positions to penetrate difficult or dangerous terrain, acquiring hours of video
  without putting human lives at risk. What is unclear is how to automate the interpretation
  of these images — a necessary measure in the face of millions of frames from individual
  flights. Human analysts cannot manually sift through data of this scale for actionable
  intelligence information. Ideally, a computer vision system would be able to identify
  objects, events, and human identities of interest to analysts, surfacing valuable
  data out of a massive pool of largely uninteresting or irrelevant images. To build
  such a system, one could turn to recent machine learning breakthroughs in visual
  recognition, which have been enabled by access to millions of training images from
  the Internet. However, such approaches cannot be used as off-the-shelf components
  to assemble the system we desire, because they do not take into account artifacts
  unique to the operation of the sensor and optics platform on a small UAV.    <strong>Where
  and When We’re Doing This:</strong>  Registration to join the challenge will take
  place through this Challenge.gov site.  From Challenge.gov, participants will be
  directed to register with the University of Notre Dame, the organizer and evaluator
  of the challenge.  Registration closes on <strong><u>April 1, 2018</u></strong>
  with algorithm submission closing on <strong><u>April 15, 2018</u></strong>.  <ul>    <li><strong>When
  does UG<sup>2</sup> registration begin?</strong>  January 31, 2018</li>    <li><strong>Where
  to learn more about the challenge, including rules, criteria and eligibility requirements?</strong> 
  <a href="http://www.ug2challenge.org/">http://www.ug2challenge.org/</a></li>    <li><strong>Where
  do participants register?</strong>  <a href="http://www.ug2challenge.org/">http://www.ug2challenge.org/</a></li>    <li><strong>When
  is the registration deadline?</strong>  April 1, 2018</li>    <li><strong>When is
  the algorithm submission deadline? </strong> April 15, 2018</li>    <li><strong>When
  will winners be announced?</strong>  May 15, 2018</li>    <li><strong>When and where
  is the CVPR workshop?</strong>  June 18, 2018 in Salt Lake City, UT</li>  </ul>  <strong>Who
  Should Participate?</strong> The UG2 Prize Challenge is intended for prize participants
  who are eligible to compete for the challenge prizes.  We encourage developers of
  computational photography and image processing algorithms to participate, both domestic
  and international, from academia and industry. Other U. S. Government Agencies,
  Federally Funded Research and Development Centers (FFRDCs), University Affiliated
  Research Centers (UARCs), or any other similar organizations that have a special
  relationship with the Government that gives them access to privileged or proprietary
  information, or access to Government equipment or real property, will not be eligible
  to participate in the prize challenge. Read the full rules and challenge eligibility
  details by going here: <a href="http://www.ug2challenge.org/">http://www.ug2challenge.org/</a>.    <strong>Why
  Participate?</strong>  The most successful and innovative teams will be invited
  to present at the CVPR 2018 workshop. Within each challenge category, the first
  and second place scoring algorithms will be awarded prize monies.  A total of $75,000
  in prizes will be awarded.'
campaignStatusName: Launched
templateId: 0
stageStatistics: []
summaryEnabled: false
voteCount: 0
ideaTabEnabledForChallenge: true
moderatorAdminOnlyIdeasNotificationEnabled: false
hideCommentAuthor: false
authorizedGroupIds: []
userSubscriptionAllowed: false
bannerImage: ''
groupId: 269
showTagline: true
challenge-title: UG2 Prize Challenge
privateCampaign: true
ideaCount: 0
memberIdeaAttachmentAllowed: false
authorEdit: false
permalink: "/challenge/ug2-prize-challenge/"
layout: json-page
---