---
ideaSubmitFormInstruction: All submissions must be entered through Innocentive, at
  (link) . Eligibility requirements and official entries are through Innocentive.
startDate: '2014-11-17T00:00:00'
votingAllowed: false
newCampaign: false
status: closed
commentCount: 0
challenge-id: 787
moderatorAdminOnlyIdeasEnabled: false
funnelId: 4
ideaFromUnauthorizedMemberAllowed: true
tagline: Build automatic speech recognition systems able to perform well across a
  variety of acoustic environments without matched training data
groupName: Office of Director of National Intelligence - Intelligence Advanced Research
  Project Activity
hideIdeaAuthor: false
template: ideation
campaignAttributes:
attributes:
total-prize-awarded-cash: ''
external-url: 'https://www.innocentive.com/ar/challenge/9933624  '
submission-end: 02/26/2015 12:00 AM
why-use-prizes: ''
submission-start: 02/11/2015 12:00 AM
fiscal-year: FY15
public-voting-end-date: ''
budget-and-resources: ''
total-prize-offered-cash: '$110,000'
campaign-owner: Mary Harper
public-voting-start-date: ''
legal-authority: Procurement Authority
total-number-of-prizes-awarded: ''
evaluation-of-submissions: ''
agency-id: '1552'
solicitation-of-submissions: ''
total-submission-received: ''
total-number-of-participant: ''
show-winners-instead-of-prizes: 'No'
estimated-value-of-partner-contributions: ''
non-monetary-incentives-awarded: "$30,000 for each of 3 winners in the single
  microphone condition and $20,000 for the winner in the multiple microphone condition."
partner-agencies-federal: ''
judging-end-date: ''
solicitation-methods: ''
advancing-the-agency-mission: ''
rules: <a href="https://s3.amazonaws.com/challenge-gov/wp-content/uploads/2015/12/ASpIRE-Evaluation-Plan-11-21-14.pdf">ASpIRE
  Evaluation Plan 11-21-14</a>
submission-start-date-1: ''
hide-challenge-timeline: 'No'
judging-start-date: ''
winners-announced-date: '09/10/2015 12:00 AM'
cash-prizes-and-non-cash-prize-awards: ''
campaign-owner-email: mary.harper@iarpa.gov
solution-type: Software and apps
partner-agencies-non-federal: ''
original-post-id: '90831'
total-number-of-winners-awarded: ''
hosting: Externally (Challenge details will redirect to external url)
hide-challenge-funnel: 'Yes'
type-of-challenge: Scientific
participation-requirements: ''
number-of-phases: ''
how-to-enter: "All submissions must be entered through Innocentive, at (link)
  .\r\n\r\nEligibility requirements and official entries are through Innocentive."
partnerships: ''
groupAttributes:
judging-criteria-description-0: Systems were evaluated for Word Error Rate on
  the evaluation data set.
judging-criteria-percentage-0: ''
judging-criteria-0: Objective criteria
judging-criteria-description-1: ''
judging-criteria-percentage-1: ''
judging-criteria-1: ''
judging-criteria-description-10: ''
judging-criteria-percentage-10: ''
judging-criteria-10: ''
judging-criteria-description-11: ''
judging-criteria-percentage-11: ''
judging-criteria-11: ''
judging-criteria-description-12: ''
judging-criteria-12: ''
judging-criteria-percentage-12: ''
judging-criteria-description-13: ''
judging-criteria-13: ''
judging-criteria-percentage-13: ''
judging-criteria-percentage-14: ''
judging-criteria-14: ''
judging-criteria-description-14: ''
judging-criteria-percentage-15: ''
judging-criteria-15: ''
judging-criteria-description-15: ''
judging-criteria-16: ''
judging-criteria-percentage-16: ''
judging-criteria-description-16: ''
judging-criteria-17: ''
judging-criteria-percentage-17: ''
judging-criteria-description-17: ''
judging-criteria-description-18: ''
judging-criteria-percentage-18: ''
judging-criteria-18: ''
judging-criteria-description-19: ''
judging-criteria-percentage-19: ''
judging-criteria-19: ''
judging-criteria-description-2: ''
judging-criteria-2: ''
judging-criteria-percentage-2: ''
judging-criteria-description-3: ''
judging-criteria-3: ''
judging-criteria-percentage-3: ''
judging-criteria-percentage-4: ''
judging-criteria-4: ''
judging-criteria-description-4: ''
judging-criteria-percentage-5: ''
judging-criteria-5: ''
judging-criteria-description-5: ''
judging-criteria-6: ''
judging-criteria-percentage-6: ''
judging-criteria-description-6: ''
judging-criteria-7: ''
judging-criteria-percentage-7: ''
judging-criteria-description-7: ''
judging-criteria-description-8: ''
judging-criteria-percentage-8: ''
judging-criteria-8: ''
judging-criteria-description-9: ''
judging-criteria-percentage-9: ''
judging-criteria-9: ''
prize-description-0: ''
prize-cash-amount-0: '30,000'
prize-name-0: First Prize - Single Microphone Condition
prize-description-1: ''
prize-cash-amount-1: '30,000'
prize-name-1: First Prize - Single Microphone
prize-cash-amount-10: ''
prize-name-10: ''
prize-description-10: ''
prize-cash-amount-11: ''
prize-name-11: ''
prize-description-11: ''
prize-name-12: ''
prize-cash-amount-12: ''
prize-description-12: ''
prize-name-13: ''
prize-cash-amount-13: ''
prize-description-13: ''
prize-description-14: ''
prize-cash-amount-14: ''
prize-name-14: ''
prize-description-15: ''
prize-cash-amount-15: ''
prize-name-15: ''
prize-description-16: ''
prize-name-16: ''
prize-cash-amount-16: ''
prize-description-17: ''
prize-name-17: ''
prize-cash-amount-17: ''
prize-cash-amount-18: ''
prize-name-18: ''
prize-description-18: ''
prize-description-2: ''
prize-name-2: First Prize - Single Microphone
prize-cash-amount-2: '30,000'
prize-description-3: ''
prize-name-3: First Prize - Multiple Microphone Microphone
prize-cash-amount-3: '20,000'
prize-cash-amount-4: ''
prize-name-4: ''
prize-description-4: ''
prize-cash-amount-5: ''
prize-name-5: ''
prize-description-5: ''
prize-name-6: ''
prize-cash-amount-6: ''
prize-description-6: ''
prize-name-7: ''
prize-cash-amount-7: ''
prize-description-7: ''
prize-description-8: ''
prize-cash-amount-8: ''
prize-name-8: ''
prize-description-9: ''
prize-cash-amount-9: ''
prize-name-9: ''
winner-solution-description-0: ''
winner-solution-link-0: ''
winner-name-0: The team from the Center for Language and Speech Processing, Johns
  Hopkins University (Vijayaditya Peddinti, Guoguo Chen, Dr. Daniel Povey, Dr.
  Sanjeev Khudanpur);
winner-solution-title-0: ''
winner-solution-link-1: ''
winner-solution-description-1: ''
winner-name-1: The multi-institutional team from Raytheon BBN Technologies (Jeff
  Ma, Roger Hsiao, William Hartmann, Rich Schwartz, Stavros Tsakalidis), Brno
  University of Technology (Martin Karafiat, Lukas Burget, Igor Szoke, Frantisek
  Grezl), and Johns Hopkins University (Sri Harish Mallidi, Hynek Hermansky)
winner-solution-title-1: ''
winner-solution-description-2: ''
winner-solution-link-2: ''
winner-solution-title-2: ''
winner-name-2: The team from the Institute for Infocomm Research, A*STAR, Singapore
  (Dr. Jonathan William Dennis and Dr. Tran Huy Dat)
winner-solution-link-3: ''
winner-solution-description-3: ''
winner-solution-title-3: ''
winner-name-3: The team from the Institute for Infocomm Research, A*STAR, Singapore
  (Dr. Jonathan William Dennis and Dr. Tran Huy Dat)
winner-name-4: ''
winner-solution-title-4: ''
winner-solution-description-4: ''
winner-solution-link-4: ''
winner-name-5: ''
winner-solution-title-5: ''
winner-solution-link-5: ''
winner-solution-description-5: ''
winner-solution-title-6: ''
winner-name-6: ''
winner-solution-description-6: ''
winner-solution-link-6: ''
winner-solution-title-7: ''
winner-name-7: ''
winner-solution-link-7: ''
winner-solution-description-7: ''
winner-solution-description-8: ''
winner-solution-link-8: ''
winner-name-8: ''
winner-solution-title-8: ''
winner-solution-link-9: ''
winner-solution-description-9: ''
winner-name-9: ''
winner-solution-title-9: ''
memberIdeaSubmissionAllowed: false
showTitle: true
description: '<p>Automatic speech recognition software that works in a variety of acoustic
  environments and recording scenarios is a holy grail of the speech research community.    IARPA’s
  Automatic Speech recognition In Reverberant Environments (ASpIRE) Challenge is seeking
  that grail.<p></p><strong>Who We Are: </strong> The Intelligence Advanced Research
  Projects Activity (IARPA) focuses on high-risk, high-payoff research. The ASpIRE
  challenge is a spin-off of our <a href="http://www.iarpa.gov/index.php/research-programs/babel">Babel
  program</a>, which works to develop agile and robust technology that can be rapidly
  applied to any human language. <p></p>   <strong>What We’re Doing: </strong>Previous work
  has shown that automatic speech recognition (ASR) performance degrades in room microphone
  conditions, especially when data used for training is mismatched with data used
  in testing. The ASpIRE challenge asks the public to develop approaches to mitigate
  the effects of these conditions and create software that can function in many acoustic
  environments and recording scenarios. Participants can address either a single microphone
  or multimicrophone scenario. <p></p>   <strong>Where We’re Doing This: </strong>Around
  the world—anyone over age 18 is welcome to participate. We’re looking for solutions
  from anyone who thinks they might have a way of addressing this problem, including
  analysts, natural language processing (NLP) specialists, machine learning programmers,
  and even experts in disciplines we haven’t yet considered.  <p></p>  <strong>When We’re
  Doing This: </strong>Fifteen hours of data (divided into a development set and development-test
  set) have been posted on the <a href="https://www.innocentive.com/ar/challenge/9933624?cc=IARPALP3624&amp;utm_source=IARPA&amp;utm_campaign=9933624&amp;utm_medium=landing+page"
  target="_blank">challenge website.</a> These data, which consist of multimicrophone
  recordings of conversational speech with transcriptions, are meant to be used for
  optimization, training selection, and tuning. At any time during this period, solvers
  may run their software against the data and revise their solutions.  <p></p>  During the
  evaluation period, participants will be given approximately 10 hours of new transcribed
  far-field microphone data from noisy, reverberant rooms. These data will be divided
  into the single-microphone or multimicrophone conditions, and word error rate will
  be the objective measure of performance. To be eligible for award, the single-microphone
  submissions must be received before February 19, 2014 and multimicrophone submissions
  before February 27, 2014.  <p></p>  <strong>Why We’re Doing This: </strong>Challenges are
  widely recognized as a cost-efficient way to gather cross-disciplinary solutions
  to difficult problems. Challenges to stimulate breakthroughs in science and technology
  also support the <a href="http://www.whitehouse.gov/innovation/strategy" target="_blank">White
  House’s Strategy for American Innovation,</a> as well as government transparency
  and efficiency. By sponsoring full and open competition via challenges, IARPA is
  tackling the most challenging research questions of today—and changing the future
  of technology.  <p></p>  <strong>Why Participate? </strong>The ASpIRE Challenge gives experts
  the opportunity to contribute to technological breakthroughs that can make what
  has been impossible in the ASR community—software that works in a variety of acoustic
  environments and recording scenarios—a reality.  <p></p>  We offered 2 prizes: $30,000
  for software that addresses the single-microphone condition and $20,000 for software
  that addresses the multi-microphone condition.'
campaignStatusName: Launched
templateId: 0
stageStatistics: []
summaryEnabled: false
voteCount: 0
ideaTabEnabledForChallenge: true
moderatorAdminOnlyIdeasNotificationEnabled: false
hideCommentAuthor: false
authorizedGroupIds: []
userSubscriptionAllowed: false
bannerImage: ''
groupId: 269
showTagline: true
challenge-title: Automatic Speech Recognition in Reverberant Environments (ASpIRE)
privateCampaign: true
ideaCount: 0
memberIdeaAttachmentAllowed: false
authorEdit: false
permalink: "/challenge/automatic-speech-recognition-in-reverberant-environments-aspire/"
layout: json-page
---